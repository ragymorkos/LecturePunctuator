welcome .PERIOD i'm bob sedgewick ,COMMA professor of computer science at princeton .PERIOD this is our online course algorithms developed by myself and kevin wayne here at princeton .PERIOD we're gonna start with an overview discussion of why you might want to study algorithms and a little bit of discussion about the resources that you need to take this course .PERIOD so ,COMMA what is this course ?QUESTIONMARK it's an intermediate level survey course on algorithms .PERIOD we're going to concentrate on programming and problem solving in the context of real applications ,COMMA and our focus is going to be on two things ,COMMA algorithms which are methods for solving problems and data structures which store the information associated in problem ,COMMA with a problem and go hand in hand with algorithms .PERIOD these are the basic topics that we'll cover in part one and part two of the course .PERIOD the first part is data type sorting and searching .PERIOD we'll consider a number of data structures and algorithms that are basic to all the methods we consider including stacks ,COMMA queues ,COMMA bags and priority queues .PERIOD then we'll consider classic algorithms for sorting ,COMMA putting things in order .PERIOD that's quicksort ,COMMA mergesort ,COMMA heapsort and radix sorts .PERIOD and we'll consider classic methods for searching .PERIOD including binary search trees ,COMMA red -DASH black binary search trees and hash tables .PERIOD the second part of the course is for more advanced algorithms including graph algorithms ,COMMA classic graph searching algorithms ,COMMA minimum spanning tree and shortest path algorithms ,COMMA algorithms for processing strings including regular expressions and data compression .PERIOD and then some advanced algorithms that make use of the basic algorithms that we developed earlier in the course .PERIOD so ,COMMA why should one study algorithms ?QUESTIONMARK well ,COMMA their input ,COMMA impact is very broad and far -DASH reaching .PERIOD from the internet to biology to ,COMMA commercial computing ,COMMA computer graphics ,COMMA security ,COMMA multimedia ,COMMA social networks ,COMMA and scientific applications ,COMMA algorithms are all around us .PERIOD they're used for movies and video games ,COMMA for particle collision simulation ,COMMA they're used to study the genome ,COMMA and all manner of other applications .PERIOD so ,COMMA that's one important reason to study algorithms ,COMMA their impact is broad and far -DASH reaching .PERIOD algorithms are also interesting to study ,COMMA because they ,COMMA they have ancient roots .PERIOD now the first algorithm we studied goes back to 300 b .PERIODc .PERIOD ,COMMA dating at least to euclid .PERIOD the concept of an algorithm was formalized actually here at princeton ,COMMA by church and turing ,COMMA in the 1930s .PERIOD but most algorithms that we consider ,COMMA were discovered in recent decades .PERIOD in fact ,COMMA some were discovered by undergraduates in a course ,COMMA course like this .PERIOD and there's plenty of other algorithms waiting to be discovered by students like you .PERIOD the main reason that people study algorithms ,COMMA is to be able to solve problems that it could not otherwise be addressed .PERIOD for example ,COMMA in the first lecture ,COMMA we're going to talk about the network connectivity problem ,COMMA where the problem is ,COMMA given a large set of items that are connected together pairwise is there a way to get from one to another with a path through the connections .PERIOD as you can see from this example ,COMMA it's not clear whether or not there's such a path ,COMMA we need a computer program to do it ,COMMA in fact ,COMMA we need an efficient algorithm to do it .PERIOD in this case the answer is that there is such a path .PERIOD another reason to study algorithms is for intellectual stimulation .PERIOD algorithms are very interesting objects to study .PERIOD don knuth who wrote several books on ,COMMA on algorithms and was a pioneer in the field said that ,COMMA "an algorithm must be seen to be believed .PERIOD" you can't just think about an algorithm you have to work with it .PERIOD another quote from francis sullivan ,COMMA says ,COMMA "the great algorithms are the poetry of computation .PERIOD" just like verse ,COMMA they can be terse ,COMMA elusive ,COMMA dense ,COMMA and even mysterious .PERIOD but once unlocked ,COMMA they cast a brilliant new light on some aspect of computing .PERIOD algorithms are interesting for intellectual stimulation .PERIOD another reason many people study algorithms and i suspect many of you ,COMMA is it's necessary to understand good algorithms ,COMMA efficient algorithms ,COMMA a good data structures in order to be a proficient programmer .PERIOD linus torvalds ,COMMA who created lin ,COMMA linux ,COMMA says that the difference between a bad programmer and a good one is whether he considers his code or his data structures more important .PERIOD bad programmers worry about the code ,COMMA good programmers worry about data structures ,COMMA and their relationships .PERIOD and ,COMMA i might add ,COMMA the algorithms that process them .PERIOD niklaus wirth ,COMMA another pioneer in computer science ,COMMA wrote a famous book called algorithms + data structures = programs .PERIOD [cough] .PERIOD another reason nowadays to study algorithms is that ,COMMA they have become a common language for understanding ,COMMA nature .PERIOD algorithms are computational models ,COMMA and algorithmic models are replacing mathematical models in scientific inquiry .PERIOD in the twentieth century ,COMMA math ,COMMA scientists developed mathematical models to try to understand natural phenomenon .PERIOD it soon became clear that those mathematical models were difficult to solve .PERIOD it was difficult to create solutions ,COMMA to be able to test hypotheses against natural phenomenon .PERIOD so ,COMMA more and more and more now a days people are developing computational models ,COMMA where they attempt to simulate what might be happening in nature in order to try to better understand it .PERIOD algorithms play an extremely important role in this process .PERIOD and we'll see some examples of this in this course .PERIOD another important reason is that if you know effect ,COMMA how to effectively use algorithms and data structures you're going to have a much better chance at interviewing for a job in the technology industry then if you don't .PERIOD so ,COMMA here's a bunch of reasons that i just went through for studying algorithms .PERIOD their impact's broad and far -DASH reaching ,COMMA they have old roots and present new opportunities ,COMMA they allow us to solve problems that could not otherwise be addressed ,COMMA you can use them for intellectual stimulation to become a proficient programmer .PERIOD they might unlock the secrets of life in the universe ,COMMA and they're good for fun and profit .PERIOD in fact ,COMMA a pr ogrammer might ask ,COMMA why study anything else ?QUESTIONMARK well ,COMMA there's plenty of good reasons to study other things ,COMMA but i'll submit there's no good reason not to study algorithims .PERIOD [cough] so ,COMMA for this course we have two resources that i want to talk about and make sure that people are familiar with before entering into the content .PERIOD this is a publishing model that kevin wayne and i developed and have been using for many years ,COMMA and we think it's a very effective way to support the ,COMMA kinds of lectures that we're going to be giving in this course .PERIOD down at the bottom ,COMMA and it's optional for this course ,COMMA we have a text book .PERIOD it's a traditional ,COMMA text book that extensively covers the topics in the course ,COMMA in fact many more topics than we can present in lecture .PERIOD and then supporting that textbook ,COMMA is free online material that we call the book site .PERIOD you can go to books ,COMMA the book site to see the lecture slides .PERIOD but more important ,COMMA there's code ,COMMA there's exercises ,COMMA tere's a great deal of information there .PERIOD in fact ,COMMA maybe ten times what's in the book ,COMMA including a summary of the content .PERIOD so ,COMMA during this course you'll be referring to the book site frequently while working online .PERIOD people often ask about prerequisites .PERIOD we're assuming that people who take this course know how to program ,COMMA and know the basics of loops ,COMMA arrays ,COMMA functions .PERIOD they have some exposure to object oriented programming and recursion .PERIOD we use the java language ,COMMA but we don't dwell on details of java ,COMMA we mostly use it as an expository language .PERIOD we do some math ,COMMA but not advanced math .PERIOD if you want to review the material that we think is prerequisite for the material in this course ,COMMA you can do a quick review by looking at sections 1 .PERIOD1 and 1 .PERIOD2 of the book .PERIOD either at the book site or in the text book .PERIOD if you want an in depth review ,COMMA we have a full text book called ,COMMA an introduction to programming in java :COLON an interdisciplinary approach .PERIOD there is a book site and text book as well .PERIOD but ,COMMA the bottom line is ,COMMA you should be able t o program ,COMMA and the quick exercise to get ready is ,COMMA to write a java program on your computer perhaps using a programming model ,COMMA as described on the book site .PERIOD we will provide much more detail information on that as we get into the assignments .PERIOD you can use your own programming environment if your comfortable with one or you download ours .PERIOD we have instructions on the web on how to do that .PERIOD 
welcome back ,COMMA today we're going to talk about balance search trees ,COMMA which will lead us to an ultimate symbol table implementation that can provide fast performance for all the simulative options we've looked at ,COMMA guaranteed .PERIOD so here's the review of where we were with single tables .PERIOD we took a look at the last time at the binary search tree ,COMMA which if things are well modeled by random exertions ,COMMA have a great performance .PERIOD they get search and insert on in time proportion for log base two of n and they support ordered operations .PERIOD but really our goal is to have these operations be guaranteed to take time proportional to log n ,COMMA because we don't have control over the order of operations and they may not be random at all .PERIOD and in fact ,COMMA in many real applications ,COMMA they're not very random .PERIOD so that's what were going to look at now is try to find an implementation that can guarantee to be fast for all the symbol table operations .PERIOD  .PERIOD that's our challenge .PERIOD so what we're going to talk about to do it ,COMMA is an algorithm ,COMMA that actually pretty old algorithm called 2 -DASH 3 trees ,COMMA and a particular implementation that requires very little code ,COMMA called left leaning red black bsts and then we'll talk about a generalization called b -DASH trees .PERIOD and these methods are all widely used throughout our computational infrastructure .PERIOD to start ,COMMA we'll talk about 2 -DASH 3 search trees ,COMMA which is a model that underlies the concise and efficient implementation that we're going to look at .PERIOD so ,COMMA the 2 -DASH 3 tree is a way to generalize bsts to provide the flexibility that we need to guarantee fast performance .PERIOD and the idea is very simple ,COMMA we allow one or two keys per node .PERIOD that is ,COMMA we allow for the possibility of something called a 3 -DASH node that can hold two keys ,COMMA but then it has to have three children .PERIOD in a regular bst node ,COMMA the 2 -DASH node ,COMMA we have one link for the keys that are less than the key in the node ,COMMA and one link for the keys that are greater .PERIOD in a 3 -DASH node ,COMMA we need three links ,COMMA one for less ,COMMA one for between and one for greater .PERIOD another property of these 2 -DASH 3 trees is that we are going to have perfect balance ,COMMA that is every path from the route to a null link is going to have the same link in the 2 -DASH 3 tree .PERIOD so ,COMMA as i mentioned ,COMMA the symmetric order is part of the definition of a 2 -DASH 3 tree .PERIOD every 3 -DASH node has three links and two keys .PERIOD the left link is for the keys that are ,COMMA points to a 2 -DASH 3 tree with the keys that are smaller than the smaller of the two keys in the 3 -DASH node .PERIOD the middle link points to a 2 -DASH 3 tree that contains all the keys that are between the two keys .PERIOD and the right link points to all ,COMMA 2 -DASH 3 tree containing all the keys that are larger than the larger of the two keys in the 3 -DASH node .PERIOD okay ,COMMA let's take a look at a demo of searching in a 2 -DASH 3 tree .PERIOD so say we have this 2 -DASH 3 tree here and we want to search for whether or not h is one of the keys in the tree .PERIOD so we start at the root ,COMMA compare the search key against the key or keys in the node .PERIOD and follow the link corresponding to the interval that we know must contain the search key by definition of the tree and then we recursively continue the search .PERIOD so ,COMMA if we're looking for h ,COMMA it's less than m ,COMMA so the only place it could be in this 2 -DASH 3 tree is in the 2 -DASH 3 tree on the left link ,COMMA so we follow the left link .PERIOD now ,COMMA we compare h with e and j ,COMMA and in this case it's between ,COMMA so now we are going to take the middle link ,COMMA that's the only place that h possibly could be .PERIOD in this case ,COMMA that node ,COMMA one node 2 -DASH 3 tree contains h ,COMMA so that's a search hit .PERIOD let's take another example for unsuccessful search ,COMMA a key that's not in the tree .PERIOD as usual ,COMMA we start at the root .PERIOD it's less ,COMMA so we go left .PERIOD and it's less than both keys ,COMMA so ,COMMA if it's in the tree ,COMMA it would have to be in the left link and it's between those two keys .PERIOD so if it's in the tree ,COMMA it would have to be on the middle link .PERIOD and that link is null ,COMMA so that's a search miss .PERIOD so the search is a natural generalization of the search in ,COMMA binary search trees .PERIOD now what about inserting ?QUESTIONMARK well ,COMMA it's a similar type of strategy as with regular binary search trees ,COMMA except that we manipulate the two and 3 -DASH node to keep perfect balance in the tree .PERIOD so the easy case is if the key winds up in a 2 -DASH node at the bottom ,COMMA like this one .PERIOD suppose we're inserting k .PERIOD k is less than m so we go left .PERIOD k is greater than both the keys ,COMMA so we go right .PERIOD k is less than l ,COMMA so the search ends at the left link of l .PERIOD and to perform an insertion all we need to do is replace that 2 -DASH node with a 3 -DASH node containing k .PERIOD now ,COMMA k is inserted into the 2 -DASH 3 tree and it satisfies all the rules .PERIOD now if we're inserting into a 3 -DASH node at the bottom ,COMMA we have to do more work .PERIOD and specifically ,COMMA the work we do is ,COMMA we add the key to a 3 -DASH node to create a temporary 4 -DASH node and then split up that four node and move it's middle key into the parent .PERIOD so ,COMMA let's see an example .PERIOD if we are going to insert z into this tree ,COMMA it's greater than n ,COMMA so we go to the right .PERIOD it's greater than r ,COMMA so we go to the right .PERIOD and now it's greater than x ,COMMA and that's a null link to the right of x ,COMMA so the search ends there and are ,COMMA what we want to do is insert z into that 3 -DASH node .PERIOD and the way we do it is ,COMMA first make a temporary 4 -DASH node that replaces that 3 -DASH node .PERIOD and then that's not a 2 -DASH 3 tree cuz it's got that one 4 -DASH node with three keys and four links .PERIOD but what we can do is split that 4 -DASH node and pass the middle key up to its parent .PERIOD so split into two 2 -DASH node and pass the middle key to the parent .PERIOD that's kind of a magical operation and believe me ,COMMA it's easier to get done in the implementation than the graphics .PERIOD but now you can see that ,COMMA that local transformation on the 2 -DASH 3 tree completes the insertion .PERIOD now ,COMMA if that parent were a 3 -DASH node ,COMMA it would become a temporary 4 -DASH node and would continue the process moving up the tree .PERIOD that's a demo of search and insertion in a 2 -DASH 3 tree .PERIOD so ,COMMA let's look at a double split like that .PERIOD so ,COMMA say we're inserting l in ,COMMA into this tree .PERIOD so ,COMMA it goes down to the middle ,COMMA and winds up needing to be inserted in the ,COMMA 3 -DASH node in the middle .PERIOD so we're going to convert that into a 4 -DASH node .PERIOD now ,COMMA l is the middle key of that one ,COMMA so we're going to split that 4 -DASH node into ,COMMA two 2 -DASH nodes and move l to the parent .PERIOD the 4 -DASH node had four links ,COMMA and the two 2 -DASH nodes have four lengths ,COMMA so nothing has to be changed below .PERIOD and then this insertion into the parent changed it from a two ,COMMA a 3 -DASH node into a 4 -DASH node essentially adding a length cuz of the split with the two 2 -DASH nodes where there was only one 3 -DASH node before .PERIOD but now ,COMMA that's not a 2 -DASH 3 tree ,COMMA so we have to split again .PERIOD and in this case there is no paren ,COMMA so we create a new one and the height of the tree increases by one .PERIOD that's the only time the height of a 2 -DASH 3 tree changes ,COMMA when the roots splits the height introduces increases by one .PERIOD so ,COMMA that's a demo of insertion into a 3 -DASH node at the bottom ,COMMA in a 2 -DASH 3 tree that percolates all the way to the top .PERIOD now let's look at constructing a 2 -DASH 3 tree from an initially empty tree .PERIOD so if we start by just inserting a key ,COMMA well ,COMMA that just creates a 2 -DASH node containing that key ,COMMA and that's legal 2 -DASH 3 tree ,COMMA so we're fine .PERIOD now ,COMMA inserting e into that well ,COMMA it's going to b if it's in the tree left of s ,COMMA that's a null lin .PERIOD so we need to convert that 2 -DASH node into a 3 -DASH node .PERIOD okay ?QUESTIONMARK and that's the legal of 2 -DASH 3 trees ,COMMA so we stop inserting a into that .PERIOD we convert that 3 -DASH node into a temporary 4 -DASH node ,COMMA but then we need to split that 4 -DASH node moving e to the parent and that creates a new ,COMMA root node and increases the size of the tree by one ,COMMA but now that's a legal 2 -DASH 3 tree so we stop .PERIOD insert r into that ,COMMA it goes to the right of e .PERIOD convert into a 3 -DASH node ,COMMA now insert c into that .PERIOD it goes to the left of e ,COMMA has to be joined with a into a new 3 -DASH node .PERIOD again ,COMMA that's a legal 2 -DASH 3 tree and we stop .PERIOD now we insert h ,COMMA that kind of goes to the right of e .PERIOD that 3 -DASH node gets converted into a 4 -DASH node .PERIOD that's a temporary 4 -DASH node and we split and move r to the parent ,COMMA now that parent's a legal and there's nothing more to be done .PERIOD we ,COMMA have a legal three tree ,COMMA 2 -DASH 3 tree .PERIOD insert x ,COMMA it's bigger than r ,COMMA goes to the right .PERIOD there's a 2 -DASH node ,COMMA there's room for the x .PERIOD insert p ,COMMA that goes between e and r .PERIOD the 2 -DASH node containing h ,COMMA right link is null ,COMMA so we convert that 2 -DASH node into a 3 -DASH node and now we have a legal 2 -DASH 3 tree .PERIOD now ,COMMA you ,COMMA you can see this next insertion is going to cause some splitting wherever it is .PERIOD so insert l ,COMMA that's between e and r .PERIOD so it goes in the ,COMMA 3 -DASH node containing h and p and we convert that into a temporary 4 -DASH node .PERIOD split that 4 -DASH node ,COMMA moving l to the parent .PERIOD now that parents of 4 -DASH node and that has to be split ,COMMA and we create a new root node .PERIOD and then the height of the tree grows by one .PERIOD and that's a legal 2 -DASH 3 tree ,COMMA so we stop .PERIOD so ,COMMA those local transformations ,COMMA converting a 2 -DASH node to a 3 -DASH node or converting a three to a four ,COMMA and then splitting and passing a node up .PERIOD those are the ,COMMA only operations we need to consider to get balance in our search trees .PERIOD alright .PERIOD so as i've mentioned and this diagram shows ,COMMA the splitting of 4 -DASH node and a 2 -DASH 3 tree is a local transformation .PERIOD it only involves changing a constant number of links .PERIOD so ,COMMA in this example ,COMMA it shows the general situation ,COMMA when the 4 -DASH node to be split is the middle length ,COMMA but the same is true if it's a left or right .PERIOD and those six subtrees drawn could be huge .PERIOD they could contain millions of keys ,COMMA but it doesn't matter what they contain .PERIOD we don't touch them at all ,COMMA nor do we touch anything above this node in the tree until the split happens .PERIOD so the transformation that splits that b ,COMMA c ,COMMA d ,COMMA node and inserts the c into the 3 -DASH node at the root ,COMMA just involves ,COMMA making that 3 -DASH node into a temporary 4 -DASH node .PERIOD and making that ,COMMA 4 -DASH node into two 2 -DASH nodes and adjusting the lengths appropriately .PERIOD just a constant number of operations and that's why ,COMMA this operation ,COMMA is ,COMMA in general ,COMMA efficient .PERIOD so let's look at the just the global properties that these manipulations preserve .PERIOD the two things that are critical is that the ,COMMA in a ,COMMA in a 2 -DASH 3 tree ,COMMA we always have symmetric order .PERIOD that is the word that we defined ,COMMA for 2 -DASH nodes and 3 -DASH nodes ,COMMA and we also have the perfect balance .PERIOD the distance from the root to the bottom is always the same .PERIOD and to prove that ,COMMA we just need to show that each transformation maintains symmetric order and perfect balance ,COMMA and these are all the possible transformations that we could do .PERIOD if we split the root ,COMMA then ,COMMA that's the ,COMMA what happens at the root ,COMMA and if there was perfect balance before ,COMMA there's perfect balance after ,COMMA with the height one bigger .PERIOD if the parent was a 2 -DASH node then the transformation is a local transformation and if you look at where the links are ,COMMA then it's easy to see by induction that if there was perfect balance before there's perfect balance afterward ,COMMA because we didn't change anything about the perfect balance in any of those subtrees .PERIOD and that's true in every case .PERIOD if the 3 -DASH nodes at the right and this one is one higher and those four are one lower and afterwards it's the same .PERIOD if there was perfect balance before there's perfect balance afterwards ,COMMA because we didn't change the height of any nodes .PERIOD we just moved things around locally within nodes .PERIOD and this is when this parent is a 3 -DASH node ,COMMA then there's the tree cases ,COMMA if we split up the last split at the middle and split at the right ,COMMA and again ,COMMA changing the four node to ,COMMA to a 2 -DASH nodes and adding links .PERIOD if there was perfect balance before ,COMMA there's perfect balance after ,COMMA because we didn't change the heights of anything else in the tree .PERIOD so our operations maintain symmetric order and perfect balance in a 2 -DASH 3 tree .PERIOD so ,COMMA that's going to give us ,COMMA a very easy way to describe a performance .PERIOD the call ,COMMA or operations have costs that's proportional to the path link from the ,COMMA height to the bottom ,COMMA and every path from the root to a null link has the same length .PERIOD how long can those paths be ?QUESTIONMARK well ,COMMA it's not hard to see that the ,COMMA in the worst case ,COMMA if they're all 2 -DASH nodes ,COMMA that's the longest they can be is log base two of n .PERIOD now ,COMMA and if they're all 3 -DASH nodes ,COMMA it would be log base three of n ,COMMA which is less ,COMMA it's about 0 .PERIOD63 log base two of n .PERIOD so ,COMMA all the paths in a 2 -DASH 3 tree with n nodes have to have length between those two bounds and those are pretty small numbers .PERIOD for a million nodes ,COMMA that's between twelve and twenty .PERIOD and ,COMMA if ,COMMA if it's a billion nodes ,COMMA that's between eighteen and 30 .PERIOD those are remarkably small numbers ,COMMA so we're going to have guaranteed performance ,COMMA even for huge databases ,COMMA we're going to be able to guarantee that we can get search and insert them with just eighteen to 30 operations and it's quite remarkable ,COMMA really .PERIOD so ,COMMA here's what our table ,COMMA will look like ,COMMA when we finish the implementation of 2 -DASH 3 trees .PERIOD every operation is guaranteed to be a constant times log n .PERIOD now ,COMMA the constant depends on the implementation ,COMMA exactly what kind of manipulations we need to do to convert ,COMMA 3 -DASH nodes to 4 -DASH nodes and so forth .PERIOD but it's ,COMMA easy to see from demo and from the diagrams that those are going to be constant ,COMMA guaranteed logarithmic performance for all operations ,COMMA which is certainly what we want in a symbol table implementation now what about the implementation ?QUESTIONMARK well ,COMMA we're actually not going to talk about a direct implementation of 2 -DASH 3 trees ,COMMA because it's kind of complicated .PERIOD it's cumbersome to maintain multiple node types .PERIOD you might need ,COMMA a multiple compares to move down the tree .PERIOD if there's a two ,COMMA a 3 -DASH node ,COMMA it takes more compares than a 2 -DASH node ,COMMA so ,COMMA it's complicated to analyze .PERIOD we have to take track ,COMMA keep track the links as we go up and down the tree to take ,COMMA handle the splitting ,COMMA and there's ,COMMA and there's a lot of cases .PERIOD i drew all the cases and ,COMMA and ,COMMA there's a ,COMMA whether you're splitting into the middle of a 4 -DASH node or the right of a 2 -DASH node ,COMMA there's just a lot of cases .PERIOD so ,COMMA you could do it but we're not going to because there's a much easier way .PERIOD so that's 2 -DASH 3 trees ,COMMA a ,COMMA a model for implementing balanced trees in guaranteed logarithmic time .PERIOD 
today ,COMMA we're going to talk about regular expressions .PERIOD now ,COMMA this is another in the series of ingenious algorithms that we're looking at in the second half of this course .PERIOD now ,COMMA this is really one of the most widely used and one of the coolest algorithms that we're going to cover .PERIOD to get started ,COMMA we have to talk about what is a regular expression .PERIOD and just putting the problem in context we've always talked about before .PERIOD in the last lecture ,COMMA we talked about the substring search problem ,COMMA which we're just trying to find one string in a text .PERIOD now ,COMMA we'll talk about a more general problem ,COMMA a pattern matching problem ,COMMA where we find one of a specified set of strings in the decks .PERIOD so ,COMMA that's specified set .PERIOD rather than talk about one string ,COMMA we have to describe a set of strings .PERIOD and that's what regular expressions are all about .PERIOD here's an example from genomics ,COMMA an actual example from a real life scientific data processing .PERIOD so ,COMMA there's a thing called fragile x syndrome ,COMMA which is a common cause of mental retardation .PERIOD the human genome contains is a string that consists of cs ,COMMA ts ,COMMA as ,COMMA and gs ,COMMA it's the way we've talked about before .PERIOD and the ,COMMA they naturally group themselves into groups of three .PERIOD and there's a way to describe a correlation with the syndrome from a property of the text string or the genome string .PERIOD the ,COMMA the actual scientific data is shown over here on the right ,COMMA but we'll just work with the text strings .PERIOD in the in the english ,COMMA the description is that you've got somewhere in your genome repeats of either cgg or agg ,COMMA that are bracketed by gcg at the beginning and ctg at the end .PERIOD now ,COMMA the number of repeats inside is very well .PERIOD so in this case ,COMMA we've got gcj that's the beginning thing and then we've got a cgg that's one ,COMMA agg that two ,COMMA cgg that's three .PERIOD so ,COMMA we got three repeats on one of these two patterns and then we have ctg .PERIOD now ,COMMA a different genome might have many more of these triplet patterns inside the number of repeats is a variable but high ,COMMA high repeat is correlated with fragile x syndrome .PERIOD so ,COMMA clearly medical p rofessionals want to know ,COMMA given a genome does it have a high number of repeats with this kind of pattern ?QUESTIONMARK then we if so then we want to look out for this fragile x syndrome .PERIOD and the specifying the problem in english is one thing ,COMMA but specifying it in a way that is enable to writing a program to help us find these patterns is another .PERIOD and this is the way that we specify the pattern .PERIOD now ,COMMA this thing is called a regular expression .PERIOD let's take this cgg ,COMMA and then either a cgg ,COMMA gcg ,COMMA and then either a cgg or an agg any number of times followed by a cgg .PERIOD that's specifying a set of strings and we might find that if the text had one of that specified set .PERIOD here's another example where regular expressions appear in real life .PERIOD there's a new source highlight program that we use to highlight syntax ,COMMA highlight keywords in our ,COMMA in our text ,COMMA and ,COMMA and also gray out comments ,COMMA and so forth .PERIOD and this is a very general program that works for many different kinds of languages and outputs to many different print formats .PERIOD and that's all about identifying one of a specified set of strings in a text and doing something with it .PERIOD it's an application of regular expressions in real life .PERIOD in google ,COMMA you can search in public search code ,COMMA it's public source code for regular expression search so you can search for code that contains any one of a specified set of strings .PERIOD and that's available facility on the web .PERIOD there's many ,COMMA many other applications .PERIOD another one is prosite in biology .PERIOD there is a bunch of specified patterns that you can use to search for genome or processing ahm natural language ,COMMA it's all about string processing and specifying sets of strings ,COMMA programming languages themselves .PERIOD and the other one we'll look at later on is validating when you are getting data entry from the web when you type in a credit card number ,COMMA you are told whether it's legal or not and that's all done with regular expressions since the string you typed in one of the specified sets .PERIOD so ,COMMA this is very widely used and widely useful application .PERIOD so we're going to look into the more general idea that this brings out ,COMMA is the idea of parsing text files ,COMMA and not only finding if the string matches a pattern ,COMMA but finding if finding the structure of a string that we can use in some kind of beneficial way .PERIOD and we'll come back to it more .PERIOD so ,COMMA we're looking at a basic capability that's widely useful ,COMMA but it also extends to cover deep issues and processes in computer science .PERIOD so ,COMMA what is a regular expression ?QUESTIONMARK well ,COMMA it's simply a notation to specify a set of strings .PERIOD the set could be infinite .PERIOD we're going to specify it with a finite pattern but it ,COMMA it could be infinite .PERIOD and we make a regular expression up just from four simple operations .PERIOD first one is called concatenation .PERIOD so ,COMMA that's we just take a bunch of letters and put them ,COMMA one after the other and a regular expression made from concatenation matches exactly precisely the sequence of characters that are specified and it doesn't match anything else .PERIOD so ,COMMA that's a simple one by itself and that's what we use for substring search for example .PERIOD then there's or .PERIOD so that one ,COMMA we give two different regular expressions and put a vertical bar between them .PERIOD and that says we're specifying now a set of size two and we're happy to match either string in that set .PERIOD there's no other string that we match .PERIOD and then there's one called closure .PERIOD and this is where an infinite comes in .PERIOD so ,COMMA when we put a star after a character ,COMMA or a regular expression ,COMMA as we'll see ,COMMA that's specifying zero or more occurrences of that character .PERIOD so ,COMMA aa matches ab<i>a because that's zero occurrences of b in</i> between .PERIOD or a with eight bs followed by an a matches ,COMMA because that's got zero or more bs in between two as .PERIOD but if you don't have an a at the beginning and the end ,COMMA or if you don't have all bs inside ,COMMA that doesn't match .PERIOD and that's an infinite number of strings ,COMMA zero on any number of occurrences of b .PERIOD so ,COMMA with just four characters were specifying an infinite set of strings .PERIOD and then ,COMMA the next operation to allow us to build regular expressions of arbitrary complexity is si mply parentheses .PERIOD if you include regular expressions within a parentheses ,COMMA then you can apply the star operator or concatenation to a ,COMMA another regular expression .PERIOD so ,COMMA these are examples of regular expressions using parentheses .PERIOD so ,COMMA this says ,COMMA a and then what's inside the parentheses ,COMMA which is the regular expression that says either a or b and then followed by aab .PERIOD so ,COMMA that matches precisely these two strings .PERIOD either a followed by an a followed by ab or a followed by b followed by aaa and it doesn't match anything else .PERIOD or if you put a more complicated regular expression inside parenthesis with a star ,COMMA it still means zero or more occurrences .PERIOD so ,COMMA just a would be zero occurrences .PERIOD and then ,COMMA this is one ,COMMA two ,COMMA three ,COMMA four occurrences of ab followed by a .PERIOD and again ,COMMA if it's not of that form ,COMMA it doesn't match .PERIOD this one doesn't have ab ,COMMA and ,COMMA and neither does this ,COMMA it has one ab ,COMMA but then the next one would have to be either ab or a .PERIOD there's been a way to get one of these strings by including zero more occurrences of ab .PERIOD these things here are ,COMMA are precedence order when we're performing the operations .PERIOD so the first thing is parenthesis ,COMMA next thing is a star ,COMMA next thing is concatenation and finally the or operation .PERIOD in this table then completely specifies what we mean by regular expression .PERIOD it's a sequence of characters .PERIOD alphabet characters like a and b and metacharacters ,COMMA like or and star and parenthesis that we use to describe a possibly infinite set of strings .PERIOD now in the real world it's often worthwhile and ,COMMA and useful to add some additional operations for convenience .PERIOD for example ,COMMA the wild card operation needs to have a dot and another metacharacter that matches any letter at all .PERIOD and that's shorthand for listing all the letters separated by or and then but that's a lot of characters and so ,COMMA with one character ,COMMA we can match the same regular expression .PERIOD and so this one you can use like to solve a crossword puzzle ,COMMA for example .PERIOD this one matches all the words that will have alternating u with all the seven letter words that have alternating us .PERIOD and so there's a couple .PERIOD but there's some other ones tha sort of have alternating use ,COMMA but not quite .PERIOD and they don't match ,COMMA so it's a wild card character .PERIOD and then ,COMMA there's classes of character ,COMMA so capital a -DASH z means any capital letter .PERIOD and then a -DASH z means any lower case letter .PERIOD so any capitalized letter ,COMMA any lower case letter followed by any number of lower case letters will match something like this but it won't match something like that ,COMMA just classes of characters .PERIOD and again ,COMMA this is shorthand for typing all the characters and using or at least one .PERIOD so ,COMMA rather than star ,COMMA which says ,COMMA zero or more occurrences ,COMMA plus means one or more occurrences .PERIOD so that's another example of a convenient shorthand or exactly k putting in braces that i want to specify ,COMMA this specifies i want exactly five digits ,COMMA followed by a dash ,COMMA followed by exactly four digits .PERIOD so ,COMMA that's a way to specify ,COMMA you know ,COMMA something like a legal plus for zip code .PERIOD and it doesn't match other things .PERIOD now in ,COMMA in practice ,COMMA in ,COMMA in ,COMMA in terms of practical clients these types of shorthands are extremely important in terms of the theory and the idea of processing regular expressions since we can specify them all with the basic operations we'll pretty much ignore them in our code .PERIOD so ,COMMA in every ,COMMA in every case we could write [a -DASH e] + if we wanted we could write this longhand of it ,COMMA but of course users are going to write the shorthand .PERIOD but still ,COMMA if we have a mechanism for dealing with this ,COMMA then we can certainly take care of the shorthand .PERIOD so ,COMMA just with those basic operations and ,COMMA and also the shorthand is helpful and our notation is amazingly expressive .PERIOD there's really a lot you can do with it .PERIOD so ,COMMA for example ,COMMA you can do substring search with a regular expression .PERIOD one way to express the substring search problem is to put your string preceded by dot star and put a dot star at the end ,COMMA you know ,COMMA and that's asking if your string is in the infinite language described by this regular expression ,COMMA is equivalent to the substring search problem .PERIOD it matches if and only ,COMMA if that string is in there so ,COMMA for example ,COMMA in these two and not in that two so notation covers the substring search problem .PERIOD but then also ,COMMA it can specify easily useful sets of strings that ,COMMA that ,COMMA you know ,COMMA that we often want to check .PERIOD so this is similar to the zip plus four ,COMMA the three digits followed by a dash followed by two digits ,COMMA followed by a dash ,COMMA followed by four digits .PERIOD that's a good start towards knowing whether the string is a legal social security number or not .PERIOD or is it a legal e -DASH mail address or not .PERIOD this is a simplified version but it basically says ,COMMA you ought to have at least one letter followed by an @ ,COMMA followed by some letters ,COMMA followed by a dot ,COMMA followed by edu or com or of course to cover all e -DASH mail addresses ,COMMA you need to consider some more possibilities .PERIOD but this is a ,COMMA a quick and succinct way to specify a set of string or java identifier ,COMMA what's a legal java identifier .PERIOD so ,COMMA this is one way to specify legal java identifier .PERIOD and indeed ,COMMA programming languages like java use regular expressions like this to define what they mean by a legal identifier ,COMMA and then ,COMMA the kinds of processes that we're going to talk about to actually check that what you typed is legal and echoes all the way up to the program itself .PERIOD the ,COMMA you know ,COMMA is ,COMMA is this a legal java program ?QUESTIONMARK it's almost but not quite ,COMMA as we'll see in regular expression pattern matching problem .PERIOD very ,COMMA very expressive in a widely -DASH used language .PERIOD now ,COMMA what's ,COMMA what's really interesting about this topic and we'll just i ,COMMA i touch on it ,COMMA even though it's extremely important to what we're going to do is that just from the standpoint of the theory of computation starting with the ,COMMA the time of turing and others in the 30s' ,COMMA our regular expressions play an important role in our understanding of the theory of computation and that understanding actually has led to that algorithm that we're going to talk about .PERIOD that's a very interesting aspect of this .PERIOD but still ,COMMA even given that you know ,COMMA regular expressions are just useful in everyday life .PERIOD this is an example of someone that used the regular expression to screen a job candidate .PERIOD and ,COMMA and this is actually illegal to look for words like enron ,COMMA or kerry ,COMMA or bush or gore or republican .PERIOD to decide whether a ,COMMA a ,COMMA a job candidate's job application will get through .PERIOD this one uses an exclamation point ,COMMA which mean just end with anything .PERIOD it's like dot star .PERIOD so someone ,COMMA a typical computer user can learn to regular expressions to with great effect .PERIOD even google supports ,COMMA a regular google search window supports a star as a full word wild card and or for union .PERIOD although not full regular expression pattern matching .PERIOD although that day is surely coming .PERIOD so people who just get into it just a little bit and start to see the utility of regular expressions certainly get excited about it .PERIOD and you can find examples of this all through the web .PERIOD this is an x ,COMMA xkcd comic about it where there's a problem ,COMMA you know ,COMMA how can we search through 200 megabytes of emails looking for something formated like an address .PERIOD and lawyers want to do this all the time nowadays ,COMMA and it's hopeless .PERIOD but now ,COMMA i know regular expressions .PERIOD and the regular expression super being swoops to the rescue and types a regular expression in perl ,COMMA which is a ,COMMA a widely -DASH used language that's based on regular expressions that we'll talk about briefly in a minute and swoops away .PERIOD so ,COMMA there is somewhat of a feeling what people don't know just a little bit that regular expressions can be used to solve any problem .PERIOD that's not quite true as we know from the theory of computation and we'll also touch on that a little bit .PERIOD so the ,COMMA the question is ,COMMA can the average programmer learn to use regular expressions effectively ?QUESTIONMARK and there's all kinds of evidence out there that lots of programmers use ,COMMA use in extensively .PERIOD but not to pour cold water on it but we have to take everything with some restraint .PERIOD and here's an example of a regular expression that you can find out on the web .PERIOD it's written in perl ,COMMA but it's a regular expression to check whether an  -DASH email address is va lid or not .PERIOD now ,COMMA that is quite a regular expression .PERIOD and one might argue whether that's really an effective way to use regular expressions .PERIOD maybe there's a simpler and easier way to check for valid e -DASH mail ,COMMA e -DASH mail addresses .PERIOD but anyway ,COMMA this one is out there and is used probably being used efficiently somewhere to the end ,COMMA effectively somewhere today .PERIOD but ,COMMA but really for people who are educated in ,COMMA in computer science ,COMMA need to know that regular expressions are definitely powerful tools ,COMMA but writing in regular expression really is like writing a program .PERIOD you have ,COMMA you have to understand the underlying programming model .PERIOD it's so often even more so than many programming languages since there's so few rules ,COMMA it's easier to write a regular expression than it is to read one .PERIOD and if it's difficult to read ,COMMA it means it's difficult to debug .PERIOD and so ,COMMA you can find a lot of flaming on the web about this .PERIOD and this is a particular apt ,COMMA particularly apt quote .PERIOD some people ,COMMA when confronted with a problem i think i know ,COMMA i'll use regular expressions .PERIOD now ,COMMA they have two problems .PERIOD and i think that's a good way to summarize the bottom line .PERIOD that regular expressions are amazingly powerful and expressive .PERIOD but you can ,COMMA they can get very complex in real in real applications .PERIOD still ,COMMA there's plenty of real applications where they can be succinct and effective .PERIOD and so ,COMMA we're going to look next at regular expression pattern matching algorithms .PERIOD 
before we can get to the algorithm ,COMMA we have to consider another abstract concept in the nfa and take a look at the nfa's now .PERIOD first of all ,COMMA there's a duality ,COMMA a well -DASH known duality between regular expressions and dfas .PERIOD dfa is a discrete ,COMMA finite automaton .PERIOD that's an abstract machine from ,COMMA theoretical computer science .PERIOD which is a very simple idea .PERIOD it's a state machine for recognizing whether a given string is in a given set .PERIOD and ,COMMA if you're not familiar with those ,COMMA they are very easy to understand and we'll ,COMMA look at some examples .PERIOD in a little summary from basic theoretical computer science ,COMMA there's a very important theorem called kleene's theorem that ,COMMA was ,COMMA developed actually here at princeton in the 30's and it says that ,COMMA for any discrete finite state automaton ,COMMA there exists a regular expression that describes the same set of strings .PERIOD and equivalently ,COMMA for any regular expression ,COMMA there's a dfa that recognizes the same set of strings .PERIOD and this is just ,COMMA an example .PERIOD and if you have seen this ,COMMA this sort ,COMMA this sort of thing will be familiar and if we have ,COMMA if you haven't you know ,COMMA and you will understand better as we get into it .PERIOD so ,COMMA a discreet finite state machine is a machine that has states that are labeled and it has transitions from state to state that are labeled with characters .PERIOD and ,COMMA the way that it works is ,COMMA if it's in a state and it reads like for every state is well defined is the next character is zero or one it's another state to go to .PERIOD so for example at state zero if you see a zero you stay in state zero ,COMMA if you see a one you go to state one .PERIOD in state one if you see a zero you stay in state one ,COMMA if you see a one you go to state two ,COMMA and so forth .PERIOD so at every state .PERIOD read a character and go to the well defined next state .PERIOD that's a discreet a deterministic final state automaton .PERIOD and so ,COMMA that's the machine you start it up on a string ,COMMA and it reads all of the characters in the string .PERIOD and then ,COMMA if it ,COMMA ends up in a state that's so called terminal state ,COMMA and started on the start state the terminal state is just in dicated by this x that are on this example .PERIOD it ends up in the right state you say that it recognizes a set of strings .PERIOD and so that's a way to determine if a given string is in a specified set .PERIOD the machine specifies the set .PERIOD in an re the ,COMMA we specify the set by writing characters and stars and meta -DASH characters in parenthesis and this regular expression recognizes these same set of strings .PERIOD describes these set of same ,COMMA same set of strings that's recognized by this dfa .PERIOD hank leany's theorem showed that it's always possible ,COMMA to ,COMMA construct such a machine .PERIOD so that gives a ,COMMA a basic plan for developing a pattern matching implementation .PERIOD and this is developed by ken thompson at bell labs ,COMMA one of the developers of unix ,COMMA and ,COMMA and this facility was an important part of early unix and developed this idea based on the well -DASH known theorem from theoretical computer science .PERIOD is let's try to build a machine ,COMMA the same way as we did for knuth -DASH morris -DASH pratt ,COMMA where we have no backup in the text input string .PERIOD so we just got a finite state machine .PERIOD with knuth -DASH morris -DASH pratt we built a ,COMMA a machine for recognizing the one string how about building one for multiple strings and that would give us a linear time guarantee .PERIOD so the unruling extractions is determine if it's fsa or dfa and the basic plan is to just go ahead and take your pattern .PERIOD it describes a set of strings and use that to build a dfa and then simulate the dfa with the texas input ,COMMA the same way we did for knuth -DASH morris -DASH pratt and if it accepts ,COMMA we say we have a match .PERIOD if it rejects ,COMMA we don't have a match .PERIOD this is a ,COMMA a fine plan but it's got a flaw .PERIOD the bad news is that the plan is infeasible because the number of states in the dfa might be exponential in the length of the re .PERIOD so ,COMMA for it's got too many states kleene's ,COMMA the proof of kleene's theorem ,COMMA standard proof of kleene's theorem  ,COMMA involves the exponential number of states .PERIOD and it's not that difficult to prove if you're interested be sure to look it up .PERIOD but from a practical ,COMMA standpoint ,COMMA too many states ,COMMA you can't use that as a basis for algorithm .PERIOD but there's an easy revision .PERIOD and again ,COMMA this gets back .PERIOD it will ,COMMA it will give us a quadratic time guarantee ,COMMA and actually ,COMMA in ,COMMA in real life ,COMMA it's usually linear ,COMMA and all we do is change the abstraction to use a non -DASH deterministic finite state machine ,COMMA an nfa ,COMMA rather than a dfa .PERIOD so ,COMMA in the same basic plan ,COMMA we're going to build an nfa .PERIOD it's a ,COMMA it's a different kind of machine ,COMMA but actually ,COMMA it's also the case that ,COMMA that ,COMMA oh yeah .PERIOD for any regular expression we can build on nfa so and in vice versa cleaning stand to this and so we're going to simulate with the nfa with the text as input .PERIOD and so ,COMMA what do we ,COMMA what do we mean by non -DASH determined as a finite state machine ?QUESTIONMARK that's what we have to talk about next .PERIOD and we'll just do it with this example that we used throughout this lecture .PERIOD so ,COMMA it's very similar to the dfa that we have before ,COMMA now we're going to put the characters in the states and actually ,COMMA the kind of nfa that we're going to build ,COMMA we're going to have one state for every character in a regular expression .PERIOD so this is an nfa ,COMMA corres -DASH  ,COMMA corresponding to this regular expression .PERIOD just ,COMMA to ,COMMA we ,COMMA we always enclose the regular expressions in parentheses .PERIOD just to ,COMMA make everything work .PERIOD and then ,COMMA got this regular expression here .PERIOD a star b or acd .PERIOD then ,COMMA we're going show how to build ,COMMA this nfa .PERIOD and then ,COMMA simulate it ,COMMA to recognize the regular expression .PERIOD and ,COMMA how is it different than a dfa so ,COMMA there's a character in every state ,COMMA and if the character's a text character ,COMMA it's the same as before .PERIOD we read that text character and moved to the next state .PERIOD but it's a more general kind of machine ,COMMA because states also have what's called epsilon transition .PERIOD and with an epsilon transition the machine is allowed to change the state without scanning any text .PERIOD so ,COMMA at the beginning the machine go from zero to one ,COMMA to two ,COMMA back to one ,COMMA i'm sorry ,COMMA two to three ,COMMA back to two or it go from zero to one over to six there's lots of places the machine could go ,COMMA without scanning any text character .PERIOD but we do have the black matc h transitions that scan text characters and so those are the rules the machine operates by .PERIOD and ,COMMA the ,COMMA final rule is when does it accept ,COMMA when does it decide a strings in the pattern .PERIOD it accepts if there's any sequence of transitions that scans all the text characters and ends in the accept case .PERIOD it's a way of specifying an infinite set of strings .PERIOD but it's got this non -DASH determinism .PERIOD it's not always determined what the machine ,COMMA will do next .PERIOD it's a little bit of a mind blowing concept in theoretical computer science .PERIOD but this particular example actually shows how such ,COMMA such a concept can be made concrete and actually give us a widely useful algorithm .PERIOD one way to think of a non -DASH deterministic machine is a machine that has super powers and can guess the proper sequence of state transitions to get to the end .PERIOD get to the accept state .PERIOD another way to think about is the sequences if you provide us particular sequences that's a proof that the machine accepts the text .PERIOD and so this is a real machine .PERIOD we don't have a real machines that can guess the right answer but it's a completely well specified abstract machine ,COMMA and we can write a program to stimulate it's operation ,COMMA and that's what we are going to do .PERIOD so let's just make sure that everyone's got the concept down .PERIOD so ,COMMA say we have the question is 4a is followed by bd ,COMMA is that accepted by this nfa down here ?QUESTIONMARK and the answer is yes because there is a sequence of legal transitions that ends up in state eleven .PERIOD so in this case ,COMMA we'll take an epsilon transition from zero to one to two and then we'll .PERIOD .PERIOD .PERIOD we've got 4a's so we'll chew up four a's ,COMMA one ,COMMA tw -DASH  ,COMMA i'm sorry .PERIOD one ,COMMA and then go back .PERIOD two ,COMMA and then go back .PERIOD three ,COMMA and then go back .PERIOD four ,COMMA and then we'll be in state three .PERIOD and then at that point ,COMMA we'll decide to take this epsilon transition .PERIOD we'll assume your machine decides to take this one .PERIOD then it recognizes the b and moves to state five .PERIOD and then ,COMMA at state five ,COMMA it no place to go but to state eight .PERIOD and then ,COMMA takes the epsilon transition to the state nine .PERIOD it recognizes the d that takes it out to ten and eleven .PERIOD so ,COMMA there is a sequence of state transitions that get to a eleven and recognizes all the characters and the strings ,COMMA so therefore it's matched .PERIOD what about so the ,COMMA it's true that there is sequences that the machine might guess and go to the wrong state or stall ,COMMA it doesn't matter as long as there's some sequence and we are going to assume that the machine always guesses the right one .PERIOD so for example ,COMMA if the machine just recognizes three a's ,COMMA one ,COMMA two ,COMMA three ,COMMA and then went to state four ,COMMA it would get stuck because there's no way for it to get out of state four because state four is looking for a b ,COMMA and it's sitting on an a ,COMMA and so forth .PERIOD so ,COMMA there's definitely ,COMMA things that the machine could do that would be wrong ,COMMA but we don't care ,COMMA as long as there's some way for it to get through .PERIOD and then ,COMMA what about if it's a string that's not in a language recognized by the state .PERIOD the machine ,COMMA well ,COMMA so we have to argue about all possible sequences and ,COMMA prove that ,COMMA no sequence of legal transition ,COMMA is transitions ends in state eleven .PERIOD and that ,COMMA seems to be ,COMMA a fairly complicated sort of argument .PERIOD so in this case the machine could recognize a bunch of a's ,COMMA and then go to state four .PERIOD but again ,COMMA there's no b ,COMMA so there's no way it's going to get out of state four .PERIOD and ,COMMA so you can make a general argument like looking at the machine that's any string that it recognizes ,COMMA it has to end in d and this one doesn't end in d .PERIOD that's a ,COMMA much more complicated thing ,COMMA than we're talking about ,COMMA is to try to come up with ,COMMA a ,COMMA simple machine that will decide whether or not a string ,COMMA is in the ,COMMA language that it specifies .PERIOD so the question ,COMMA so question that we have is ,COMMA we have this non deterministic machine ,COMMA how are we going to decide whether a given string is in the language that it recognizes .PERIOD so for deterministic machines ,COMMA like we used for knuth -DASH morris -DASH pratt it's very easy ,COMMA because at every time ,COMMA there's only one possible transition .PERIOD but for non -DASH deterministic ,COMMA if you're ,COMMA in some states ,COMMA there's ,COMMA multiple ways to go ,COMMA and you have to ,COMMA figure out the right transition .PERIOD but actually ,COMMA the situation isn't so bad .PERIOD and what we can do is ,COMMA to simulate the nfa ,COMMA is just to make sure that we consider all possible ,COMMA transition sequences .PERIOD and that's what our algorithm for a regular expression pattern matching is going to be based on .PERIOD that's what we will look at next .PERIOD 
now ,COMMA we'll look at red black bsts which is a simple data structure that allows us to implement 2 -DASH 3 tree with very little extra code beyond the basic binary search tree code .PERIOD so this is ,COMMA and actually the version that we're going to ,COMMA looking at is called left -DASH leaning red -DASH black bsts .PERIOD on a personal note ,COMMA i wrote a research paper on this topic in 1979 with leo givas and we thought we pretty well understood these data structures at that time and people around the world use them in implementing various different systems .PERIOD but just a few years ago for this course i found a much simpler implementation of red -DASH black trees and this is just the a case study showing that there are simple algorithms still out there waiting to be discovered and this is one of them that we're going to talk about .PERIOD so ,COMMA the idea is that we are ,COMMA are going to represent every two ,COMMA three tree as a binary search tree .PERIOD and in order to get that done ,COMMA we just need a simple representation for three notes .PERIOD so ,COMMA what we are going to do is use internal left -DASH leaning links to glue the three nodes together .PERIOD so ,COMMA the larger of the two nodes in the tree node will always be the root of a little binary search tree of size two for the three node and the link between the two nodes ,COMMA the left link that links the larger key to the smaller one we'll color red .PERIOD and that's to distinguish those links from the other links in the binary tree so that we can tell when we're inserting things which nodes belong to tree nodes and which ones don't .PERIOD and you can see from this transformation that it's easy to perform this ,COMMA see this correspondence the middle link between a and b ,COMMA those are the keys that are less than b and larger than a .PERIOD so ,COMMA that takes two comparisons to get to them the ones that are less than a ,COMMA less than ,COMMA less than a ,COMMA that's two comparisons for that and the ones that are greater than b are the right link of b .PERIOD so ,COMMA just following those three cases ,COMMA i see t hat this correspondence is going to work .PERIOD so ,COMMA any 2 -DASH 3 tree corresponds to a left leaning red -DASH black bst in this way .PERIOD just take the three nodes and split them into little binary search tree of size two held together by a red link .PERIOD and correspondingly given a red -DASH black bst then you can get the 2 -DASH 3 tree if you wanted it .PERIOD but just look at the properties of looking at the properties over a left leaning red -DASH black bst .PERIOD you know ,COMMA with reference to what we know about 2 -DASH 3 trees .PERIOD first of all no node has two red links connected to it cuz the only red links are internal to three nodes .PERIOD and those have to have ex ,COMMA external links or tree links connecting them to some other node .PERIOD every path from the root down to a null link has the same number of black links that just follows directly from the corresponding property for 2 -DASH 3 trees .PERIOD a left -DASH leaning red -DASH black bst has perfect black balance .PERIOD and all the red links lean left .PERIOD so ,COMMA given a bst with some of the links colored red that has those properties that's going to correspond to a 2 -DASH 3 tree .PERIOD and that's a key property is this one -DASH to -DASH one correspondence between 2 -DASH 3 trees and left -DASH leaning red -DASH black trees .PERIOD given a 2 -DASH 3 tree ,COMMA we saw how to do it .PERIOD given a ,COMMA a ,COMMA given a red -DASH black tree ,COMMA we just make the red links horizontal ,COMMA and merge the nodes together to be three nodes .PERIOD so ,COMMA all of the operations that we're going to look at for red -DASH black trees can be understood in terms of the corresponding operations on 2 -DASH 3 trees .PERIOD now the first ,COMMA and really one of the most critical observations ,COMMA is that search in a red -DASH black bst is exactly the same as for an elementary bst ,COMMA we just ignore the color .PERIOD now ,COMMA it's going to be much faster because of better balance in the tree ,COMMA but in terms of the code ,COMMA we don't have to change the code at all .PERIOD our regular search code doesn't examine the color of a link and so we can just use it exactly as is .PERIOD and in fact ,COMMA most of the other operations that we implemented on bsts are also identical .PERIOD they d on't need the colors ,COMMA but they can all benefit from the fact that the trees are much better balanced .PERIOD so this aspect of red -DASH black bsts is an extremely nice one because of the operations that we implemented for regular bsts that involves some complicated code for floor and ceiling and rank and so forth ,COMMA and we don't have to change that code at all .PERIOD we just during the insertion ,COMMA make sure that we ,COMMA we [cough] maintain the properties the balance properties and by doing that ,COMMA we wind up with balance trees and we make all the operations quick and we don't have to re -DASH implement ,COMMA we don't have to change it at all .PERIOD so first before we get to the code for insertion ,COMMA we have to look at the representation .PERIOD we don't actually have explicit representation of links or links in trees or just references to nodes .PERIOD you could implement this by building explicit links but the an easier thing to do is to know that every node is referenced by just one link in a tree the one from it's parent .PERIOD so ,COMMA you can put the color of a link in the node that it references .PERIOD so ,COMMA in this case we have a red link connecting e and c .PERIOD what we do is put a bit ,COMMA a color bit in each in the node class .PERIOD and then ,COMMA if the link coming into a node is red we set that to true .PERIOD so this simple thing just tests is a node red .PERIOD we consider all null nodes to be black null links to be black ,COMMA we don't have red links dangling off ,COMMA that would be incomplete pre -DASH nodes .PERIOD and [cough] otherwise if the color's red ,COMMA we return true otherwise return false to test whether a node is red .PERIOD so in this tree ,COMMA the color of h .PERIODleft is red ,COMMA the color of h .PERIODright is black and so forth .PERIOD so ,COMMA that's the way we represent colors by putting the ,COMMA a color bit in the node for the color of the length that points to it .PERIOD [cough] alright ,COMMA so now ,COMMA there's a couple of elementary operations that we have to perform on red -DASH black trees ,COMMA called rotations .PERIOD and the idea is that during the construction of a tree ,COMMA or during an insertion operation ,COMMA sometimes we wind up with red links that are leaning in the wrong direction .PERIOD and so we'll need what's called a left rotation ,COMMA and the job of that operation is to take a ,COMMA a right leaning red link that is there for whatever reason and reorient it to lean to the left .PERIOD [cough] so ,COMMA in this case ,COMMA we have the right link of e points to s and s is red so that's a right -DASH leaning red link and so now that's the before and what we want to do is reorient things so that it leans to the left .PERIOD and again ,COMMA that has to be a local operation that only changes a few links and just from the diagram it's not difficult to see that this little bit of code will do the job .PERIOD if we start with a right -DASH leaning red link .PERIOD so ,COMMA first thing we do is take the reference of h .PERIODright ,COMMA and save that in x .PERIOD so ,COMMA that's the node that's going to be the new root of the three nodes so to speak .PERIOD and ,COMMA and then ,COMMA x .PERIODleft after the rotation is going to be h .PERIOD and also whatever color h was ,COMMA well ,COMMA it looks like it should be black .PERIOD but actually this situation is where it could be red .PERIOD then x is going to have that color cuz the link coming into h is going to be the link coming into x .PERIOD and then h's color is going to be black afterwards .PERIOD and then ,COMMA we return x to link further up the tree which happens during our standard recursive insert .PERIOD so ,COMMA that's a rotate left operation .PERIOD now ,COMMA the property of this operation that's very important is it maintains a symmetric order .PERIOD the keys between e and s are still there .PERIOD we just changed the way we get to them .PERIOD and the keys less than e and so forth .PERIOD and also we maintain perfect black balance because we didn't change the black height ,COMMA height of anything by doing this transformation .PERIOD all those subtrees ,COMMA those three subtrees are exactly the same relative to the top and bottom of the tree ,COMMA as they were before the rotation .PERIOD now paradoxically and you'll see why very soon it also turns out that to get the insertion done properly we sometimes need to take a left -DASH leaning red link and temporarily make it lean right .PERIOD and later on ,COMMA we'll get it back to the left again .PERIOD but anyway ,COMMA that's a basic operation that we sometimes need .PERIOD and so that's just the symmetric code to the code that we just did .PERIOD now again ,COMMA now x is h .PERIODleft .PERIOD and h .PERIODleft is going to be x .PERIODright after the rotation .PERIOD x's color is still going to be h's color .PERIOD and h's color is going to be red .PERIOD and the right rotation implements this and again that's going to maintain a ,COMMA a symmetric order in perfect black balance we change the way the red goes but we didn't change anything about the black .PERIOD okay ,COMMA that's a right rotation .PERIOD now ,COMMA here's the third elementary operation that we're going to perform .PERIOD it's called a color flip .PERIOD sometimes during the insertion ,COMMA we might wind up with a node that's got two red links coming out of it .PERIOD that's corresponds precisely to our temporary four node when we're doing 2 -DASH 3 trees .PERIOD and what we wanted to do with the temporary four node was to split it and pass the center node up to the root .PERIOD well ,COMMA you can see from this structure that we're all set to do that all we need to do actually is not change any links ,COMMA just change all the colors .PERIOD and so ,COMMA that is ,COMMA we change the link from e to a and from e to s to be black .PERIOD that essentially splits the four node .PERIOD and then ,COMMA we want to insert the e into its parent .PERIOD and we just do that by changing its link to be red .PERIOD so ,COMMA that's flipping the colors .PERIOD and that's the way we split a temporary four node in a left -DASH linear red -DASH black tree .PERIOD and again ,COMMA that's just flipping colors .PERIOD it doesn't change any links so it still ,COMMA of course ,COMMA maintains symmetric order and perfect black balance .PERIOD so ,COMMA those are the three basic operations we're going to use .PERIOD rotate left ,COMMA rotate right and flip colors .PERIOD so ,COMMA the basic s trategy is ,COMMA with those operations ,COMMA maintain one -DASH to -DASH one correspondence with 2 -DASH 3 trees when we do insertions .PERIOD so ,COMMA here's an example .PERIOD if we want to insert c into this red black tree which is a representation of this 2 -DASH 3 tree ,COMMA then c is going to be less than e greater than a .PERIOD so ,COMMA it will get added to ,COMMA as the right link of a and every time we add a node we just create a red link to its parents and so ,COMMA that's changing the two node into a three node .PERIOD in this case it's three nodes that's oriented the wrong way so we need to do a left rotate .PERIOD after we do the left rotate ,COMMA we have a legal left -DASH leaning red -DASH black tree ,COMMA and it exactly corresponds to that 2 -DASH 3 tree ,COMMA so the insertion of c gives us exactly what we would want ,COMMA that correspondence with the 2 -DASH 3 tree .PERIOD we have to work through other cases that can arise but there's not too many so we'll work through and we have the basic operations ,COMMA left rotate ,COMMA right rotate ,COMMA and flip colors .PERIOD alright ,COMMA so first ,COMMA warm up ,COMMA insert into a tree with exactly one node .PERIOD well ,COMMA if it goes on the left ,COMMA then we just make a red link and add it on then we're done .PERIOD if it goes on the right ,COMMA then we attach a new node with the red link on the right but we have to rotate it to the left to make a legal three node .PERIOD so ,COMMA that's inserting to a tree with the one node and make it a tree with two nodes .PERIOD and that one generalizes to help us insert into a two node at the bottom .PERIOD so ,COMMA we do the standard bst insert color the new link red and then if that [cough] new three node happens to lean right ,COMMA rotated to the left .PERIOD that's the case that we just did .PERIOD so now ,COMMA let's look at the second warm -DASH up .PERIOD so ,COMMA say ,COMMA we have just two nodes in the tree ,COMMA so it's we have two nodes and that means it's a single three node .PERIOD then there's three cases .PERIOD so ,COMMA one is that the new one is larger than both of the keys .PERIOD if that's true ,COMMA then we attach the new node with the red link as always .PERIOD and that gives us a temporary four node .PERIOD and what we want to do is split that four node and in this case ,COMMA since we are at the root that's all so that just flips the colors .PERIOD now ,COMMA the color of the root in our code will temporarily turn red and then we turn it black again .PERIOD so ,COMMA that's inserting into a tree that's a single three node a node that's larger than both of them ,COMMA a key that is larger than both of them and we get wind up with a four node .PERIOD well ,COMMA let's look at the other two cases and these understanding needs is crucial to understanding the whole algorithm .PERIOD let's say ,COMMA the new key is smaller than both of the keys in our three node .PERIOD now ,COMMA we attach a new link at the left of the smaller node .PERIOD and now ,COMMA we've gotta find bst .PERIOD but it has two red links in a row .PERIOD and that's something that's not allowed .PERIOD so ,COMMA what we're going to do is we're going to rotate the top link to the right .PERIOD so that puts b at the root .PERIOD and now ,COMMA it's got two red children .PERIOD it reduces to this case .PERIOD and we flip the colors and we have a single four node .PERIOD sorry a ,COMMA a red black .PERIOD a tree that's got three two -DASH nodes and no red links so same situation as before .PERIOD so ,COMMA we had a single temporary four note and we split it up into a two ,COMMA two note not connected to a four note .PERIOD and then ,COMMA so that's the case when it's smaller .PERIOD now ,COMMA we have to look at the third case ,COMMA which is ,COMMA when it's ,COMMA the new node inserted this in between and comes out of this link here .PERIOD again ,COMMA we just had a red link and now we have a bst with two red links along the path connected to a and that's not allowed .PERIOD in this case it's a bit trickier to affix the situation ,COMMA what we do is we rotate the bottom link left .PERIOD so ,COMMA and that gives us this and reduce it to the other situation that we had before .PERIOD and then we rotate the top link right and then ,COMMA we flip the colors .PERIOD so ,COMMA this one we used all three of our operations ,COMMA rotate left rotate right and flip the colors .PERIOD and that gets us an insertion into a tree that has from a tree that i s a single three node to a tree that is three two nodes that is containing three keys .PERIOD so that sort of operation is going to work in a big tree when we insert into a new three node at the bottom .PERIOD we do the standard bst insert ,COMMA color the new link red ,COMMA and we do the rotations that we need ,COMMA either one or two rotations to balance the temporary four node ,COMMA and then we flip colors to pass the red link up one level and then remind me to rotate to that to make that one lean left .PERIOD so ,COMMA for example if we insert h in to this tree here ,COMMA it comes off as the left link of r so that gives us a temporary four node that's not balanced so we need to rotate the link from s to the right and that gives us now temporary four node that is balanced and again ,COMMA these are all local transformation it's not changing the rest of the tree .PERIOD now ,COMMA we flip colors and that gives us a ,COMMA a good red -DASH black tree ,COMMA except that ,COMMA that one red link that we just is leaning the wrong way .PERIOD so ,COMMA now we need to rotate left and then once we've done that ,COMMA now we have a legal left -DASH leaning red -DASH black tree .PERIOD so [cough] that's a insertion into a three node at the bottom .PERIOD so ,COMMA here's another one that involves ,COMMA remember ,COMMA we passed that red link up .PERIOD there might ,COMMA if that gets passed up to a three node ,COMMA then we have to continue moving up the tree and just treat it in the same way as we just treated inserting at the bottom .PERIOD we have a new red link appearing into some three node .PERIOD there's the three cases that could happen and here's an ,COMMA an a ,COMMA an example .PERIOD so ,COMMA say ,COMMA we're inserting p into this left -DASH leaning red black tree it goes to the right event so we get a temporary four node that's got two red links both children are red in that thing so we want to flip the colors .PERIOD we flipped the colors and now our temporary 4 -DASH node is up higher in the tree but it's not balanced so we are going to have to do two rotations to make that balanced .PERIOD first one is to make the bottom link left -DASH leaning and then the second one is to make the top link right -DASH leaning so that we can have the temporary four node balance .PERIOD and then the last thing we do is flip the colors and now that's the result of that insertion .PERIOD it's a bunch of transformations but they're all simple using our flip colors or left or right rotation .PERIOD and [cough] that one happened to be at the root .PERIOD if that red link were ,COMMA were way down in the tree and there were another three node about it ,COMMA we might have to do it again .PERIOD again ,COMMA exactly as what would happen in a 2 -DASH 3 tree .PERIOD so ,COMMA let's do a demo of constructing the red -DASH black bst from our standard set of keys .PERIOD so ,COMMA we start with a single key .PERIOD now ,COMMA if we want to insert e ,COMMA if it goes to the left ,COMMA that's fine .PERIOD that's a legal left -DASH leaning red -DASH black tree .PERIOD a would go to the left of e two lefts in a row so we have to rotate that to right .PERIOD and then we have to flip the colors .PERIOD and that's a legal red -DASH black bst .PERIOD so now ,COMMA if we insert r into this one then it goes on a red link to the left of x ,COMMA s and that's fine ,COMMA it's a red -DASH black bst .PERIOD and now ,COMMA if we insert c into this one ,COMMA it goes less than e ,COMMA greater than a it's a red link connecting a and c but it's leaning the wrong way .PERIOD so ,COMMA we have to do a left rotation ,COMMA legal -DASH red black bst .PERIOD and you want to insert h that goes to the left of r ,COMMA two reds in a row ,COMMA rotate the top .PERIOD rotate the top ,COMMA our temporary four node is balanced ,COMMA flip colors .PERIOD now ,COMMA we have a three node ,COMMA but the red link is leaning right so we have to rotate .PERIOD and now ,COMMA we have a legal red -DASH block bst .PERIOD insert x into that one that goes to the right of s ,COMMA it's leaning the wrong way ,COMMA rotate left .PERIOD insert m into this one ,COMMA goes to the right of h ,COMMA leaning the wrong way ,COMMA rotate left .PERIOD most of the operations are simple ones like this happening at the bottom .PERIOD insert p ,COMMA that goes to the right of m that makes m a temporary four node that happens to be balanced ,COMMA so flip the colors .PERIOD flip the colors ,COMMA now we h ave a temporary four node that's out of balance so we need a double rotation .PERIOD first rotate e to make that link point lean to the left ,COMMA then rotate r to make the ,COMMA bring the temporary four node into balance .PERIOD and then ,COMMA flip the colors and that's a legal red -DASH black bst .PERIOD insert l into that one .PERIOD it goes to the right of h ,COMMA leading the wrong way rotate left .PERIOD [cough] and that's an example of building a red -DASH black bst from our standard set of keys .PERIOD now ,COMMA we're ready to look at the implementation for ,COMMA of the code for inserting into a left -DASH leaning red -DASH black tree .PERIOD and the key to understanding this code is to realize that the same code ,COMMA code handles all of the cases .PERIOD and the way that it works is we are always reducing one case to another .PERIOD we get this most complicated case we did a left rotate on the bottom node and that ,COMMA that transformed it to this case where they're both leaning left .PERIOD and then we did a right rotate on the top node ,COMMA and that transformed to the case where our temporary four node is balanced .PERIOD and then we flipped colors on that .PERIOD so ,COMMA for a particular insertion ,COMMA we can take advantage of this reduce one case to another by ,COMMA in ,COMMA in the way that we're moving in the tree ,COMMA not to get everything happen with just a ,COMMA a few extra lines of code in our standard binary search tree .PERIOD so ,COMMA in gray is our ,COMMA standard insertion code for binary search trees .PERIOD and remember we took some pains to think about the recursive implementation where when we go down a link we replace that link by whatever the recursive routine gives us back and that strategy is going to pay off in giving us a really simple code .PERIOD [cough] and because in this implementation for left -DASH leaning red -DASH black trees we're going to return the link whenever we're done ,COMMA and then that will get that link installed up in the node above whether it be left or right .PERIOD typical implementations of red -DASH black trees that do not use this recursive strategy wind u p having lots of cases depending on whether left or right or double rotate to the left or double rotate to the right can be critical of this code because my own was this way for the first three editions of the book .PERIOD and it's only in this edition that we figured out how to make the code this simple .PERIOD okay .PERIOD so what are the things left to be done ?QUESTIONMARK let's just check .PERIOD when we insert a new node all we want to do is create a new node with the ,COMMA i've given ,COMMA associating the given value with a given key ,COMMA as before but now we just make that node red .PERIOD so ,COMMA that's adding a new node with a red link at the bottom inserting that into whatever the two or three node it's attached to .PERIOD and then we do the comparisons as ,COMMA as before and that ,COMMA and that's all fine .PERIOD now ,COMMA when it's returned then that's the point at which we're going to check whether the left ,COMMA the links are leaning to the left as they are suppose to and whether or not there are any double links or not .PERIOD so the first thing is if ,COMMA if is red h .PERIODright and not is red h .PERIODleft ?QUESTIONMARK so ,COMMA that means h is h .PERIODright is red so that means the right link of h is leaning the wrong way .PERIOD so ,COMMA h is a three node leaning the wrong way .PERIOD so we just rotate left h .PERIOD so ,COMMA whenever we find a right link ,COMMA we're sitting on a right red link we just rotate it left and return that .PERIOD so ,COMMA that would be in this case here ,COMMA we'd rotate it left and reduce it to that one .PERIOD [cough] or in ,COMMA in you know ,COMMA in the case when we're just inserting a new node and it's turns out to be the right red link attached to a black one ,COMMA if that handles that case .PERIOD now ,COMMA if h .PERIODleft is red and h .PERIODleft is also red that's this case here where we have two left -DASH leaning red links .PERIOD and then in that case ,COMMA we just rotate the top one right and that brings us to this one .PERIOD so ,COMMA notice ,COMMA we're in this case we do this rotation first ,COMMA we're on this node and then  ,COMMA that returns and we come up to deal with the situation on this node after the return ,COMMA and then we do that rotation .PERIOD and then after that rotation ,COMMA or if there were no rotations at all ,COMMA if the insertion happened over here then we'd test and flip the colors .PERIOD it's a little mind bending at first because of the recursive structure but it won't take you long to convince yourself that this little bit of extra code completes the implementation of left -DASH leaning red -DASH black trees .PERIOD it's quite remarkable ,COMMA actually .PERIOD so ,COMMA let's look at a visualization .PERIOD watching the [unknown] ,COMMA this is a balanced tree getting constructed in the worst case where everything that comes in is in ascending order .PERIOD a regular binary search tree will just be all strung out in a single line and wouldn't have quadratic time for this input but a left -DASH leaning red -DASH black tree actually when ,COMMA whenever it becomes a power of two is completely balanced as you can see from this example .PERIOD even though they came in ,COMMA in ascending order ,COMMA the tree winds up being perfectly balanced .PERIOD and what about descending order .PERIOD well ,COMMA it's left leaning and the process is a little bit different and sometimes the left path can get long but not that long .PERIOD the worse that can happen is that it alternates red and black .PERIOD and then after it gets to that worse case it also winds up being completely balanced when we have a power of two .PERIOD interesting to think just ,COMMA just about this case and to prove to yourself that it's always going to be perfectly balanced when it's descending .PERIOD and this is just for random insertions .PERIOD the tree stays very balanced .PERIOD it's guaranteed that the longest path which is alternating red and black can be no more than twice as long as the shortest path which is all blacks .PERIOD and so in this case the longest path is ten and the average path is seven for 255 .PERIOD very close to log based two of n .PERIOD so easy to prove by correspondence with 2 -DASH 3 trees that t he height is guaranteed to be less than two log base two n .PERIOD every search in left -DASH leaning red black three is guaranteed to take less than two log base two of n cuz every path gets the same number of black links so you never have two red links in a row .PERIOD [cough] and actually ,COMMA in typical applications with any kind of randomness or even if there is a lot of order its difficult to find situations orders of keys that build the trace of height is bigger than actually one log n in ,COMMA in a real application ,COMMA its very close to fully balanced all the time .PERIOD so ,COMMA that completes our summary for a symbol table implementations with red -DASH black bsts .PERIOD we have full code it's the regular bst code with the couple of lines adding the calls and the basic operations .PERIOD she rotate right ,COMMA rotate left .PERIOD in color flip ,COMMA we could guarantee logarithmic performance not just research ,COMMA insert ,COMMA in delete code .PERIOD delete code is a bit more complicated but it's on the book side and in the book .PERIOD but also ,COMMA since it's the compare -DASH to interface ,COMMA and since it's a binary tree representation all the other comparable operations extended operations for ordered symbol tables are going to be implemented and take time proportional to the log n .PERIOD a lot of people ask why use the name red -DASH black .PERIOD well we invented this data structure this way of looking at balance trees at ,COMMA at xerox parc which was the home of the personal computer and many other innovations that we live with today entering graphic user interface and internet and object oriented programmings and many other things .PERIOD but one of the things that was invented there ,COMMA was the laser printing and we were very excited to have nearby color laser printer that could print things out in color and out of the colors ,COMMA the red looked the best .PERIOD so ,COMMA that's why we picked the color red to distinguish red links the types of links in three nodes .PERIOD so ,COMMA that's an answer to the question for people t hat have been asking .PERIOD now ,COMMA here's another war story about red -DASH black bsts .PERIOD as i mentioned they're widely used .PERIOD and there was an example not that long ago ,COMMA where a telephone company contracted with a database provider to build a database that could store customer information and the provider implemented the database using red -DASH black bsts for search and insert .PERIOD now ,COMMA our ,COMMA our original paper on red black trees was the way the paper was laid out ,COMMA it turned out that the delete implementation happened to be placed after all the references .PERIOD so ,COMMA a lot of people didn't see the delete implementation .PERIOD and also we didn't have the simple left -DASH leaning representation .PERIOD so it was more complicated and involved a lot more cases and so usually not all the cases were put in the text books .PERIOD so ,COMMA people found deletion more difficult .PERIOD in fact ,COMMA that's what lead to [unknown] analyze the situation then come up with a left -DASH leaning variant .PERIOD so ,COMMA what they did in this implementation was they just put in regular hibbard deletion in the binary search in the red -DASH black bst .PERIOD not the deletion algorithm that's guaranteed to keep the constant black height all the time .PERIOD and so but ,COMMA but they still thought that it should be balanced and it shouldn't matter much .PERIOD and they had a complex error recovery process that ,COMMA that got triggered if the height limit got too big .PERIOD and they rebuild the whole tree and ,COMMA and then because of the way they did this deletion ,COMMA well ,COMMA the end of the story was that they had extended the client had extended outage because the implementer didn't use the full algorithm .PERIOD and there was a lawsuit and some legal testimony and i am happy to report that ,COMMA that it was clear that hibbard deletion was the problem once the expert analyzed it and the expert witness ,COMMA who's a colleague of mine ,COMMA said if implemented properly ,COMMA the height of a red -DASH black bst with n keys is at most two log n .PERIOD and so that's the st ory of red -DASH black bst's guaranteed logarithmic performance for all symbol table operations .PERIOD 
okay .PERIOD we're going to finish up by talking about some ,COMMA practical applications of red black trees .PERIOD and in particular ,COMMA b trees which are a general ,COMMA general version .PERIOD so the idea the sign behind bee trees is that often ,COMMA the data that we're ,COMMA trying to store is ,COMMA is really huge .PERIOD there's a ,COMMA a large amount of data .PERIOD and we're ,COMMA we're going to look at a more general model for external storage .PERIOD where ,COMMA we work with continuous blocks of data that are big .PERIOD maybe four ,COMMA 4k or bigger ,COMMA or maybe even a whole file .PERIOD and all we want to count is the first time we access a page ,COMMA because the main cost is trying to find where the page is .PERIOD once it's read in we get to read all of the page for free pretty much .PERIOD so the real property of external storage that not your local memory ,COMMA is that the time required to get to a page is way larger than the time to access data within a page .PERIOD so what we want to do is try to access data that's out ,COMMA externally ,COMMA using a minimum number of probes .PERIOD that's a model of a file system that is pretty workable .PERIOD and so bee trees are a generalization of .PERIOD balance trees ,COMMA that allow for this .PERIOD the idea is to ,COMMA allow not just two or three ,COMMA keys per node ,COMMA but a large number like the number that can fit in a page .PERIOD so ,COMMA might be ,COMMA m = 1000 or m = 4000 .PERIOD and well ,COMMA we've gotta have at least ,COMMA two ,COMMA keys at the root .PERIOD and ,COMMA and the only other restriction is that ,COMMA we don't want the nodes to get too empty .PERIOD so we have less than m .PERIOD but we want to have at least m over two .PERIOD and as you'll see ,COMMA this is ,COMMA a generalization of ,COMMA two three trees .PERIOD that allows us to ,COMMA build balance trees that ,COMMA are very ,COMMA very shallow .PERIOD typically ,COMMA these are set up so that ,COMMA the ,COMMA all the data is in the external nodes .PERIOD and so the external nodes have no links ,COMMA they just have keys .PERIOD and their in ,COMMA kept in sorted order .PERIOD so ,COMMA for example ,COMMA this is a external ,COMMA this is m = six .PERIOD this is an external five node .PERIOD so it's got five keys .PERIOD it's got ,COMMA room for one more temporary one ,COMMA and then what will happen is ,COMMA when you insert into a full node ,COMMA it'll split in the same as before .PERIOD and then we'll pass the s plit up causing a split up higher so the red keys in the internal nodes are copies of keys down below that direct the search .PERIOD and it is that ,COMMA that's a little extra detail .PERIOD it just makes the implementation a little bit easier and that's the way it's usually done .PERIOD so but for now the main idea is that it's like a 233 except that we allow way more keys per node .PERIOD and then when a node gets filled it splits .PERIOD into two so a node is always between half full and full .PERIOD so it's in 1000 ,COMMA it splits in two .PERIOD and then each side has 500 .PERIOD and then we can use ,COMMA that property of the trees ,COMMA in the analysis to ,COMMA show that ,COMMA it's not going to be very many probes to get to any key .PERIOD so the ,COMMA search is ,COMMA you know ,COMMA just the same as we've been doing ,COMMA just generalized .PERIOD there's a list of keys at every internal node and that key ,COMMA tells you that ,COMMA then links for every key that give you ,COMMA a place where your key would have to be .PERIOD so ,COMMA this link is for all the keys in the b tree that are between this key and the next one and in every case ,COMMA it's that way .PERIOD so if we're looking for e .PERIOD b and this b tree would go down the left link .PERIOD and then looking on the second link cuz e is between d and h .PERIOD and that's just the way it organized .PERIOD and then when you get to an external node you just look for and so that's a ,COMMA that's the all searches terminated in external node ,COMMA in other words that's just a generalization of what we just did .PERIOD and insertion ,COMMA works the same way ,COMMA where we get to the bottom ,COMMA and then ,COMMA and then we split .PERIOD so let's look at just inserting a into this b tree .PERIOD it comes into the node on the left .PERIOD and then that makes that temporarily overful .PERIOD it's got one too many .PERIOD so we split it into two nodes .PERIOD and that causes us to add a new entry into this internal ,COMMA node .PERIOD in this case ,COMMA it's the c ,COMMA which is the smallest one in this new page .PERIOD and that had to be added .PERIOD and we can move all those over .PERIOD there's plenty of time by the memory model .PERIOD we're only counting the number of times we access the pages .PERIOD we get to move things around for free .PERIOD and you could have some hybrid struc ture where you use something different for the internal model .PERIOD but usually it's fine just to do that .PERIOD now that one becomes overfull .PERIOD so it has to split and we have to create a new route ,COMMA just in the same way as we've been doing .PERIOD so without seeing all the details yo can understand that the same basic idea is going to work in this situation where we're dealing with much ,COMMA much more memory .PERIOD and so the end result is that a search or an insertion in a b -DASH tree in a order m ,COMMA that's where we're putting m keys per page ,COMMA requires between log base m  -DASH  1n and log .PERIOD base m over two m probes and that's going to be a really small number ,COMMA so say m is a 1000 ,COMMA log base m over two is ,COMMA is log base 500 .PERIOD so what power do you have to raise 500 to get bigger than n ?QUESTIONMARK in practice that's going to be like four or five .PERIOD and we can keep the root page in memory so that it means ,COMMA for any conceivable application ,COMMA you can get to any piece of data .PERIOD even if it's trillions of ,COMMA of pieces of data in this huge ,COMMA huge file .PERIOD you can get to any one with only five or six probes .PERIOD that's quite amazing .PERIOD it's really an astounding example of algorithmic technology .PERIOD doing something that ,COMMA you wouldn't really ,COMMA necessarily think that you could do so easily .PERIOD maintain a dynamic search symbol table with trillions of keys ,COMMA so that you can get to any key just by looking five or six places but that's what b -DASH trees provide for us .PERIOD this is a simulation that shows a ,COMMA a growing b -DASH tree so when a page ,COMMA at the top ,COMMA there's just one page that fills up .PERIOD when it fills up ,COMMA it's red ,COMMA and that splits into two half pages and then keys get added on one side or the other so each .PERIOD lying in this table some pages getting a new key and eventually one of them fills up and splits .PERIOD now we have three pages and we keep going eventually one of them fills up and splits .PERIOD now we have four pages and now this time the first one fills up and splits and so forth .PERIOD so the black is the occupied part of the page .PERIOD the white is the unoccupied part .PERIOD and the full page about to split then right below there's two pages .PERIOD s o this shows the process of building a large b -DASH tree .PERIOD and that and you can see the amount of black .PERIOD it's kind of half empty .PERIOD it's a little more than half empty usually now ,COMMA as this shows .PERIOD and ,COMMA and people have variants of these algorithms that keep it more ,COMMA much more than half empty if that kind of space is a ,COMMA is a consideration .PERIOD so ,COMMA as i've mentioned ,COMMA red black trees and b -DASH trees are widely used as system symbol tables .PERIOD the java implementation of tree map and tree set is red black trees ,COMMA c++ ,COMMA the standard template library uses ,COMMA red black trees .PERIOD and it's also ,COMMA used in the ,COMMA linux kernel ,COMMA and in many other systems .PERIOD b -DASH trees ,COMMA there's many different variants that ,COMMA give different characteristics of ,COMMA space usage and other characteristics .PERIOD in most databases ,COMMA nowadays that ,COMMA that you might use .PERIOD sql or oracles database and others ,COMMA are based on ,COMMA some variant of b -DASH trees because they're so ,COMMA so effective .PERIOD but you really know that your data structure and algorithm is used by a lot of people when it appears in the popular culture .PERIOD my friend philippe flajolet who recently died was a famous french mathematician send me an e -DASH mail late one night .PERIOD he was quite excited because he was watching a re -DASH run on ,COMMA of an english actually canadian tv show on french tv .PERIOD i didn't know he spend his time doing that but he was very excited because he saw this clip .PERIOD >> it was the red door again .PERIOD >> i thought the red door was the storage container .PERIOD >> but it wasn't red anymore ,COMMA it was black .PERIOD >> so red turning to black means what ?QUESTIONMARK >> budget deficits ,COMMA red ink ,COMMA black ink .PERIOD >> it could be from a binary search tree .PERIOD the red black tree tracks every simple path from a node to a descendant leaf that has the same number of black nodes .PERIOD >> does that help you with the ladies ?QUESTIONMARK >> so not only is there some excitement in that dialogue but it's also technically correct which you don't often find with math in popular culture of computer science .PERIOD a red black tree tracks every simple path from a node to a descendant leaf with the same number of black nodes they got that rig ht .PERIOD and that's also true of b -DASH trees and both of these methods are very effective and widely use .PERIOD 
now ,COMMA first we're going to look at the process of simulating the operation of an nfa .PERIOD and in order to do that ,COMMA we have to look at the representation .PERIOD so for state names we're just going to use the integers from zero to n and those are just indexes into the regular expression strain with one extra one for the except state .PERIOD so ,COMMA if re has m characters ,COMMA we've got m plus one states .PERIOD and then ,COMMA we forget the match -DASH transitions .PERIOD so for with this ,COMMA we'll just keep the regular expression in an array .PERIOD and then for characters that are not metacharacters that are just characters from the alphabet there's match -DASH transition just to the next element just to add one ,COMMA so that's an implicit representation of the match -DASH transitions .PERIOD and then the next thing is the epsilon transitions .PERIOD so ,COMMA since there might be multiple edges leaving from any given state and it is directed ,COMMA it always says ,COMMA go from this state to another one we'll use directed graph .PERIOD so we just have a bunch of edges with given vertex names .PERIOD and that's convenient .PERIOD that's what we use for our graph processing algorithms ,COMMA was indexes for vertex names .PERIOD so ,COMMA this is totally well -DASH suited to building a digraph using the basic digraph processing methods that we talked about when doing graph processing .PERIOD so ,COMMA that's our representation and then given that representation it's very ,COMMA you know ,COMMA straightforward to find out for any state what are the possible next states and if it's got a character in a possible next state is to match a character in angle up one otherwise it's the vertices that they are pointed to by the edges and its adjacency list does have epsilon transitions .PERIOD so ,COMMA let's take a look at just given that basic idea ,COMMA that we can always get to the transition from any given state how we're going to do a simulation ?QUESTIONMARK and so ,COMMA the idea is summarized by this diagram here .PERIOD what ,COMMA what we're going to do is at every step each text character that the machine does read ,COMMA we're going to keep track of the ,COMMA the set of all possible states where the nfa could be after reading in the i ,COMMA i text ch aracter .PERIOD so ,COMMA say ,COMMA we've done that and ,COMMA you know ,COMMA there's this is just a schematic .PERIOD so ,COMMA there's a bunch of states that we could get to after reading i characters .PERIOD now in some of those states they ,COMMA they are labeled with characters .PERIOD and if that character matches our text character ,COMMA they can take us to another state .PERIOD so ,COMMA say ,COMMA in this case ,COMMA there is three of them that matches and the other one has some other character or different character and it couldn't take us to another state .PERIOD so ,COMMA that gives us a all the possible states that you could be in just after reading the i plus first symbol .PERIOD and now ,COMMA what we do is take a look at the possible null transitions that we could go to from those states .PERIOD and that might take us to lots of other states .PERIOD but that's all the machine could do .PERIOD it could read a character .PERIOD and then it can take a bunch of null transitions .PERIOD and but that's all it knows how to do .PERIOD and that will give us all the possible states that it could be in after reading i1 plus one symbols .PERIOD and then ,COMMA we just continue in that from every one of those states .PERIOD some of them match the character match the character ,COMMA and then ,COMMA look at all the epsilon transitions .PERIOD so ,COMMA that's the basic idea is to simply keep track of all possible states the nfa could be in after reading the first i text characters .PERIOD so the only thing that's complicated is how do we get all the states that we could reach by epsilon transition .PERIOD and we'll look at that in just a second .PERIOD it's actually very straightforward .PERIOD but let's look at a demo first .PERIOD so this is our machine for a<i>b or a ,COMMA or ac followed by d .PERIOD and let's suppose</i> it has this input .PERIOD so ,COMMA let's do this demo .PERIOD okay .PERIOD so ,COMMA we're going to ,COMMA to check if the input is matching the pattern .PERIOD we're going to start the machine in state zero and so the zero is one of the states ,COMMA you could reach from the start .PERIOD and then now we want to get to all the states that you could reach by epsilon transitions from the start .PERIOD and so there's a bunch of them so we could go to one and from one ,COMMA we could go to either two or six .PERIOD from two ,COMMA we could go to three .PERIOD from three ,COMMA we could go to two or four .PERIOD so we could get to all those places from the start without scanning a single character .PERIOD so ,COMMA zero ,COMMA one ,COMMA two ,COMMA three ,COMMA four ,COMMA and six the machine could be in any one of those states before it scans a single character .PERIOD so ,COMMA that's where it could be after zero characters .PERIOD but what about now after the first character ?QUESTIONMARK well ,COMMA out of those states only two and six involve matching an a .PERIOD so the only thing that could happen next to read ,COMMA the machine could do next ,COMMA is to read the a in either state two or state six .PERIOD i know there's going to be match -DASH transitions .PERIOD so in the first case ,COMMA it goes to three and ,COMMA and the second case ,COMMA it goes to seven .PERIOD so ,COMMA the stead of states ,COMMA it can be reachable just after matching the a ,COMMA is just three and seven .PERIOD but now from those states it might get somewhere with epsilon transitions .PERIOD we have to look at the epsilon transition graphs and what states could it go to from epsilon transitions from these two .PERIOD well ,COMMA from three ,COMMA seven has nowhere to go ,COMMA and from three it could go either to two or four .PERIOD from two ,COMMA it could go back to three so the total number states that it could be after matching a is two ,COMMA three ,COMMA four ,COMMA and seven .PERIOD and so that's one step .PERIOD we've matched one character ,COMMA and we have kept track of all possible states the machine could be in after matching that character .PERIOD now ,COMMA what about the next character ?QUESTIONMARK you can see ,COMMA these four states take us all different ways .PERIOD you could have an a ,COMMA a b ,COMMA or a c next ,COMMA and it could get somewhere .PERIOD but it happens ,COMMA we have an a ,COMMA and the only one of these states that matches an a is two .PERIOD so ,COMMA after matching the second a the only place it could get to is three .PERIOD and so that now ,COMMA we have only one state to work with .PERIOD but where could we get with via epsilon transitions ,COMMA from three ?QUESTIONMARK and so ,COMMA well ,COMMA you can go from three to four or two .PERIOD well ,COMMA we did this before .PERIOD and then ,COMMA from two back to three .PERIOD so ,COMMA we could be in two ,COMMA three ,COMMA or four after matching two as .PERIOD so that's all the possible states we could be in after mat ch ,COMMA after matching the two as .PERIOD now ,COMMA what's next is b ,COMMA only state four matches to b ,COMMA so the only place we could be right after matching the b is in state five .PERIOD and that's after matching the b ,COMMA now what about epsilon transitions ?QUESTIONMARK well ,COMMA state five has an epsilon transition to state eight .PERIOD so we could take that one and eight has got one to nine .PERIOD so it could be an either five ,COMMA eight ,COMMA or nine after matching aab and then following all of the epsilon transitions .PERIOD but its really important to keep in mind ,COMMA there's no other state the machine could be and it doesn't have any other way to get to after matching aab it couldn't get state seven or six or two .PERIOD those are the only possible states it could be in .PERIOD since we're ,COMMA each time ,COMMA progressing through the input we're making progress to the end for sure .PERIOD so now to finish up this example the only state out of those three that matches d is state nine .PERIOD and so ,COMMA that's a match -DASH transition that reads the d .PERIOD and the only place you could be after matching aabd is state ten .PERIOD and then now ,COMMA we follow epsilon transitions .PERIOD and that epsilon transition could take us to eleven .PERIOD so ,COMMA the only place that machine could be after matching abd is ten or eleven .PERIOD now ,COMMA our condition on whether we accept the string or not is whether we could get to the accept state ,COMMA and in this case ,COMMA we could .PERIOD it is possible for the machine to get from zero to the accept state and read all the input characters so that simulation is approved ,COMMA that the machine accepts the input aabd when simulated its operation ,COMMA all possible ways and we managed to find the accept state .PERIOD of course ,COMMA if we had tried some input that the machine doesn't recognize ,COMMA we'd get stuck somewhere and either not get through the input or have no possible states it could be in .PERIOD and that would be a proof that it does not accept since we try all possibilities .PERIOD so ,COMMA the only thing that's complicated in this computation is reachability .PERIOD but actually from our study of digraphs this is the ,COMMA one of the simplest problems that we discussed .PERIOD what we really discussed was single source reachability .PERIOD that is given the source ,COMMA can you find all vertices that are reachable from that source ?QUESTIONMARK and that was depth firts search .PERIOD so we have very simple depth first search but also in that api we put vertices reachable from a set of sources ,COMMA so an iterable of sources and so can we get the ,COMMA the ,COMMA what we really need is all vertices reachable from a given source from its source set of vertices .PERIOD and it's easy using dfs .PERIOD you just run it from each of the sources and you don't unmark the ones that you get to and that stops dfs from revisiting any vertices and it marks all the vertices that you could get to from that set .PERIOD so ,COMMA its just a simple extension of our dfs implementation .PERIOD it's going to run in time proportional to the number of edges plus number of vertices in the digraph and it's a very simple computation digraph reachability .PERIOD so given that capability which we discussed in graph processing the implementation of in a ,COMMA in the nfa stimulation is very straightforward .PERIOD so this is a ,COMMA a data type that implements the nfa .PERIOD so ,COMMA we have a constructor that takes a regular expression as its argument .PERIOD and it's going to build the nfa and its got a ,COMMA a method to build the digraph that we'll talk about later but ,COMMA but its also got a ,COMMA a client method recognizes where the client can after the nfa is constructed ,COMMA it can that they could text string and return true or false by simulating the operation .PERIOD so we'll take a look at the building the digraph in a second but the one that we're talking about now is simulating the operation of the nfa once it's built for a given text string .PERIOD and this is the complete code and it's expresses in code what we talked about in english during the demo .PERIOD it's amazingly compact implementation of this idea of simulating the operation of an nfa .PERIOD so we keep a ,COMMA a bag of integers or set of integers called pc ,COMMA that's kind of like program counter .PERIOD so ,COMMA that's the set of all possible states that the nfa could be in .PERIOD so and we build a dfs from our epsilon transition graph .PERIOD so the first thing that we do is do a ,COMMA a ,COMMA a for we put on to the ,COMMA the pc all the states that you could get to from state zero .PERIOD so that's build a dfs that marks all the states you could get to from state zero and then go through and put all of the states on ,COMMA on to the pc .PERIOD so ,COMMA that's our starting point ,COMMA is all the places that you could get to via epsilon transitions from state zero .PERIOD so now during the execution of this for loop pc is the thing that we have all the states that you could reach after scanning past the ith character ,COMMA so we initialize for the 0th character .PERIOD and then all we do is for everyone one of those states well ,COMMA first thing we do is test if we reach the accept state .PERIOD if we reach the accept state we're going to have nothing ,COMMA we're ,COMMA we have nothing left to do .PERIOD if we have a match ,COMMA that is ,COMMA if the a character in the re if that state position matches our ith text character ,COMMA then we're going to keep another set of possible states called match .PERIOD so ,COMMA those are the ones you could get to just after matching a text character .PERIOD and so ,COMMA we'll just add v .PERIOD plus one .PERIOD so ,COMMA if we find a matching character at v ,COMMA we just go to v plus one ,COMMA that's the implicit match -DASH transition .PERIOD and here ,COMMA we'll throw in ,COMMA don't care ,COMMA cuz it's so easy to do if the regular ,COMMA regular expressions says ,COMMA i don't care what character matches then throw that one to .PERIOD so this just adds don't care to the implementation .PERIOD and so we do that for all states in our pc in the states we can ,COMMA can be in just before ,COMMA just while looking at the ith character .PERIOD if we have a match then we put the next states into a match .PERIOD so now ,COMMA what we have to do is follow the ,COMMA epsilon transitions from match .PERIOD so now ,COMMA we build another dfs which gives us marks all the states that you could reach by starting with any of the states in match .PERIOD and now when we build a new pc ,COMMA we'll just set pc to a new ,COMMA new bag ,COMMA and put all the marked states for that search .PERIOD so ,COMMA those are all the ones that you could get to via epsilon transitions right after a match ,COMMA and put that in the pc .PERIOD now .PERIOD we have a new pc .PERIOD and we've r ead the ith ,COMMA character and we go to the i plus first character ,COMMA and simply continue .PERIOD so ,COMMA when we're done with all of the text then we can test if we made it to the accept state .PERIOD that is ,COMMA if any of the states in our current set of states is the accept state ,COMMA we return true .PERIOD and if we didn't get to the accept state after all of that ,COMMA we return false .PERIOD a very compact code that takes advantage of our implementation of reachability for digraphs in a ,COMMA a reasonable way to simulate the operation of an nfa by keeping track of all reachable states .PERIOD so ,COMMA what about the n analysis ?QUESTIONMARK well it's easy to see that the not difficult to see that if our text is n -DASH character and we have an m -DASH character pattern .PERIOD the worst that can happen is that we take time proportional to m times n .PERIOD and that's just because for everyone of the characters we have a set of states ,COMMA a set of all possible states .PERIOD and we iterate through that set of possible states a few times .PERIOD we even run dfs on it ,COMMA but that's linear .PERIOD and there's the extra point that the number of edges that we have is less than 3m .PERIOD no node has more than three edges leaving it .PERIOD so the total amount of time for each character is proportional to m and there's n -DASH characters ,COMMA so there are any proportional to m times n .PERIOD so ,COMMA that's the ,COMMA the cost of the simulation .PERIOD of course a lot of times ,COMMA the size of the set of states is much smaller than that .PERIOD so in many real world problems ,COMMA it's closer to linear .PERIOD that's nfa simulation .PERIOD 
so the final step in our regular refreshing pattern matching algorithm is to construct and then determine the thick finite automaton .PERIOD so how do we go ahead and do that ?QUESTIONMARK and this is an integral part of the algorithm .PERIOD but we pretty much have got all the pieces ,COMMA but really what makes it intricate is that if ,COMMA an illustration of what a programming line has to do to when trying understand your program ,COMMA what your programming does .PERIOD what we need to do is somehow understand what's in the regular expression and then take that information and use it to build the machine .PERIOD now ,COMMA that's what parson ,COMMA that's called parsoning .PERIOD to try to figure out the structure of your program or regular expression and then ,COMMA do something with it .PERIOD and this is a simple example of that but useful as well .PERIOD so the first thing that needs clear what to do .PERIOD so we're going to have one state per character as we talked about before ,COMMA so that's easy to set up .PERIOD and then the match transition edges .PERIOD if a state contains a character in the alphabet ,COMMA we just put in a match transition to the next state .PERIOD and actually ,COMMA that's implicit in our algorithm .PERIOD so now what about other things ?QUESTIONMARK well ,COMMA if we have for any parenthesis we find ,COMMA we'll just put in an epsilon transition to the next state .PERIOD so our machines all have that .PERIOD now closure is one that you know ,COMMA has quite a bit of action .PERIOD so ,COMMA for every star let's look at the one that is just a one character closure .PERIOD so we have a single character closure .PERIOD so this is a star .PERIOD and ,COMMA and what we need is epsilon transitions for the star that allow the machine to go and pick up well ,COMMA there has ,COMMA there has to be one ,COMMA an epsilon transition that goes out to the star to cover the case ,COMMA so we have zero matches .PERIOD and then after zero ,COMMA then we want to go back to have as many matches as we want before taking the sorry ,COMMA take the match transition .PERIOD we're going to be able to go back and match as many as we want before going up to the next .PERIOD so for star ,COMMA we have to add three epsilon transitions .PERIOD the one that goes if you have a character in i and a star in i + one  ,COMMA you have to add these edges going both ways and then an edge out to the next character for ,COMMA to get out of the star .PERIOD and that works also if there's a closure involving parentheses .PERIOD if the character before the star is a parenthesis then we want to add the same kind of mechanism from the parenthesis ,COMMA go out and skip the whole thing to cover the zero match case or go back and match as many times as we need to match and then finally ,COMMA go out .PERIOD so there's three edges have to be added for each star and defined and well defined what they are .PERIOD and then or there's two epsilon transition edges that we have to add .PERIOD and that is to allow the machine to skip the first part of the expression and do the second or to skip the ,COMMA do the first part of the expression and skp the second .PERIOD so if we keep track of where the left parenthesis is when we end the or operator when we get to the right parenthesis ,COMMA we have all the information that we need in order to be able to add those two edges .PERIOD so those are the edges that we have to put together to build the nfa .PERIOD and the trick is keeping track of the information of where the previous operators are particularly since parentheses can be nested .PERIOD but this is not that difficult to do because we have a mechanism for doing that .PERIOD how to ,COMMA to ,COMMA remember where the left parentheses are and ,COMMA and the or and that's to maintain a push down stack .PERIOD and so the ,COMMA the algorithm is to push left parenthesis in or onto the stack .PERIOD and then when we hit right parenthesis ,COMMA then we can pop of course the corresponding left parenthesis and maybe ,COMMA maybe the or and that gives us all the information that we need to add the epsilon transition edges and so the stack takes care of the nesting of the parenthesis .PERIOD and when you think about it ,COMMA this is a very natural mechanism to use very similar to the early programs that we wrote using dexter's algorithms for medic expressions .PERIOD so let's look at a demo and you'll see how that works .PERIOD so we're going to build the machine corresponding to this regular expression and it's the one that we've been working with .PERIOD and so what we do is just go from left to right through the regular expression and  ,COMMA take the appropriate action ,COMMA for each character .PERIOD so for left parenthesis .PERIOD there's always an epsilon transition from ,COMMA left parenthesis to the next state .PERIOD and then the other thing is ,COMMA if you remember that last parenthesis on the push down stack .PERIOD so we put the index zero onto the stack .PERIOD so now we got another left parenthesis again ,COMMA we put the epsilon transition on ,COMMA and we push that one onto the stack .PERIOD so now ,COMMA if we have an alphabet symbol what we need to do is add the match transition to the next state .PERIOD and then there's a couple ways to this ,COMMA but one easy way ,COMMA in this case ,COMMA is to just look for the star and if you see that the next one is a star then you've got everything you need for the epsilon transitions .PERIOD so ,COMMA in this case the next one is a star so we'll add those epsilon transitions from the from two to three and from three to two .PERIOD and adding epsilon transitions ,COMMA that's just ,COMMA adding edges to the phi graph .PERIOD then with closure that just takes us to the next state and we took care of the other two earlier .PERIOD now we have an alphabet symbol ,COMMA that's the b ,COMMA so we just put in the transition to the next state .PERIOD now we have an or .PERIOD all we do for an or is put it on the stack .PERIOD now it's got for a ,COMMA we got the match transition ,COMMA for c ,COMMA we got the match transition .PERIOD and now we have the first right parenthesis .PERIOD so this right parenthesis so one thing we ,COMMA the first thing we do is an epsilon period just to get it over to the next state .PERIOD but then we go to the put down stack and we pop .PERIOD and if the thing at the top of the stack is an or that's one thing ,COMMA piece information that we need .PERIOD the other piece of information we need is the position of the corresponding left parenthesis and that'll be the next thing on the stack .PERIOD so we add the transition we pop the or off the stack and we pop the or on and off the stack and that gives us the information that we need to put in the epsilon transition .PERIOD we're at stage eight .PERIOD we put one from the or to eight ,COMMA and then we put one from the one to the or + one .PERIOD there's the ,COMMA that's what we need to do .PERIOD and ,COMMA look for a star the same way as we did for one character .PERIOD now in this case we have a no star .PERIOD so we just do the finite alphabet symbol and we add the match transition .PERIOD and now we have the right parenthesis and so we pop the corresponding left parenthesis .PERIOD and it's not an or .PERIOD so in this case you know ,COMMA there's nothing to do except do the epsilon transition to the accept state .PERIOD so that's the process for each character in the regular expression ,COMMA it's well defined what we do .PERIOD left parenthesis and or we put onto the stack characters we do the match transitions and right parenthesis we do a pop and if it's an or ,COMMA put a numeric transitions .PERIOD otherwise we do the look at to check for the star .PERIOD and that's the demo of the construction for nondeterministic finite state of phenomena .PERIOD so ,COMMA it's actually a remarkably simple process .PERIOD we figured out what to do with each character in the regular expression and this is the second part of the regular expression pattern -DASH matching algorithm ,COMMA which is constructing the nfa .PERIOD and again it's a remarkably little code .PERIOD so it's a routine that builds the epsilon transition .PERIOD this is a part of the nfa .PERIOD so it's got the regular expression  .PERIOD yes ,COMMA a useless variable to refer to .PERIOD and it's going to build a new diagraph with one state ,COMMA one extra state ,COMMA the accept state m+11 if the rate description has m characters .PERIOD so ,COMMA the and then we maintain a stack which is just integers .PERIOD and for every character in a regular expression we do the processing that we just described .PERIOD if it's a left parenthesis or an or we just put it on to the stack .PERIOD and that's it .PERIOD if it's a right parenthesis then we pop .PERIOD if that pop is an or ,COMMA then we put in the two edges to skip the or .PERIOD and otherwise ,COMMA we look ahead and do the closure exactly as described .PERIOD if it's any one of the metal symbols ,COMMA we just put in a next line transition to the next edge .PERIOD and then a remarkably little code to go ahead and construct the nfa from a given regular expression .PERIOD and so ,COMMA the final step is the analysis that's going to take time and space proportional to m .PERIOD and that's immediate ,COMMA because for every character we do most of two stack operations and add at most three epsilon transitions .PERIOD and ,COMMA this is a generous upper bound ,COMMA time and space proportional to the number of characters in the regular expression .PERIOD so that's how we get the nfa 
so that's a regular expression ,COMMA pattern -DASH matching that we implement by constructing and simulating a nondeterministic finite state machine .PERIOD really ,COMMA one of the most ingenious algorithms that we look at in this course .PERIOD next we'll look at some applications .PERIOD so ,COMMA the most famous is called ,COMMA grep and this is what ken thompson implemented in the initial unix .PERIOD and it was a very ,COMMA very important tool for programmers working on the tiny really tiny ,COMMA computers that were available at that time .PERIOD it was really important to be able to ask questions about programs of this type .PERIOD and it allowed the development of bigger and bigger computational infrastructure like the unix operating system that's still widely used today .PERIOD so grep was a simple command .PERIOD what you want to do is take a regular expression as a command line argument and print the lines from standard input to have some substring that's matched by the regular expression .PERIOD programmers use that all the time to try to figure out what variables they use in what part of what programming .PERIOD many programmers ,COMMA use grep every day still today .PERIOD and here's how we implement it using the code that you know ,COMMA we've talked about so far .PERIOD so first thing is ,COMMA is create the re that we're going to match to make it more like subscreen search .PERIOD we just care for the things in there anywhere at all .PERIOD so we put a dot star before and after and we enclose it in parenthesis just cuz ,COMMA cuz our code simplified ,COMMA if our re's enclosed in parenthesis .PERIOD build an nfa from that regular expression .PERIOD and then as long as there's an align in standard input ,COMMA we read the line and we ask if the nfa recognizes it .PERIOD so the constructor builds the nfa and recognizes is the simulation .PERIOD if one nfa on that string ,COMMA if it's there ,COMMA you print it out .PERIOD if it doesn't recognize it the final accept state is not in the substrateq you could get to ,COMMA for that string ,COMMA it won't print it out .PERIOD and we just do that for every line in the input .PERIOD pretty ,COMMA amazingly simple implementation ,COMMA although ,COMMA quite elegant ,COMMA conceptually .PERIOD it's a very ,COMMA elegant ,COMMA and ,COMMA and ,COMMA ef ficient permutation of this basic process .PERIOD absolutely correct .PERIOD so ,COMMA in the bottom line for it is in the worst case it's the same as for the ,COMMA elementary substring search algorithm that we looked at when we first started talking about string searching and it's really amazing .PERIOD the brute force algorithm that you come up with of tri -DASH matching the string ,COMMA the single string at every character position .PERIOD the worst case is time proportional to m times n .PERIOD but here we have a regular expression which specifies an infinite set of patterns .PERIOD and we can tell if any one of those infinite set of patterns is matched by our string in the same worst case kind .PERIOD it's really an amazing algorithm that's ken thompson ,COMMA grep .PERIOD once you have grep available ,COMMA then crossword puzzles become a lot easier .PERIOD a lot of it's standard in unix to a dictionary or if you can't find one on your system ,COMMA we have it on the book site that simply has all the words on the dictionary ,COMMA all the lower case one per line .PERIOD and if you have a crossword puzzle where you're missing a couple of letters you can just grep for in words .PERIODtxt for and ,COMMA and leave ,COMMA don't care is for those letters ,COMMA and it'll tell you the ,COMMA the things you can put in there .PERIOD in this case it's the one that has exactly that many letters .PERIOD it's stricter .PERIOD so that's a typical ,COMMA application and i'm sure lots of people use it that way now .PERIOD now for industrial strength nowadays there's ,COMMA a lot of things that people expect when using regular expressions .PERIOD our implementation doesn't have character classes .PERIOD it doesn't have the extra meta characters like plus and other things .PERIOD the idea of capturing which actually get the part of the string that satisfies ,COMMA that matches the regular expression of various different extensions of closure .PERIOD and then there's the idea of greedy versus reluctant matching .PERIOD so ,COMMA for example ,COMMA if you have a regular expression ,COMMA blink .PERIOD /blink which you'd find in hml for the blinking text .PERIOD there's two possibilities .PERIOD so called reluctant matching would be like the tightest match ,COMMA matches that you'd get .PERIOD you h ave two of them but then ,COMMA the greedy matching would get as much text as it possibly could in different applications ,COMMA you might want different things .PERIOD capturing means give me the substring that matches .PERIOD and so those things are not difficult to add to the basic code that we've done and all that has to be in industrial strength implementation .PERIOD many programming systems have grep that have all these sorts of things .PERIOD again originated ,COMMA originated in unix in the 1970s and nowadays ,COMMA every language has to have some kind of extended regular expression facility .PERIOD there's ,COMMA language unix commands like grep and lock ,COMMA and old programmer's tools like eamcs .PERIOD there's modern programmer's tools like perl or php python and javascript .PERIOD all of these things have regular expression processing .PERIOD and so ,COMMA programmers demand this facility nowadays .PERIOD in fact ,COMMA perl is an example of an entire language that's built on regular expressions .PERIOD and again there is various command line options you can say run it for each line and you have replacement facilities and many other things that is ,COMMA is certainly a worthwhile facility for any programmer to use nowadays and many programmers use these things .PERIOD now to ,COMMA again to go back to the slide that was filled up with a regular expression you want to use these things wisely there are definitely computational tasks ,COMMA where it might be better to just write a java program ,COMMA not try to use a regular expression .PERIOD so every tool has it's place and try not to do everything with the regular expression language .PERIOD in java various facilities ,COMMA are built in to different parts of the java library .PERIOD and so and understanding how the implementation works .PERIOD you can understand how to use these .PERIOD so one simple ,COMMA implementation is in the java string library .PERIOD so if there's a ,COMMA you have a string called input and another string called regexp and the matches method in the string library will return the bullion that says if the strings in the line which you know ,COMMA described by the regular expression .PERIOD so this is just a simple stub that i call validate that takes a regular expression and an input from the command line ,COMMA unless you know if the ,COMMA the ,COMMA the string is in the line that's described by the regular expression .PERIOD so ,COMMA like as i dent one ,COMMA two ,COMMA three ,COMMA and leave a little java identifier giving that regexp legal java identifiers that we looked at earlier and so forth .PERIOD so that's one thing that's built in to java .PERIOD so in java programs you can use regular expression pattern -DASH matching in that simple way .PERIOD another thing ,COMMA another kind of task that is better handled with a that's handled with this java implementation as the idea of harvesting .PERIOD so we want to print all the sub strings of the input that match a given re .PERIOD so ,COMMA say this is the fragile x syndrome we want to harvest all the patterns from the dna that ,COMMA have this property that starts with gcg and ends with ctg and has any number of these triple gcg or cth ,COMMA triples inside .PERIOD or maybe you want to harvest the same program harvests all the e -DASH mail addresses from a web page .PERIOD that's kind of amazing that the same program can work for two such diverse tasks .PERIOD that's ,COMMA that's a testimony to the utility of this abstraction .PERIOD so how do we do harvesting within java ?QUESTIONMARK well it's got a ,COMMA java has two classes called pattern and matcher that implement regular expression pattern -DASH matching basically by ,COMMA as we did ,COMMA separating the construction of the machine from the simulation .PERIOD so this is what the code looks like for harvester .PERIOD we take our regular expression as the first command line argument and we setup an input stream from the second command line argument ,COMMA can be a file or a webpage .PERIOD and then we read the input stream .PERIOD then we use java's pattern class ,COMMA to ,COMMA to build a pattern which essentially is an nfa that is constructed from the regular expression .PERIOD in the pattern class ,COMMA has a method called a matcher and that essentially creates an nfa stimulator from that nfa for that text .PERIOD and ,COMMA so that's a machine that not only does matching in the way that we did ,COMMA but it also finds a match and keeps track of what's called group ,COMMA which is the substring that caus e the match .PERIOD so it adds that extra code to do these things that are useful in this illustrates one line of code for each one of those facilities .PERIOD that is ,COMMA create the nfa ,COMMA create the simulator find the next match and get the substring that cause the match .PERIOD that's an implementation of harvester that can go through and do things like get fragile x indicators from a chromosome or get e -DASH mail addresses from a web page .PERIOD and of course ,COMMA you could extend that to print out the index of where they occur and other things .PERIOD this is a very powerful facility to have in a programming language and java certainly has it .PERIOD now there is a caveat about this that's really important .PERIOD this introduces the idea that we talked about with hashing and this is another example of the algorithmic complexity attack .PERIOD and that is ,COMMA if you know something about the way that a website is implemented at facility .PERIOD in this case ,COMMA it's possible to implement regular expression pattern -DASH matching in a not so efficient way and atypically ,COMMA actually ,COMMA the implementations that we see out in the wild like the ones in unix or ,COMMA or java or perl ,COMMA do not guarantee quadratic performance the way we have .PERIOD they do not guarantee the running time's going to be proportional to the product or the length of the string and the length of the regular expression .PERIOD in fact ,COMMA they go exponential .PERIOD again ,COMMA going back to kleene's theorem ,COMMA it's relatively simple to prove .PERIOD it's not so difficult to develop an implementation that is more like kleene's theorem ,COMMA but it can take exponential time .PERIOD and you can try it yourself in java or perl ,COMMA if you try to look for a match for this regular expression in a string like that ,COMMA you add just a couple of characters to the string then running time will double .PERIOD again ,COMMA going back to our algorithmic performance lectures .PERIOD if that's what happens ,COMMA if i just add one thing and my running time doubles that means i have exponential time .PERIOD and so if i'm using a facility that has one of these exponential time implementations then ,COMMA this is ,COMMA what's called a spamassassin reg ular expression .PERIOD it's going to take exponential time on certain e -DASH mail addresses and ,COMMA somebody can create trouble by sending such addresses to a mail server the mail server will take exponential time just trying to determine if it's spam or not .PERIOD and by having an inefficient algorithm ,COMMA a server like that is definitely subject to such a tax .PERIOD generally ,COMMA you don't want to have exponential algorithms you particularly don't want to have exponential algorithms if you have arbitrary clients out there that can cause trouble for you .PERIOD a another pitfall is things that kind of look like regular expressions but aren't actually regular expressions .PERIOD so it's common to have the backslash one notation .PERIOD so that's supposed to match the self expression that was matched earlier .PERIOD so this thing dot plus back slash one is a string that is two copies of something ,COMMA like couscous or with at least one character .PERIOD and this one is a similar one .PERIOD this one actually is number of ones is not prime .PERIOD it matches ,COMMA so you can write pretty sophisticated computational thing just with these little references .PERIOD but there's a problem and it's a fundamental problem ,COMMA is that  .PERIOD that kinds of languages of the sets of strings that you specify with such notation are not regular .PERIOD that is ,COMMA like i said ,COMMA it's a point you can't write a regular expression to specify .PERIOD and so these are examples like strings to the form ww for sum w ,COMMA you can't write a regular expression that ,COMMA will recognize ,COMMA that will describe all such strings .PERIOD there are even scientific applications like complemented palindromes .PERIOD so that's like a palindrome ,COMMA but also complements a's to t's and c's and g's .PERIOD so that's another ,COMMA example .PERIOD and if they're not regular ,COMMA then kleene's theorem doesn't hold .PERIOD there's no nfa that corresponds to them ,COMMA and in fact we're ,COMMA we'll talk in a couple of lectures about intractability .PERIOD in fact ,COMMA nobody knows an efficient method for guaranteeing performance when you have back references .PERIOD so ,COMMA if you're allowing back references you're pretty much subject to performance attacks like the one we just mentioned .PERIOD and that's where ,COMMA we'll will finish up this lecture .PERIOD this is an amazingly elegant ,COMMA and efficient ,COMMA and ingenious algorithm ,COMMA and it's based on the theory of computation that has been studied since the 1930's and it's the basis for much of the programming ,COMMA programming languages that we do .PERIOD it's really worth understanding this theory and grep is a wonderful example of why it's important to understand theory like this .PERIOD it really it takes us to the next level of algorithms and that's writing programs that translate a program to machine code .PERIOD actually ,COMMA what we've looked at ,COMMA both for kmp and for grep are examples of compiler ,COMMA they're simple examples of compiler .PERIOD for kmp ,COMMA we took a string and we built a dfa .PERIOD for grep ,COMMA we took an re and we built an nfa .PERIOD and all java c does is take java language code and translate it to a byte code .PERIOD now ,COMMA it uses more complicated theorems and laws from theory of computation to get the job done ,COMMA because a java program is also not regular .PERIOD but ,COMMA it really is worthwhile thinking about the progression from kmp to a java compiler .PERIOD whereas in java compiler ,COMMA you have a program ,COMMA now ,COMMA you want to compile of and know if it's legal you want to get byte code and then you've got a java simulator ,COMMA and that's not so substantially different from what we just did for grep in a stage along the way .PERIOD that's quite interesting to see this kind of context to get us such a practically useful and important algorithm .PERIOD so the summary is we did some from the standpoint of the program ,COMMA we implemented substring search by simulating a dfa and we implement a regular expression pattern -DASH matching by simulating an nfa .PERIOD from theoretician what's interesting about these abstractions is that nfas and dfas and re are equivalent in power .PERIOD if you can describe a set of strings for one of them ,COMMA you could describe a set of strings with any of them .PERIOD so that's interesting .PERIOD and also interesting is that there's limitations ,COMMA there's sets of strings like palindromes and so forth ,COMMA that you can't specify with a dfa or ,COMMA o r an nfa .PERIOD but from a student in an algorithms class it ,COMMA it really is you know ,COMMA worthwhile to see that these principles are not just theory .PERIOD they're a practical use and this is an essential paradigm all throughout computer science .PERIOD you know ,COMMA we want to find an intermediate abstraction that we can understand and make sure we pick the right one ,COMMA and then we pick clients that can use it in a real implementations that can implement it .PERIOD and by building the right intermediate abstraction ,COMMA we can solve some important practical problems .PERIOD those are the lessons that grep teaches us .PERIOD 
welcome back .PERIOD today ,COMMA we're gonna take a look at a number of interesting applications of symbol tables and the binary search tree data structure to address problems with processing geometric data .PERIOD so let's take a look at it .PERIOD the idea is that we're gonna be talking about geometric objects ,COMMA not simple keys like strings and numbers .PERIOD so here's an example .PERIOD so say your geometric objects are points in the plane and you specify a rectangle that's oriented with the horizontal/vertical axes .PERIOD and you might wanna ask ,COMMA which points are inside the rectangle or how many points are inside the rectangle ?QUESTIONMARK or maybe what you are processing is rectangles .PERIOD you have a set of rectangles ,COMMA and we want to know which of these rectangles intersect ?QUESTIONMARK or how many rectangles intersections are there ?QUESTIONMARK these are interesting problems that have lots and lots of applications ,COMMA from computerated design ,COMMA to games and movies and also in abstractions such as data bases and other situations where you might have multiple keys or multiple dimensions .PERIOD and it's a very interesting extension of the ideas that we've looked at for symbol tables for all sorts of familiar applications .PERIOD and ,COMMA surprisingly binary search trees and these associated algorithms that we've looked at are going to provide very efficient solutions to a number of important problems in this area .PERIOD and really have enabled a new developments and new technology in all of these kinds of applications .PERIOD so ,COMMA to get started ,COMMA we're going to look at a simple problem called one -DASH dimensional range search .PERIOD and it really forms the basis for what we're going to do .PERIOD it's a little bit of an extension of the ordered symbol table api that we gave before and we're going to have operations range -DASH search and range -DASH count .PERIOD so ,COMMA a one -DASH dimensional just means we have one key ,COMMA so we'll insert a key value pairs before and what we want to do is to be able to search for a key ,COMMA and a value associated with it ,COMMA want to b e able to delete .PERIOD but then we want these operations range -DASH search and range -DASH count .PERIOD so ,COMMA find all the keys that are between two given keys ,COMMA or give how many keys are there between two given keys .PERIOD so ,COMMA for this example at right we have insert a number of keys and ,COMMA and we're just showing them in sorted order .PERIOD but then ,COMMA you might say ,COMMA well ,COMMA how many keys are there that are between g and k ?QUESTIONMARK in this case ,COMMA there's just two .PERIOD and then the client might say ,COMMA well ,COMMA what are those keys and you want to be able to return them .PERIOD and this is a very common operation ,COMMA say ,COMMA in databases .PERIOD you want to return how many taxpayers have salaries between one million and ten million and then which ones are they and so forth .PERIOD so ,COMMA range searching is a very important fundamental operation .PERIOD now ,COMMA in geometric interpretation ,COMMA we just think that the keys as points on a line .PERIOD and so ,COMMA the key values well ,COMMA are just specified as points on a line .PERIOD we might convert the letters to numbers ,COMMA or we might ,COMMA keys might be numbers .PERIOD and then ,COMMA what we're looking for is to find or count the points in a given interval in one dimension .PERIOD so how we're going ti implement that ?QUESTIONMARK well this is the basic problem that is very similar to our symbol table problem .PERIOD we might consider keeping the things in an unordered array .PERIOD just put them in an array ,COMMA and then ,COMMA well ,COMMA insertion is ,COMMA is fast .PERIOD we just add it to the end of the array .PERIOD we might have to use resizing to make the array grow .PERIOD but this is unattractive because for large numbers of keys ,COMMA in order to count the keys that fall within a given range ,COMMA you have to go through all the keys and test whether they're in the range or not and to return them the same way .PERIOD so take linear time for large number of keys .PERIOD if you keep the things in order like in a binary search situation then to insert in order to keep it in order in an array ,COMMA you might need to move the larger ones over one pos ition and so forth or elementary implementation of binary search when we did symbol tables did this .PERIOD so ,COMMA the insertion time might be linear ,COMMA but then you can use binary search ,COMMA to look for the two endpoints ,COMMA that's only going to take time proportional to log in .PERIOD and then from that ,COMMA you can figure out how many keys there are or return them all between the index ,COMMA the lowest one in the range ,COMMA index the highest one in the range .PERIOD so ,COMMA those elementary implementations are no acceptable for a large numbers of keys cuz they have the linear time operation .PERIOD so ,COMMA what we really want is to have time proportional to log in .PERIOD for insert and ,COMMA and for counting .PERIOD for range search ,COMMA of course ,COMMA we ,COMMA we have to touch every key that we return ,COMMA so the running time is going to be proportional to the number of keys that match .PERIOD but anyway ,COMMA those are reasonable goals .PERIOD and they're easy to achieve .PERIOD so [cough] so ,COMMA for example what about one -DASH dimensional range counting ?QUESTIONMARK well ,COMMA what we're going to do is just keep the keys in a binary search tree and we looked at the implementation of the rank function for binary search trees where for every key ,COMMA we can compute how many keys are there that are strictly less than that key .PERIOD so in this case ,COMMA the rank of e is two and h is three and so forth .PERIOD so ,COMMA in a binary search tree ,COMMA those rank numbers go in an increasing order as we do in an ordered traversal and that's easy to compute .PERIOD you need to keep that rank tree as a field ,COMMA or keep a field which has the size of the tree and it's easy to complete the rank from that .PERIOD so how many keys between ,COMMA say e and s ?QUESTIONMARK well one ,COMMA two ,COMMA three ,COMMA four ,COMMA five .PERIOD it's actually just the difference between the ranks plus one if the high [cough] entry in the range query is in the table and not +one over .PERIOD so ,COMMA there's the same number of keys between e and s as there are between e and t five .PERIOD between f and t ,COMMA there's only f our .PERIOD so ,COMMA that's a ,COMMA a really 1d range count is a very easy computation to perform in ,COMMA in log time with a binary search tree .PERIOD the [cough] number of nodes examined when we do a search is the length of the search path to low plus the length of the search path to high to [cough] find their ranks and that's going to be time proportional to log n .PERIOD [cough] .PERIOD so and a range search .PERIOD well ,COMMA we just do a recursive search and to find all the keys between low and high you look in the left subtree if any of them could fall in the range .PERIOD you look at the current node and you look at the right subtree ,COMMA if any of them could fall in the range .PERIOD and it's easy to tell whether any of them could fall in the range by just checking whether they're range overlaps the root or not .PERIOD so ,COMMA if we are looking for all the keys between f and t then we have to look at both the subtrees of the root s .PERIOD but we don't to look at the left subtree of e because all of those are less than e and therefore are less than f .PERIOD so ,COMMA we don't have to have to look there .PERIOD but otherwise ,COMMA it's a simple modification of recursive tree search to find all the keys and it's easy to see the running time to that is going to be proportional to the number of keys returned plus log n .PERIOD so ,COMMA that's one dimensional range search using binary search trees .PERIOD 
today we're going to talk about data compression .PERIOD now this is a family of algorithms that ,COMMA everyone uses .PERIOD and it's based on ,COMMA many of the classical ideas ,COMMA that we've covered in terms of ,COMMA implementing basic algorithms .PERIOD we'll start with a introduction ,COMMA just what data compression is .PERIOD so the idea is to reduce the size of a file .PERIOD really for two primary reasons .PERIOD one is to save some space when storing it .PERIOD and the other is to save some time with transmitting it .PERIOD and often having significant savings is not too difficult because most files have ,COMMA plenty of redundancy .PERIOD but of course we're interested in efficient algorithms that can guess ,COMMA get the best savings possible .PERIOD so ,COMMA you might think that with the way that technology ,COMMA has been improving over recent years .PERIOD that we wouldn't really need compression ,COMMA we can just buy a bigger ,COMMA faster disk .PERIOD but the problem with that idea is ,COMMA that even though .PERIOD moore's law tells us that we're going to get ,COMMA twice as much space every one and a half to two years .PERIOD it's also the case that we ,COMMA whatever space we have ,COMMA we're going to want to fill it up ,COMMA with ,COMMA better ,COMMA higher quality ,COMMA data .PERIOD so you want a higher resolution movie if you get more space .PERIOD and if we can remove redundancy ,COMMA you're always going to want to do that .PERIOD so it's a cheap way to ,COMMA save space ,COMMA that allows us to do more with the space that we have available .PERIOD this is a report last year on big data .PERIOD every day we could create 2 .PERIOD5 quintillion bites of data ,COMMA so much that 90 percent of the data in the world today has been created in the last two years alone .PERIOD if we can use data compression to cut that amount of data in half then that's all the data in the world created in a year .PERIOD so this is a very interesting topic to consider from an algorithmic point of view .PERIOD because the basic concepts some of them date back to the 1950's .PERIOD when it was extremely important to save time when transmitting information cuz of ,COMMA or space .PERIOD because it was so costly .PERIOD but some of the best technology ,COMMA algorithmic technology ,COMMA has devel -DASH  ,COMMA been developed recently ,COMMA and much of it uses ,COMMA the data structures that we've considered for other applications .PERIOD and we'll see that as we get into the topic .PERIOD so ,COMMA just specific applications that ,COMMA maybe are familiar for file compression .PERIOD all file systems and ,COMMA and disks have built -DASH in ,COMMA compression technologies .PERIOD such as ,COMMA as zip ,COMMA and b -DASH zip and many others of similar type .PERIOD technologies .PERIOD and the multimedia ,COMMA everybody's familiar with ,COMMA the jpeg and mp3 and mpeg ,COMMA and all those sorts of things for images ,COMMA sound and video .PERIOD those are all about data compression .PERIOD and for communication ,COMMA now ,COMMA that's ,COMMA what has ,COMMA what enabled ,COMMA fax ,COMMA and also enables new technologies ,COMMA like skype ,COMMA the ability to ,COMMA reduce the ,COMMA amount of data that you actually need to send .PERIOD for any kind of technology ,COMMA is gonna ,COMMA help ,COMMA improve things ,COMMA and improve the quality of what you can do .PERIOD  .PERIOD also ,COMMA the types of massive amounts of data that ,COMMA people are saving ,COMMA nowadays .PERIOD google and facebook and other ,COMMA  ,COMMA other web giants are saving lots of data .PERIOD and they're going to be able to save more ,COMMA because of data compression .PERIOD now from a theoretical point of view the type of compression that we're going to consider ,COMMA lossless compression is very simple conceptually .PERIOD so we think of a ,COMMA we talk about a bitstream rema ,COMMA everything can be encoded in bits ,COMMA so we might as well just consider a ,COMMA a stream of bits that we want to compress and we'll call that b .PERIOD in a data compression algorithm it's going to be a black box that goes ahead and takes those bits and produces a compressed version ,COMMA which is many fewer bits .PERIOD and i will call that c of b .PERIOD but we hope that it's many fewer bits .PERIOD and so that's what we save or we send ,COMMA but then we need a companion algorithm ,COMMA an expansion algorithm ,COMMA that takes c of b and produces b back .PERIOD that's lossless compression .PERIOD we want to get back precisely the same bits that we put in .PERIOD and that's very important ,COMMA in many applications .PERIOD it's not so important in some applications ,COMMA like images and video where you're happy with an approximation and the original a bit strained but we're not going to consider that kind of algorithm .PERIOD we're just going to consider a lossless compression ,COMMA where maybe it's a program or that you can't afford to lose a single bit .PERIOD now it turns out that where we talk about in terms of evaluating our algorithms ,COMMA it's what's the compression ratio .PERIOD now ,COMMA we also care about efficiency .PERIOD we don't want to spend a lot of time creating cfb ,COMMA but the compression ratio is the measure that we use to compare algorithms ;SEMICOLON and we're interested in knowing the percentage of bits ,COMMA a percentage of the size would be that we're able to save .PERIOD and surprisingly even for natural languages texts we can get ,COMMA 50 to 75% or even better compression ratios .PERIOD now just in the larger context ,COMMA data compression has been with us since antiquity .PERIOD it's always better to try to express what you're doing concisely .PERIOD mathematical notation is an example of that ,COMMA or number systems ,COMMA or even natural languages .PERIOD communications technology has evolved ;SEMICOLON it definitely has to do with data compression from braille to morse code to the telephone system .PERIOD those are all ways of trying to ,COMMA they depend on ,COMMA trying to achieve good data compression .PERIOD in a modern life ,COMMA everybody's trying to get pictures or movies on their devices ,COMMA and it's definitely enabled by good data compression .PERIOD so ,COMMA something to think about ,COMMA what role data compression is going to play in the future .PERIOD but ,COMMA it's really hard to see it going away .PERIOD number one ,COMMA it is effective .PERIOD number two ,COMMA it is not that difficult to implement ,COMMA and it's in software .PERIOD so ,COMMA you don't have to buy a bigger disk to have a good compression algorithm in many situations .PERIOD here's a simple example that sprung up just in recent years .PERIOD so we've talked about in other applications that genome is a string over a four letter alphabet .PERIOD and the string might be huge .PERIOD it might be billions of letters .PERIOD and so ,COMMA and there might ,COMMA and there might be lots of them ,COMMA for different individuals and different species .PERIOD so the huge genome data base is out there with these very long strings of the alphabet a ,COMMA c ,COMMA t and g .PERIOD now ,COMMA the standard way to store them in standard programming language ,COMMA standard computers ,COMMA is to use ascii ,COMMA and there's eight bits per character ,COMMA and so if you have an n bit genome ,COMMA genomic string ,COMMA it'll be eight n bits .PERIOD if it's a billion ,COMMA characters ,COMMA it's eight billion bits .PERIOD but just look at the problem .PERIOD really there's only four characters .PERIOD you can get by with just two bits per character .PERIOD so ,COMMA that's one quarter the storage .PERIOD if you spent x dollars on this space to store your stuff ,COMMA you could spend x over $four .PERIOD and that might be a significant number .PERIOD and ,COMMA the fact in general ,COMMA if you know you have a small alphabet you can get a savings in this way .PERIOD this seems very obvious and straight forward ,COMMA but it's amazingly true that in the 1990's when generally ,COMMA data basis started to emerge there were four times too big .PERIOD they used ascii then ,COMMA didn't think to use this trivial coding that could have cut costs by one fourth .PERIOD so again ,COMMA if it's so easy to do ,COMMA why not do it ?QUESTIONMARK if you can cut your cost by a factor of four .PERIOD and where else ,COMMA would you give up ,COMMA reducing cost by a factor of four so easily .PERIOD so that's why we're interested in data compression .PERIOD now we're going to need some tools that are slightly different from the tools that we've been using in order to write effective data compression algorithms .PERIOD and so we've got  ,COMMA extensions to our standard in and standard out libraries that work with bits .PERIOD so ,COMMA these are what we want to ,COMMA what the methods that we're going to use to write bits to standard output and standard input .PERIOD so ,COMMA these bit streams are different than a standard in ,COMMA standard out .PERIOD they're binary standard in ,COMMA binary standard out .PERIOD and so ,COMMA what we can do is read boolean ,COMMA which is just read one bit ,COMMA or to save some processing ,COMMA we can read eight bits of data and put it in a care .PERIOD or in general ,COMMA r bits ,COMMA where r is less than eight ,COMMA and put it into a care value .PERIOD and we can also ,COMMA if we want ,COMMA put it into nth values long and boule in a similar methods .PERIOD and we don't have to read all the bits if we've got some .PERIOD  ,COMMA a scheme where we only wanna use a certain number of them .PERIOD but the idea is that ,COMMA we can read a variable number of bits ,COMMA and get'em ready for processing easily ,COMMA by putting them in one of java's ,COMMA primitive types .PERIOD and conversely ,COMMA we have binary standard out ,COMMA where we can write a bit .PERIOD or we can write ,COMMA eight bits ,COMMA or we can write any number of bits from a care value or from an int value ,COMMA or any others .PERIOD so this allows us to take in bit streams and to write out bit streams and takes care of all the encoding between java primitive types and bit streams .PERIOD and it's not too difficult to use and it's very intuitive .PERIOD and you'll see when we come to code .PERIOD just to ,COMMA give an example of how just having this ,COMMA can save space .PERIOD this is just a simple example of representing a date .PERIOD so if you ,COMMA represent the date ,COMMA 12/31/1999 ,COMMA as an ascii character string ,COMMA in java .PERIOD then ,COMMA when you write out the string ,COMMA you've got one ,COMMA two ,COMMA three ,COMMA four ,COMMA five ,COMMA six ,COMMA seven ,COMMA eight ,COMMA nine ,COMMA ten characters .PERIOD in each one of the characters is eight bits so that's a total of 80 bits .PERIOD so the standard ascii encoding is to just look up the ascii of the one and that's 00110001 and then the two and so forth .PERIOD so in the slash 31 and so forth .PERIOD so for each character we've got eight bits and we put them up and that's 80 bits .PERIOD if it was unicode there would be even more bits .PERIOD so that's one way that you might consider representing a date with bits .PERIOD now if we represent it as three nth values ,COMMA that's not so effective a way to do it .PERIOD the month is a nth ,COMMA the day is an nth and the year's an nth and each one of those is going to be 32 bits .PERIOD and that's the total of 96 bits though that's ,COMMA that's actually even worse .PERIOD by the month in all these things are within small ranges .PERIOD so ,COMMA with binary standard out we can say ,COMMA well ,COMMA we're learning right out the right most four bits of the month end cuz that give us a number between zero and sixteen and months between one and twelve .PERIOD and the five bits of the day .PERIOD and you input that again ,COMMA and that's ,COMMA between zero and 31 .PERIOD and that's going to cover any possible day .PERIOD and then twelve bits for the year .PERIOD and if we do that  .PERIOD then we have a total of 21 bits .PERIOD and there's a little bit of extra at the end ,COMMA because our byte streams ,COMMA our bits really are implemented ,COMMA reasonably in most situations as byte streams .PERIOD so they're going to get carved into chunks of size ,COMMA eight by ,COMMA hardware or ,COMMA their drivers .PERIOD and so ,COMMA we always round up to the nearest multiple of eight to get the proper alignment on bytes .PERIOD but that's still pretty ,COMMA significant savings from 80 to 24 ,COMMA just by having ,COMMA the ability to ,COMMA write out portions of ,COMMA int values .PERIOD and if we had a billion dates ,COMMA then that would be a huge cost savings that would translate to dollars ,COMMA as well .PERIOD the other thing ,COMMA that we do to give some visual impression of our effectiveness of our compression algorithms particularly in the text ,COMMA is to look at different ways to examine the contents of a bit -DASH stream .PERIOD so we have on the book site a binary dump program that ,COMMA prints out ,COMMA the bits ,COMMA sixteen bits at a time ,COMMA rows of sixteen bits at a time .PERIOD and then the total number of bits .PERIOD so ,COMMA this file aver .PERIODtext is ,COMMA a standard character stream .PERIOD so everything's encoded with ,COMMA eight bits .PERIOD and so there's twelve characters and it's 96 bits .PERIOD and you can see what all the bits are .PERIOD or ,COMMA sometimes it's convenient to use a hex dumpler .PERIOD we just read the hex digits considering the bits ,COMMA four bits at a time .PERIOD and so those 96 bits are twelve bytes ,COMMA or 24 hex digits .PERIOD and we print it out so that we can see them .PERIOD another thing that's useful sometimes for big files is to look at the bits as a pitcher where we just do a .PERIOD give the width and the height of a pixel window and just map the bits to white squares and black squares .PERIOD so this is the same aver .PERIODtext .PERIOD it's just that you can see that they all start with zero one much more easily .PERIOD this visual representation sometimes gives an interesting perspective into what a compressed or what a bunch of bits looks like .PERIOD so ,COMMA this is just the hex to ascii conversion table that ,COMMA that if you are not familiar with it it's a quick way to find the hexadecimal corresponding to an ascii character .PERIOD so ,COMMA you look up sa y r in the table and that's in row five and column two .PERIOD so it's 52 .PERIOD so this is a 52 for the r in abracadabra .PERIOD and so those are the basic tools ,COMMA that we are going to use when we talk about compression algorithms .PERIOD now there's one thing that's ,COMMA really important to think about .PERIOD and that's the idea that ,COMMA you cannot have a compression algorithm that can compress every file .PERIOD despite the fact that ,COMMA somebody has ,COMMA patented that .PERIOD and ,COMMA and there's a claim that ,COMMA methods for data compression is capable of compressing all files .PERIOD and ,COMMA also ,COMMA this ,COMMA this is another ,COMMA thing that came out of slash dot a few years ago ,COMMA where a company had announced a breakthrough in data compression that does a 100 to one losses compression of random data .PERIOD and unfortunately ,COMMA they do say ,COMMA if this is true ,COMMA our then withdrawals got a lot smaller .PERIOD cause ,COMMA there's no way that is true ,COMMA and lets look at why that's the case .PERIOD proposition is no algorithm can compress every bit string .PERIOD here's one easy way to prove it ,COMMA not by contradiction .PERIOD so ,COMMA let's suppose that we have an algorithm mui that can go ahead and compress every possible bit string .PERIOD so we take a bit string and we use our algorithm to compress it ,COMMA to get a smaller bit string .PERIOD but since our algorithm can compress every bit string .PERIOD why not use it on that one ?QUESTIONMARK use it on that one ,COMMA you get a smaller one .PERIOD then we keep going .PERIOD since it's a compress ,COMMA can compress every bit string ,COMMA eventually we get down to a bit string of size one .PERIOD and since it can compress that one ,COMMA it gets down to zero .PERIOD so if you can have an algorithm that compresses every bit string ,COMMA it means that you can compress all bit strings to zero bits ,COMMA and that's absurd .PERIOD so that's a proof by contradiction .PERIOD or another way to see the same thing is just by counting .PERIOD so let's say you've got an algorithm that can compress all 1000 bit strings ,COMMA just to pick a number .PERIOD now there's a lot of 1000 bit strings .PERIOD there's two^1000 of them .PERIOD but how many of those ,COMMA can be encoded with 99 ,COMMA 999 bits or fewer .PERIOD well .PERIOD just one plus two plus four ,COMMA and the powers of two up to two ,COMMA and out to the 99 ,COMMA 999 .PERIOD or ,COMMA like less than 500 ,COMMA that's .PERIOD so that's way fewer than the total number of ,COMMA of possible bit strings .PERIOD well ,COMMA it says it's one if you add up the sum that's 2 ,COMMA501 .PERIOD so ,COMMA there's one that can't be compressed .PERIOD so ,COMMA that's it .PERIOD so ,COMMA if you want to say do fewer bits ,COMMA you have much worse problem .PERIOD only one out of every two forty ninth can be encoded with less than 500 bits .PERIOD it's just the smaller number of git ,COMMA bits gives you way number ,COMMA way fewer possible bit strings and you have to ,COMMA be able to get your original bit string back .PERIOD so ,COMMA the smaller number of bits gives you ,COMMA a limit on the number of ,COMMA bit strings that you can possibly compress .PERIOD so ,COMMA we can't have universal data compression .PERIOD and if you want to convince yourself of that ,COMMA now just try running your favorite compression algorithm on the  ,COMMA result of what it produces .PERIOD say for a photo most good compression algorithms will figure out that you're doing that ,COMMA and just give you the same file back .PERIOD so at least it won't make it get larger but there's plenty of ,COMMA of methods out there that will make your file larger .PERIOD there's another kind of basic idea .PERIOD and ,COMMA and that is that there's no way to find the best way to compress a file .PERIOD and if you think about it ,COMMA it can be extremely complicated .PERIOD this is just an example that illustrates the point .PERIOD but it's also a relevant example ,COMMA cuz it applies to so much of the data that we deal with .PERIOD so at the top is a picture dump of a million bit file .PERIOD so that's a million bits and it's ,COMMA those are random bits .PERIOD well they're not random ,COMMA they're pseudorandom .PERIOD what do i mean ,COMMA pseudorandom ?QUESTIONMARK well we talked about that .PERIOD they're generated by a program .PERIOD and ,COMMA this is a java program that uses a pseudo random number generator to generate bits .PERIOD and ,COMMA that's where those bits came from .PERIOD but if you think about it ,COMMA this program is representation of those million bits .PERIOD it's only a couple of dozen characters ,COMMA so ,COMMA you know ,COMMA if you want to find the optimal way to compress those bits ,COMMA one of the things you would have to consider is this program t hat's a pretty compact way to represent a million bit .PERIOD and ,COMMA if you think about it so much of the data that's out there actually was created by a program so ,COMMA compression amounts to finding the program that creates ,COMMA created the data .PERIOD and ,COMMA that's obviously a pretty difficult problem in fact it's known that it's undecideable .PERIOD so ,COMMA let's not think that we can find the best possible compression algorithm .PERIOD and the other point that i want to finish with in the introduction is ,COMMA to realize that when we're talking about ,COMMA compressing ,COMMA say english language ,COMMA it's amazing to see that actually there's a lot of ,COMMA redundancy in the english language .PERIOD and so this is ,COMMA a ,COMMA  .PERIOD a perturbed version of an english language paragraph that shows that you can change letters and even delete letters and still figure out what it says .PERIOD and actually at the end ,COMMA it's you really need the first and last two letters ,COMMA in a lot of situations to ,COMMA really ,COMMA figure out readability .PERIOD so ,COMMA there ,COMMA there is a lot of freedom ,COMMA because there's so much redundancy .PERIOD and since there's so much re ,COMMA redundancy ,COMMA we can actually do ,COMMA really well on ,COMMA on compressing english language texts ,COMMA for example .PERIOD so that's an introduction to data compression and we'll take a look at algorithms next .PERIOD 
so now let's look at a basic geometric data processing problem of determining intersections among a set of line segments .PERIOD so ,COMMA it's called the orthogonal line segment ,COMMA segment intersection search where the lines segments or constrained to be either horizontal or vertical .PERIOD and so ,COMMA suppose we have a large number of such line segments and what we want to be able to do is to find all places where they intersect .PERIOD and as we'll see this extends to a practical problem in a number of situations .PERIOD so ,COMMA in this case there's four places where these lines intersect .PERIOD so ,COMMA how are we going to be able to determine these intersections efficiently ?QUESTIONMARK now ,COMMA the natural algorithm ,COMMA or the naive brute -DASH force algorithm ,COMMA is quadratic in time .PERIOD so that is ,COMMA for every line segment ,COMMA you check whether it intersects with every other line segment .PERIOD and again ,COMMA as we know ,COMMA such an algorithm is not going to be practical ,COMMA for huge numbers of line segments .PERIOD so ,COMMA just ,COMMA to simplify our code in the slides in it's off ,COMMA off from the case for geometric data processing .PERIOD we don't have to worry about degeneracies where lots of things have the same x or y coordinate .PERIOD and just to simplify the code and to get it the main principles of the algorithms ,COMMA we're going to assume that all the coordinates that we have are distinct that we've preprocessed in some way to remove the ones that touch without intersecting .PERIOD so the method that we're going to look at is a so called sweep line algorithm and the idea is to think of vertical line that sweeps left to right through the data .PERIOD in to .PERIOD consider it as a every time it hits some line segment as an event where we have to do something .PERIOD so sweeping from left to right means we consider each x coordinate as an event .PERIOD so first thing is if we hit a horizontal line segment .PERIOD well we're going to hit the left endpoint first ,COMMA and so what we'll do when we hit the left ,COMMA endpoint is ,COMMA insert ,COMMA the y coordinate of that line into a binary search tree .PERIOD so ,COMMA we're going to keep track of y coordinates in a binary search tree .PERIOD so that's what's happening over in the right there .PERIOD so now again ,COMMA sweep from left to right .PERIOD what's the next smallest x coordinate ?QUESTIONMARK in this case it's the line number one there ,COMMA and we'll remember its y coordinate in a binary search tree .PERIOD and then two and three .PERIOD so those that's one kind of event that can happen as we sweep from left to right .PERIOD another kind of event is that we hit the right endpoint of a horizontal line segment .PERIOD in this case we hit the right endpoint of line segment two .PERIOD so ,COMMA at that point the right point of a horizontal line segment we just remove it because we've processed that line completely .PERIOD in this case we didn't find any intersections .PERIOD so ,COMMA left endpoint insert the y coordinate into a bst ,COMMA right endpoint remove that ycoordinate from the bst .PERIOD so ,COMMA the bst contains the y coordinates of all the horizontal lines that currently might involve an intersection .PERIOD and then the third kind of event is what happens when we hit a vertical line segment ?QUESTIONMARK well ,COMMA in that case all we want ,COMMA need to do is just do a range search ,COMMA for the interval of y end points .PERIOD so ,COMMA any point that's inside that interval ,COMMA is going to represent a horizontal line segment that is an intersection .PERIOD that's the basic idea behind the sweep line algorithm ,COMMA to find intersections in sets of horizontal and vertical lines .PERIOD and it's actually a very simple algorithm ,COMMA and it's very easy to see that the running time is going to be proportional to n log n plus the number of intersections returned .PERIOD where there's n horizontal vertical line segments .PERIOD and it's ,COMMA and a couple of ways to implement it ,COMMA one thing is you could sort according to the x coordinates ,COMMA or you could just put them all on a priority queue .PERIOD and then ,COMMA so ,COMMA so that's going to take n log n for every one of the lines to process them all either n to build the priorit y queue and then log n to take the smallest off each time ,COMMA or n log n for the sort .PERIOD and then putting the y coordinates into ,COMMA into a binary search tree is ,COMMA again ,COMMA n log n .PERIOD and same for deleting .PERIOD each point has to be inserted ,COMMA deleted .PERIOD it could be as many as n in the tree for each one .PERIOD so it's a total of n log n .PERIOD and then the ,COMMA range search ,COMMA in the binary tree ,COMMA for each ,COMMA each one of the range searches .PERIOD it might take ,COMMA log n ,COMMA it might be as many as n .PERIOD and then there's ,COMMA plus the number of points return .PERIOD so ,COMMA that's a ,COMMA quick sketch of the proof of this proposition .PERIOD and with that 1d range search ,COMMA implementation ,COMMA we get an efficient n log n ,COMMA 2d orthogonal ,COMMA orthogonal line segment ,COMMA intersection 
as a warm up we're going to look at run length encoding ,COMMA which is actually an effective method in many applications .PERIOD simple method that's very effective .PERIOD it's based on the idea that it's very often the case in a bit string that you have long runs of repeated bits .PERIOD so in this case ,COMMA there's a long run of zeros followed by a medium length run of ones ,COMMA another medium length run of zeros ,COMMA and then more ones .PERIOD so there's 40 bits but only switches from zero to one in three places .PERIOD and so what you can do is rather than write out all the bits .PERIOD we can write counts to represent alternating runs of zeroes and ones .PERIOD a very simple method .PERIOD so in this case ,COMMA there's fifteen zeroes ,COMMA seven ones ,COMMA seven zeroes and eleven ones .PERIOD and ,COMMA with four bits to represent each one of these counts ,COMMA we can just write fifteen ,COMMA seven ,COMMA seven ,COMMA and eleven to get ,COMMA instead of 40 bits ,COMMA get down to sixteen bits .PERIOD that's effective ,COMMA whether there's long runs of zeroes and ones ,COMMA in a bitstream .PERIOD now ,COMMA you have to decide how many bits to use to store the counts .PERIOD it's not necessarily a good idea to use ,COMMA say ,COMMA 32 bits .PERIOD and maybe four is too small .PERIOD so ,COMMA in our code ,COMMA we use eight bits .PERIOD so that'll handle runs up to 256 bits .PERIOD we used four in the example above ,COMMA but in a realistic thing ,COMMA it's fine to use eight .PERIOD and then if we have longer runs ,COMMA then we have to figure out what to do .PERIOD if the run length is bigger than the mass count ,COMMA well ,COMMA we can just intersperse runs of length zero .PERIOD and there's one way to handle it ,COMMA there's other ways to handle it too .PERIOD but this is a very simple scheme that covers all the bases and can be a very effective .PERIOD and  .PERIOD for example ,COMMA consider a bit map representation of this slide .PERIOD there's huge long runs ,COMMA saved with black and white .PERIOD there's huge long runs of white that ,COMMA depending on the resolution ,COMMA might be hundreds or 1000 bits ,COMMA but could be represented with just a few counts .PERIOD and so in many applications of bit maps of texts and other things like that ,COMMA this is very effective and it's used in all kinds of technologies like jpeg and fax and others .PERIOD and it's very simple t o implement .PERIOD so this is our warmup data compression algorithm that implements run -DASH length encoding .PERIOD actually we left the compress for the book .PERIOD this is just the expand .PERIOD so i'm given a bunch of counts .PERIOD how do i reproduce the original uncompressed text string into  .PERIOD it's as simple as that .PERIOD so log r is the number of bits per count .PERIOD and so basically what we do is read log r bits at a time into an end ,COMMA whatever the value is ,COMMA so we put that into the end run .PERIOD so ,COMMA that's a number between zero and 256 ,COMMA which is the maximum you can get in eight bits .PERIOD and then ,COMMA starting with zero the first count .PERIOD that's the number of zeroes we need to write ,COMMA so we just write them one ,COMMA one bit at a time .PERIOD zero at one bit at a time ,COMMA and then we flip the bit to make it one .PERIOD and read the next count ,COMMA and now we ,COMMA we write out that many 1s and so forth .PERIOD so this is a ten line program that does ,COMMA expansion for ,COMMA run length and coding .PERIOD and you can ,COMMA think about it or look at the book ,COMMA for ,COMMA how to do ,COMMA compression .PERIOD it's just as simple .PERIOD so this is just the ,COMMA an example of the effectiveness of ,COMMA learning some coding for ,COMMA one letter ,COMMA the letter q ,COMMA in a ,COMMA in a typical black and white scheme doing .PERIOD even for a single letter ,COMMA there's ,COMMA lots of ,COMMA redundancy ,COMMA lots of runs of 0s .PERIOD so with a relatively small ,COMMA number of counts .PERIOD we can ,COMMA represent a ,COMMA a bitmap .PERIOD and this is the hard case .PERIOD actually ,COMMA most of a printed page is all this blank space ,COMMA as i said .PERIOD so ,COMMA typically .PERIOD if you just don't compress at all and you have an eight and a half by eleven piece of paper with three hundred pixels per inch ,COMMA that'd be eight million bits .PERIOD but most of those are white ,COMMA and typically with run length and coding ,COMMA you can get substantial savings simply by basically counting the white bits .PERIOD and even when there's letters involved ,COMMA you can get ,COMMA say maybe there's only three thousand characters .PERIOD that's another example .PERIOD if it's all text then maybe the text itself is a great way to compress it .PERIOD or the program or the document processor that produced the text ,COMMA but now we're starting to get into undecidabi lity issues .PERIOD so lets think more in terms of a ,COMMA a page that has a ,COMMA an image ,COMMA a drawing ,COMMA and some text and so forth .PERIOD so it makes sense to start with a bitmap and then use as few bits a possible .PERIOD and then run length encoding's going to be very effective .PERIOD that's our warm up case for data compression .PERIOD 
next ,COMMA we'll look at huffman encoding .PERIOD this is a classic algorithm that is still widely -DASH used and effectively used today .PERIOD it's definitely on the list of algorithms that everyone should know cuz it's quite ingenious .PERIOD so we start out with the idea of variable length codes .PERIOD so far ,COMMA we've talked about codes where every character is represented with the same number of bits .PERIOD but there's no reason to do that .PERIOD for example ,COMMA look at morse code .PERIOD the idea in a way that we assign dots and dashes to letters is that frequently ,COMMA you'll use letters should have smaller number of characters .PERIOD so for example ,COMMA an e is only one dot and so forth .PERIOD and letters that are used less frequently ,COMMA like q are going to be longer .PERIOD more dashes and more characters .PERIOD so with this we can ,COMMA it's an idea ,COMMA a compression idea ,COMMA of let's use fewer characters for frequent fewer bits or fewer code characters for frequently used characters .PERIOD now ,COMMA there's an issue with this and that is that it can be ambiguous .PERIOD so ,COMMA this message everybody knows ,COMMA looks like sos ,COMMA three dots followed by three dashes ,COMMA followed by three dots .PERIOD but actually it could be it's any one of these others .PERIOD like v is dot ,COMMA dot ,COMMA dot ,COMMA dash .PERIOD thats good .PERIOD and then ,COMMA seven is dash ,COMMA dash ,COMMA dot ,COMMA dot ,COMMA dot ,COMMA so it could be v7 .PERIOD or it could be either of these two .PERIOD there's lots of different things that this thing could be .PERIOD so ,COMMA morse code is actually ,COMMA it's not just dots and dashes it actually has they have a little space between the code words to avoid this problem that there's an ambiguity caused by the fact that one code word can be prefix of another and there's no way to tell that it's not without separating the code words .PERIOD so now that's the way it's solved in morse code and that's not necessarily the most efficient way to solve it ,COMMA and that's what huffman codes addresses .PERIOD also ,COMMA a problem with morse code is don't be trying to transmit a lot of numbers with morse code ,COMMA because the codes for those are pretty long and ,COMMA and you'll have much longer representations for codes that involve a lot of messages and involve a lot of numbers .PERIOD but there's a really elegant way to avoid ambiguity .PERIOD and that is to just adopt a rule that no code word is going to be a prefix of another one .PERIOD so fixed length codes do that .PERIOD if every code is the same number of bits and every character encode different bits ,COMMA then no code word's a prefix of another .PERIOD they're just all different .PERIOD another thing you can do is have a ,COMMA a special stop character like ,COMMA like the space in morse code to end to each code word .PERIOD that's really what it's doing .PERIOD so the code words are all different .PERIOD and they end with a character that's special .PERIOD and so ,COMMA none can be a prefix of another one .PERIOD but there's also just an easy way to just make sure that you use a code that has this prefix free property .PERIOD so ,COMMA for example ,COMMA this code here no code word is a prefix of another .PERIOD and it means when you have bits there's a unique way to decode .PERIOD so here ,COMMA the compressed bitstream starts with zero ,COMMA the only way that can happen is if the first letter is a .PERIOD then ,COMMA when you're done with the a you've got four ones and that means it's got to be a b .PERIOD and then ,COMMA you get rid of the b ,COMMA and so forth .PERIOD and it's three ones and a zero ,COMMA it's got to be an r ,COMMA and so forth .PERIOD since no code word is a prefix of another you can just read off the code from the bit string without having any special stop character or any efficiency ,COMMA inefficiency caused by that .PERIOD all we have is the bits and we are able to uniquely decode it .PERIOD and there is numerous prefix -DASH free codes .PERIOD for example here's another prefix -DASH free code that for the same five characters and it actually uses fewer bits .PERIOD so ,COMMA the idea of huffman encoding within these rules where we must have a prefix -DASH free ,COMMA free code .PERIOD and we've got a particular message .PERIOD what's amazing about huffman encoding is ,COMMA that it finds the code that uses the fewest bits for that message .PERIOD and that's why ,COMMA you know ,COMMA it's so effective .PERIOD so the interesting thing one interesting thing about prefix -DASH free code is that they're really easy to represent with trie .PERIOD and ,COMMA and the idea is very simple .PERIOD we put characters in the leaves and we imagine that every ,COMMA this is binary trie ,COMMA so we imagine that there's only two links per node .PERIOD and we imagine that every left link is labeled zero and every right link is labeled one .PERIOD and then ,COMMA just following the path from the root to a leaf ,COMMA so say we go right ,COMMA so it's one ,COMMA zero ,COMMA zero ,COMMA that's d .PERIOD those bits are not stored in the trie ,COMMA we just keep ,COMMA we just implicitly keep track of them .PERIOD if we go left we keep zero ,COMMA if we go right we keep one .PERIOD and so a try for prefix -DASH free code uniquely determines the code .PERIOD and that means that just working with the trie we can decompress a bit string just by starting at the root ,COMMA reading the bits take them where they take us ,COMMA and when we get to a leaf ,COMMA we've got a character .PERIOD so that's the trie corresponding to that code ,COMMA that's the trie corresponding to that code .PERIOD this one starts out with one ,COMMA one ,COMMA so starting at the root ,COMMA we go one ,COMMA one ,COMMA and the first letter is a .PERIOD and then ,COMMA the next letters are zero ,COMMA zero ,COMMA and so we go zero ,COMMA zero ,COMMA and we come to b ,COMMA and so forth .PERIOD a simple representation of a prefix -DASH free code that is that makes for easy decoding ,COMMA given the bit ,COMMA bit string in the trie ,COMMA it's pretty easy to decode .PERIOD you could also keep a symbol table of pairs but sorry ,COMMA for compression ,COMMA how do we do compression that was in expansion ?QUESTIONMARK so ,COMMA for compression ,COMMA we can just keep the table and use it .PERIOD you could also use the trie to figure out the code by following the path h ,COMMA up to the root .PERIOD and for expansion ,COMMA as i just said ,COMMA you start out at the root i go left at zero ,COMMA right of one and it's very easy .PERIOD so for among comp ,COMMA expansion ,COMMA so we will look at the code for both of these .PERIOD the question is how to construct ,COMMA the first question is how to construct the trie .PERIOD so let's start with the data type .PERIOD so this is similar to other tree structures that we've built before where we have a character that we don't use for internal nodes ,COMMA just for leaves .PERIOD we've got the frequency that we use while we're building the tribe ,COMMA not when we're expanding and then every node has a left and a right .PERIOD and th is ,COMMA is the constructor ,COMMA you just fill in all the fields .PERIOD we need a method to tells us if the current node is a leaf .PERIOD and that's when so that's if both its links are null .PERIOD and we need to compare it to ,COMMA to compare nodes by frequency .PERIOD and we'll see why that's needed later on .PERIOD so that's the data type for the nodes that we're going to use to build the tries .PERIOD and so now ,COMMA let's look at expansion .PERIOD so ,COMMA this is in code what i just talked about .PERIOD so ,COMMA we're going to have a method that reads in some of the bit string ,COMMA and converts it to a trie .PERIOD now ,COMMA that's one clever part of the algorithm .PERIOD and then the first thing is the number of characters in the code in the message ,COMMA you know ,COMMA we also get that .PERIOD so ,COMMA we get the trie ,COMMA and then ,COMMA we get the number of characters .PERIOD and then we simply for do a for loop for the number of characters and start at the root .PERIOD if we're not at a leaf we read a bit .PERIOD and if it's zero ,COMMA we go left ,COMMA and if it's one ,COMMA we go right .PERIOD and that's it .PERIOD if as soon as we get to a leaf ,COMMA we just write out the character that we get and then ,COMMA go back to the root and keep going .PERIOD we're not in a leaf if we read a bit ,COMMA we have zero ,COMMA go to the left ,COMMA one ,COMMA go to the right .PERIOD and when we get to a leaf ,COMMA we write out the character extremely compact code for expanding .PERIOD given a bit string ,COMMA the first thing is to trie .PERIOD we have to talk about how to get the trie in from a bit string number of characters .PERIOD and then ,COMMA the simple loop that expands according to the trie representation .PERIOD so that's networks for any prefix -DASH free code ,COMMA not just the cuffman ,COMMA huffman code .PERIOD in the running your time ,COMMA it's obviously linear in the number of bits cuz for it's just a loop that chews up a bit every time in the loop .PERIOD okay .PERIOD so ,COMMA so again ,COMMA for any prefix -DASH free ,COMMA free code ,COMMA how are we actually going to write the trie ?QUESTIONMARK well it's a little ,COMMA little clever but by this time ,COMMA you should be ready for this kind of algorithm .PERIOD what you can do is traverse the trie in pre -DASH order and when you and then come to an internal node you write a zero .PERIOD when you come to a leaf ,COMMA you write a one f ollowed by the 8 -DASH bit character at that leaf .PERIOD so it's a simple pre -DASH order traversal .PERIOD if this is a recursive program to write out in trie if you're at a leaf ,COMMA you write a one followed by the 8 -DASH bit characters at the leaf and you're done .PERIOD and if you're not at the leaf ,COMMA you simply write a zero .PERIOD and then recursively ,COMMA do the two sub -DASH tries .PERIOD and that gives a unique representation of the trie that can be used to construct the trie from that bit string .PERIOD so and the idea is that typically ,COMMA we're talking about a ,COMMA a very long message the trie itself is just basically encodings of all the possible characters in a message .PERIOD and that's going to tend to be small compared to the length of the message .PERIOD so for say ,COMMA a genomic sequence there would be only four characters and the ones that used most frequently ,COMMA hopefully would be encoded with not that many bits .PERIOD of course ,COMMA but anyways ,COMMA the size of the trie itself is going to be much smaller than the length of the message .PERIOD so reading in the trie and this requires a little bit of thought ,COMMA but and we see the code ,COMMA the code is extremely simple .PERIOD we justreconstructed from the pre -DASH order traversal to trie .PERIOD so ,COMMA this is the readtrie method that we needed ,COMMA that reads the bits from binary standard in and produces the trie ,COMMA and it's also recursive .PERIOD and if the bit that you read is zero that sorry ,COMMA if the bit that you read is one that means you have to create a leaf otherwise ,COMMA you recursively read the left and read the right .PERIOD and make a new node that has a subtree that ,COMMA that denotes to the left and the right .PERIOD and it doesn't it doesn't use the character in the second one ,COMMA the frequency we initialize to zero .PERIOD so ,COMMA in internal nodes ,COMMA we don't use the character .PERIOD so if you look at what would this code do for this bit string so the first bit is zero .PERIOD so it's going to recursively call itself to read the trie on the left .PERIOD and so ,COMMA the next bit is a one .PERIOD so ,COMMA it's going to read the next eight bits to get the a .PERIOD and it's going to return a new node with that character in it that's a leaf .PERIOD so ,COMMA that's going to be the left subtree of the initial trie ,COMMA the first recursive call .PERIOD and then ,COMMA it'll read the right subtree ,COMMA which is an internal node ,COMMA another internal node .PERIOD it takes a little thinking to convince yourself this ,COMMA this works .PERIOD but it does .PERIOD and it's very compact and easy code .PERIOD and again ,COMMA works for an prefix code .PERIOD you encode the trie with the prefix traversal .PERIOD and with a very small amount of code ,COMMA you can reconstruct the trie and transmit a bitstream .PERIOD and so ,COMMA this is a compression of a trie structure .PERIOD so now ,COMMA the question is ,COMMA how do we ,COMMA there's a lot of prefix pre -DASH codes ,COMMA how we will find the best one ?QUESTIONMARK well ,COMMA and there's an idea called the shannon -DASH fano algorithm which says the ,COMMA the ,COMMA the key idea is that you've got characters that appear with different frequency .PERIOD and you want to get the ones that appear very frequent to use fewer bits .PERIOD and so ,COMMA it's of interest to find the ones that are very frequent ,COMMA and so the shannon -DASH fano algorithm says ,COMMA just divide all the symbols in ,COMMA into two roughly equal frequency and start the ones in the first one with zero and the ones in the second one with one ,COMMA it's kind of a balanced code .PERIOD and then ,COMMA and then kind of re ,COMMA recur .PERIOD so if you have a appearing five times ,COMMA and you c appearing one time at six for those and then you get six for all of those .PERIOD and then you try to encode those with and try to use zeroes for roughly half the character .PERIOD and one for roughly half the character .PERIOD so in order to deal with that ,COMMA you have to figure out how to divide up the symbols .PERIOD and you can imagine an algorithm for doing that .PERIOD but the real problem with this method is that it's not optimal .PERIOD and so that's the kind of situation that huffman was faced with way back when coming up with the algorithm .PERIOD and the best way to explain the huffman algorithm is through a demo .PERIOD and so ,COMMA that's what we'll do next .PERIOD so ,COMMA here's a ,COMMA a demo of the huffman algorithm .PERIOD so ,COMMA the first thing that we do is count the frequency of each character in the input .PERIOD and so that's what the algorithm is based on .PERIOD so ,COMMA in this case ,COMMA there's five as ,COMMA two bs ,COMMA o ne c ,COMMA one d ,COMMA and so forth .PERIOD so our goal is to use fewer bits to encode a and more bits to encode c ,COMMA d ,COMMA and exclamation point  ,COMMA !EXCLAMATIONMARK ,COMMA ,COMMA for example and we want to prefix -DASH free code .PERIOD so it's kind of a bottom up method .PERIOD so what we do is we build one node for each character and we keep in the node corresponding to each character ,COMMA a weight that's equal to the frequency .PERIOD and then we imagine keeping them in a sorted order .PERIOD so that's how the method starts out .PERIOD now remember ,COMMA our node representation had an instance variable that allowed for storing these frequencies .PERIOD and then the idea is to given these are sub -DASH tries of size one ,COMMA the idea is to combine two of them and merge them into a single tribe with a cumulative weight .PERIOD and so we're going to find the ones that are ,COMMA the two that have the smallest weight and create a new internal node for them .PERIOD and the weight of that node is going to be the sum of the two weights .PERIOD so ,COMMA that's the frequency of all the code characters below it .PERIOD and then ,COMMA just put that into the mix .PERIOD so now we have five sub -DASH tries to deal with and that's the algorithm .PERIOD select the two tries with minimum weight .PERIOD in this case ,COMMA it's ,COMMA since we're keeping them sorted so it's going to be the ones on the left .PERIOD combine them and add their two weights .PERIOD so ,COMMA make a parent node .PERIOD it doesn't matter which goes in left which goes right ,COMMA really .PERIOD and then ,COMMA add the weights to the frequency of the parent node and then put it into the list .PERIOD now ,COMMA if you look up at the table at the right what we're doing when we're doing this combination is building up the code corresponding to the characters moving from left to right .PERIOD so ,COMMA so far ,COMMA we know that the code for d is going to end in zero and the code for c is going to end in one ,COMMA one .PERIOD and so for exclamation is going to end in one zero .PERIOD so that now continue the rule .PERIOD now the b and r are get combined .PERIOD and again we're figuring out how those code words end .PERIOD and so now ,COMMA we have just three to choose from .PERIOD now ,COMMA we're going to combine the two big ones and now ,COMMA we have new prefix bits for all of them .PERIOD and notice that our letter that appear with highest frequency gets added in late ,COMMA which means ,COMMA it's going to be nearer the root .PERIOD so now ,COMMA we have just the two and we finish the algorithm .PERIOD there's only two left now ,COMMA so we combine them .PERIOD i merge into a single try .PERIOD and that corresponds to prepending a one to the codes for all the other letters and just having a one bit code for a .PERIOD and that now winds up with a single try .PERIOD that's a demo of huffman's algorithm in operation .PERIOD so ,COMMA the huffman code is an answer to the question of how to find the best prefix code that's really very simple to describe .PERIOD count a frequency for each character in the input .PERIOD and you start with one node corresponding to each character with weight given by its frequency .PERIOD and just ,COMMA until you have a single trie ,COMMA you select the two with the minimum weight and merge them into a single trie by creating a new node with a weight sequel or the sum of the frequencies .PERIOD this algorithm is used in many different and familiar compression applications from pdfs to gzip to mp3s to jpeg .PERIOD and it's pretty simple to code up in java given the tools that algorithmic tools that we've built up .PERIOD so what we're going to do is this is the f of the frequencies have been computed .PERIOD and we're going to build a try given the frequencies .PERIOD and we're going to use a priority q in our generic priority q ,COMMA we might as well put nodes on it .PERIOD we implemented a compare -DASH to method .PERIOD all we need is the compare -DASH to to be able to build a priority q from data of that type .PERIOD so ,COMMA we have a priority q of nodes and for all the possible character values ,COMMA if they ,COMMA and if they appear in the message ,COMMA they have a nonzero frequency we'll just put in a new node with the given frequency that's a leaf onto the priority q .PERIOD and then the huffman algorithm is just as long as there's more than one node in the priority q .PERIOD we pull off the smallest two nodes ,COMMA we create a new node ,COMMA that's apparent .PERIOD it's character value is not used .PERIOD we compute the total frequency ,COMMA the sum of the two children and we make those children of that nod e ,COMMA and then we put that back onto the priority q .PERIOD and that's it .PERIOD take two off ,COMMA put one on .PERIOD it reduces in size by one .PERIOD so ,COMMA this while loop is eventually going to terminate .PERIOD when it's done ,COMMA there's only one node on the priority q and that's the root of the trie .PERIOD extremely simple implementation of huffman's algorithm using our generic priority q .PERIOD you can also implement it by presorting the of the nodes as well .PERIOD but this is a particularly nice way to do it .PERIOD now you do have to prove that it produces an optimal code .PERIOD that's in the sense that no code produces ,COMMA produce ,COMMA uses fewer bits .PERIOD and that proof is in the book .PERIOD it's ,COMMA it's not terribly difficult but we're not going to do it in the lecture .PERIOD the ,COMMA and that's ,COMMA huffman proved that it in the 1950s .PERIOD so ,COMMA there's no point looking for a better prefix -DASH free code .PERIOD and prefix -DASH free codes are so convenient cuz you don't need to worry about the ambiguity it's a fine method that's pretty easy to do .PERIOD so now what we have to do ,COMMA one disadvantage of huffman and some other methods don't have is ,COMMA we have to have two passes through the data .PERIOD we have to go through and read all the character frequencies and then build the trie and then we have to go back through the data and encode the file ,COMMA either traversing the trie from bottom up or using just a symbol table for to look up the code for each symbol in the message .PERIOD and the running time is pretty clear from the use of the trie ,COMMA the trie ,COMMA the number of characters in the number of nodes in the trie is just the alphabet size .PERIOD and so it's going to be alphabet size log r because there's trie operation that might involve depth of log for using heap implementation .PERIOD and then you have to be the for each character ,COMMA you have to do some kind of lookup to encode .PERIOD and actually a question is ,COMMA can we do better in terms of running time ?QUESTIONMARK and well ,COMMA stay tuned ,COMMA we'll look at a different method .PERIOD that's huffman compression .PERIOD 
now we're going to look at kd trees ,COMMA which is an extension of bsts that allow us to do efficient processing of sets of points in space and it's very flexible and very useful in lots of applications .PERIOD so now we're going to extend the api to talk about two dimensional keys .PERIOD so that's just ,COMMA you can think of two dimensional keys as ,COMMA points in the two dimensional geometric space .PERIOD so we're going to talk about insertion ,COMMA and search .PERIOD we won't talk about deletion and then range search and range count .PERIOD so ,COMMA we want to be able to insert and delete ,COMMA points .PERIOD you can think of a two dimensional key as a point in two dimensional space .PERIOD and we want to be able to find all keys that lie within a two dimensional range .PERIOD that's a rectangle .PERIOD as i mentioned at the beginning or count the number of keys that lie in a two dimensional range .PERIOD so again ,COMMA the geometric interpretation is the keys or points in the plane .PERIOD and we have a ,COMMA a ,COMMA a range ,COMMA 2d range is a ,COMMA a rectangle ,COMMA or is oriented ,COMMA to align with the horizontal ,COMMA vertical axes .PERIOD and we want to be able to find or count the points in a given rectangle .PERIOD in this one has many ,COMMA many applications and we'll talk about some of them later on .PERIOD and even if it's not points in the plane ,COMMA just databases you might ask for all the people with incomes between 1 ,COMMA000 ,COMMA000 and 10 ,COMMA000 ,COMMA000 who are between 40 and 50 years of age .PERIOD and this kind of algorithm and data structure would be useful for that kind of situation too .PERIOD so how are we going to solve this problem ,COMMA implement this api ?QUESTIONMARK we build a data structure containing points that can efficiently support range searching and range counting .PERIOD well one easy way to do it is to just think about dividing space into a grid of squares .PERIOD so we'll pick a parameter m and divide space into an m by m grid of squares and then process all the points and make a list of points that are contained in each square .PERIOD we can use a two dimensional array to directly index ,COMMA relevant squares .PERIOD and for insert ,COMMA you just ,COMMA take x ,COMMA y .PERIOD figure out which square it belongs to .PERIOD simply divide by ,COMMA both coor dinates by n ,COMMA and look into the two dimensional array .PERIOD and just add the point to the list for the corresponding square .PERIOD and then range searches ,COMMA only find the squares that intersect the query ,COMMA and process the points ,COMMA in that square .PERIOD and depending on the value of the parameter m ,COMMA you have a space/time tradeoff .PERIOD the amount of space required is m^2 for the grid + n .PERIOD you have to have a linked list element ,COMMA or whatever for each point .PERIOD and then the time ,COMMA though ,COMMA gets divided by m^2 .PERIOD your number of points and were spread out over the n squared ,COMMA different squares .PERIOD and so on average you examine n over m^2 points per square .PERIOD so you don't want to make m too big that would be too much space ,COMMA you don't want to make m too small that would be too much time .PERIOD so what we want to choose is the square size that would best balance these two needs and then it is easy to see that what you should choose is m to be about n square root of n .PERIOD so then your space is within a constant factor of n and your time is constant .PERIOD so if the points are randomly distributed ,COMMA then this is ideal .PERIOD it takes us ,COMMA linear time to initialize the data structure .PERIOD and to insert and search ,COMMA it take constant time per point in the range .PERIOD and this is absolutely a fine method that ,COMMA is not that difficult to implement ,COMMA in the case that the points are evenly distributed .PERIOD unfortunately ,COMMA it's usually the case that ,COMMA in geometric data ,COMMA that the points are not evenly distributed .PERIOD there's a well known phenomenon known as clustering that says that ,COMMA the ,COMMA the points aren't going to be evenly distributed all over the whole thing .PERIOD in the case of the ,COMMA the grid implementation ,COMMA they might all fall on the same square .PERIOD and so ,COMMA the average list length is short .PERIOD this is like what we encountered with hashing .PERIOD if you take ,COMMA all the points in one square ,COMMA and zero and all the rest of them .PERIOD your average is still ,COMMA n over m squared .PERIOD but .PERIOD they are all in that long list and you're going to have a slow algorithm if it's ,COMMA if it's based on this .PERIOD so we need a data structure that more gracefully adapts to the distribution of the data .PERIOD and again it ,COMMA it's well known that most geometric data has this kind of problem .PERIOD so for example here's some data which cities in the us .PERIOD it's got 13 ,COMMA000 points ,COMMA but if you try to use the grid implementation for this ,COMMA you'd find that half the squares would be empty .PERIOD and half the points are in just ten percent of the squares .PERIOD so ,COMMA the clustering in the data is going to make the implementation inefficient .PERIOD we need to adapt to the data .PERIOD and this is very ,COMMA very typical ,COMMA in geometric data .PERIOD particularly ,COMMA in higher dimensional data ,COMMA as we'll see in a minute .PERIOD so ,COMMA people have developed all different kinds of ,COMMA methods for ,COMMA adapting in this way .PERIOD and what we're going to look at is one of the most widely used .PERIOD which is basically to use a tree to represent a recursive subdivision of the plane ,COMMA of two dimensional space .PERIOD it's going to be recursive .PERIOD it's going to be based on the points the way in which we divide into half planes .PERIOD and its one of many different algorithms that ,COMMA have been ,COMMA studied for this ,COMMA but again its a simple one and widely used .PERIOD so ,COMMA for example if you played the game doom or use the flight simulator ,COMMA that ,COMMA these types of graphical simulations and animations are made possible only through the use of space partitioning trees ,COMMA like 2d trees and quad trees and also in all different types of scientific data processing these things are extremely important whenever you're processing .PERIOD geometric data ,COMMA doing some kind of geometric search .PERIOD where is the closest thing ?QUESTIONMARK how am i going to find the closest thing efficiently ?QUESTIONMARK what things are nearby ,COMMA and so forth ?QUESTIONMARK so ,COMMA rest assured ,COMMA these types of algorithms ,COMMA lie at the heart of ,COMMA any program that you use that ,COMMA is involving a lot of geometric data .PERIOD so ,COMMA those are just ,COMMA two examples .PERIOD so let's look at how it looks now .PERIOD so ,COMMA a 2d tree ,COMMA is ,COMMA again ,COMMA it's going to be a data structure based on a bunch of points that's going to facilitate ,COMMA efficient data processing of these points .PERIOD so ,COMMA just as we do for ,COMMA symbol tables ,COMMA where we take ,COMMA keys .PERIOD now we're going to ta ke points ,COMMA and we're going to build a data structure based on these points .PERIOD and the idea is to ,COMMA build a tree that corresponds to recursively partitioning the plane .PERIOD so arbitrarily our first point we're going to divide the plane into two parts based on a vertical line through that point .PERIOD so now ,COMMA in the tree on the right there ,COMMA all the points that fall to the left of the first point are going to be on the left ,COMMA and all the points that fall to the right .PERIOD that first point ,COMMA you're going to be on the right .PERIOD but then we get to the next point ,COMMA we'll switch and we'll partition on a horizontal line .PERIOD so now ,COMMA our second point ,COMMA in the tree ,COMMA the left sub -DASH tree corresponds to everybody below that horizontal line ,COMMA and the right sub -DASH tree corresponds to everybody above it .PERIOD similar if our third point comes on the left again we'll partition according to the horizontal line through that point on the left .PERIOD so if we go left and then left that means all the points to the left of one and above three ,COMMA so the square in the upper left is represented .PERIOD by ,COMMA that node in the tree .PERIOD and ,COMMA again .PERIOD now ,COMMA when we go one level below ,COMMA we switch again to vertical .PERIOD alternate between horizontal and vertical partitioning ,COMMA of the plane .PERIOD so it's a regular binary search tree .PERIOD but it's got this interpretation based on the geometric data ,COMMA where we switch which key we use for ,COMMA the comparison ,COMMA the x coordinate or the y coordinate ,COMMA at each level .PERIOD and that corresponds to this partitioning of the plane .PERIOD so now five comes in ,COMMA that's to the left of four because it was partitioned at a vertical and five's going to partion on a horizontal .PERIOD this is simple ,COMMA and completely well defined partion of the plane corresponding to a binary tree .PERIOD now the ninth point well it's to the left of eight ,COMMA above to and to the left of eight and then corresponds to horizontal partitioning ,COMMA tenth point is to the right of one ,COMMA it's below two and we go to the left and it's to the right of seven so we go to the right .PERIOD so that's a way to build a binary tree corresponding to a partitioning of the pla ne .PERIOD and it's really the same as the binary search tree .PERIOD it's just that we alternate which coordinate we use as the key .PERIOD at the even levels ,COMMA we think of a vertical line .PERIOD and the left subtree is all the points to the left ,COMMA and the right subtree is all the points to the right .PERIOD on odd levels ,COMMA we use a horizontal line ,COMMA in the left subtrees all points below .PERIOD in the right subtrees ,COMMA all points above .PERIOD and the ,COMMA and the code for this is ,COMMA you know ,COMMA the same as for binary search trees .PERIOD it's simply ,COMMA which ,COMMA coordinate we use for the comparison .PERIOD that's the only difference .PERIOD so that's 2d tree implementation .PERIOD so now what about solving a problem like this rain search problem for a 2d tree .PERIOD so now we have a query like this green rectangle and what we want to find is all the points in the data structure that fall within that rectangle .PERIOD well ,COMMA we're going to use ,COMMA the 2d tree represents our points and we are going to use the structure and definition of that tree ,COMMA to go ahead and help us find the points that are in the rectangle .PERIOD if ,COMMA if the root node lies in the rectangle then we're done .PERIOD we can return that ,COMMA that point but we have to look on both sides to look for more ,COMMA but if the rectangle lies to the left of the root node then we have to look at the left and so forth .PERIOD so let's look at how this works in the demo .PERIOD all right ,COMMA so ,COMMA we're going to try to find all the points that are contained in that green query rectangle .PERIOD so first thing is ,COMMA to check if our rectangle contains the node of the root .PERIOD in this case it doesn't .PERIOD so since ,COMMA it's to the left of the splitting line of the root we only have to search in the left sub -DASH tree .PERIOD now ,COMMA we search the left sub -DASH tree and we're going to check if it contains .PERIOD3 .PERIOD it does not contain .PERIOD3 ,COMMA but now which ,COMMA sub -DASH trees do we search ?QUESTIONMARK in this case ,COMMA now the rectangle intersects a splitting line ,COMMA so we have to search both subtrees ,COMMA both above and below .PERIOD so ,COMMA first we search the left subtree that's the one below does it contain  .PERIOD4 ?QUESTIONMARK no .PERIOD it's to the left so we're going to have to search the left sub -DASH tree of  .PERIOD4 .PERIOD and so we search the left sub -DASH tree and we check if it contains point five and it does ,COMMA that's the one that we return .PERIOD it ,COMMA it also intersects the splitting lines ,COMMA we have to search both the sub -DASH trees ,COMMA in this case they're both empty .PERIOD so we're done with that but now we have to go back and we have to search the other sub -DASH tree of point three and that's the above ,COMMA so now we check this  .PERIOD6 in the rectangle .PERIOD in this case ,COMMA it's not .PERIOD and it's still a left sway if it's to search the left sub tree a  .PERIOD6 and that one's empty and now we return and we're done .PERIOD so we don't always go down just one branch if our splitting line hits a rectangle we have to go down both branches but still this is a very efficient algorithm ,COMMA particularly think about the rectangle being small ,COMMA it's going to be not that different than a regular search in a binary search tree .PERIOD alright .PERIOD so what about the analysis of how long is this going to take ?QUESTIONMARK well again ,COMMA a typical case .PERIOD a rectangle's small that we're only going to examine ,COMMA really ,COMMA a path of the three ,COMMA maybe a couple of other nodes along the path .PERIOD and the running time will be proportional to the number of points returned plus lg n .PERIOD with geometric data the worst case can be bad .PERIOD so ,COMMA like all the points could be arranged in a circle .PERIOD all ,COMMA all different types of problems that might occur in ,COMMA with some difficulties .PERIOD it's possible to prove ,COMMA that even if the tree is balanced ,COMMA you can get a worst case proportional to square root of that .PERIOD so analysis of 2d trees that the under scope .PERIOD but ,COMMA for many practical applications they are easily implement and worth using .PERIOD let's look at another using 2d trees to solve another problem ,COMMA a so called nearest neighbor search .PERIOD so now ,COMMA instead of a rectangle ,COMMA we have a query point .PERIOD and our goal is to find the closest point to that point .PERIOD so in this case our query point is ,COMMA over here in green .PERIOD and our algorithm's going to want to return to 0 .PERIOD5 .PERIOD that's the closest one to the query point .PERIOD so let's see how that looks in a demo .PERIOD so again ,COMMA we start at the root .PERIOD and wh at do we want to do ?QUESTIONMARK well ,COMMA we're going to check .PERIOD and i ,COMMA whenever we're at a node ,COMMA it represents a point so we're going to check that point and we'll compute the distance from that point to our query point .PERIOD and ,COMMA if that distance is less than the best found so far ,COMMA then we'll keep that as the champion .PERIOD so the first point ,COMMA that's the closest we've found so far to the query point .PERIOD so we'll say ,COMMA number one is the distance .PERIOD and we'll only worry about the possibility of finding something closer ,COMMA than that .PERIOD and so just using that distance we recursively search ,COMMA any part of the tree that could contain a closer point .PERIOD and so that's well it continued to do so in this case the query point is to the left of the splitting line and will always go towards the query point first and so in this case we have to search both to see if there might possibly be a closer point than one over on the right if you come like straight across ,COMMA there might be a closer point .PERIOD we're going to have a look at both as far as we know now but we'll go towards .PERIOD the query point and see if we can find something closer .PERIOD so in that case now we go to  .PERIOD3 .PERIOD compute the distance of that point to the query point .PERIOD it's closer so we update three to be our new champion .PERIOD so now we are going to look in parts of the tree that could give us a point that is closer to our query point then three .PERIOD so already that would mean when we search the point one we wont search the right sub tree because there could be no point on the right sub -DASH tree right of the splitting line .PERIOD so lets closer to query point than three and so that idea getting closer and closer to the query point is going to cut out different parts of the tree as we process so ,COMMA but anyway starting at point three as far as we know that we may have to look at both sub trees ,COMMA so sometimes when we look at both sub -DASH trees but as we get closer and closer we only look at one so lets look at point three now .PERIOD so ,COMMA again ,COMMA go towards the query point .PERIOD so we'll ,COMMA go to the top first ,COMMA and that takes us to six .PERIOD six is not any closer than three was .PERIOD so that's not going to ,COMMA update our champion .PERIOD and so we'll search 6's left sub -DASH tree which is empty which is right sub -DASH tree and the nearest neighbor can't ,COMMA we don't have to go down the right sub -DASH tree of six because you can't have a point in that rectangle that's closer to the query point than three .PERIOD so now we can return from that ,COMMA and now we have to look at the bottom sub tree associated with three .PERIOD and so that takes us to four ,COMMA and that one is ,COMMA not closer .PERIOD so we still have three as our current champion .PERIOD so now ,COMMA we'll search the left subtree of four first because that query point is to the left of that splitting line .PERIOD and that takes us to five and five is our new champion .PERIOD so that's the closest point that we know about .PERIOD could there be a node that's closer to five ,COMMA to our right query point than five in the right subtree of four ?QUESTIONMARK oh .PERIOD we have to go above .PERIOD sorry to look at the top sub -DASH tree associated with five ,COMMA and we find that it's empty .PERIOD and now we're back at four .PERIOD do we have to search the right sub -DASH tree of four ?QUESTIONMARK no ,COMMA because there can't be a closer point ,COMMA than five in the right sub -DASH tree of four .PERIOD so we're done with four ,COMMA and we return to ,COMMA come to three ,COMMA and now we search the ,COMMA suppose to search and return from there we are now at one ,COMMA suppose to search the right subtree one next but we can term that nearest neighbor couldn't be in there .PERIOD so ,COMMA then we are done and we found that the nearest neighbor ,COMMA is five .PERIOD and this is going to be ,COMMA very efficient because as we get closer and closer ,COMMA the query point ,COMMA we are cutting out all the subtrees that are away ,COMMA and again in practice ,COMMA the running time of this algorithm ,COMMA is going to be close to logarithmic .PERIOD so in ,COMMA in typical cases that the running time of nearest neighbor search in a 2d tree is going to be proportion to logarithmic .PERIOD it is possible to concoct cases where you are going to have to examine all the points for example if they're all arranged in a circle and your query points to the center or something of that sort .PERIOD but for typical data it's very efficient .PERIOD now we're going to look at an application where we simulate a phenomenon in nature .PERIOD and this is what kind of patterns do things like starlings and geese or cranes or ,COMMA or fish or fireflies ?QUESTIONMARK how do they flock together .PERIOD and we'll look at a simulation that corresponds to that .PERIOD and then ,COMMA when the moment is right ,COMMA they behave in a way ,COMMA that should be impossible .PERIOD [music] and it happens everyday ,COMMA right through the winter .PERIOD just a couple of miles from my doorstep .PERIOD help you desire .PERIOD >> so to ,COMMA there's a simple model developed by craig reynolds awhile ago for simulating this situation called the boid .PERIOD and the idea is to use three simple rules to you get something very close to this complex flocking behavior .PERIOD so ,COMMA you have col ,COMMA collision avoidance where you always try to point away from the k nearest boids .PERIOD you have centering where you try to point near the center of mass of the k nearest boids ,COMMA and velocity matching where you update your .PERIOD philosophy to the average of the k nearest boids .PERIOD and that algorithm works like this .PERIOD so as that example shows ,COMMA 2d trees are extremely effective in quickly processing huge amounts of geometric data ,COMMA and what's more ,COMMA it expands to more dimensions .PERIOD with a very simple modification we can take it to d tree and created data structure known as a kd tree ,COMMA which even works for k dimensions and the idea is even if there is k dimension ,COMMA what we will do is recursively partition one dimension at a time ,COMMA so that's called a kd tree and we use the same ideas for two d trees ,COMMA but instead of cycling through just horizontal vertical ,COMMA we cycled through ,COMMA however many dimensions there are ,COMMA so its where in three space ,COMMA we use a plane and do above and below and then simply cycle through the dimensions .PERIOD at level i ,COMMA we put on the left points whose i -DASH th coordinates are less than p and on the right ,COMMA we put the points to whose i -DASH th coordinates are greater than p and at level in cycle three of the dimensions at the level i might k we just use that dimension of the point to do the comparison .PERIOD the implementation is simple ,COMMA ex cept for the comparison .PERIOD and we get the same kind of partitioning for three dimensional data ,COMMA so we could do boids in three dimensions or for databases with large number of dimensions .PERIOD you could do even much higher dimensional data .PERIOD and find nearest neighbors and do range searching extremely efficiently .PERIOD it's a very efficient and simple data structure for processing k dimensional data that's very widely used and the whole idea is that data clusters ,COMMA particularly ,COMMA in high dimensions .PERIOD and also one point to make for this class is that ,COMMA this algorithm was discovered by an undergraduate in an algorithms class ,COMMA so that's ,COMMA john bentley ,COMMA who discovered this while an undergraduate at stanford .PERIOD and ,COMMA so it's a simple idea that ,COMMA but ,COMMA experts scientists where struggling with ,COMMA dealing with huge amounts of geometric data ,COMMA and ,COMMA bentley found this way ,COMMA to process it efficiently that's been widely used ever since .PERIOD and in ,COMMA in particular just as another example consider the idea of n body simulation which is a classic problem in physics .PERIOD where you've got n particles mutually affected by gravity and basically the computation is based on computing the interacting force for each pair of particles .PERIOD and so then there'd be mutual gravitational pull .PERIOD [inaudible] and this is what happens with a large number of particles in a certain simulation and people understand properties in the universe by coming up with ,COMMA doing these kinds of calculations and comparing against what's observed in space .PERIOD now but the thing is for each pair of particles ,COMMA so if you have m particles and you have to do it for each pair ,COMMA that's m^2 so the progress of scientific investigation is going to be affected by how quickly ,COMMA you can do this calculation for a large number of particles .PERIOD there's a lot of particles out in the universe .PERIOD and ,COMMA you can't do a quadratic calculation for large n .PERIOD so ,COMMA another ,COMMA undergraduate in an algorithms class discovered ,COMMA this idea ,COMMA for n body simulation .PERIOD and that's ,COMMA andrew appel .PERIOD and his idea was that if some part .PERIOD particle is way away from som e cluster of particles ,COMMA we can treat that cluster as a single aggregate particle .PERIOD and not do the individual force calculation between our particle and every one of those in the aggregate .PERIOD but use the center of mass .PERIOD and you get a very accurate approximation to the n body doing that .PERIOD and the algorithm that he used is based on 3d trees .PERIOD with the n particles as nodes and storing the center of a mass of a sub -DASH tree in each node .PERIOD and then to compute the total force ,COMMA traversing the tree of all the information that you need ,COMMA to ,COMMA complete the n body calculation .PERIOD but in time ,COMMA much closer to n lg n than to n^2 .PERIOD and that ,COMMA idea that ,COMMA you didn't need to take time proportional to n^2 but with a ,COMMA a geometric algorithm ,COMMA like a 3d tree ,COMMA you could get the time to n lg n .PERIOD that enabled ,COMMA all sorts of new scientific investigation in this example of the use of algorithms to enable new 
okay next we're gonna look at another extension of geometric algorithms to process slightly more complicated objects and then we'll see an important application .PERIOD this is called interval search .PERIOD so now instead of points ,COMMA our data is intervals .PERIOD so this is ,COMMA we'll start with one dimension as before and right away you can see that it's a more complicated problem than we've been dealing with .PERIOD so we want to support the following operations .PERIOD we wanna be able to insert an interval .PERIOD so an interval is just a left endpoint ,COMMA right endpoint of a 1 -DASH dimensional data or points on the line .PERIOD we wanna be able to insert an interval search for an interval ,COMMA delete an interval but the main thing is we want the interval intersection query .PERIOD so given a query interval ,COMMA we want to find all intervals in the data structure that overlap that interval or find any interval we'll start with that simpler problem .PERIOD so how are we going to support that ?QUESTIONMARK so this is the api in java code [cough] ,COMMA so we ,COMMA have ,COMMA intervals ,COMMA so instead of one key we have two ,COMMA which is left and right end points of the interval for input .PERIOD and [inaudible] ,COMMA and then we have delete ,COMMA and then we have intersects .PERIOD and again simplify the code ,COMMA we are going to make the non degeneracy assumption that no two intervals have the same left end point .PERIOD [cough] and ,COMMA [cough] .PERIOD easy ,COMMA easy to fix but ,COMMA but we don't simplify the code .PERIOD so now we'll look at a data structure called an interval search tree that helps to solve this problem .PERIOD and ,COMMA it's a extremely ,COMMA simple algorithim ,COMMA but surprisingly ,COMMA complicated to understand ,COMMA so we'll go slowly .PERIOD so the first thing is what we're going to do is use the left end point of each interval as the binary search tree key .PERIOD so our ,COMMA eh ,COMMA our node stored intervals ,COMMA but we only use our left end point as the key .PERIOD so this is the binary search tree that's built from those five intervals ,COMMA six intervals in our example .PERIOD seventeen ,COMMA nineteen is at the root ,COMMA so everybody with a le ft end point less than seventeen is to the left ,COMMA the left end point greater than seventeen is to the right and so forth .PERIOD so that's a binary search tree built ,COMMA from those intervals .PERIOD so that's easy .PERIOD i just build a binary search tree .PERIOD i just use ,COMMA the left end point ,COMMA as the search key .PERIOD but we're also in the ,COMMA each node of the tree ,COMMA we're gonna store ,COMMA not just the interval .PERIOD but we're gonna store the ,COMMA largest endpoint in the subtree rooted at that node .PERIOD so at every node ,COMMA we're gonna store the maximum endpoint and subtree rooted at that node .PERIOD so at the root ,COMMA the maximum endpoint or the rightmost point covered by an interval ,COMMA is 24 .PERIOD so we [inaudible] 24 at the root ,COMMA and ,COMMA of course ,COMMA the right subtree .PERIOD and the left subtree .PERIOD the max end point is that eighteen so that's what we store for the associated data with the note to the left of the root and so forth .PERIOD so .PERIOD we going to have to ,COMMA that's data that we're going to have to maintain when we do an insert and it's data that we'll use when we're doing an interval -DASH intersection search .PERIOD so let's take a look at an insertion into an interval search tree with a demo .PERIOD all right ,COMMA so ,COMMA the ,COMMA insertion algorithm is pretty simple .PERIOD we do the bst insertion ,COMMA just so we have to do that ,COMMA update of the maximum in each node on the search path .PERIOD so ,COMMA to insert 16/22 in this tree ,COMMA while we use the ,COMMA left endpoint as the search key ,COMMA sixteen is the left endpoint of our insert interval [cough] .PERIOD we compare that with seventeen and therefore go left .PERIOD how sixteen is bigger than five so we go right .PERIOD now sixteen is bigger than fifteen so we go right .PERIOD and that's null ,COMMA so that's where we insert our new ,COMMA interval .PERIOD [sound] .PERIOD so now ,COMMA we're gonna go back up the tree .PERIOD and ,COMMA for every node that we encounter ,COMMA it could be that ,COMMA our right endpoint of our interval ,COMMA is bigger than what was there .PERIOD so we have to check ,COMMA all the way up the path ,COMMA the maximum in each node on the path .PERIOD so we have to check each node ,COMMA to see if 22 is bigger ,COMMA and ,COMMA for the three nodes to the left it is bigger than eighteen .PERIOD for the node at the root ,COMMA it's not .PERIOD that stays to be 24 .PERIOD so ,COMMA it's just binary tree insertion ,COMMA but then after the insertion on the way up ,COMMA we go ahead and ,COMMA check ,COMMA if the maximum that we have is bigger than the maximum there and update it if necessary .PERIOD so easy to code .PERIOD [sound] .PERIOD alright ,COMMA so now about ,COMMA how do we do a ,COMMA a search .PERIOD so the searches is definitely more complicated and kind of mysterious ,COMMA but let's look at the rules for search in an interval search tree .PERIOD alright so now we're gonna look to see if we have an intersection what a .PERIOD we want to find just .PERIOD any interval that intersects this query interval 23 25 .PERIOD we're not gonna try to find them all we'll get back to that in a minute .PERIOD try to find any interval that intersects our query interval .PERIOD so let's ,COMMA let's see what we have to do .PERIOD so first thing is if at the root ,COMMA we have an intersection ,COMMA then we're done .PERIOD we just return .PERIOD in this case ,COMMA 2325 does not intersect ,COMMA 1719 .PERIOD so ,COMMA we have to go down the tree somewhere .PERIOD so left subtree is [inaudible] right ,COMMA okay ?QUESTIONMARK otherwise ,COMMA we have to check whether the max endpoint in the left subtree is less than ,COMMA the low point in our interval .PERIOD [inaudible] it's easy to see ,COMMA well ,COMMA if that's the case ,COMMA then we're not gonna find an intersection .PERIOD in the left .PERIOD the maximum end -DASH point in the left is 22 ,COMMA and we're looking for 23 ,COMMA and we're not gonna find anything there ,COMMA so we just wanna go right .PERIOD so in this case we'll go right 22 ,COMMA 23 no inter sectional left ,COMMA so we go right and now we do find an intersection 21 ,COMMA 24 does intersect with 23 ,COMMA 25 because 23 is in the middle there ,COMMA so we find an intersection .PERIOD now on the other hand ,COMMA let's say they were looking for 1214 ,COMMA so no intersection .PERIOD so .PERIOD all the algorithm says is that ,COMMA if you didn't go right ,COMMA go left .PERIOD so let's go left ,COMMA in this case .PERIOD so we weren't able to show that there was no intersection ,COMMA on the left .PERIOD so ,COMMA so we're gonna go left .PERIOD in this we compare twelve fourteen to five eight ,COMMA so now we apply the same rules .PERIOD does it intersect ?QUESTIONMARK no ,COMMA it doesn't intersect .PERIOD so should we go left .PERIOD well no ,COMMA the maximum ,COMMA end point in the left node is eight .PERIOD so we can have intersection there ,COMMA so we gonna go right ,COMMA [inaudible] to twelve and go right .PERIOD so ,COMMA now does twelve ,COMMA fourteen intersect fifteen ,COMMA eighteen it does not so there's no intersection so now what do we do .PERIOD should we go left no the max in point on left is ten so we shouldn't go left .PERIOD so we're going to go right .PERIOD those 12 -DASH 14 intersect 16 -DASH 22 .PERIOD it does not ,COMMA so ,COMMA now ,COMMA the left end point's null .PERIOD and so we're just gonna go right .PERIOD and there's no intersection .PERIOD so in both cases we just went along one path in the tree to determine whether or not there was an interval or intersection .PERIOD let's look at one more example .PERIOD 21 ,COMMA 23 .PERIOD so let's see .PERIOD 21 thru 23 to seventeen ,COMMA nineteen .PERIOD they do not intersect ,COMMA so now ,COMMA what are we gonna do next ?QUESTIONMARK well we're gonna compare the left sub -DASH tree ,COMMA and it's not ,COMMA 22 falls within our interval so it's not less than'r' so there might be an intersection there so we better go to the left ,COMMA so we do go to the left .PERIOD now we compare against 5 -DASH 8 ,COMMA and there's no intersection .PERIOD so now ,COMMA we're gonna go left to right .PERIOD well ,COMMA we're gonna go to the right ,COMMA because ,COMMA the max endpoint in the left subtree is eight ,COMMA and our interval's 21 ,COMMA so no intersection on the left .PERIOD so we're gonna go right .PERIOD intersection 21231518 .PERIOD they do not intersect .PERIOD so now ,COMMA do we go left or right ?QUESTIONMARK again ten is less than our left endpoint 21 .PERIOD so we better go to the right .PERIOD [cough] .PERIOD and now 2123 does intersect 1622 ,COMMA so we return and intersection .PERIOD again one path through the tree to determine an intersection .PERIOD so from these rules you can see that the man of code required to implement this intersecting inter role is extremely low .PERIOD just check for an intersection ,COMMA if we find it ret urn if left is no we go right .PERIOD otherwise if the max is less than low we go right .PERIOD otherwise we go left .PERIOD could hardly be simpler .PERIOD really amazingly simple and efficient algorithm .PERIOD we should convince ourselves really that it always works and so we'll spend just a moment on a short proof .PERIOD so let's look at the ,COMMA the cases that could happen .PERIOD so first thing is if the search goes right .PERIOD then there's no intersection on the left .PERIOD and that's easy to convince ourselves of that just from ,COMMA from what we did in the demo .PERIOD of course ,COMMA if the last sub -DASH tree's empty ,COMMA there's no intersection there .PERIOD but if the max endpoint in the left sub -DASH tree is less than low ,COMMA that means every interval in the left sub -DASH tree has a max endpoint less than mah ,COMMA low ,COMMA and so therefore it can't intersect .PERIOD so if you go right ,COMMA there's no intersection in the left .PERIOD any possible intersection would have to be in the right ,COMMA and then the other point is that if you go left ,COMMA then either there's an intersection there ,COMMA or there's no intersections at all .PERIOD so lets suppose that there is no intersect ,COMMA and that's equivalent to saying ,COMMA if there is no intersection in the left then there is no intersection in the right .PERIOD so lets look at it if there is no intersection in the left ,COMMA since we went to the left and then we have got ,COMMA low less than max .PERIOD but ,COMMA for any interval ,COMMA in the right subtree ,COMMA its got to appear after .PERIOD low .PERIOD be ,COMMA because since there's no intersections in the left sub tree high has gotta be less than c .PERIOD where ,COMMA because they're sorted by left n point .PERIOD and then that means that c -DASH s got to be less than a if it is in the right ,COMMA so therefore there can't be any interesection in the right either .PERIOD no intersection in the left means no intersections at all ,COMMA so those two cases is enough to show that this algebroid finds an intersection ,COMMA if there is one .PERIOD and the other thing we can do with this is just use a red -DASH black bst to guarantee that we solved this in time proportional to log in .PERIOD so insert ,COMMA find ,COMMA delete ,COMMA and find any interval that intersects .PERIOD all take time ,COMMA guaranteed ,COMMA proportional to log in .PERIOD and if we wanna find all intervals we just have to run the algorithm fur each interval that's ,COMMA until we come up against no intersection ,COMMA so it'll take time proportional to r log n if there's r intervals that intersect .PERIOD the theoretical best that you could possibly do would be r plus log n but in practice r log n is quite efficient .PERIOD this is an easy and very efficient algorithm to solve this interval search problem and as we'll see this algorithm .PERIOD it's applicable to an important application that we'll see in a 
so ,COMMA huffman coding is an optimal prefix -DASH free code .PERIOD and can we have a better data compression algorithm ?QUESTIONMARK and as you might suspect the answer is yes .PERIOD and that's we're going to look at next it the lzw algorithm ,COMMA named after abraham lempel and jacob ziv ,COMMA and w is for terry welch who got involved .PERIOD and so the way that we improve on huffman coding is by changing the rules under which it operates .PERIOD and we've already changed the rules once ,COMMA so let's take a high level view .PERIOD so one idea for codes is that we're going to ,COMMA for all text that we ever encounter ,COMMA we're going to use the same code or the same model of the text .PERIOD and so everybody's got that model ,COMMA we don't have to transmit it .PERIOD but the problem is that one text might have a lot of as another one might have a lot of zs .PERIOD they have different statistical properties .PERIOD so ,COMMA it's not going to be optimal for a given text .PERIOD but still ,COMMA over the preponderance of text that we see this can be effective .PERIOD and so ,COMMA that's really what an ascii is .PERIOD but now ,COMMA for huffman ,COMMA well ,COMMA we consider ,COMMA we change that rule .PERIOD and we said ,COMMA well ,COMMA we're going to use different encodings depending on what the text is .PERIOD so ,COMMA we're going to look at the text ,COMMA figure out the frequencies and then ,COMMA go ahead and create a code that works for that text .PERIOD now ,COMMA we have to transmit the code .PERIOD that's what the huffman's code is .PERIOD for every text we've got a code that's suited for that text .PERIOD what we're going to look at now is another change in the rules ,COMMA where it's called an adaptive model ,COMMA where we're going to just read the text one character a time .PERIOD but we're going to use the text to update the model and learn about the model as we read it .PERIOD and we're going to assume the decoder does the same thing .PERIOD and this gives perhaps it does give more accurate modelling and better compression over the ,COMMA throughout the text .PERIOD and it's a very effective method ,COMMA so let's look at how it works .PERIOD we'll just do this through an example .PERIOD now ,COMMA this is ,COMMA we're going to use hex values .PERIOD so ,COMMA in lzw encoding we start with our input ,COMMA which is which is characters .PERIOD o r say ,COMMA ascii characters .PERIOD and what we're going to do is keep a dictionary of code words .PERIOD and the code words are going to be fixed length .PERIOD and so ,COMMA we'll use eight bits or two hex characters as an output .PERIOD and we'll start out with just the ascii value for all the characters that we're going to use in the message .PERIOD so ,COMMA that's the starting point .PERIOD so ,COMMA at the beginning ,COMMA so this is going to be compression for this string here .PERIOD at the beginning we just pick off characters and output their value from the from the table .PERIOD but every character that we read ,COMMA it gives us a little new information .PERIOD for example ,COMMA in this case we've seen ab and what we're going to do is say ,COMMA okay ,COMMA we've seen ab ,COMMA maybe that occurs again in the text if it does we'll since ,COMMA since we've seen it ,COMMA we know where it is ,COMMA we know what it is .PERIOD we'll just give it the value 81 and we'll maintain this table .PERIOD if we see ab again we'll use those eight bits .PERIOD so we put out the b ,COMMA but we remember the fact that we saw ab .PERIOD and similarly ,COMMA when we see br then that will be an 8 -DASH bit code word that we can put out .PERIOD and the idea is that the decoder or the expander can do the same thing .PERIOD we don't actually have to transmit this table .PERIOD we can know that the expander is going to do the same thing ,COMMA and we'll have the same a table .PERIOD so now ,COMMA we see the r .PERIOD so ,COMMA this is br .PERIOD so then ,COMMA and that's going to be encoded with 82 but the r is asking for r52 so we put that out .PERIOD now we see the a and so ,COMMA that's going to be 83 .PERIOD if we if we see it again and ,COMMA but the a is just 41 and then the ac is going to be 84 the c is the 43 .PERIOD ca is going to be 85 and then 41 .PERIOD and so ,COMMA what we're doing is building up a table that is a model for what the string has and it will allow us to get better compression as we get layer into the message .PERIOD so now ,COMMA we're reading the a after the b ,COMMA so d is going to be 87 .PERIOD but now ,COMMA we see that the next letter is b ,COMMA we look in our table in for ab and it's there .PERIOD so ,COMMA we can put out 81 instead of just putting that a out there .PERIOD so at this point when we look at the b we can know that we had ab .PERIOD and we can look that up on the table and just put out 81 .PERIOD and similarly we when we ,COMMA but now ,COMMA when we look at the r our previous character was ab .PERIOD so now ,COMMA we're going to code abr with 88 .PERIOD and again ,COMMA ra if we look that up in the table and we can put out 83 .PERIOD and now ,COMMA we can remember rab is going to be 89 .PERIOD so now ,COMMA what happens next ?QUESTIONMARK now ,COMMA we look at our next characters .PERIOD we look for the longest prefix that we can match in the table and that's going to be the code word that we put out .PERIOD so in this case ,COMMA we have br that's in there that's 82 .PERIOD and the next character is a so i'm going to put a bra in there .PERIOD and now this is the remaining to be encoded and we're going to look for the longest prefix that we know the code for ,COMMA and in this case ,COMMA it's going to be abr ,COMMA which is 88 .PERIOD so the previous characters in the text built a model that allow us to more effectively encode the text .PERIOD and that's 88 abr and then all that's left is the last a .PERIOD so ,COMMA for this small example the ,COMMA compression is not great ,COMMA but the idea is still there's definitely some savings in there ,COMMA cuz these code words ,COMMA the input was 8 -DASH bit ascii code words ,COMMA and these code words are ,COMMA are also eight bits ,COMMA and the key thing is we don't have to transmit the table ,COMMA cuz we can assume that the expander is going to rebuild the table ,COMMA the same way that we built it .PERIOD so ,COMMA that's the basic idea beside behind lzw compression .PERIOD we also have a stop character at the end that says ,COMMA it's the end of the message .PERIOD so ,COMMA this is the summary of lzw compression .PERIOD we created a symbol table that associates fixed length code words with string keys .PERIOD we initialize it with code words for single character keys .PERIOD now ,COMMA when it's time to encode part of the input ,COMMA we look for the longest string in the symbol table that's a prefix of the part of the input we haven't seen .PERIOD and that string ,COMMA that's the longest one ,COMMA its the best we can do .PERIOD we're going to have a fixed length code word for that string .PERIOD and then ,COMMA we look ahead to the next character in the input and add a new entry into the symbol table with tha t one extra character .PERIOD that's the lzw compression .PERIOD so one question that comes up is how do we represent that code table in ,COMMA in code .PERIOD and actually ,COMMA the answer is really simple .PERIOD we're going to use a trie .PERIOD because what a trie can do for us is if you remember ,COMMA when you looked at the tries ,COMMA if you don't know ,COMMA when we looked at tries ,COMMA what we did was support longer prefix match operation .PERIOD so ,COMMA this trie represents all the prefixes that we have seen so far in the message ,COMMA and it's very easy if the next four characters in the text for abra ,COMMA then we have the code word for it .PERIOD for anything that we've seen in the text we've got a code word for a fixed length code word .PERIOD so ,COMMA as the trie gets bigger ,COMMA as we move down more into the trie ,COMMA we get better compression cuz we're using the same length code word to compress more letters .PERIOD so here's the implementation of lzw compression .PERIOD again very simple implementation for such a sophisticated algorithm ,COMMA really .PERIOD and we're actually going to use the tst so that we'll have to worry about the extra space .PERIOD and so ,COMMA first thing we do is initialize the tst with a code word for each of the single characters ,COMMA so it's rated xr ,COMMA so there are different letters .PERIOD and we'll just put an entry into the trie for each one of the letters along with its coding .PERIOD and so we didn't show ,COMMA we only showed a few letters in the examples ,COMMA but in general ,COMMA we'll ,COMMA we'll assign the code word i to each one of the ,COMMA to the ith letter .PERIOD and then ,COMMA the rest of the trie is built from the input string .PERIOD and you know ,COMMA so the very first thing we do is find the longest prefix of the input string in the symbol table .PERIOD and that longest prefix of method just marches down the trie eating off the characters in the input string one character at a time until it gets to the bottom ,COMMA because the bottom it has a code word .PERIOD so it ,COMMA it actually ,COMMA the symbol table method actually gives us back the string .PERIOD and so ,COMMA then we can use that to get the value associated with that string out in the symbol ,COMMA in the second call .PERIOD and that gives us the code word .PERIOD an d then what we want to do is get the length of that longest prefix match and add one more character to it and add which is the next character in the input .PERIOD and add that code word to the to the symbol table .PERIOD and then scan past that in the input .PERIOD so that's the entire compression algorithm for lzw compression using a trie .PERIOD and so ,COMMA what it's doing is writing out a fixed -DASH length code word and chewing up the longest substring that we've seen before .PERIOD and then ,COMMA at the end ,COMMA it writes out a stop close code word ,COMMA and closes out the input stream .PERIOD so ,COMMA using the tech ,COMMA trie technology that we've developed we have a compact implementation of lzw compression .PERIOD now ,COMMA let's look at the expansion .PERIOD and expansion is going to be basically the same code .PERIOD all that the expansion algorithm get ,COMMA gets is the list of fixed length code words .PERIOD and it's going to maintain its own code word table in order to get the expansion done .PERIOD now ,COMMA we can start it out again by generating the table for a each other single letter that's going to be in the message or if it's only a few may be .PERIOD there is some other sliding coding that needs to be done at the beginning .PERIOD but so ,COMMA it seems 41 in roles are switched .PERIOD the fixed length code words of the key and the values are strings .PERIOD so ,COMMA we just look up the key and write out the values as we see at 42 ,COMMA that's a b we see .PERIOD a 41 ,COMMA that's an a .PERIOD but not only do we want to put ,COMMA put out the ,COMMA the character corresponding to the code word .PERIOD but we also want to build up code words in the same way that the compression method would have done it .PERIOD so ,COMMA the compression method i want to see is an ab would have associated the string ab with a new key .PERIOD and now ,COMMA we read a 52 .PERIOD look up 52 ,COMMA that's an r but we also put a new entry in the table for the string br .PERIOD same way the compression algorithm would have done .PERIOD we see 41 we get an a .PERIOD now ,COMMA we put ra in the table 43 we put a c and we put a c in the table 41 ,COMMA we put an a .PERIOD we put ca in the table now 81 .PERIOD we look up at our table ,COMMA and it's i'm sorry .PERIOD the d is 44 and ad in the table .PERIOD and now 81 ,COMMA we look at up ,COMMA and we have ab and once we have seen the ab then we know the compression were to put da on the table .PERIOD and that's a little bit tricky because the expansion is kind of one step behind the compression .PERIOD it's got to put out the characters before it knows it .PERIOD and it does lead to a slightly tricky situation that we'll talk about .PERIOD so now 83 is going to be ra .PERIOD and once we put out the ra ,COMMA then we know that compression would have done abr now ,COMMA so now 82 is br .PERIOD and again ,COMMA we know compression would have put rab in there .PERIOD and 88 is abr and compression would have put bra in there .PERIOD 41 is a and then 80 is the stop character .PERIOD oh ,COMMA and we would have put and once it did the a ,COMMA then it would have put abra in there .PERIOD and then ,COMMA 80 is the stop character .PERIOD so ,COMMA that's an expansion just building the table in the same way the compression would have and then ,COMMA using the table to figure out the string associated with ,COMMA with each fixed length code word .PERIOD so this is a summary of expansion which is pretty much the same as for compression except the reverse .PERIOD so we're going to create a symbol table that has fixed linked keys and associates string values with them .PERIOD we put in the single character values .PERIOD we read a key ,COMMA we find the string value and write it out .PERIOD and then ,COMMA we update the symbol table from the last the two things that we ,COMMA the first character ,COMMA the thing we just wrote out and the thing we wrote out before that .PERIOD and again you know ,COMMA to represent the ,COMMA the code table this time we can just use an array .PERIOD and because we ,COMMA our keys are ,COMMA are fixed linked .PERIOD and we assign them one ,COMMA one bit at a time .PERIOD so ,COMMA we can just store the strings in an array .PERIOD and use the ,COMMA the key bits ,COMMA the key values ,COMMA the fixed bits ,COMMA key values we get to index into the array and give us the right string .PERIOD so that part's easier .PERIOD so now there's a tricky case that really everyone needs to work through this case a few times to really understand what's going on .PERIOD and it's worth doing once even in lecture .PERIOD so ,COMMA let's look at this case where we have ab ,COMMA ab ,COMMA aba and just follow through th e algorithm for this for this case .PERIOD so we get an a ,COMMA and we look it up ,COMMA and it's 41 .PERIOD and so ,COMMA that's what we're going to put out .PERIOD and then ,COMMA we look at the next character .PERIOD and it's ab so we're going to remember 81 in our code word table .PERIOD then ,COMMA we read a b .PERIOD and we look it up ,COMMA and it's 42 .PERIOD and the next character is a .PERIOD so ,COMMA we're going to say ,COMMA well ,COMMA ba is going to be ,COMMA be 82 .PERIOD then next character is b .PERIOD we look up ab and we have 81 .PERIOD and so ,COMMA we can put out the 81 .PERIOD and now ,COMMA the next ,COMMA look ahead ,COMMA the next character is a .PERIOD so ,COMMA we're going to do a code for aba .PERIOD that's going to be 83 .PERIOD now ,COMMA we have the rest of our string to be encoded is aba and our longest prefix match is aba .PERIOD so ,COMMA we're going to put out 83 .PERIOD and that's the end of the string .PERIOD so ,COMMA we do the 80 ,COMMA which is the end of the string .PERIOD so ,COMMA that's compression for that string ,COMMA working the same way as for the other example .PERIOD now ,COMMA lets look at expansion for this case .PERIOD they start up the same way .PERIOD so now ,COMMA we see a 41 and we look it up in our table .PERIOD and again ,COMMA this can be just an indexed array .PERIOD so it's going to be a so that's a starting point and now ,COMMA 42 is going to be a b and then we look back ,COMMA we just put out an a and a b so our compression algorithm would have encoded an ab as 81 ,COMMA we know that .PERIOD so now ,COMMA we can when we see 81 we've got ab so we can put a b .PERIOD and so now ,COMMA we look at the and we put out the ad and the next entry in our table is going to be ba ,COMMA because that's what our compression were to put out .PERIOD but now ,COMMA we just got a problem .PERIOD the next character that we see that we need to expand is 83 but we need to know what key has value 83 but it's not in the symbol table yet .PERIOD so that's definitely a tricky case for the now it is possible to when we go through that one again .PERIOD so i ,COMMA at the time that we ,COMMA we read the 83 ,COMMA we need to know which key has value 83 before it gets into the symbol table .PERIOD in all of its first characters is going to be a ,COMMA so that means that aba has convenience with the code .PERIOD in a book which you can examine has a way to test for this case ,COMMA and it's definitely a tr icky case that at least can be considered for lzw expansion .PERIOD we expand 83 at the same time that we put it in the symbol table ,COMMA in this example .PERIOD okay .PERIOD so there are all different kinds of details for lzw ,COMMA we've just given one sometimes people find it effective to clear out the symbol table after a while v maybe how big do we make this symbol table ,COMMA how big do we let it get .PERIOD maybe it's not worthwhile to keep older parts of the message .PERIOD it should adapt the pieces of the message .PERIOD there's many other variations like that ,COMMA that have been developed .PERIOD so ,COMMA so ,COMMA for example ,COMMA what gif does ,COMMA is when the symbol table is full ,COMMA we just throw it away and start over .PERIOD unix compress it's throws the keeps a measure of how well it's doing .PERIOD and throws it away when it's not being effective .PERIOD and there's many ,COMMA many other variations .PERIOD why not put even longer substrings ?QUESTIONMARK why just one character at a time ?QUESTIONMARK why not the double ones and so forth .PERIOD and there have been many variations like that have been develop ,COMMA developed .PERIOD and actually in the real world the ,COMMA the development of this tech ,COMMA technology was influenced by patent law .PERIOD there's a version called lz77 and another version called lzw because these guys worked for a company in the summer and then it was patented for a while you couldn't use lzw unless you paid the patent holder .PERIOD but that expired in 2003 and then things started to go up again .PERIOD so there's lots and lots of different effective methods that are variants of lzw .PERIOD and really to do a good job you might also ,COMMA you need to include huffman coding for the characters or run -DASH length encoding and in really just combinations of these basic ,COMMA basic methods that we talked about that are ,COMMA are most effective .PERIOD so you see this technology author up computational infrastructure that you use everyday .PERIOD and ,COMMA and at the time we were talking about tries ,COMMA they seemed a bit abstract ,COMMA but actually they are ,COMMA tries are definitely part of the algorithmic infrastructure and they are really fine example of a clear ,COMMA clean ,COMMA elegent data structure and algorithmic idea of be ing used to great effect in the real world .PERIOD and this is there's people ,COMMA plenty of people still doing that research .PERIOD even on lossless data compression there's still ideas being developed .PERIOD and these are the kind that does a famous benchmark of set of texts that if you think you have a good new compression algorithm you can run it on this benchmark .PERIOD where it's asking you is a seven bits per character ,COMMA it's eight bit but one of the bits is redundant ,COMMA so you will immediately get down to seven .PERIOD these are the kinds of compression ratios that people have achieved with various mostly levels of variance down to less than half of what you can get with asking .PERIOD but it continues to drive down and there was a completely new method called the burrows -DASH wheeler method developed in the 90s' that took a ,COMMA a big jump down and there's a few more that have continued to improve even through the 90s' .PERIOD so there's still room for improvement in lossless data compression ,COMMA but it's a really fine example of the power of good algorithmic technology .PERIOD so here's our quick summary on data compression .PERIOD so ,COMMA we considered two classic fundamental algorithm .PERIOD the first one ,COMMA huffman encoding ,COMMA represents fixed length symbols with variable length codes .PERIOD so the prefix code uses ,COMMA tries to use smaller number of bits for the most frequently used symbols .PERIOD the other way the ,COMMA the lempelziv method takes variable length symbols and uses fixed length code .PERIOD so ,COMMA it's interesting to think about those two ends of the spectrum .PERIOD there's plenty of compression algorithms out there that don't try to get an exact compression ,COMMA but just try to get an approximation using fft and wavelets and many other mathematical techniques .PERIOD and that's appropriate for things like pictures and movies where maybe you can miss a few bits .PERIOD but lossless compression is still a very important when you download an application which is machine code onto your computer .PERIOD you can't afford to have one of the bits be wrong .PERIOD so that's why lossless compression will always be with us .PERIOD there's a theory on compress ion .PERIOD this theoretical limits that is ,COMMA is a measure of the and it's called the entropy ,COMMA shannon entropy of a text that says a ,COMMA a very fundamental way to indicate how much information there is in a text as a function of its frequency .PERIOD so ,COMMA it's a sum of overall characters of the product of the frequency .PERIOD the log and the frequency with these methods we can get very close to the entropy in some theoretical session settings .PERIOD but actually in ,COMMA in practice the most effective methods uses tricks and techniques that have extra knowledge about the data being compressed to really get the most effective kind of results .PERIOD as i explained ,COMMA if you're doing a page like this ,COMMA you better use a method that does really well on huge amounts of wide space for example .PERIOD that's lzw compression and our last compression algorithm .PERIOD 
to finish up ,COMMA we're going to look at the rectangle intersection problem that's got important practical applications and ,COMMA uses the techniques that we've been studying so far .PERIOD and it's a simple generalization of our line intersection problem .PERIOD so now ,COMMA we have a bunch of rectangles .PERIOD they're all oriented horizontal or vertical .PERIOD and what we need to do is find all the intersections in that set of rectangles .PERIOD and again n could be huge in applications ,COMMA as we'll talk about in a second .PERIOD and the [cough] naive brute -DASH force algorithm involves checking each pair of rectangles for intersection .PERIOD and what we want is a more efficient algorithm than that as usual .PERIOD and again ,COMMA to keep the code simple we're going to assume that all the coordinates are distinct .PERIOD we don't have any ,COMMA any equal lines that we have to worry about whether we consider rectangles that touch to be intersecting ,COMMA and so forth .PERIOD so that's ,COMMA that's the problem ,COMMA rectangle intersection search .PERIOD this is historically ,COMMA an extremely ,COMMA important problem .PERIOD in the 1970s ,COMMA when we switched to very large scale integration for computers ,COMMA we were switching from a situation where we were wiring physical devices together ,COMMA to a situation where we were essentially drawing the computer .PERIOD and there were machines that would take drawings and ,COMMA and return ,COMMA [cough] and from those drawings ,COMMA like this ,COMMA make ,COMMA physical things that implemented computers with different layers and different ,COMMA physical materials interacting ,COMMA in different ways .PERIOD some things are wires ,COMMA and some things are switches that ,COMMA are used to ,COMMA implement memory bits and computer logic .PERIOD but the key point about it is that designing a computer became a geometric problem .PERIOD and so ,COMMA people ,COMMA to design new computers ,COMMA would ,COMMA make huge drawings that just showed the lines that corresponded to the materials that had to be created to make the computer .PERIOD now ,COMMA it was very expensive .PERIOD you didn't want to have any bugs when you're making a chip .PERIOD and ,COMMA there were various rules about what you can do on these drawings .PERIOD and basically ,COMMA these rules had to do with doing this ortho ,COMMA orthogonal rectangle intersection search .PERIOD you ,COMMA you can't have [cough] lines that come too close to other lines ,COMMA certain types of lines can't intersect .PERIOD need spacing between certain types of wires and ,COMMA you wanted to ,COMMA before you tried to make the physical circuit to do this checking ,COMMA which involved this orthogonal rectangle intersection sort .PERIOD and it was actually the case that the progress of faster and faster processors with more and more components was slowed because people were using the naive quadratic algorithm to do this design rule checking .PERIOD and its example of ,COMMA of moore's law .PERIOD so ,COMMA as we built a faster computer say ,COMMA in 1970x ,COMMA we needed to check in rectangles .PERIOD but now ,COMMA maybe a year and a half later ,COMMA you have a computer that's two times faster but you also want to build a bigger computer so you have twice as many rectangles to check .PERIOD so you have two end rectangles to check now ,COMMA and your computer's twice as fast .PERIOD so ,COMMA we get to use the faster and bigger computer to build faster and bigger circuits but that doesn't help if you're using a quadratic algorithm .PERIOD if you're using a quadratic algorithm and it takes you n days to check your design rules ,COMMA and people were running these things on the order of days ,COMMA then for the next computer ,COMMA it would take 2n days ,COMMA it would take twice as long .PERIOD and so people that were using quadratic algorithms were definitely held back and ,COMMA it was ,COMMA ed ,COMMA ed mccreight at xerox park who ,COMMA discovered interval search trees and the logarithmic algorithm that allowed us to sustain moore's law and keep building bigger and bigger computers .PERIOD by changing this quadratic algorithm to a linear logarithmic algorithm ,COMMA and let's see how it works .PERIOD really ,COMMA it's a modification of the sweep line algorithm that we looked at for intersecting lines .PERIOD but now we're going to use that for intersecting rectangles rather than using range search as our basic operation ,COMMA we're going to use interval search .PERIOD so now ,COMMA every time the line sweep hits a rectangle ,COMMA that corresponds to an interval .PERIOD if it's the left part of a rectangle ,COMMA then we put that interval into our interval search tree .PERIOD so in this case we put on zero and then we put on one and then we put on two .PERIOD and ,COMMA and that will give us now three rectangles on our sweep line .PERIOD and so now ,COMMA the question is when we hit a ,COMMA a new rectangle ,COMMA we want to do an interval search to ,COMMA if we're at the left to check which ones intersect and the interval search tree algorithm is going to tell us which intersections there are right away .PERIOD when we reach the right then we remove intervals and so forth .PERIOD but with the basic interval search tree algorithm and the sweep line process that we've talked about ,COMMA you can get the orthogonal ,COMMA orthogonal rectangle intersection search problem solved in time proportional to analog n log n + r log n ,COMMA where r is the number of intersections .PERIOD and typically ,COMMA in design rule checking ,COMMA you wouldn't expect too many intersections .PERIOD so again ,COMMA just as with ,COMMA line intersection search ,COMMA using a priority queue or a sort is only n log n for processing the x coordinates .PERIOD and because the interval search trees take log n for every operation ,COMMA the insert and delete intervals is n log n totaled and the searches is n log n + r log n .PERIOD so ,COMMA the bottom line is that the sweep line algorithm takes this rectangle intersection problem and reduces it to 1d interval search and we have an efficient algorithm for that problem and that enables us to solve the problem in linear rhythmic time instead of quadratic time .PERIOD and that definitely enabled new progress in technology and it's a fine example of the importance of algorithmic technology .PERIOD so here's our summary of applications of binary search trees for geometric problems .PERIOD we started with one dimensional range search and just used regular binary search tree to compute ranks to get the answer .PERIOD but that as the basis ,COMMA we're able to solve the two dimensional line segment intersection search using the sweep line algorithm .PERIOD then we looked at range search and other operations using kd trees .PERIOD again ,COMMA modification of binary search trees .PERIOD and then the interval search tree to solve the one dimensional n over search problem and then how that corresponds to the basic algorithm that you get to if you use the sweep line algorithm to solve rectangle intersection .PERIOD many of these problems are the basis for geometric processing of huge amounts of data that we see all over the web .PERIOD and our basic search tree mentality and apis ,COMMA and binary search tree data structure give us efficient solutions to these important practical problems .PERIOD 
welcome back .PERIOD today we're going take a look at hashing ,COMMA which is another approach to implementing symbol tables that can also be very effective in practical applications .PERIOD here's our summary where we left of with red black bsts ,COMMA where we can get guaranteed logarithmic performance for broad range of symbol table operations .PERIOD and the question is ,COMMA can we do better than that .PERIOD is logarithmic performance the best we can do .PERIOD and the answer is that actually we can but it's a different way of accessing the data .PERIOD and also doesn't support ordered operations .PERIOD but there's plenty of applications where the extra speed for search and insert that we can get this way is worthwhile .PERIOD the basic plan is to think of the symbol table ,COMMA as really try to reduce the problem to being like an array .PERIOD and what we do is use the function known as a hash function ,COMMA that takes the key a symbol table key and reduces it to an integer and array index .PERIOD now we use that array index to store the key in the value in an array ,COMMA maybe the value in a parallel array .PERIOD now ,COMMA there are a lot of issues in doing this .PERIOD first thing is we need to be able to compute the hash function that is easy for some types of data ,COMMA but it can get complicated for more complicated types of data .PERIOD then the other thing is that instead of doing comparatives we're going to be doing equality tests .PERIOD so we have to be sure we've got the method that we want for checking whether two keys are equal .PERIOD all we're going to do is look in to the table and try to see if the key that's there is equal to the key we're looking for .PERIOD and then is the problem of collision resolution where it's ,COMMA since there are so many possible values for typical data type ,COMMA your going to get the situation where two values hash to the same array index .PERIOD and we need a collision resolution strategy to try to figure out what to do in that case .PERIOD and these things are not difficult ,COMMA but they are all worth articulating as separate issues that we have to deal with in order to get an effective symbol table implementation .PERIOD hashing really at its core is a classic space time tradeoff .PERIOD if we had no limitation on space at all ,COMMA then we could have a very huge array with space for every possible key and just use the key itself as an index .PERIOD if our keys are 32 bit integer keys and we've got a table of size two^32 ,COMMA then we're just fine .PERIOD if there were no time limitation at all ,COMMA then i would just hash everything to the same place and then do sequential search .PERIOD but sequential search can be slow if we have lots of keys .PERIOD so what hashing is kind of in the real world where we're trying to trade off this idea that we don't have unlimited space and we also don't have unlimited time .PERIOD so we are trying to find something in between .PERIOD so we'll look at hash functions ,COMMA separate chaining .PERIOD and then two collision resolution methods ,COMMA called separate chaining and linear probing .PERIOD now look at the implementation of hash functions .PERIOD so idealistically what i'd like is to be able to take any key and uniformly scramble it to produce a table index .PERIOD we have two requirements .PERIOD now one is that ,COMMA we have to be able to compute the thing efficiently in a reasonable amount of time .PERIOD and the other is that it should be the case that every table index is equally likely for each key .PERIOD now mathematicians and computer scientists have researched this problem in ,COMMA a lot of detail and its quiet a bit known about it ,COMMA but in practice ,COMMA this is something that's still ,COMMA we have to worry about ,COMMA somewhat .PERIOD so for example ,COMMA lets suppose that our keys are phone numbers .PERIOD probably a bad idea if you use the first three digits of the phone number as a hash function because so many phone numbers'ill have the same area code .PERIOD it's not equally likely that each phone number has the same ,COMMA same first three digits .PERIOD you have a better chance using the last three digits .PERIOD but actually ,COMMA in most cases ,COMMA you want to find a way to use all the data .PERIOD another example ,COMMA social security numbers .PERIOD again ,COMMA it's not to good to use the first three digits because ,COMMA their associated with some geographic region and it's better to try and use the last three digits .PERIOD and the real practical challenge with hashing is that with developing hash function is ,COMMA ,COMMA that every type of key needs a hash function and you need a different approach for every key type .PERIOD now ,COMMA for standard keys like integers ,COMMA and strings ,COMMA and ,COMMA doubles ,COMMA and so forth .PERIOD the ,COMMA we can count on the implement ,COMMA designers and implementers of java to implement good hash function .PERIOD but ,COMMA if we're going to be implementing symbol with our own types of data .PERIOD we're going to have to worry about these things in order to get a hash function that's effective that leads to an effective symbol table implementation .PERIOD so hashing is ,COMMA widely used for ,COMMA systems programming and applications ,COMMA so ,COMMA some conventions for hashing are built into java .PERIOD in particular ,COMMA all java classes inherit a method called hash code ,COMMA which is ,COMMA returns a 32 bit int value .PERIOD and it's a requirement that if ,COMMA x and t y are equal ,COMMA then their hash code should be equal .PERIOD so ,COMMA that's ,COMMA something that is a convention that's built into java and that enables the hash code to be used for hashing .PERIOD also ,COMMA of course ,COMMA if they're not equal then you'd like it ,COMMA like it to be that their hash codes are not equal but you can't always get that .PERIOD now the default implementation for hashing is the ,COMMA memory address ,COMMA of the object .PERIOD for hashing an object is the memory address of an object .PERIOD so that ,COMMA kind of ,COMMA meets these two requirements for java .PERIOD the one that it doesn't ,COMMA maybe ,COMMA meet is the idea that every table position should be equally likely .PERIOD so ,COMMA so usually we'll do some more work ,COMMA to try to ,COMMA make that one happen .PERIOD as far as the algorithms go ,COMMA as far as the rules go ,COMMA you could always return seventeen that's legal .PERIOD it doesn't have this ,COMMA highly desirable attribute .PERIOD but everything would compile .PERIOD so you have to be a little careful that somebody isn't in there doing that .PERIOD and again for important .PERIOD key types that lots of people are going to use .PERIOD some care has gone into the design of hash functions and the built in implementations .PERIOD so java has customized implementations for the standard data types that people would use for simple table keys .PERIOD and that's the sweet spot for hashing where some expert has done implementation of the hash -DASH code .PERIOD and also ,COMMA your application does not need ordering .PERIOD but for useful to find types ,COMMA you're on your own .PERIOD and we'll talk a little bit about how to implement hash codes .PERIOD so here is the java library implementations for a few standard types .PERIOD and they are what they are ,COMMA and what we'll do is ,COMMA with knowledge that that's what the hash code is we'll do some extra work to try to get this extra property that every table position should seem to be equally likely .PERIOD so if it's an integer ,COMMA the hash code supposed to be 32 bits ,COMMA the integer supposed to be 32 bits ,COMMA so they just return the value .PERIOD if it's a boolean ,COMMA they pick out a couple of particular values that they return so hashing a boolean types ,COMMA there's only two different values so well it's hard to think about what you really might want there .PERIOD for double value this is the code they convert to 64 bit and x or the most significant 32 bits with the least significant 32 bits .PERIOD this illustrates something that you want to do if you have a lot of bits ,COMMA you want to try and involve all the bits somehow in the hash function .PERIOD and for strings it kind of creates the string as a ,COMMA a huge number and then really computes the value of that number a mod 32 it uses an arithmatic a way of evaluating a polynomial or a number ,COMMA a so called horner's method ,COMMA where for each digit ,COMMA you just multiply .PERIOD so it treats it as a base 31 number and to get ,COMMA to compute that whole number you multiply 31 times where you have so far and add the next digit .PERIOD and that's called horner's rule and if you're familiar with it ,COMMA fine .PERIOD if you're not you can look at this little example and decide what it is .PERIOD and again it involves all the characters of the string ,COMMA in completing the ,COMMA hash function .PERIOD so .PERIOD and actually ,COMMA since strings are immutable ,COMMA what java does is keep the hash value in an instance variable so it only gets computed once .PERIOD and that is going to be very effective for performance in lots of applications .PERIOD so once it computes the hashcode ,COMMA it stores as an instance variable .PERIOD and the next time you ask for the hascode for that string ,COMMA it will just provide it .PERIOD and that works because strings are immutable .PERIOD so how about implementing a hash code for our own type of data .PERIOD and so ,COMMA we might have ,COMMA our transaction type might have a couple of instance variables ,COMMA a string ,COMMA a date ,COMMA and a double .PERIOD and we need to compute a hash code ,COMMA so return a 32 bit value .PERIOD and again ,COMMA we want to try to make use of all the pieces of data that we have .PERIOD and we also want to make use of the hash code implementations for the types of data that we're using .PERIOD so ,COMMA one thing ,COMMA to do is ,COMMA start out with some ,COMMA small prime number ,COMMA and this kind of mimics ,COMMA horner's method ,COMMA to ,COMMA just add in more data as we get it .PERIOD so we pick some other small prime number and for each field we multiply by 31 and then add the hash code for that field .PERIOD so ,COMMA if it's a reference type just use the hash code ,COMMA so who was a string ?QUESTIONMARK so string has a hash code method ,COMMA so we add that in and dates and when's a date ,COMMA so we add that hash code ,COMMA multiply it by 31 and add that hash code in .PERIOD trying to take all the bits and scramble all the bits and use'em and for primitive types ,COMMA take the wrapper type and use the hash code .PERIOD so that's a ,COMMA a simple example of implementing a hash code for our own type of data that might include several different types of instants variables .PERIOD so that's the standard recipe .PERIOD use the 31 x plus y rule to combine all the fields .PERIOD if it's a primitive type ,COMMA use the wrapper hash code .PERIOD if the field is null ,COMMA return zero .PERIOD and if it's a reference type ,COMMA use that hash code and apply it recursively .PERIOD and if you have an array ,COMMA you have to apply it to each entry .PERIOD or actually java implements that in the array ,COMMA in its arrays library .PERIOD so this recipe works pretty well in practice and it's used in several ,COMMA in java's libraries .PERIOD now in theory it's possible to do something that has the property that ,COMMA that all positions are equally likely .PERIOD it's called universal hash functions .PERIOD these things exist ,COMMA but they're not so widely applied in practice .PERIOD so the basic rule is if you're computing your own ,COMMA try to use the whole key ,COMMA but consult an expert if you're seeing some performance problems or you really want to be certain in some performance critical situation .PERIOD now what we get back from the hash code is a int value that's between  -DASH two^31 and two^31  -DASH  one .PERIOD now ,COMMA what we need is ,COMMA if we have a table of size m ,COMMA an array of size m that we're going to use to store the keys ,COMMA we need an int value between zero and m  -DASH  one .PERIOD and the value of m is maybe a power of two or sometimes we pick ,COMMA pick a prime because of the way that we normally would get the big hash code value down to be a number between zero and m  -DASH  one is just to do mod m .PERIOD and if mod ,COMMA if m is a prime then ,COMMA then from math ,COMMA modular arithmetic ,COMMA we know that we are using all the bits in the number in that point too .PERIOD now ,COMMA since the hash code can be negative this doesn't quite work the way this arithmetic is implemented in java cuz it's one in a billion times .PERIOD you really have to take the absolute value well sorry you have to take the absolute value i would because other wise it'd be negative and you cannot have a negative ,COMMA you want it to be between zero and  -DASH one .PERIOD but even if you take the absolute value there's going to have  -DASH two^31 is possible .PERIOD so you have to just take the 31 bits .PERIOD you get the hash code out make it positive and then mod m as the way to go .PERIOD the math doesn't quite work out right so anyway ,COMMA that code down at the bottom is you can use that as a template for what you might want to do .PERIOD and that's what we do in order to get the hash code to be a number between zero and m minus one .PERIOD and if m is prime ,COMMA it gives us some comfort that we have some possibility of each table position appearing with equal likelihood .PERIOD so that's our assumption .PERIOD that each key is equally likely to hash to an integer between zero and m -DASH 1 .PERIOD and this assumption again ,COMMA it's ,COMMA with work it's possible to come close to this .PERIOD lots of researches have done good work to show this .PERIOD we'll assume that as a starting point .PERIOD and that allows us to model the situation with the so -DASH called bins and balls model that directly relates the study of hash functions to classical probability theory .PERIOD so we've got the n bins ,COMMA that's our that's our corresponds to our hash table and we get m balls and with some number of balls ,COMMA however many keys we have and we throw'em uniformly ,COMMA at random ,COMMA into m bins .PERIOD and ,COMMA with .PERIOD these things are studied in classical combinatoric analysis .PERIOD for example ,COMMA there's the birthday problem .PERIOD which ,COMMA how many balls do you throw before you find two hitting the same bin ?QUESTIONMARK when do you get the first collision ?QUESTIONMARK and the answer to that is ,COMMA it's about square root of pi m over two .PERIOD when does all the bins fill up ?QUESTIONMARK that's called the coupon collector problem .PERIOD after about m ,COMMA natural log m tosses ,COMMA every bin has at least one ball .PERIOD those are just examples of classic results from commonatorial analysis .PERIOD it help us understand what happens when we do this ,COMMA which is what we're doing with hashing .PERIOD and we'll look at more advanced versions of these problems when we wanna study hashing .PERIOD and in particular it's known that after you've thrown n balls into the n bins ,COMMA then the most loaded bin has about log m over log ,COMMA log n balls .PERIOD so that's going to help us get a handle on the performance of hashing algorithms when we get to the implementations .PERIOD so this is just an example showing all the words in a tale of two cities using the modular hashing function for strings like the one that java uses .PERIOD and their pretty uniformly distributed .PERIOD and that's the summary for hash functions .PERIOD 
today we're going to talk about reductions .PERIOD this is something that we've done several times throughout the course ,COMMA but we're going to want to take a little bit more formal look at it ,COMMA because it plays a critical role in some of the advance ,COMMA advanced topics that we're going to want to consider next .PERIOD just a quick overview of the next few lectures .PERIOD these are advanced topics related to algorithms and you can take more advance courses that go into all these things in depth .PERIOD but it's important to talk about them in context of the algorithm so that we seem to put everything into ,COMMA into perspective so what we're going to talk about in this lecture is called reduction and it's a technique that we use t take the good algorithms that we know and use them effectively to build more complicated algorithms .PERIOD and as i said ,COMMA we've done that before but it brings up some interesting ideas .PERIOD that are bigger than any particular algorithm .PERIOD and one idea that we've talked about is the idea of a problem -DASH solving model .PERIOD we saw that we could use shortest paths and max flow to solve problems that didn't seem to be related at all .PERIOD and there's a particularly important problem -DASH solving model called linear programming that we'll talk about in the next lecture .PERIOD but then there's a limit ,COMMA and that brings us to the topic of intractability that we'll talk about in the last lecture .PERIOD so we're shifting gears from individual problems to thinking about problem -DASH solving models that are more general than a particular individual problem .PERIOD and also ,COMMA as part of this ,COMMA we're moving into problems that are much more difficult to solve .PERIOD and not just linear and quadratic fast algorithms ,COMMA but a just a different scale .PERIOD and we'll talk about that in the next couple of lectures .PERIOD and then we're not going to really be talking that much about code for awhile .PERIOD it's more about the conceptual framework and where the problems that you really want to work on fit into the big picture .PERIOD so the ,COMMA our goals are we've looked at some terrific ,COMMA fantastic ,COMMA very useful classical algorithms .PERIOD but they fit into a larger context .PERIOD we're going to encounter new problems .PERIOD you want to have all those algorithms in the tool box ,COMMA but you also under .PERIOD want to understand where they fit in to the big picture .PERIOD there's some very interesting ,COMMA important and essential ideas that have been developed at in great depth over the past several decades .PERIOD and it's important for every practitioner to ,COMMA have a good feeling for ,COMMA for those ideas and ,COMMA and what they imply .PERIOD and really ,COMMA by thinking about these big ideas ,COMMA in addition to particular algorithms for particular problems ,COMMA most people find that they're inspired to learn much more about algorithms .PERIOD so by way of introduction let's talk about what a reduction is .PERIOD so this is just a big bird's eye view .PERIOD the idea is that what we would really like to do is if we ,COMMA if we have a new problem that we have solve ,COMMA we'd like to be able to classify the problem according to the cost that it's going to take to solve it .PERIOD what's ,COMMA what's an order of growth of a ,COMMA of an algorithm ,COMMA a good algorithm or any algorithm to solve the problem .PERIOD and we've already touched on this a little bit when we talked about sorting algorithms .PERIOD not only did we have a ,COMMA a good algorithm for solving sorting several good algorithms but we also developed a lower bound that said that no algorithm can do better .PERIOD and so we can think of the sorting problem as classified as being order -DASH of -DASH growth ,COMMA linearithmic or n log n .PERIOD and then we saw plenty of linear time algorithms that we just examine all the data and we can get it solved .PERIOD and we like to have more things like this other algorithms that we need quadratic time to solve and so forth .PERIOD so we're going to think about how difficult are problems to solve ,COMMA that's the first idea .PERIOD now there's really frustrating news on this front that we'll be talking about over the next couple of lectures .PERIOD and the frustrating news is there are a large number of practical problems that we'd like to solve that we don't really know how hard they are to solve .PERIOD and that's a profound idea that we'll get to soon .PERIOD so ,COMMA but what we want to talk about in this lecture is one of the most important tools that we use to try to classify problems .PERIOD and it's actually been very successful ,COMMA in lots of instances .PERIOD and so if we know that we could solve some problem efficiently we want to use that knowledge to figure out what else we could or could not solve efficiently .PERIOD and that's what reduction is all about .PERIOD it's just a single tool and maybe kind of gets to this archimedes quote ,COMMA give me a lever long and a fulcrum on which to place it and i will move the world .PERIOD that's what reduction does for us .PERIOD so here's the basic idea .PERIOD we say that a problem x reduces to a problem y .PERIOD if you can use a problem that solves y to help solve x .PERIOD so ,COMMA what does that mean ?QUESTIONMARK this schematic diagram gives an idea of what we are talking about .PERIOD so ,COMMA in the middle ,COMMA we ,COMMA we assume that we have a ,COMMA in the middle box there ,COMMA labeled in blue .PERIOD and so ,COMMA we have an algorithm for solving problem y in ,COMMA it's not really relevant what that ,COMMA algorithm is ?QUESTIONMARK it just knows that if you have any instance of problem y you can solve it .PERIOD and the idea behind reduction is that we take an instance of problem x and we transform it into an instance of problem y .PERIOD then use the algorithm for y to solve that instance of y and then transform the solution back to the solution to be the instance of problem x .PERIOD so we take that transformation into an instance of problem y .PERIOD the transformation ,COMMA the solution back to a solution 2x .PERIOD then that whole thing enclosed in the box on the dotted line is an algorithm for problem x .PERIOD and what's the cost ?QUESTIONMARK the cost of solving problem x is the cost of solving y .PERIOD plus the cost of reduction .PERIOD it's like pre -DASH processing and post -DASH processing for ,COMMA problem y .PERIOD then we see a number of calls to y ,COMMA in a reduction .PERIOD and the pre -DASH processing and post -DASH processing might be ,COMMA expensive .PERIOD again ,COMMA we've seen some specific examples of this ,COMMA and we'll go over it ,COMMA in a minute .PERIOD so here's a really simple example .PERIOD finding the median ,COMMA reduces to sorting .PERIOD so in this case problem y is sorting and so we assume that we have a sorting algorithm .PERIOD if you need to find a median ,COMMA then we take the items that's the instance of x in this case there's no transformation just sort and then once they're sorted ,COMMA you take that sorted solution and just pick the middle ,COMMA middle item and return it so the transformation of solution is also easy .PERIOD so the cost of .PERIOD solving ,COMMA finding the median is the cost of sorting which is n log n plus the cost of the reduction which is just constant time .PERIOD if you can sort you can find the median .PERIOD so finding the median reduces to sorting so here's a ,COMMA a second ,COMMA simple example .PERIOD suppose problem x is the element distinctness problem and so that one is ,COMMA you have a bunch of elements .PERIOD and you want to know if they're all different .PERIOD an easy way to solve that ,COMMA that we looked at back in the coding lecture ,COMMA is ,COMMA again ,COMMA just sort .PERIOD we assume that we have a sorting algorithm .PERIOD and then we take that instance of ,COMMA the element ,COMMA the distinctness problem ,COMMA and just all the elements ,COMMA and sort them .PERIOD and then after you sort'em ,COMMA then you can just go through ,COMMA and ,COMMA any items that are equal are going to be adjacent to each other .PERIOD so ,COMMA simply make a path through ,COMMA in this post processing phrase ,COMMA and check ,COMMA adjacent pairs for equality ,COMMA 'cause anything equal's going to be right next to one other .PERIOD and that gives a solution to the element distinctness problem .PERIOD so again ,COMMA element distinctness reduces to sorting ,COMMA because you use sorting to solve it .PERIOD and in this case the cost of solving element distinctness is the cost of sorting and log n ,COMMA plus cost of reduction ,COMMA this time you have to make a path through it .PERIOD so this means that we can solve element distinctness in time proportional to n log n .PERIOD it could be that you could find ,COMMA a algorithm that doesn't use sorting to solve element distinctness .PERIOD but that might be a bit of a challenge .PERIOD by reduction .PERIOD maybe the hard work is done by the sorting .PERIOD and we get an algorithm for this other problem .PERIOD that's the basic idea .PERIOD as long as these cluster reductions not too much ,COMMA that's the basic idea ,COMMA of being able to use red uctions .PERIOD to design new algorithms .PERIOD 
now ,COMMA we'll look at a couple of more interesting examples that show how useful reductions are for designing new algorithms .PERIOD so again that's the basic definition and the implication of the definition is that in order to design an algorithm for a problem x .PERIOD we can go ahead and use some existing algorithm for y .PERIOD and here's the ,COMMA some of the many examples that we've already seen in this course finding the median and element distinctness .PERIOD i just talked about the scheduling problem ,COMMA reduces the topological sort .PERIOD we saw that in the shortest paths lecture .PERIOD also ,COMMA the arbitrage problem of is ,COMMA involves building a ,COMMA a ,COMMA a digraph for currency exchange .PERIOD we reduce that to shortest paths .PERIOD and there's several other examples .PERIOD so ,COMMA it's an important and useful technique .PERIOD so that just the general mentality is ,COMMA if i know how to solve y ,COMMA i have a new problem .PERIOD can i use that to solve x ?QUESTIONMARK and every programmer does that and saying ,COMMA well ,COMMA i've got some code that solves y or i've got a library function that does y .PERIOD can i use that to solve x ?QUESTIONMARK that's reduction .PERIOD so ,COMMA our first example is convex hull problem that we looked at briefly back in the sorting lecture .PERIOD and ,COMMA and that's where your given endpoints in the plane and what you want to do is ,COMMA i identify the points on the periphery ,COMMA these ,COMMA that's called extreme points on the convex hull .PERIOD you can imagine a ,COMMA a bunch of points on a big range and a rancher wants to use the cheapest amount of fence to surround them all .PERIOD and so it's a minimum parameter way to draw a line that surrounds all the points ,COMMA it's a convex hull .PERIOD and there's many other ways to define it .PERIOD that doesn't seem to be all that closely related to sorting but it's actually true that convex hull reduces the sorting .PERIOD that is if you can sort ,COMMA you can compute the convex hull .PERIOD and that's an algorithm known as the graham scan algorithm that we'll look at in the next slide .PERIOD the cost of a convex hull is the cost of the sort and log n plus the cost of the reduction .PERIOD and that graham scan algorithm just uses linear time .PERIOD so ,COMMA with sorting we get an n log n algorithm for convex hull ,COMMA which is a nice algorithm design technique .PERIOD and this is a diagram of the ,COMMA that shows the graham scan algorithm we which we won't go through in detail but it's pretty intuitive .PERIOD what we do is we pick a point one over in the corner and maybe the smallest y coordinate point .PERIOD and then ,COMMA sort the points by polar angle swept out by that coordinate .PERIOD so ,COMMA if you think of a ,COMMA of a line sweeping through and just picking out the points by polar angles centered at that point ,COMMA then we get the points in order along this polygon .PERIOD and because we're doing it by polar angle the lines don't intersect .PERIOD it's a simple polygon which with no intersecting lines .PERIOD and then ,COMMA the graham scan algorithm is just to proceed along ,COMMA over here ,COMMA it proceeds along that polygon .PERIOD but if you ever come to a point where you are going to make a right turn or clockwise turn you throw out the points that would have caused that .PERIOD so ,COMMA in this case ,COMMA this point will cause us to make a right turn so we throw it out .PERIOD and now ,COMMA our most recent points are these three .PERIOD and again ,COMMA that's a right point ,COMMA so we throw that one out and it puts us in this position here and so ,COMMA and the idea is that any point that would cause a right -DASH hand turn is not going to be on the convex hull .PERIOD it's going to kind of a ,COMMA we kind of have a proof that the points inside just buys into the fact that it would make us do a right turn .PERIOD so ,COMMA we throw this one out and that leaves that and then we go here .PERIOD and that would be a right turn on the ,COMMA on our path .PERIOD so throw that one out ,COMMA and we're here .PERIOD another one and continuing in this way .PERIOD when we finally get back to the beginning we've computed the points on the convex hull .PERIOD so ,COMMA the cost of the algorithm is the cost of the sort which is n log n .PERIOD but the cost of the scan is only linear .PERIOD every point only gets considered once .PERIOD that's an excellent example of a reduction to get a new algorithm .PERIOD if you didn't have the fast sort this wouldn't be so effective .PERIOD here's another example of a reduction we implemented and looked at short est path for digraphs .PERIOD what about shortest paths on undirected graphs ?QUESTIONMARK it still makes sense .PERIOD that's why i have a weighted undirected graph with non -DASH negative weights and i'm going to find the shortest path from a given vortex ,COMMA source vortex ,COMMA s2 or a given target vortex t ,COMMA and if it's the lowest weight path from s to t .PERIOD so how are we gonna solve that one ?QUESTIONMARK we have shortest path that works for digraphs .PERIOD well ,COMMA if we just replace each undirected edge by two directed edges ,COMMA then the shortest path algorithm for digraphs works .PERIOD in fact ,COMMA with our graph representation it's just running that algorithm cuz our undirected graphs are represented with the edges going in both directions so they're actually represented as digraphs .PERIOD and again ,COMMA what's the cost ?QUESTIONMARK the cost this time is the cost of pre -DASH processing to just take the graph in its undirected form and convert it to directed form and then the cost of shortest pass of the digraph is e log v .PERIOD so that gives us an algorithm for shortest path in undirected graphs .PERIOD notice that it doesn't work if there's negative weights in the undirected graph ,COMMA because the reduction creates a negative cycle .PERIOD it is possible to find shortest paths in these graphs but you need a ,COMMA a much more sophisticated algorithm to do it .PERIOD so just continuing in this way we've considered quite a few problems that involved reductions .PERIOD so ,COMMA i just talked about finding median and element distinctness in convex hull reducing to sorting .PERIOD and there were a bunch of other problems that we considered as exercises when we talked about applications to applications of sorting .PERIOD so ,COMMA application of sorting really means problem reduces to sorting .PERIOD so sure as processing time scheduling and ,COMMA and ,COMMA and lots of other problems that are reduced to sorting .PERIOD and in the graph world we looked at some pretty complicated problems .PERIOD arbitrage we looked at a parallel ,COMMA parallel scheduling or cpm method and i just talked about shortest paths and undirected graphs and those all reduced to shortest paths and digraphs .PERIOD we looked at problems that reduced to max flow bipartite matching ,COMMA reduces to max flow and the linear program problem that we'll talk about next time ,COMMA actually both max flow and shortest paths and digraphs reduce to linear program programming .PERIOD so this is a pretty diversed set of problems that all through the set of reduction we found ways to solve them using some core kinds of problem solving models .PERIOD and so reduction is an extremely important algorithm design technique .PERIOD 
next we'll look at separate chaining ,COMMA a collision red solution strategy that makes use of elementary link list .PERIOD so ,COMMA what are we supposed to do when two different keys hash to the same index ?QUESTIONMARK the birthday problem tells us that we're going to have collisions .PERIOD you need a quadratic amount of memory to avoid collisions .PERIOD in the lower balancing ,COMMA a coupon collector analysis tell us that the collisions are going to be evenly distribute ,COMMA distributed among the table ,COMMA around the table .PERIOD so ,COMMA what we want to do is have an easy way to deal with collisions .PERIOD and so the first way we'll look at is called separate chaining and it's a very diagonal idea back1953 ,COMMA and the idea is just build a link list for each of the table positions .PERIOD so ,COMMA we'll have a table that's smaller than the number of keys that we have ,COMMA the hash function will map each key to some integer .PERIOD so in this case ,COMMA we have a table of size five .PERIOD so the hash function will map any key .PERIOD in this case ,COMMA we use single letter keys .PERIOD it'll map any key to an integer between zero and four and then to [cough] do an insertion we'll just keep a link list at the table position corresponding to the hash value .PERIOD so s hash is to position two ,COMMA it'll be on the link list that is first link is at position two .PERIOD and e goes to zero ,COMMA and a goes to zero .PERIOD and for search ,COMMA we're going to have to go to ,COMMA if we're going to look at is c in this table say ,COMMA we're going to find the hash value for c and we'll look down the list to see if we can find c .PERIOD so we have to look through the whole list for search but you only have to look through one list out of all the lists .PERIOD essentially if you have m entries in the hash table and m keys the link of list you're going to look at is about n over m cuz they're evenly distributed .PERIOD so that's a straightforward and simple scheme for implementing symbol tables with hashing .PERIOD now ,COMMA we could use a interval bag or some data structure like that and hide the link list structure underneath and that's a perfectly fine way to proceed in modern programming .PERIOD this implementation directly implements the link list .PERIOD now ,COMMA for a practical situation we picked some kind of ,COMMA some value of m .PERIOD you could make it so that the hash table itself grows once it gets really huge and such hybrid methods are easy to implement .PERIOD so we won't talk to much about that .PERIOD we need to just in terms of implementation details ,COMMA our keys and values have to be objects .PERIOD because we can't have an array of generics .PERIOD so ,COMMA since we're making array of nodes ,COMMA a node would have generics if we use to key in value .PERIOD so we have to make them objects then when we get things off ,COMMA we're going to have cast .PERIOD so [cough] this is the get procedure .PERIOD so to look for a key in the hash table we compute the hash value .PERIOD in our hash function is pull out the system hash code ,COMMA make it positive by ending off the sign bit and then mark with m to get a number of ,COMMA zero and  -DASH one .PERIOD so we pick that number ,COMMA i and then we just go to that list and this is the standard code for diversing a link list start at the first node as long as it is not null go x = x dot x .PERIOD and if you find a key that's equal to the key you're looking for ,COMMA return the value and we have to cast it to value because of the generic recreation problem in java ,COMMA otherwise return null .PERIOD so that's not much code ,COMMA and it's trivial code at that for doing an efficient symbol table search using hashing .PERIOD and insertion is not much more difficult if you do the same thing and if you find a node where key equal to key on the link list ,COMMA reset the value and return .PERIOD otherwise ,COMMA you make a new node and put it at the beginning of the link list with the standard code .PERIOD now ,COMMA replace stfi with a new node that links to the old stfi .PERIOD so again ,COMMA very little code to implement search and insert using hashin g and that's why it's so popular .PERIOD and what about the analysis ?QUESTIONMARK well ,COMMA again this the [cough] standard probabilistic analysis of the balls and bins problem tells us a lot of information of what goes on .PERIOD and again ,COMMA if the uniform hashing assumption holds the probability that the number of keys within a list is within a constant factor of n over m is extremely close to one .PERIOD so ,COMMA it means that we've divided the search cost which would be n if we have a sequential search by a factor of m .PERIOD and ,COMMA and in many applications even setting m = 100 or 1 ,COMMA000 is going to be very effective .PERIOD and that's why so many system programs refuse that .PERIOD so ,COMMA number of pros for search and insert's proportional to n over m .PERIOD now typically ,COMMA what we'd what a programmer would do is try to figure on making m about equal to the number of keys divided by five say .PERIOD so ,COMMA you can't make m too large ,COMMA you have too much space and you'll have empty chains or short chains .PERIOD and if you make m too small then they're too long ,COMMA you have to search through them all .PERIOD so let's say ,COMMA n over five and then you get constant time searches and not much extra space .PERIOD you have extra space for the links to implement the link lists but the rest of the table is not much extra space .PERIOD and those are typical parameters .PERIOD if you want a full service symbol table which is going to ,COMMA going to grow from small to huge and then back down to small again then you'd want to use array re -DASH sizing to make sure that m is always within a constant factor of n but we will leave that detail out for now .PERIOD so that brings us to this summary where red -DASH black trees ,COMMA we were happy with a log based two of n for search and insert with separate chaining ,COMMA you can really get it down to a constant number of operations for search and insert .PERIOD so hashing's going to be preferred for short keys where the hash function's easy to compute .PERIOD and where we don't need ordered iteration or any of the ordered symbol table operations because it has really fast access to the symbol table .PERIOD that's our first collision resolution method ,COMMA hashing with separate chaining .PERIOD 
that's another very important reason to use reductions .PERIOD and that gets us closer to our goal of being able to classify the difficulty of problems ,COMMA and that's to establish lower bounds .PERIOD so let's take a look at that .PERIOD so ,COMMA what we want to do is come up with a proof that a problem requires a certain number of computational steps .PERIOD and we had an example of that for sorting .PERIOD we showed in the de ,COMMA decision tree model ,COMMA any compare based sorting algorithm has to use at least at least n log n and compares in the worst case .PERIOD and we show that be showing that no matter what the algorithm is ,COMMA it has to distinguish between all the possible cases of sorting .PERIOD and that led us to in fact ,COMMA a tree that has n factorial leaves on the bottom .PERIOD and the height of the tree has got to be at least log of that ,COMMA which is n log n .PERIOD and you can go back to the sorting lecture and look at that .PERIOD now that's a complicated argument that certainly took you a little while to understand .PERIOD and ,COMMA in general ,COMMA it's extremely different ,COMMA difficult to establish lower bounds because it's generally requires a complicated argument like that .PERIOD you have to be arguing about all possible algorithms and that's very often tough to do .PERIOD initially ,COMMA there was a lot of optimism that we would be able to have lower bounds as researchers worked more and more .PERIOD and we'd be able to classify problems .PERIOD this actually worked out pretty difficult to get non -DASH trivial lower bounds for all kinds of computational problems where people thought it would be easy .PERIOD but the good news is that reduction allows us to take the ones that we have and spread the lower bound .PERIOD so ,COMMA for ,COMMA if we can reduce sorting to a new problem and ,COMMA without too high a cost of reduction ,COMMA that gives us an n log n lower bound on that problem .PERIOD so ,COMMA let's see how that works .PERIOD so we have to make sure the cost of the reduction is not high ,COMMA that's key .PERIOD so ,COMMA and actually ,COMMA most of the time ,COMMA like in the examples that we've looked at ,COMMA we used linear time reductions .PERIOD so ,COMMA that is we only use a constant number of calls to y .PERIOD and we use just a linea r number of steps ,COMMA so usually we're going through everything in the input and output to do some kind of conversion ,COMMA and that's what we've done in all the examples that we've seen so far .PERIOD so ,COMMA then the idea is ,COMMA so if there's a lower bound for x ,COMMA and you reduce x to y ,COMMA that establishes a lower bound than y ,COMMA right ?QUESTIONMARK so why is that ?QUESTIONMARK if i could solve for y more quickly ,COMMA then i could use the reduction to solve x more quickly .PERIOD so if i have a reduction from x to y and there's a lower bond of n log n and x ,COMMA i can't have a linear logarithm on y .PERIOD because if i did and i have a linear time reduction ,COMMA that would give me a linear time algorithm for x .PERIOD same way if i have a lower bound of n squared for x ,COMMA i can't have an n login algorithm for y .PERIOD because if i ,COMMA if i did ,COMMA since i reduced x to y ,COMMA then that would give me linear time algorithm for y .PERIOD so ,COMMA the reduction allows us to propagate the lower bound .PERIOD if i could solve y ,COMMA then i could easily solve x but i know i can't easily solve x ,COMMA so therefore i can't easily solve y .PERIOD it's a very powerful technique and really where most of our lower bounds comes from .PERIOD so ,COMMA just for an example ,COMMA let's look at lower bound for the convex hull algorithm .PERIOD and it's again ,COMMA convex hull certainly don't seem so related but it's actually the case that in any algorithm for convex hull is going to take n log n .PERIOD and so we start with a more general statement about sorting .PERIOD use the so -DASH called quadratic decision tree model .PERIOD and this is just a detail about the model of computation that makes the idea of comparing a serving algorithm to a ,COMMA a convex hull algorithm .PERIOD it makes ,COMMA it makes them both use the same operation .PERIOD so quad ,COMMA quadratic decision tree you get not just these comparisons ,COMMA but you can use tests like this the ,COMMA the product of the difference of two numbers .PERIOD are they less than zero or not ?QUESTIONMARK and those are the basic kinds of operations that you're going to use in the in the geometric algorithms .PERIOD and so ,COMMA the proposition is that under this model ,COMMA sorting linear time reduces to convex hull .PERIOD so that says ,COMMA if i can com pute the convex hull ,COMMA then i can sort .PERIOD since i can't sort faster than n log n ,COMMA i can't do convex hull faster than n log n .PERIOD and the proof is not terribly difficult but the implication is really important .PERIOD so ,COMMA convex hull algorithms it was just based on that idea ,COMMA am i making the right turn ?QUESTIONMARK that's called a ccw test in computational geometry .PERIOD i have three points ,COMMA and going from first to second to third ,COMMA is that a count ,COMMA counterclockwise turn ?QUESTIONMARK and then ,COMMA you can implement that test with these kind of quadratic things .PERIOD it's just testing the slopes of two lines and comparing them .PERIOD so ,COMMA it's kind of like a comparison .PERIOD and ,COMMA and the implication of the fact that sorting reuses a convex hull means that you can't solve a convex hull fast .PERIOD and so how do we do the reduction between sorting and convex hull ?QUESTIONMARK and again ,COMMA the ,COMMA i have a sorting instance ,COMMA i have some numbers to sort .PERIOD and what i want to do is create a convex hull instance that gives me sort .PERIOD well ,COMMA all we do is we take the numbers that were supposed to be sorted and we convert them to points on a parabola .PERIOD so we just take x1 and x1 squared ,COMMA and x2 and x2 squared and like that .PERIOD those are points parabola .PERIOD now ,COMMA there's no points and ,COMMA and we give that to the convex hull algorithm .PERIOD now ,COMMA all of those points are on the convex hull .PERIOD in a convex hull algorithm ,COMMA its supposed to return on in clockwise order .PERIOD and you can see with just finding the smallest that gives us the points in sorted order .PERIOD so the convex hull algorithm does its job .PERIOD however ,COMMA it does it we can take the solution to the convex hull algorithm ,COMMA and get a solution to the sorting algorithm .PERIOD sorting reduces the convex hull .PERIOD therefore our convex hull can't be easy cuz that would make sorting easy .PERIOD this kind of thinking is really ,COMMA is really profound and it has really done a lot to enhance our understanding of the difficulty of different algorithmic problems .PERIOD so ,COMMA that's ,COMMA that's the proof that i just explained .PERIOD this parabola thing is definitely going to be convex and all the things are on the hull ,COMMA so we just get the po int that's got the most negative x coordinate and you've got the integers in order .PERIOD so establishing lower bounds through reduction is really important .PERIOD we have a big convex hull problem to solve and ,COMMA and we're wondering ,COMMA do we have a linear time algorithm for this ?QUESTIONMARK it's a quite natural thing to wonder .PERIOD and so how are you going to convince yourself that there's no linear time convex hull algorithm ?QUESTIONMARK one thing you can do ,COMMA and believe me ,COMMA a lot of people did this ,COMMA is just try to find a linear time algorithm .PERIOD keep working at it ,COMMA keep working at it .PERIOD you're going to use algorithms that are based on this simple kind of comparison between points .PERIOD it doesn't seem like it should take n log n ,COMMA it seems like we should be able to find a linear time algorithm .PERIOD and that's the hard way .PERIOD the easy way is to know that reduction from sorting ,COMMA and that means there's no point in to try to put in our effort to try to improve on the graham scan .PERIOD graham scan gets it done in n log n .PERIOD we can't do better than n log n so we might as well call it a day and move on to some other problem .PERIOD and that's an example of reduction for proving lower bounds to help us guide our algorithm design efforts .PERIOD 
another popular closure resolution method is known as linear probing .PERIOD in this you know many different versions of hashing that are based on this idea .PERIOD with linear probing is called open addressing and is also around the same time in the 50's the idea is just use an array .PERIOD instead of using space for the length in a length list .PERIOD i use that same space ,COMMA and just ,COMMA allocate an array .PERIOD in this case ,COMMA the size of the array is going to have to be bigger than the number of keys that we [inaudible] expect .PERIOD and we use the empty slots in the array .PERIOD to .PERIOD essentially terminate the length of the [inaudible] list that we have to search through when we're doing a insertion .PERIOD so let's look at a demo of how it looks .PERIOD so to hash again we do the same thing ,COMMA we just map the key to a index .PERIOD but ,COMMA in linear probing ,COMMA to insert what we do is when we put it in position i if that's free ,COMMA if not we just look at i plus one ,COMMA and i plus two ,COMMA and wrap around to the beginning if we reach the end .PERIOD now that's also simple to implement and it works well as long the size of the array is ,COMMA significantly bigger than the number of keys .PERIOD let's look at ,COMMA well it's a demo .PERIOD so we start with an empty table ,COMMA insert s ,COMMA it's hash value is six ,COMMA six is empty so we put it there .PERIOD now we look at e ,COMMA hash of e is ten ,COMMA we look at ten ,COMMA it's empty so we put e there .PERIOD so at the beginning we're going to be fine .PERIOD a is four ,COMMA empty ,COMMA put it there .PERIOD r is fourteen ,COMMA empty ,COMMA put it there .PERIOD so we just essentially ,COMMA using the hash funtion as an array index .PERIOD c is five ,COMMA that's empty and we put it there .PERIOD so h now ,COMMA the hash value of h is four .PERIOD so now we look at four ,COMMA and that's occupied ,COMMA so we can't put the h there .PERIOD and then linear probing says ,COMMA just look at the next position ,COMMA look at five .PERIOD that's still not empty .PERIOD so we look at six .PERIOD and we keep going till we find an empty place ,COMMA and then we put h there .PERIOD now when we search ,COMMA we're going to have to do the same thing .PERIOD we'r e going to have to look at all those positions to look at h .PERIOD the .PERIOD group of four key ,COMMA continuous keys in a table space there is called a cluster and clearly we want to keep those clusters small .PERIOD and we do that by juts by not putting too many keys in to the table .PERIOD so x hashes to fifteen ,COMMA that's empty so we put it there ,COMMA m hashes to one ,COMMA that's empty and we put it there .PERIOD p hashes to fourteen ,COMMA 14's occupied ,COMMA 15's also occupied ,COMMA now we run off the end of the table ,COMMA and look at zero ,COMMA and that's empty so we put it there .PERIOD l hashes to six .PERIOD six is occupied .PERIOD we look at seven ,COMMA seven is occupied .PERIOD we look at eight ,COMMA and we put it there .PERIOD and ,COMMA so that's an example of inserting ,COMMA keys into a hash table .PERIOD and now ,COMMA for a search ,COMMA we just do the same thing .PERIOD we ,COMMA use the hash function .PERIOD to search for e ,COMMA e's hash value is ten so we look in ten and there it is .PERIOD so that's a search hit .PERIOD if we're going to search for say l l's hatch value is six so it's not there .PERIOD so in order to look at every place in the table where l could be ,COMMA we have to keep looking til we found an empty table position ,COMMA or we find l itself .PERIOD so now we look at seven l not there ,COMMA we look at eight l is there ,COMMA that's a search hit .PERIOD if we have a value that's not in the table like k ,COMMA well hash and is in position five ,COMMA no ,COMMA six no ,COMMA seven no ,COMMA eight no and we find an empty position at that point we can conclude that k is not in the table .PERIOD because if k were in the table it would be somewhere between it's hash point five and that empty position nine .PERIOD that's a search miss ,COMMA and we return all .PERIOD so that's a short demo of linear probing hashing .PERIOD so here's a summary of linear probing ,COMMA hashing .PERIOD to .PERIOD to get started we map a key to a integer between zero and m -DASH 1 where m is the sides of our array where we are storing the keys .PERIOD to insert we put the key value pair .PERIOD use parallel arrays [inaudible] and the value array with the same index .PERIOD we put the entry at the table index a for three .PERIOD if not try i+1 i+2 until getting to a empty position .PERIOD and for search you do the same thing you hash to the table position and you look there into the right .PERIOD to find the key and you stop when you find an empty table position .PERIOD find the key or find an empty table position .PERIOD now ,COMMA it's essential that the array size is greater than the number of key value pairs n .PERIOD and for linear probing hashing ,COMMA really ,COMMA the implementation needs to include array resizing ,COMMA whenever the hash table gets too full .PERIOD here's the implementation .PERIOD and it's ,COMMA quite straightforward ,COMMA given the demo that we talked about .PERIOD you use the same hash function .PERIOD and we use parallel arrays for the value in the keys .PERIOD and we have to use ugly cast ,COMMA 'cause we can't have a race of generics .PERIOD then let's do the search .PERIOD so .PERIOD we just have a for loop starting at hash of key and going until we get to a position that's null .PERIOD as long as it's not null ,COMMA we stay in the loop and increment i mod m .PERIOD so that's when i gets to the end it gets to the end ,COMMA it's in the position m minus one and it goes .PERIOD .PERIOD .PERIOD in the next increment goes back to zero at the left end of the table and we just test for all the non null keys .PERIOD if it's equal ,COMMA if it is ,COMMA go ahead and return the associated value and if you get to an empty position ,COMMA then return null .PERIOD and the implementation of put is similar .PERIOD find a ,COMMA a position ,COMMA if it's ,COMMA that's equal ,COMMA and then ,COMMA reset the key ,COMMA in the value .PERIOD if the key's there ,COMMA it just resets the value .PERIOD if they key's not there ,COMMA it puts a new entry in .PERIOD so again ,COMMA that's ,COMMA fairly little code ,COMMA to implement ,COMMA a fast symbol table and insert ,COMMA search and insert .PERIOD but it's only going to be fast ,COMMA if the ,COMMA table size is set appropriately .PERIOD in ancient times ,COMMA memory was ,COMMA at quite a premium and so people were very concerned in m -DASH m -DASH making sure that the hash table never ,COMMA got too empty .PERIOD remember in the first computers ,COMMA each bit was a physical thing ,COMMA a magnetic core that somebody had to string a wire through ,COMMA so .PERIOD the bits were really expensive ,COMMA and people wanted to make sure ,COMMA that they were making best use of the memory .PERIOD and just leaving empty positions around ,COMMA in a hash table ,COMMA or using links in a link list ,COMMA did not seem like an appropriate use of space .PERIOD and ,COMMA so there was quite a bit of effort ,COMMA devoted to figuring it out ,COMMA how full we could get the hash table ,COMMA in linear probing .PERIOD and how close it could get to full without sacrificing performance .PERIOD and one way to think about what goes on is to just watch what happens when a hash table fills up .PERIOD so here we just as ,COMMA as it goes up we're showing each key getting inserted in the number of probes of the table that are needed for the insertions are j hash to the same position that a ;SEMICOLON you had to look for a while ,COMMA and the one thing to notice is as the table gets full ,COMMA is that first of all .PERIOD you have ,COMMA these clusters or these chains building .PERIOD and so ,COMMA what's clear about that is that ,COMMA it means that ,COMMA the new hash is likely to hash into a big cluster .PERIOD >> and not only that once you have a big cluster and you hash into the middle of it you've got a good chance that ,COMMA that clusters going to get longer ,COMMA or worse .PERIOD that's it's even going to merge with another big cluster .PERIOD and so ,COMMA that's the situation as the table fills up .PERIOD you get long clusters and they're likely to get longer .PERIOD and the math bares that out .PERIOD now this was studied in detail by knauf ,COMMA don knauf ,COMMA in the 1960's and actually this problem ,COMMA knauf says ,COMMA was the origin of the origin of analysis of algorithms .PERIOD mathematicians were trying hard to understand this problem and were ready to give up and he realized you could use classical balls and bins type probabilistic analysis .PERIOD not an easy analysis ,COMMA but we actually could make precise accurate statements about the performance of this algorithm .PERIOD and those statements can be borne out in practice ,COMMA because the hash functions approximate random ,COMMA the math assumes random and the formulas predict what actually happened in practice .PERIOD no way can you formulate the problem as so called parking problem .PERIOD so ,COMMA what happens is that you are on a one way street and you are looking for a parking place and ,COMMA it's ,COMMA the idea's you start looking for a parking place at particular times and say "okay ,COMMA now i need a parking place" ,COMMA and what you're doing is linear probing hashing .PERIOD if the current space is taken ,COMMA you try the next space and the one after and so forth .PERIOD and the question is .PERIOD if every car .PERIOD starts looking for a place at a random time .PERIOD that .PERIOD then that models the hash function ,COMMA then how far do they have to go to look for a place ?QUESTIONMARK that's canoot's parking problem .PERIOD and he was able to show ,COMMA and we'll talk just a little bit about this ,COMMA that if ,COMMA there's ,COMMA only half of the parking spaces are occupied ,COMMA then ,COMMA on average ,COMMA half the people find ,COMMA find it after one place and the other half have to look one extra .PERIOD so that's the kind of performance that we want .PERIOD but as it gets full .PERIOD the displacement gets up to square root ,COMMA of pi m over eight .PERIOD which is obviously much higher than we want .PERIOD we don't want our searches to take that long .PERIOD and that actually ,COMMA the analysis ,COMMA is amazing function that goes back to famous roman nuygen and other classical results from our commentorial analysis .PERIOD what canute's theorem says is that under the uniform hashing assumption ,COMMA the number of probes in the linear hash table size m ,COMMA that is alpha percent full ,COMMA so the number of keys is a fraction of m ,COMMA is for a search miss half one plus one over alpha ,COMMA and a search miss one plus one over one minus alpha squared .PERIOD one myse alpha is for the hit ,COMMA one myse alpha for the squared for the insert .PERIOD now as alpha gets close to one ,COMMA you can see these things are going to grow ,COMMA and particularly the search miss is growing to grow quite ,COMMA quite a bit .PERIOD if it's 9/10's full one over one minus alpha squared is 100 one over 100 ,COMMA so it means it's going to be 50 p robes for a search miss if it's 9/10's full ,COMMA and that's independent of n and m ,COMMA whereas if it's half full then we get the nice .PERIOD numbers of only 3 -DASH house for a hit ,COMMA and only 5 -DASH house for a miss .PERIOD and ,COMMA again these formulas are nice approximate formulas ,COMMA but knuth ,COMMA once he figured this out ,COMMA in 1963 ,COMMA tells stories ,COMMA that time ,COMMA he decided to write his famous series of books on algorithms .PERIOD now there's four volumes out and more planned ,COMMA and this is where ,COMMA all computer scientists go .PERIOD for detailed information on a performance ,COMMA eval grievance .PERIOD so ,COMMA in ,COMMA in summary .PERIOD you can't have m too large ,COMMA what we want to use nowadays is array resizing to make sure that the array is always about half time ,COMMA half full .PERIOD and if we can keep the array about half full then we get constant time performance for search hit and search miss .PERIOD and linear probing is very attractive in this case .PERIOD there's other things that we can do algorithmically to bring down the search time a little bit .PERIOD like using another hatch function rather than looking at the next entry .PERIOD use another hatch function to determine the stride that we're going to use .PERIOD and that brings it down somewhat and allows us to keep the tables more full .PERIOD but the bottom line is that now we have two methods that under the uniform hashing assumption can give us constant time ,COMMA search ,COMMA search it insert and delete .PERIOD for symbol table implementations where we don't need ordering .PERIOD and we've got a reasonable hash function .PERIOD so ,COMMA that's a summary of linear probing or second hash ,COMMA collision avoidance strategy .PERIOD 
now ,COMMA if we put the last two sections together it gives us a way to start to think about how to classify problems according to their difficulty .PERIOD let's look at how that works .PERIOD so what we're always looking for is a problem that where the algorithm matches the ,COMMA the ,COMMA lower bound .PERIOD and so ,COMMA one way to do that is just use reduction .PERIOD so ,COMMA in order to ,COMMA we want to prove that two problems x and y ,COMMA have the same complexity or the same research requirements .PERIOD first ,COMMA we show that x linear time reduces to y .PERIOD and then we show that y linear time reduces to x .PERIOD and then with that way ,COMMA even if we don't know what the complexity is at all ,COMMA we know that x and y are ,COMMA have the same computational requirements .PERIOD and this is what we just did for sorting in convex hull .PERIOD in this case ,COMMA we know that both of them take time proportional to n log n but the reducing one to the other in both directions shows us their ,COMMA their equivalent with respect to computational requirements .PERIOD in the one case reducing sorting to convex hull gave us a lower bound .PERIOD in the other case ,COMMA reducing convex hull to sorting gave us a useful algorithm .PERIOD but together they're useful because it helps classify those problems .PERIOD now ,COMMA there is a bit of a caveat to this and this is a little bit of an idealized situation .PERIOD but it actually is ,COMMA is something that can lead to trouble in the real world .PERIOD so ,COMMA we have these two problems .PERIOD and we have the ,COMMA these two propositions ,COMMA that they ,COMMA in linear time ,COMMA reduce to one another .PERIOD now ,COMMA it could be that in a big software engineering effort there there's a lot of people making decisions .PERIOD and well ,COMMA so we found out they have the same complexity .PERIOD but maybe some system designer has a big project and there's a lot ,COMMA a lot of things ,COMMA so they need both sort and convex hull .PERIOD and one programmer is charged with a job of implementing sort .PERIOD and understands that well ,COMMA you could do that using convex hull .PERIOD i learned this cool trick .PERIOD and the other one knows the graham scan ,COMMA says ,COMMA okay ,COMMA i'm going to index convex hull using sort .PERIOD and that's in a big system .PERIOD and that's going to lead to a problem .PERIOD it's an infinite reduction loop which certainly is going to lead to problems .PERIOD whose fault ,COMMA well that would be the boss .PERIOD alice and bob just did what they were suppose to .PERIOD and it's ,COMMA they were all ,COMMA somebody could argue alice maybe could have used a library routine for the sort but you ,COMMA you get the point for a complex situation .PERIOD this definitely could have come up just to show the power of this kind of technique and how it relates to research that's still ongoing in computer science .PERIOD let's look at some simple examples from arithmetic .PERIOD so here's the grade school integer nullification .PERIOD let's do it with bits .PERIOD so ,COMMA i have two n bit integers i want to compute the product .PERIOD and this is the way you learned to do it in grade school .PERIOD for every bit in the bottom you multiply it by the top and then you add them all together .PERIOD and that's going to take time proportional to n^2 .PERIOD you have n bits and you have n rows .PERIOD and so that's time proportional to n^2 .PERIOD and but now ,COMMA nowadays ,COMMA people are doing integer multiplication on huge integers because mathematical properties of integers play an important role in cartography and other applications .PERIOD so ,COMMA people are interested in algorithms that are faster than quadratic for something like integer multiplication .PERIOD now one ,COMMA one thing that you can do ,COMMA first you can do with reduction is people have figured out that you can take integer division or square or square root and all different other integer operations and reduce them to integer multiplication .PERIOD so ,COMMA you can show that all of these and ,COMMA and vice versa .PERIOD and so ,COMMA you can show that all of these things have the same complexity ,COMMA even though we all know what it is just by simple reductions one to the other .PERIOD so and you can imagine how to do divide to multiply and so forth .PERIOD these have been done in all different directions .PERIOD so now ,COMMA the question is that so now ,COMMA they're all the same difficulty as the brute force algorithm and how hard is the brute force algorithm .PERIOD well ,COMMA people have studied that for a long time and actually one of the ,COMMA the earliest divide and conquer algorithm by karatsuba and ofman showed that the integer multiplication could be done in time into the 1 .PERIOD585 .PERIOD and it was divide and conquer ,COMMA we divide the integers in half and then find a clever way to combine it to reduce the exponents .PERIOD and people have been working on this .PERIOD you can see through the decades ,COMMA actually ,COMMA there's a big breakthrough just in 2007 that is going to get much closer to n log n .PERIOD although there's no known lower bound for this problem could be linear .PERIOD and some people are still going to work on it .PERIOD so ,COMMA and all these different algorithms ,COMMA they get more complicated and may be ,COMMA you know ,COMMA useful for very large n or for different ranges of n .PERIOD and actually in practice there's the multi precision library that's used in many symbolic mathematics packages has one of five different algorithms that it uses for integer multiplication ,COMMA depending on the size of the operands .PERIOD and ,COMMA and again ,COMMA in applications such as cryptography the n can be truly huge .PERIOD and people want to do this computation .PERIOD so we don't know what the difficulty of integer multiplication is ,COMMA we just know that all the integer operations are described by this one thing .PERIOD and it's similar for a matrix multiplication .PERIOD one of the ,COMMA another famous problem that people are still trying to understand .PERIOD and again ,COMMA the secondary school algorithm to compute the entry in row i and column j ,COMMA you compute the dot product of the ith row of one argument ,COMMA and the jth column of the other and the dot product of that ,COMMA that fills that entry ,COMMA and you do that for every entry ,COMMA so that's going to be time proportional to n cube ,COMMA because you have to do n multiplications for each of the n^2 entries in the result matrix .PERIOD and again there's all different kinds of matrix operations that can be proven to be equivalent in difficulty to the matrix multiplication through reduction .PERIOD and so ,COMMA that's the you know ,COMMA of called matrix multiplication as all these other things like solving systems of linear equations and determine and ,COMMA and other things .PERIOD bu t how difficult is it to multiply two matrices .PERIOD so again ,COMMA reduction gives us a big class of problems to make it even more interesting to know the difficulty of this one problem .PERIOD and then ,COMMA research on the difficulty of this one problem has been ongoing .PERIOD in this case running time is n cube for the brute force algorithm and who knows when that was discovered i don't know ,COMMA eighteenth century or fifteenth or something .PERIOD and then but ,COMMA when ,COMMA once computers got involved the strassen's famous divide and conquer algorithm like you know ,COMMA integer multiplication breaks it down through divide and conquer and gets the exponent down to 2 .PERIOD808 .PERIOD and people have been working through the years to find successive improvements to this .PERIOD the last one went from 2 .PERIOD3737 to 2 .PERIOD3727 which doesn't seem like much ,COMMA but maybe one of these research results will be a breakthrough that will give us an efficient new algorithm for all of these problems involving matrices .PERIOD so again ,COMMA it's very useful to have classified all these problems and make the even increase the leverage of the research even more .PERIOD so ,COMMA when we started this lecture we started with the idea that it would be good to classify problems .PERIOD but it's ,COMMA it's tough to actually classify them because there's new research involved ,COMMA even for things as simple as integer or matrix multiplication but at least what we can do is put the defined complexity classes .PERIOD even though we don't want to know what it is ,COMMA we know there's a lot of important problems that have that same complexity .PERIOD and there's a really important one that we're going to talk about in the last lecture ,COMMA called the np -DASH complete problems ,COMMA and all kinds of important problems that fall into that but as the time wears on ,COMMA researchers have found ways to put many ,COMMA many problems into ,COMMA into ,COMMA into equivalence classes .PERIOD so ,COMMA at least we know that there's those problems are have the same difficulty even ,COMMA even if we don't know what it is .PERIOD this is actually called the ,COMMA the complexity zoo there's really a large number of complexity classes .PERIOD now a lot of these are de finitely theoretical devices that are only important in filling in our understanding of some ,COMMA some important part of the theory .PERIOD but many of them like ,COMMA like matrix multiplication ,COMMA integer multiplication ,COMMA are very important to practical algorithms .PERIOD so there's certainly a huge amount of research ,COMMA i guess ,COMMA still going on into trying to understand computational difficulty of the problems .PERIOD so ,COMMA in summary ,COMMA we use reductions to design algorithms ,COMMA to establish lower bounds ,COMMA and to help us classify problems .PERIOD but in practice ,COMMA we've been using them already .PERIOD we ,COMMA we designed algorithms that made use of priority queues in effective ways .PERIOD that's a reduction and lots of algorithms for sorting ,COMMA and really that's the idea of reusable software modules .PERIOD we find ,COMMA you know ,COMMA fundamental problems ,COMMA and we develop implementations that can be used by clients .PERIOD every client using an implementation is doing a reduction .PERIOD and the other thing is that reductions help us determine the difficulty of our problem and guide our search towards finding efficient solution for it .PERIOD so in particular ,COMMA when we get to extremely difficult problems ,COMMA we'll know whether or not we should look for an exact algorithm or we should find something that doesn't quite solve the problem .PERIOD and we'll talk a lot more about that in the last lecture .PERIOD and then all of these studies ,COMMA in the complexity zoo and in any algorithm that we're going to develop for a complicated problem ,COMMA what we're going to want is reduction to link the new problem to problems that we know how to solve .PERIOD 
so let's just look at a little bit of the context of hashing in practical applications .PERIOD as i mentioned ,COMMA it's very widely used .PERIOD so here's an ,COMMA here's an example right from java .PERIOD the first .PERIOD implementation of java 1 .PERIOD1 .PERIOD the designers found that the cost of computing the hash function for strings seemed to be excessive ,COMMA particularly for long strings .PERIOD and that was one of the main uses of hashing ,COMMA was just to be able to do searching with string keys .PERIOD and so what they decided in the first implementation was let's just look at every eighth or ninth character ,COMMA and that way ,COMMA we don't have to spend a lot of time computing the hash function .PERIOD so they had a hash function pretty much like the one that we use .PERIOD except that it compute a skip that would mean that ,COMMA that only look at about every eight key and they wouldn't have to do quite so much work performing the hash function .PERIOD and that's diffidently one thing to consider when using hashing is that the cost of computing the hash function for a complicated key might exceed the cost of searching and using a simpler structure like a binary search tree .PERIOD and anyway for java 1 .PERIOD1 what happened was that there was a huge potentail for really bad collision patterns on typical data .PERIOD so here's the example of typical data ,COMMA which is a url .PERIOD all of these keys ,COMMA which are totally different ,COMMA would wind up having the same collision .PERIOD and so client programs and system programs on the java system were having terrible performance on their symbol table because of the shortcut in hashing .PERIOD so this well illustrates that you need to use all of the data in the hash function and sometime we do a closer analysis .PERIOD the cost of computing the hash function can mean that something like red black trees will even outperform hashing even for just searching and insert .PERIOD so there is another thing about the uniform hashing assumption is that it is an assumption and if you are writing code where we have to have guaranteed performance like when your aircraft is landing or you are controlling a nuclear reactor or somebody's pa cemaker .PERIOD that ,COMMA if that assumption doesn't hold and you get bad performance you're going to have disastrous consequences .PERIOD so that's another reason to think about maybe paying a little extra and using to guarantee that you get with red black search trees .PERIOD instead of hashing .PERIOD and there's another surprising situation that happens in today's world .PERIOD for example java publishes its hash function .PERIOD and so if you're trying to provide a service over the web .PERIOD an adversary can learn your hash function and just send you data that causes huge performance problem by just making all that data hash to one particular item .PERIOD and that's definitely something to worry about .PERIOD and ,COMMA and in the real world you can nowadays find on the web particular sequences of keys that will cause particular services to crash .PERIOD and again ,COMMA that's a little harder to do with something like a red black tree where we have performance guarantees .PERIOD when you make an assumption you better be sure and you're depending on that assumption ,COMMA you better be sure that it holds somehow .PERIOD this is different than for example for quick sort when we ,COMMA our assumption was we're going to create randomness and we are going to depend on that randomness .PERIOD in this care we're kind of hoping for randomness and maybe that doesn't really always hold .PERIOD so that's certainly something to be aware of when using hashing in practice .PERIOD so here's just simple example on hashing in java .PERIOD so what we can do is it's pretty easy to find a family of strings that have the same hash code for example with just a little fooling around now days you can just look it up on the web ,COMMA you can see that these two character keys ,COMMA both have the same hash code because when you just do the math in a base 31 hash code it'll tell you that answer .PERIOD well what that means is that actually ,COMMA just like working in binary you got ,COMMA you can combine those things .PERIOD in all possible ways ,COMMA and you can get two to the n strings ,COMMA for any n of length to n that all hash to the same value .PERIOD and somebody's implemented a service in java that it uses a simp le table that takes string keys ,COMMA you can cause that to crash in this way .PERIOD little bit scary for some systems designers .PERIOD at least reason for pause in using hashing .PERIOD now ,COMMA hashing also has a extremely important application in today's internet commerce .PERIOD and so the ,COMMA it's the concept of so called one way hash functions which mean that we ,COMMA we ,COMMA use it for secure to try to be ,COMMA have some secure fingerprints for use on the web .PERIOD and there's been a lot research done to develop functions that take keys as input ,COMMA and then produce values that look random .PERIOD in such a way that ,COMMA it's hard for someone else to find another key that collides with that .PERIOD this technology is ,COMMA is useful for storing passwords and digital fingerprints and things .PERIOD but it's too expensive for use ,COMMA in a symbol table .PERIOD so the bottom line is separate chaining versus linear probin collision resolution message methods .PERIOD now there's a number of considerations to take into account .PERIOD separate chaining is really easy to implement both insert and delete it performs ,COMMA it degrades ,COMMA it does so gracefully and the clustering is ,COMMA is maybe less of a problem if you have a bad hash function .PERIOD linear probing tends to make better use of space .PERIOD and also it'll perform better for huge tables whereas caching is involved .PERIOD and if ,COMMA in the classic algorithm or computer science problems for people to think about is what do we do to delete in these two situations and exactly how do we resize .PERIOD those are all at the level of exercises in the context of the kinds of algorithms that we've seen .PERIOD and as i mentioned ,COMMA there's been many ,COMMA many improved versions of hashing that have been studied .PERIOD i mentioned the two probe ,COMMA or double hashing version .PERIOD another way to use two hash functions is just to hash the two positions and put the key in the shorter of the two chains .PERIOD in ,COMMA in that case ,COMMA then the expected length of the longest chain will be lg ,COMMA lg n which is quite an improvement .PERIOD you get constant time expected and lg ,COMMA lg n worst case .PERIOD double hashing is the variant of layer probing where you just skip a variable amount ,COMMA not one each time .PERIOD and that pretty much wipes out clustering but it ,COMMA it is more difficult to implement delete for that one .PERIOD in a new method called ,COMMA relatively new method called cuckoo hashing .PERIOD it's another variant of linear probing where we hash a key to two positions and insert the key in either one .PERIOD if occupied you ,COMMA you reinsert the displaced key into its alternative .PERIOD it was in one ,COMMA each one can go to two .PERIOD and that one actually gives constant worst case time for search .PERIOD that's another variation on the team .PERIOD and all of these things allow us to make better use of memory ,COMMA allows the table to become nearly full .PERIOD it would have been very exciting .PERIOD thing to be researchers in the 1950's who cared so much about memory and nowadays a little extra memory is not something that people care about so much and most people just go with the easy algorithm except for really performance critical applications .PERIOD what about hash tables versus balance search trees ?QUESTIONMARK well hash tables are really simple to code usually if you don't have to do the hash function .PERIOD and if you don't have order in the keys at all then you need the compare to ,COMMA to implement balance search trees .PERIOD so you have to use hashing if you don't have the comparison .PERIOD and it'll probably be faster for simple keys to use hashing .PERIOD it's a few arithmetic operations to do the hash versus lg n and compares for the balance tree .PERIOD and there's some better system support in java for strings that cache hash code means that you don't even have to compute the hash if your ,COMMA your simple table for strings is in an inner loop .PERIOD on the other hand ,COMMA balanced search trees have a much stronger performance guarantee .PERIOD it ,COMMA you don't have to assume anything .PERIOD it's going to be less than lg n and compares and it's got support for all those ordered st operations ,COMMA and compared to and is pretty easy and natural function to implement .PERIOD so it's more flexible and more broadly useful .PERIOD and actually the java system and other systems include both so that programmers can make use of either one in diff erent situations .PERIOD that's our context for hashing algorithms .PERIOD 
welcome back .PERIOD today we are going to look at some symbol table applications ,COMMA give you some idea of how symbol tables might be used ,COMMA by client program for practical problems .PERIOD first when we look at ,COMMA seems even simpler than the regular symbol tables ,COMMA and that's about sets .PERIOD so ,COMMA a mathematical set is just a collection of distinct keys .PERIOD and so ,COMMA there are plenty of applications where we want to just be able to implement ,COMMA this really simple api .PERIOD i want to be able to create an empty set ,COMMA we've got methods to add a key to the set ,COMMA and to check whether a given key is in the set or not .PERIOD to remove a key ,COMMA and maybe return the number of keys in the set ,COMMA and also have an iterator to iterate through keys in the set .PERIOD this is simpler than symbol tables because it's got no associated value .PERIOD so ,COMMA it's a very simple api but of course ,COMMA we're going to be able to do these operations efficiently ,COMMA how we'd we go ahead and implement that .PERIOD well ,COMMA if you think about it for just a minute ,COMMA you see that what you need to do is just remove all references to value from any of the symbol table implementations that we'd look at .PERIOD the implementation is easy .PERIOD take one of our symbol table implementations and get rid of the code that refers to values .PERIOD okay ,COMMA so let's look at a couple of applications where this set api might be useful in client programs .PERIOD one thing that is very common is the idea of an exception filter .PERIOD so the way we'll set that up is to think about having a list of files a list of words in a file that are exceptional in some way .PERIOD in this case ,COMMA we'll have the word ,COMMA the file list .PERIODtext that has these four words in it :COLON was ,COMMA it ,COMMA the ,COMMA and of .PERIOD so this two ,COMMA complimentary ways to look at this .PERIOD one is so -DASH called white listing where we want to take the words in that file and ,COMMA and then we have some other much bigger file .PERIOD and what we want to do is print out all the occurrences of our exceptional words in our given file .PERIOD those are the ones that we care about ,COMMA that we want to get through .PERIOD so in this case ,COMMA tinytale .PERIODtxt the first couple of words from "a tale of two cities .PERIOD" and these words appear often ,COMMA "it was the of ,COMMA it was the of .PERIOD" another ,COMMA a complementary approach is to think of these words as words that we don't want to ever see .PERIOD they're blacklist ,COMMA and we want to take them out of our source file .PERIOD so a blacklist client would print out all the words in our source file ,COMMA tinytale .PERIODtxt except was ,COMMA it ,COMMA be ,COMMA and of .PERIOD in this case ,COMMA best times ,COMMA worst times ,COMMA and so forth .PERIOD so that's the exception filter ,COMMA and that's useful in lots of applications such as the ones listed here .PERIOD for example ,COMMA you might have a spellchecker where you want to identify misspelled words .PERIOD so ,COMMA then your key would be a word or a string .PERIOD and in your exceptional list would be words that are in the dictionary .PERIOD and you'd want to print out all the words that are not in the dictionary .PERIOD that's an example of a ,COMMA an exception filter .PERIOD or in a browser you might want to mark your visited pages or block sites and so forth .PERIOD or like the one at the bottom credit cards .PERIOD maybe ,COMMA you run a credit card company and you want to check for stolen cards then your keys would be numbers .PERIOD i .PERIOD and in your list ,COMMA might be kind of short ,COMMA which would be the stolen cards that you know about ,COMMA and you'd want to run a ,COMMA a white list filter for those cards and print out in your long list of transactions which ever transactions have that stolen cards ,COMMA so ,COMMA that's just a couple of examples of exception filters .PERIOD what's the implementation of an exception filters ?QUESTIONMARK here's a simple one using the said api that we just articulated .PERIOD so ,COMMA we start by creating an empty set of strings ,COMMA and again since we don't have associated values ,COMMA we just have the one generic for strings ,COMMA and then create a new input stream from ,COMMA from the first argument so that's the name of the file that contains the exceptional words and so this just reads the strings while the input string is not empty and then adds the m to the set .PERIOD so that now ,COMMA we have our set of exceptional words .PERIOD and now ,COMMA from standard input we read words ,COMMA as long as our set contains the word ,COMMA we print it out .PERIOD and if doesn't contain it ,COMMA we don't print it out .PERIOD so that's an example of a white list filter .PERIOD and to implement black list we just this call to contains ,COMMA we just change that to a ,COMMA a not .PERIOD if it's not in the exceptional list ,COMMA then we print it out .PERIOD so that's a simple example of a filter using sets .PERIOD 
now ,COMMA let's look at a dictionary client ,COMMA another very useful and common application of symbol tables .PERIOD so ,COMMA in this case ,COMMA we are going to write a client called lookup csv that [cough] is going to take three arguments .PERIOD the first will be a file name ,COMMA a so -DASH called common separated value file and the next two arguments are integers which will tell us what to treat as keys and values in the file .PERIOD in this example or csv file relates urls to ip addresses .PERIOD so ,COMMA each line has a url and ip address and are separated by commas .PERIOD and in general ,COMMA a csv file might have many fields separated by comma ,COMMA comma .PERIOD so ,COMMA we number them zero ,COMMA one ,COMMA and so forth starting from the left .PERIOD so ,COMMA what we are going to do with this client is specify with integers which field is the key ,COMMA and which is the value .PERIOD so ,COMMA if we call this client with second argument zero and third argument one ,COMMA that means we want to use the url field zero on the csv file as the key ,COMMA no one use the ip address that's field one in the csv as the value ,COMMA you want to associate keys with values .PERIOD so the client will build a symbol table that makes us associations for every line in the file and this could be huge file .PERIOD and then ,COMMA if we want to look up the ip address associated with a given url we can just type in urls and the client will return the ip address ,COMMA it'll do the look up .PERIOD so ,COMMA adobe .PERIODcom has got this ip address that's shown if this line here in the table ,COMMA and so forth .PERIOD princeton .PERIODedu has this ip and ebay .PERIODedu is not in the file .PERIOD now ,COMMA on the other hand ,COMMA we could ,COMMA from this same file ,COMMA we could build a symbol table where we treat the ip address as the ,COMMA as the key and the url as the value .PERIOD so ,COMMA in that case ,COMMA it'll build a symbol table with ip addresses as keys and we can type in an ip address and get the associated url .PERIOD so ,COMMA with one client we can handle lookups of all kinds in csv files .PERIOD for example ,COMMA here's another csv file that from biology that deals with ,COMMA amino acids and codons and names .PERIOD so ,COMMA in this case ,COMMA the first field is three letters from the dna sequence which ,COMMA represents a codon .PERIOD and certain codons have names ,COMMA that's the amino acids .PERIOD so ,COMMA tcc is called serine ,COMMA and so forth .PERIOD and that's an association that's well known to biologist and then you can use this lookup csv client to quickly get the name associated with any given codon .PERIOD that's just another simple example .PERIOD this is a very general tool .PERIOD any csv file ,COMMA you can pick any field as the key ,COMMA any other field as the value .PERIOD so here's still another example where we might use for a class list ,COMMA which has the person's year of graduation ,COMMA last name ,COMMA first name precept name and login name .PERIOD and so in the first call over here ,COMMA we might use the login name as the key and the first name as the value .PERIOD so ,COMMA we type in somebody's login name we get their first name .PERIOD and again ,COMMA with the same client login is key and get the section as a value .PERIOD so ,COMMA all kinds of information processing that we might need to do for large amounts of data ,COMMA represented in comma ,COMMA comma separated value files this one client which is based on a symbol table will provide useful functionality .PERIOD and here's the implementation there's very little to it given the symbol table api that we've articulated and the implementations that we have .PERIOD so what do we do to get lookup csv implemented ?QUESTIONMARK well ,COMMA first thing is to set up the input stream from the first argument ,COMMA so that's our input file .PERIOD and then ,COMMA get the numbers of the fields ,COMMA so the key and the value .PERIOD and now build a simple table that associates strings with strings .PERIOD then there there's a while loop where we just read a new line in that read line ,COMMA read line and then split according to comma into tokens in an array .PERIOD and then ,COMMA the index in the array is going to build the fields that we're going to use .PERIOD so ,COMMA the key is the string in the key field entry of the array ,COMMA and the value is the string in the value field entry in the array ,COMMA and we simpl y put that into symbol table .PERIOD so ,COMMA this value loop just builds the symbol table from the file .PERIOD then from standard input we take queries ,COMMA just read a string ,COMMA check if the symbol table contains the string .PERIOD it ,COMMA it doesn't ,COMMA print not found .PERIOD and if it does ,COMMA print the value associated with the key .PERIOD so ,COMMA a very small amount of code based on a symbol table implementation that gives us the dictionary functionality .PERIOD 
here's another simple client program for symbol tables related to indexing .PERIOD again ,COMMA another common function that's easily handled by symbol tables .PERIOD there's all kinds of cases where we just have a lot of information ,COMMA maybe on our pc or all over the web ,COMMA and we want to create an index that allows us to specify .PERIOD a search key and get all the associated information .PERIOD and you've ,COMMA you've used programs like this  likely .PERIOD   9  10 11 00 :COLON00 :COLON45 ,COMMA210  -DASH  -DASH > 00 :COLON00 :COLON48 ,COMMA870 12 00 :COLON00 :COLON48 ,COMMA870  -DASH  -DASH > 00 :COLON00 :COLON53 ,COMMA930 13 00 :COLON00 :COLON53 ,COMMA930  -DASH  -DASH > 00 :COLON00 :COLON57 ,COMMA040 14 00 :COLON00 :COLON57 ,COMMA040  -DASH  -DASH > 00 :COLON00 :COLON57 ,COMMA540 00 :COLON00 :COLON58 ,COMMA590  -DASH  -DASH > 00 :COLON01 :COLON00 ,COMMA690 so ,COMMA in this small example .PERIOD so ,COMMA our client is going to called file index .PERIOD and in this small example say we are going to have five text files .PERIOD and these are just pieces of literature .PERIOD  index from that set of text files .PERIOD  want  contain that key .PERIOD  in the  tale   25  26 27 00 :COLON01 :COLON44 ,COMMA460  -DASH  -DASH > 00 :COLON01 :COLON48 ,COMMA520 28 00 :COLON01 :COLON48 ,COMMA520  -DASH  -DASH > 00 :COLON01 :COLON52 ,COMMA230 29 00 :COLON01 :COLON52 ,COMMA230  -DASH  -DASH > 00 :COLON01 :COLON56 ,COMMA300 30 00 :COLON01 :COLON56 ,COMMA300  -DASH  -DASH > 00 :COLON02 :COLON02 ,COMMA290 31 00 :COLON02 :COLON02 ,COMMA290  -DASH  -DASH > 00 :COLON02 :COLON06 ,COMMA270 32 00 :COLON02 :COLON07 ,COMMA290  -DASH  -DASH > 00 :COLON02 :COLON09 ,COMMA610 00 :COLON02 :COLON09 ,COMMA610  -DASH  -DASH > 00 :COLON02 :COLON15 ,COMMA180 program ,COMMA to find places where certain ,COMMA 00 :COLON02 :COLON15 ,COMMA180  -DASH  -DASH > 00 :COLON02 :COLON18 ,COMMA430 terms are used in a bunch of programs .PERIOD so ,COMMA normally we have a bunch of dot  application .PERIOD  with  from   40  41  42  43 44 00 :COLON02 :COLON42 ,COMMA690  -DASH  -DASH > 00 :COLON02 :COLON47 ,COMMA450 45 00 :COLON02 :COLON47 ,COMMA450  -DASH  -DASH > 00 :COLON02 :COLON53 ,COMMA870 46 00 :COLON02 :COLON53 ,COMMA870  -DASH  -DASH > 00 :COLON02 :COLON57 ,COMMA470 47 00 :COLON02 :COLON57 ,COMMA470  -DASH  -DASH > 00 :COLON02 :COLON59 ,COMMA860 00 :COLON02 :COLON59 ,COMMA860  -DASH  -DASH > 00 :COLON03 :COLON02 ,COMMA200 the string we type what's the value ?QUESTIONMARK well what we're going to use for value is a set of files ,COMMA the files that contain the query string .PERIOD so just given that high level description then the implimintation is pretty direct .PERIOD here's the implementation of file index using our symbol file implimintation .PERIOD so now we're going to build a symbol table .PERIOD that associates string keys with sets of files .PERIOD so this creates a new symbol table  files .PERIOD  the index .PERIOD  going to take  line .PERIOD  create an input stream .PERIOD  if  word .PERIOD  put that in the symbol table ,COMMA   65  66  67  68  69  70  71  72  73 74 00 :COLON04 :COLON41 ,COMMA870  -DASH  -DASH > 00 :COLON04 :COLON45 ,COMMA280 75 00 :COLON04 :COLON45 ,COMMA280  -DASH  -DASH > 00 :COLON04 :COLON49 ,COMMA200 76 00 :COLON04 :COLON50 ,COMMA250  -DASH  -DASH > 00 :COLON04 :COLON53 ,COMMA480 77 00 :COLON04 :COLON53 ,COMMA480  -DASH  -DASH > 00 :COLON04 :COLON57 ,COMMA900 78 00 :COLON04 :COLON57 ,COMMA900  -DASH  -DASH > 00 :COLON05 :COLON03 ,COMMA460 79 00 :COLON05 :COLON03 ,COMMA460  -DASH  -DASH > 00 :COLON05 :COLON07 ,COMMA120 80 00 :COLON05 :COLON07 ,COMMA120  -DASH  -DASH > 00 :COLON05 :COLON10 ,COMMA370 81 00 :COLON05 :COLON10 ,COMMA370  -DASH  -DASH > 00 :COLON05 :COLON12 ,COMMA600 00 :COLON05 :COLON12 ,COMMA600  -DASH  -DASH > 00 :COLON05 :COLON17 ,COMMA810 find all occurrences of that word along 00 :COLON05 :COLON17 ,COMMA810  -DASH  -DASH > 00 :COLON05 :COLON22 ,COMMA580 and context just means a few words before 00 :COLON05 :COLON22 ,COMMA580  -DASH  -DASH > 00 :COLON05 :COLON32 ,COMMA430 so for example ,COMMA in tail of two cities .PERIOD 00 :COLON05 :COLON32 ,COMMA430  -DASH  -DASH > 00 :COLON05 :COLON38 ,COMMA660 this one place and this is [cough] context 00 :COLON05 :COLON38 ,COMMA660  -DASH  -DASH > 00 :COLON05 :COLON43 ,COMMA930 with the forwards tongues of the two 00 :COLON05 :COLON43 ,COMMA930  -DASH  -DASH > 00 :COLON05 :COLON49 ,COMMA120 the word majesty appears in three places ,COMMA 00 :COLON05 :COLON49 ,COMMA120  -DASH  -DASH > 00 :COLON05 :COLON53 ,COMMA540 in well ,COMMA this is ,COMMA the very special case 00 :COLON05 :COLON53 ,COMMA540  -DASH  -DASH > 00 :COLON05 :COLON54 ,COMMA920 in web searches .PERIOD you type in a word ,COMMA and then you get  context .PERIOD  an easy way to implement this .PERIOD   94  95  96 97 00 :COLON06 :COLON22 ,COMMA812  -DASH  -DASH > 00 :COLON06 :COLON29 ,COMMA360 98 00 :COLON06 :COLON29 ,COMMA360  -DASH  -DASH > 00 :COLON06 :COLON34 ,COMMA630 99 00 :COLON06 :COLON34 ,COMMA630  -DASH  -DASH > 00 :COLON06 :COLON39 ,COMMA410 100 00 :COLON06 :COLON40 ,COMMA770  -DASH  -DASH > 00 :COLON06 :COLON41 ,COMMA780 00 :COLON06 :COLON41 ,COMMA780  -DASH  -DASH > 00 :COLON06 :COLON48 ,COMMA460 and then we're going to create a new 00 :COLON06 :COLON48 ,COMMA460  -DASH  -DASH > 00 :COLON06 :COLON51 ,COMMA130 strings with sets of integers .PERIOD and again the string is the key and the sets of integers are going to be the places in the array where the given work appears .PERIOD so ,COMMA we go through .PERIOD all the words ,COMMA pick out our key ,COMMA s ,COMMA and again ,COMMA if ,COMMA it's not there yet ,COMMA we create a new set associated with that s ,COMMA and ,COMMA then ,COMMA afterwards ,COMMA we go ahead and .PERIOD  that set .PERIOD  queries ,COMMA where we take a  associated with that query .PERIOD   112  113  114  115  
as a final example of a symbol table client ,COMMA we'll take a look at a mathematical application where we want to implement sparse vectors and matrices .PERIOD so ,COMMA this is a standard matrix vector multiplication that you learn in math where we have a square matrix and a column vector and we want to do a dot product of ,COMMA of first row with the column vector to get the first entry in the result .PERIOD so ,COMMA in this case ,COMMA they're all zero ,COMMA except for 0 .PERIOD04 0 .PERIOD9 which is 0 .PERIOD36 .PERIOD and then similarly ,COMMA dot product of this with that column is 0 .PERIOD297 and so forth .PERIOD so standard implementation of this is quite easy .PERIOD we have a two -DASH dimensional matrix one -DASH dimensional column vector for the multiplicand and the result .PERIOD and then they get initialized in some way ,COMMA but the main computation is a pair of nested four loops for each row in the matrix we have to go through each entry in the column vector and compute a running sum of for that row in the matrix ,COMMA that corresponding expanding entry with the entry in the column and them ,COMMA keep the running sum and then that's the result that we put in the result column factor for every value of i .PERIOD and the key thing about this standard implementation that it's two nested four loops that each run up to n .PERIOD so ,COMMA that's n^2 or quadratic running time .PERIOD and that's fine in typical applications when the matrix is small ,COMMA or when there's lots of entries in the matrix .PERIOD but the fact is that in many practical applications ,COMMA the matrices are what's called sparse .PERIOD they ,COMMA most of the entries are zero .PERIOD and so ,COMMA symbol tables provide us with a way to provide a more efficient implementation of ,COMMA of this process when we have lots of zero entries .PERIOD so in a typical thing ,COMMA say ,COMMA maybe the matrix dimension would be 10 ,COMMA000 ,COMMA and maybe there would only be ten non -DASH zero entries per row .PERIOD or ,COMMA even nowadays you might have matrices that are ,COMMA are even bigger .PERIOD 10 ,COMMA000 by 10 ,COMMA000 if ,COMMA if there was ,COMMA if it was full ,COMMA that would be a billi on or 100 million entries .PERIOD and so that's definitely going to be costly eh ,COMMA if you're doing this operation a ,COMMA a lot .PERIOD and the idea is to cut down on that cost by taking advantage of idea that there's a lot of zeros .PERIOD so let's start by just looking at vectors .PERIOD so the standard representation that we use for vector is to simply use a one dimensional array .PERIOD we have constant time access to every element ,COMMA but the space is proportional to n .PERIOD so ,COMMA even if there's a lot of zeros we ,COMMA we still have to take the space to store them all .PERIOD instead ,COMMA we're going to use a symbol table representation where our key is the index and the value is the entry .PERIOD and we just use that for every non -DASH zero entry in the vector .PERIOD so ,COMMA this has got the same amount of information .PERIOD it says that index one has got 0 .PERIOD36 ,COMMA index five also has 0 .PERIOD36 ,COMMA index fourteen has 0 .PERIOD18 and so forth .PERIOD but the space is proportional instead of to n ,COMMA it's just proportional to the number of non -DASH zero entries which again ,COMMA in typical applications ,COMMA may be way ,COMMA way less .PERIOD and so now ,COMMA just we ,COMMA we know we have a symbol table implementation that has efficient iterator .PERIOD and also access is not bad .PERIOD it's just that we're able to do it with way less space .PERIOD so ,COMMA here's what the implementation of a sparse vector might look like .PERIOD so first thing is the representation is going to be a symbol table .PERIOD and in this case ,COMMA we might as well use a hash table because the order in which we process things is not important .PERIOD uh -DASH huh ,COMMA we just want to get at the ,COMMA all the non -DASH zero entries .PERIOD so the constructor is going to create in this [cough] symbol table .PERIOD just a new symbol table that associates integer indices with double values .PERIOD so ,COMMA the put which is to store a value associated with an index i ,COMMA is just put into that hash table ,COMMA associate key i with value x .PERIOD associate an integer with a double .PERIOD and get i'll return zero if the index key is not in the symbol table .PERIOD we didn't ,COMMA that's the whole poin t was ,COMMA we don't represent zeroes .PERIOD other ,COMMA otherwise it returns the value associated with the index .PERIOD and the iterable just returns all the key to iterate .PERIOD and the most important thing is that if we want to do a dot product with a vector ,COMMA say ,COMMA then the time that it takes is only proportional to the number of non -DASH zero keys .PERIOD the zero keys are going to be zero on the dot product so what we're going to do is take the item key of the vector and multiply it by whatever value we get for the non -DASH zero entries .PERIOD so ,COMMA it's a dot product that takes time proportional to the number of non -DASH zero entries in the vector .PERIOD and ,COMMA and that's going to be important in the use of a matrix .PERIOD so instead of using the standard matrix representation ,COMMA where every row of a matrix is an array ,COMMA that's what a two dimensional array is and the space is proportional to n^2 .PERIOD now we're going to use a sparse matrix representation ,COMMA where each row of the matrix is a sparse vector .PERIOD we can iterate through the elements in ,COMMA in constant time ,COMMA and with a hash table ,COMMA we can get at them in near constant time and then constant time in the average .PERIOD but the space is only proportional to the number of non -DASH zero elements plus n for the extra symbol table overhead .PERIOD so ,COMMA those are independent symbol table objects .PERIOD but they allow us to have a much more efficient matrix multiplication method .PERIOD so now if we have a sparse matrix times a vector our running time is going to be constant for each row or proportional to the number of non -DASH zero entries for each row which means that the running time is going to be linear for a sparse matrix just by the use of a symbol table .PERIOD and this clearly can make the difference between being able to address a huge problem .PERIOD if we have a 10 ,COMMA000 by 10 ,COMMA000 matrix we can get it done nearly instantly linear time versus 10 ,COMMA000^2 .PERIOD if we now run out of space ,COMMA we might run out of time .PERIOD but with the symbol table implementation we can ef ficiently process huge sparse 
welcome back to algorithms .PERIOD today ,COMMA we're going to talk about the union find problem .PERIOD a set of algorithms for solving the so -DASH called dynamic connectivity problem .PERIOD we'll look at two classic algorithms .PERIOD quick find and quick union ,COMMA and some applications and improvements of those algorithms .PERIOD the subtext of today's lecture really is to go through the steps that we'll follow over and over again to develop a useful algorithm .PERIOD the first step is to model the problem .PERIOD try to understand ,COMMA basically ,COMMA what are the main elements of the problem that need to be solved .PERIOD then we'll find some algorithm to solve the problem .PERIOD in many cases ,COMMA the first algorithm we come up with would be fast enough and maybe it fits in memory and ,COMMA we'll go ahead and use it ,COMMA and be off and running .PERIOD but in many other cases maybe it's not fast enough ,COMMA or there's not enough memory .PERIOD so ,COMMA what we do is try to figure out why ,COMMA find a way to address whatever's causing that problem ,COMMA find a new algorithm and iterate until we're satisfied .PERIOD this is the scientific approach to designing and analyzing algorithms ,COMMA where we build mathematical models to try and understand what's going on ,COMMA and then we do experiments to validate those models and help us improve things .PERIOD so ,COMMA first we'll talk about the dynamic connectivity problem ,COMMA the model of the problem for union find .PERIOD so ,COMMA here's the idea .PERIOD they're going to have a set of n objects .PERIOD doesn't really matter what they are .PERIOD we're going to use the numbers ,COMMA zero through n to model our objects .PERIOD and then ,COMMA we have the idea of a connection between two objects .PERIOD and ,COMMA we'll ,COMMA postulate that there's going to be a command that says ,COMMA connect two objects .PERIOD given two objects ,COMMA provide a connection between them .PERIOD and then key part of the problem is find query or the connected query ,COMMA which just asks ,COMMA is there a path connecting the two objects .PERIOD so for example ,COMMA in this set of ten objects ,COMMA we performed already ,COMMA a bunch of union commands ,COMMA connecting four and three ,COMMA three and eight ,COMMA six and five ,COMMA nine and four ,COMMA two and one .PERIOD and now we might have a connected query that says ,COMMA is zero connect ed to seven ?QUESTIONMARK well ,COMMA in this case ,COMMA there is no connection ,COMMA so we say no .PERIOD but if we ask is eight connected to nine ?QUESTIONMARK we are going to say yes ,COMMA even no we don't have a direct connection between eight and nine .PERIOD there is a path from eight to three to four to nine .PERIOD so ,COMMA that's our problem ,COMMA to be able to officially support these two commands for given set of objects .PERIOD now ,COMMA let's say we add a union five ,COMMA zero .PERIOD so ,COMMA that creates a connection between five and zero .PERIOD seven and two creates a connection between seven and two .PERIOD and six and one ,COMMA between six and one .PERIOD so ,COMMA now if we ask our zero connected to seven ,COMMA well one and zero we can do that too .PERIOD and that's a redundant connection .PERIOD and now ,COMMA if we ask is zero connected to seven we're going to answer yes .PERIOD so that's our problem ,COMMA intermix union ,COMMA commands and connected queries and we need to be able to officially support those commands for a large number of objects .PERIOD so ,COMMA here's a much bigger example .PERIOD and you can see that we're going to need efficient algorithms for this .PERIOD first of all ,COMMA you can see we're going to need a computer for this .PERIOD it would take quite ,COMMA quite some time for a human to figure out whether there's a connection .PERIOD in this case there is a connection .PERIOD now ,COMMA the algorithms that we're looking at today are not going to actually give the path connecting the two objects .PERIOD it's just going to be able to answer the question ,COMMA is there a path ?QUESTIONMARK in part two of the course ,COMMA we'll consider algorithms that explicitly find paths .PERIOD they're not as efficient as union find because they have more work to do .PERIOD now ,COMMA applications of these ,COMMA these algorithms involve objects of all types .PERIOD these are used for digital photos ,COMMA where the objects are pixels they're used for networks ,COMMA where the objects are computers ,COMMA social networks ,COMMA where it's people ,COMMA or computer chips ,COMMA where it's circuit elements or abstract things like variable names in a program ,COMMA or elements in a mathematical set ,COMMA or physical things like metallic sites in a composite system .PERIOD so ,COMMA all different types of objects for ,COMMA but for programming we're going to associate each object with a name and we'll just name the objects with a number ,COMMA integers from zero to n -DASH 1 .PERIOD that's a very convenient initial starting point for our programs because we can use integers as an index into an array then ,COMMA and then quickly access information relevant to each object .PERIOD and it also just supresses a lot of details that are not relevant to union find .PERIOD in fact ,COMMA to make this mapping from an object name to the integer zero through n  -DASH  one is to find application of a symbol table or a searching algorithm ,COMMA which is one of the things that we'll be studying later in this course algorithms and data structures for solving that problem .PERIOD now ,COMMA the connections ,COMMA well ,COMMA we need ,COMMA a few abstract properties that these connections have to satisfy .PERIOD and they're all quite natural and intuitive .PERIOD so we assume that is connected to is an equivalence relation .PERIOD that is ,COMMA every object's connected to itself ,COMMA it's symmetric .PERIOD if p's connected to q ,COMMA then q's connected to p ,COMMA and it's transitive .PERIOD if p's connected to q ,COMMA and q's connected to r ,COMMA then p's connected to r .PERIOD now these properties are very intuitive .PERIOD but it's worthwhile to state them explicitly and make sure that our algorithms maintain them .PERIOD when we have an equivalence relation a set of objects and connections divide into subsets called connected components .PERIOD a connected component is a maximal set of objects that's mutually connected .PERIOD for example in this small example here ,COMMA there's three connected components .PERIOD one consisting of just object zero ,COMMA second one objects one ,COMMA four and five .PERIOD and third one the other four objects .PERIOD and these components have the property that if any two objects in them are connected and there is no object outside that is connected to those objects ,COMMA that's connected components .PERIOD our algorithms will gain efficiency by maintaining connected components and using that knowledge to efficiently answer the query that's ,COMMA that they're presented with .PERIOD okay ,COMMA so to implement the operations ,COMMA we have to find query and the union command .PERIOD and so we're going to mai ntain the connected components .PERIOD the find is going to have to check if two objects are in the same component and the union command is going to have to replace components containing two objects with their union .PERIOD so ,COMMA for example ,COMMA if we have these components ,COMMA and we get the command to union connect ,COMMA two and five .PERIOD essentially ,COMMA we need to merge the connected components containing the one containing two or the one containing five to get a big connected components and now we have only two connected components .PERIOD all of that leads up to ,COMMA in a programming world to specifying ,COMMA a data type which is simply specification of the methods that we are want to going to implement in order to solve this problem .PERIOD so you know ,COMMA typical java model ,COMMA what we will do is create a class called uf that contains two methods ,COMMA one to implement union ,COMMA the other one to implement connected ,COMMA which returns a boolean .PERIOD the constructor ,COMMA takes sr unit ,COMMA the number of objects ,COMMA so that it can build data structure based on the number of objects .PERIOD so ,COMMA and we have to ,COMMA bear in mind ,COMMA as we're building our logarithms ,COMMA that both the number of objects can be huge ,COMMA but also ,COMMA the number of operations .PERIOD we can have a ,COMMA a very large number ,COMMA of union and connected ,COMMA operations and our algorithms are going to have to be efficient ,COMMA under those conditions .PERIOD one of the practices that will follow often in this course is to check our api design before getting too far into dealing with the problem ,COMMA by building a client that is going to use the data type that we develop .PERIOD so ,COMMA for this example ,COMMA we've got a client that ,COMMA will read information from standard input .PERIOD first ,COMMA an integer which is the number of objects that are going to be processed .PERIOD and then a series of pairs of object names .PERIOD and what the client does is it ,COMMA it'll ,COMMA first it'll read the integer from standard input ,COMMA and create a ,COMMA a uf object .PERIOD and then as long as standard input is not empty ,COMMA it's going to read two integers from the input .PERIOD and if they're not connected ,COMMA then it'll connect them and print them out .PERIOD if they are connected it'll ignore .PERIOD so ,COMMA that's our test client and that's a fine test client to make sure that any implementation does what we expect that it will .PERIOD so ,COMMA that's the setup .PERIOD we've described the operations we want to implement all the way down to code and we have client code that we're going to have to be able to service with our 
welcome back .PERIOD our topic today is algorithms for processing undirected graphs which are a model that are widely used for many ,COMMA many applications .PERIOD we'll see plenty of examples and then we'll look at three fundamental algorithms for processing undirected graphs and consider some of the challenges of developing algorithms for ,COMMA for this kind of structure .PERIOD so as introduction we'll take a look at the basic ideas behind undirected graphs and applications .PERIOD what is an undirected draft ?QUESTIONMARK it's the ,COMMA the definition is very simple .PERIOD it's a set a verticies connected pairwise by edges .PERIOD so this is an example of an undirected graph that describes the paris metro .PERIOD you've got stations and if there's a rail line between the stations there's an edge .PERIOD so why do we study graphs and graph algorithms ?QUESTIONMARK well there are literally thousands of practical applications where graphs are an appropriate models and we'll take a look at a few others in just a minute .PERIOD because there are so many applications ,COMMA there's literally hundreds of graph algorithms known and these are sometimes quite sophisticated ,COMMA as we'll see and also very important in understanding what's going on in an application .PERIOD even without the applications a graph is really an interesting and broadly useful abstraction to try and understand that's so simple to describe ,COMMA but leads to quite complex and difficult to understand structures .PERIOD in a general graph theory and graph algorithms is a very challenging branch of computer science and discreet math that we're just introducing now .PERIOD so here's an example of a graph ,COMMA in ,COMMA in genetics or in genomics ,COMMA where if the network where the nodes are proteins and the edges are interactions among the proteins .PERIOD and genomicists are trying to understand how these biological processes work .PERIOD need to understand the nature of connections like this .PERIOD here's another example ,COMMA the internet itself ,COMMA where ,COMMA every node is a computer and every edge is or ,COMMA or a node ,COMMA every ,COMMA a computer or a communications device ,COMMA and every edge is connections .PERIOD and of course ,COMMA the internet is driven by loops and bounds ,COMMA so this is a huge craft ,COMMA in this lot of needs ,COMMA lot of interest understanding ,COMMA properties of this craft .PERIOD this is a ,COMMA social graph having to do the way science is carried out .PERIOD so it's the ,COMMA the nodes are and scientist websites and the edges or ,COMMA clicks connecting one to another .PERIOD this one shows how scientists in different fields are interacting .PERIOD and again interesting and important to understand properties of this graph .PERIOD you're certainly familiar with facebook .PERIOD that's one of the hugest one of the biggest graphs .PERIOD it's absolutely huge ,COMMA and it's always changing .PERIOD it's very dynamic and people want to understand its property .PERIOD this is an example of a graph ,COMMA that was used ,COMMA in litigation ,COMMA where people were trying to understand ,COMMA exactly ,COMMA precisely ,COMMA the communications patterns ,COMMA in a particular corporate culture ,COMMA that was of great interest to many people .PERIOD another similar example ,COMMA this is people lobbying the fcc and how are they connected .PERIOD so from the breadth and variety of these examples ,COMMA you can see that number one .PERIOD graphs are very general model ,COMMA and number two ,COMMA graphs can be huge .PERIOD this is another one showing the framingham heart study and connections among people in the study and how it relates to obesity .PERIOD so those examples in this list shows that it's graphs are very flexible and very dynamic model and that the graphs involved can be huge they could have complex properties .PERIOD and so our challenge is to try to figure out efficient algorithms that can give us some insight into the structure of graphs like this .PERIOD that's what we're going to be talking about for the rest of this lecture .PERIOD so now back to a starting point which is we need some simple and clear and specific definitions about basic terms that we're talking about .PERIOD and then we'll look at algorithms that work for a small example but also the same algorithms do what we need for big graphs of the type we just considered .PERIOD so this is the terminology for that we'll use for graph processing .PERIOD so we have a vertex which is a black dot in this graph and an edge which is black line connecting two vertices .PERIOD and then a few more concepts that are important in many applications .PERIOD so one is the idea of the path .PERIOD that's just a sequence of vertices connected by edges .PERIOD and the idea of a cycle ,COMMA which is a path who's first and last vertices are the same .PERIOD so over on the left ,COMMA you can see a cycle of length five ,COMMA that connects these five vertices .PERIOD and wherever you start ,COMMA you go back to the same place .PERIOD so we say the two vertices are connected if there's a path between them .PERIOD and then that definition leads us to the idea of a graph dividing up into connective components ,COMMA which is subsets of the graph where each pair of vertices is connected .PERIOD and ,COMMA so one of the algorithms that we're going to look at today is one for identifying connected components in ,COMMA in a graph .PERIOD so that's just one example .PERIOD here's some examples of problems that might arise in graph processing that are easily understood just given these basic definitions .PERIOD so the very first one is given two vertices ,COMMA is there a path connecting those two vertices ?QUESTIONMARK like in the internet graph ,COMMA you want to know ,COMMA can i get from where i am to where i want to get ?QUESTIONMARK or maybe you want the shortest path ,COMMA the most efficient way to get between two vertices .PERIOD you might want to know is there a cycle on the graph ?QUESTIONMARK if the graph maybe represents electrical kind activity a cycle might represent a short circuit ,COMMA you would want to check for that .PERIOD or maybe you want to systematically go everywhere in the graph ,COMMA so there's two related problems called the euler tour and the hamilton tour .PERIOD euler tour is ,COMMA is there a cycle that uses each edge exactly once ?QUESTIONMARK can i go look around the graph and touch every edge in it ?QUESTIONMARK and the one called the hamilton tour ,COMMA which says well i'm really just interested in getting to the vertices .PERIOD is there a cycle that uses each vertex exactly once ?QUESTIONMARK or basic connectivity problems .PERIOD so you want to know ,COMMA is there some way to connect all the vertices ?QUESTIONMARK is there a path between each pair of vertices in the graph or not ?QUESTIONMARK or you might want to know what's called the minimal spanning tree ,COMMA which is the shortest set of edges ,COMMA or the best way to connect all of the vertices .PERIOD and then various processing issues related to connectivity .PERIOD for example ,COMMA is there a vertex whose removal disconnects the graph ?QUESTIONMARK drawing the graph .PERIOD can you draw the graph in the plane with no edges crossing ?QUESTIONMARK some of the graph with nodes are correspond to places in the plan or cities on the earth or whatever ,COMMA but some of the other graphs are very abstract ,COMMA may have nothing to do with geometry .PERIOD you might want to know can you draw with no crossing edges or you might have two graphs ,COMMA and a vertex named different to represent the same graph .PERIOD so one of the biggest challenges in graph processing that we'll address today in this lecture somewhat is just to decide how difficult are these problems .PERIOD some of them are very easy ,COMMA some of them are very difficult and some of them ,COMMA actually ,COMMA is unknown how difficult they are .PERIOD there's such a broad variety of problems that are simply stated .PERIOD one of the first things that we have to be aware of when doing graph processing is that we ,COMMA we are entering into a forest of ,COMMA of all different possibilities and ,COMMA and we have to be careful that we're working on a problem that we can solve .PERIOD and we'll try to give some insights into that during the lectures that we gave on graph -DASH processing .PERIOD so that's our introduction to 
 .PERIOD as we'll see ,COMMA in little bit later in the lecture the way that we're going to set up our graph processing algorithms ,COMMA is to develop an api to cover our representation of the graph and provide simple set of methods for clients to call to process the graph .PERIOD so ,COMMA let's take a look at that in detail .PERIOD so ,COMMA the idea is we have to represent ,COMMA a ,COMMA graph within the computer .PERIOD one of the first things ,COMMA to remember is that ,COMMA you can ,COMMA draw a graph ,COMMA that maybe ,COMMA that provides some kind of intuition ,COMMA about the structure ,COMMA an ,COMMA but you could have two drawings that represent ,COMMA represent the same graph that look pretty different .PERIOD and so one of the things to remember in any graph representation is ,COMMA it can give you some intuition .PERIOD but that intuition may be misleading .PERIOD and we'll just remember that as we look at different representations .PERIOD so first thing is how to represent the vertices .PERIOD so what we're going to do in this lecture is just use integers between zero and v minus one .PERIOD the reason we do that is it allows us ,COMMA to use vertex indexed arrays ,COMMA within the graph representation .PERIOD and we understand ,COMMA from earlier algorithms ,COMMA lectures ,COMMA that we can use a symbol table to convert names to integers ,COMMA with a symbol table .PERIOD and so ,COMMA we'll ,COMMA leave that part as a symbol table application .PERIOD and ,COMMA just work with graphs with vertex names between zero and v minus one where v is the number of vertices .PERIOD now we have to remember when we're doing representation we can have various anomalies in the graph .PERIOD so we can we draw edges ,COMMA but actually ,COMMA in real data we might have multiple edges or we might have a self loop .PERIOD and we'll take that into account when we look at the representation ,COMMA graph representation .PERIOD so here is the api that we're going to use .PERIOD so again our graph processing algorithms are going to be clients of this api .PERIOD the idea is that will use this to build graphs .PERIOD and then our processing programs will be client at this program ,COMMA in this ,COMMA of this api .PERIOD and the idea is most of them have a very simple operations that they need to do ,COMMA and those are the one's that we put in the api .PERIOD so we have two constructors .PERIOD one that creates an empty graph would be vertices .PERIOD another one that creates a graph from an input stream .PERIOD then the basic operation for building a graph is just add edge ,COMMA so that adds an edge connecting two vertices ,COMMA v and w .PERIOD the basic operations for processing our graph ,COMMA well there's v and e that gives a number of edges and vertices .PERIOD but then there's an iterator that takes the vertex's argument ,COMMA then iterates through the vertices adjacent to that vertex .PERIOD all of our graph processing can be cast in terms of this iterator .PERIOD so down here is an example of a client program that prints out every edge in the graph .PERIOD so we created an input stream ,COMMA maybe with a given final name ,COMMA create a graph from that input stream ,COMMA and we'll look at the code for that .PERIOD and then the client program for every vertex ,COMMA so remember the vertices are numbered between zero and g dot the number of vertices minus one .PERIOD so for every vertex ,COMMA we iterate through all the vertices adjacent to that vertex and print out an edge ,COMMA if ,COMMA if there's an edge connecting v and w we print out v and then a little dash to indicate an edge and then w .PERIOD this actually prints out every edge twice and in an undirected graph because if the v and w are connected by an edge then w appears in v's adjacency list and v appears in w's adjacency list .PERIOD so heres an example of a running that client ,COMMA if ,COMMA if we have a file tinyg .PERIODtxt ,COMMA our standard is we have a number of vertices as an integer in the first is the first integer in the file .PERIOD number of edges is the second integer in the file and then pairs of vertex names .PERIOD and so .PERIOD the constructor will read those two things and then call that edge for all of these pairs of things and that enables this client ,COMMA to ,COMMA if we run it for that graph ,COMMA to print out all the edges .PERIOD so everybody adjacent to zero ,COMMA 61 and five ,COMMA everybody adjacent to one is just zero ,COMMA so you notice the edge 0 -DASH 1 appears twice in the list .PERIOD so that's the sample client of our basic graph in api .PERIOD and so here's some typical and simpicle ,COMMA simple graph processing code that uses the api .PERIOD so you can write a static method that takes a graph and a vertex as argument .PERIOD and returns the degree ,COMMA the number of edges that are connect ,COMMA number of vertices that are connected by an edge to v .PERIOD so all it does is set a local variable degree to zero ,COMMA and then iterate through all the vertices adjacent to v and increment that and return it .PERIOD similarly ,COMMA you can compute the maximum degree of a vertex in a graph .PERIOD and that's for every vertex ,COMMA compute the degree and find the biggest one or the average degree .PERIOD well ,COMMA the average degree ,COMMA if you think about it ,COMMA it's just twice the number of edges divided by the vertex or you could go through all the way through every vertex and edge and compute the total and divide ,COMMA but this is probably a much more efficient way to do it or say number of self loops .PERIOD and so that involves going through the whole graph of every vertex for every edge adjacent to that vertex you check whether it's v and we've got a self loop .PERIOD and if it does then your return the number of self loops that divided by two because every edge is counted twice .PERIOD so those are examples of static methods that a client might use .PERIOD in just example of the use of the ati .PERIOD so now how we going to implement that ?QUESTIONMARK that's our usual standard of lets look at some clients and now let's talk about a representation that we can use to implement the graph api .PERIOD so one possible representation is ,COMMA set of edges representation ,COMMA where ,COMMA for every edge ,COMMA we just maintain a list ,COMMA maybe an array of edges or a linked list ,COMMA of edges .PERIOD so for every edge in the graph ,COMMA there's ,COMMA a representation of it .PERIOD and that one is a possible representation ,COMMA but it leads to ,COMMA inefficient ,COMMA implementation ,COMMA much less efficient ,COMMA that would make it unusable for ,COMMA the huge graphs that we see in practice .PERIOD another one is called the adjacency matrix representation ,COMMA here we maintain a 2 -DASH dimensional v x v array ,COMMA it's a boolean array ,COMMA 0 -DASH 1 or true or false .PERIOD and for every edge v -DASH w in the graph you put true for row v in column w and for row w in column v .PERIOD so it's actually two representations of each edge in an adjacency matrix graph representation .PERIOD s ,COMMA you can immediately ,COMMA give a v and w test whether there's an edge connecting v and w .PERIOD but that's one of the few operations that's efficient with this representation and it's not very widely used ,COMMA because for a huge graph ,COMMA say with billions of ,COMMA of ,COMMA vertices ,COMMA you would have to have billion squared number of entries in this array ,COMMA which is going to be too big for your computer ,COMMA most likely .PERIOD so this one actually isn't that widely used .PERIOD a ,COMMA the one that is most widely used in practice ,COMMA and the one that we'll stick with ,COMMA is called the adjacency list representation .PERIOD and that's where we keep a vertex index array where ,COMMA for every vertex ,COMMA we maintain a list of the vertices that are adjacent to that .PERIOD so ,COMMA for example ,COMMA vertex four ,COMMA has ,COMMA five ,COMMA is connected to five ,COMMA six ,COMMA and three ,COMMA so its list has five ,COMMA six ,COMMA and three on it .PERIOD now ,COMMA on lower level representations we've talk about using linked width or array for these ,COMMA but actually in modern lingo with the background that we'd built with algorisms what we're going to use is an abstract data type .PERIOD our bag representation for this ,COMMA which is implemented with a linked list ,COMMA but we don't have to think about it when we're talking about graphs .PERIOD we'd keep the vertices ,COMMA names of ,COMMA numbers of the vertices that are adjacent to each given vertex in a bag .PERIOD and we know that we can implement it ,COMMA such that we can iterate through and time proportional to the number of entries and the space taken is also proportional to the number of entries ,COMMA ,COMMA and that's going to enable us to process huge graphs .PERIOD so here's the full implementation of the jason c ,COMMA list graph representation .PERIOD so ,COMMA the private instance variables that we're gonna use area the number of vertices in the graph and then a array of nags of integers .PERIOD so data the types and set of values ,COMMA set operations on those values ,COMMA so those are the sets of values for a graph .PERIOD so here's the constructor of an empty graph with v vertices .PERIOD we keep the value v in the instance variable as usual .PERIOD then we create .PERIOD an array of size v .PERIOD and ,COMMA of bags of integers .PERIOD and ,COMMA store that array in ,COMMA [inaudible] as the adjacency array of the graph .PERIOD adjacency lists array .PERIOD and then ,COMMA as usual .PERIOD when we create ,COMMA a ,COMMA a ,COMMA an array of objects .PERIOD we go through .PERIOD and for every entry in the array ,COMMA we initialize with ,COMMA a ,COMMA empty object .PERIOD so ,COMMA after this code ,COMMA we have the empty bags .PERIOD and so that's the constructor and then the other main engine and building graphs is at edge and so ,COMMA to add an edge between v and w ,COMMA we add w to v's bag ,COMMA and we add v to w's bag .PERIOD that's it .PERIOD and to iterate through all the vertices adjacent to a given vertex we simply return the bag which is iterable .PERIOD this is a nice example ,COMMA illustrating the power of abstraction .PERIOD because we did the low level processing ,COMMA for ,COMMA that ,COMMA that's involved ,COMMA with our bag implementation in one of the early ,COMMA lectures .PERIOD and now we ,COMMA we get to use that to give a very compact implementation ,COMMA and efficient implementation ,COMMA of the ,COMMA graph data structure .PERIOD so it's really important to understand this code .PERIOD and you should make sure ,COMMA that you study it .PERIOD so ,COMMA as i mentioned in practice .PERIOD we're gonna be using this adjacency list representation .PERIOD because all the algorithms are based on iterating over the vertices adjacent to v .PERIOD and this gets that done in time proportional to the number of such vertices .PERIOD so that's number one and number two ,COMMA in the real world ,COMMA the graphs have lots of num ,COMMA lots of vertices ,COMMA but a pretty small vertex degre .PERIOD so number one ,COMMA we can afford to represent ,COMMA represent the graph when we use the adjacency list representation because basically our space is proportional to the number of edges .PERIOD and number two ,COMMA we can afford to process it because our time taken is proportional to the number of edges that ,COMMA that we examined ,COMMA with the ray of edges representation in the adjacency matrix representation it gets very slow for some very simple task ,COMMA but ,COMMA mostly ,COMMA it's very slow for iterating over the vertices given to ,COMMA adjacent to a given vertex .PERIOD which is the key operation .PERIOD a list of edges ,COMMA you have to go through all the edges to find the ones adjacent to a given vertex .PERIOD adjacency matrix ,COMMA you have to go through ,COMMA all possible ,COMMA vertices adjacent and that's just going to be much too slow in practice ,COMMA because adjacency list gets it done ,COMMA in time proportional degree of v ,COMMA which is much smaller ,COMMA for the huge graph that we see in the real world .PERIOD so that's our basic api .PERIOD next ,COMMA we'll look at some algorithms that are clients of this api .PERIOD 
now we'll look at our first implementation of an algorithm for solving the dynamic connectivity problem ,COMMA called quick -DASH find .PERIOD this is a so called eager algorithm ,COMMA for solving kind activity problem .PERIOD the data structure that we're going to use to support the algorithm is simply an integer array indexed by object .PERIOD the interpretation is the two objects ,COMMA p and q are connected if and only if ,COMMA their entries in the array are the same .PERIOD so for example in this example with our ten objects the idea array that describes the situation after seven connections is illustrated in the middle of the slide .PERIOD so that ,COMMA after the ,COMMA at this point zero ,COMMA five ,COMMA and six are all in the same connected component ,COMMA because they have the same array entry ,COMMA zero .PERIOD one ,COMMA two ,COMMA and seven all have entry one .PERIOD and three ,COMMA four ,COMMA eight ,COMMA and nine all have entry eight .PERIOD so that representation is ,COMMA shows that they're connected .PERIOD and clearly ,COMMA that's going to support a quick implementation of the find operation .PERIOD we just check the array entries to see if they're equal .PERIOD check if p and q have the same id .PERIOD so ,COMMA six and one have different ids .PERIOD one has id one ,COMMA six has id zero .PERIOD they're not in the same connected component .PERIOD union is more difficult in order to merge the components ,COMMA containing two given objects .PERIOD we have to change all the entries ,COMMA whose id is equal to one of them to the other one .PERIOD and arbitrarily we choose to change the ones that are the same as p to the ones that are same as q .PERIOD so if we're going to union six and one ,COMMA then we have to change entries zero ,COMMA five ,COMMA and six .PERIOD everybody in the same connected component as six .PERIOD from zero to one .PERIOD and this is ,COMMA as we'll see ,COMMA this is a bit of a problem when we have a huge number of objects ,COMMA because there's a lot of values that can change .PERIOD but still ,COMMA it's easy to implement ,COMMA so that'll be our starting point .PERIOD so we'll start with a ,COMMA a demo of how this works .PERIOD so ,COMMA initially ,COMMA we set up the id array ,COMMA with each entry ,COMMA equal to its index .PERIOD and so all that says is that all the objects are independent .PERIOD they're in their own connected component .PERIOD now ,COMMA when we get a union operation .PERIOD so ,COMMA say ,COMMA four is supposed to be unio n with three .PERIOD then we're going to change ,COMMA all entries ,COMMA whose id is equal to the first id to the second one .PERIOD so in this case ,COMMA we'll change the ,COMMA connect three and four means that we need to change the four to a three .PERIOD and we'll continue to do a few more so you'll get an idea of how it works .PERIOD so three and eight now so to connect three and eight now three and four have to be connected to eight .PERIOD so both of those entries have to change to eight .PERIOD okay ?QUESTIONMARK so now ,COMMA what about six and five ?QUESTIONMARK so again ,COMMA we change the first one to match the second one .PERIOD so to connect six and five ,COMMA we change the six to a five .PERIOD what about nine and four ?QUESTIONMARK so ,COMMA now we have to change the ,COMMA to connect nine and four ,COMMA we have to change ,COMMA 9's entry to be the same as 4's .PERIOD so now we have three ,COMMA four ,COMMA eight ,COMMA and nine .PERIOD all have entries eight .PERIOD they're all on the same connected component .PERIOD two and one means that we connect two and one by changing the 2201 .PERIOD eight and nine are already connected .PERIOD they have the same ,COMMA entries in the idea array .PERIOD so ,COMMA that connected query ,COMMA that find says ,COMMA true ,COMMA they're already connected .PERIOD and five and zero have different entries .PERIOD they're not connected ,COMMA so we'd return false ,COMMA in that case ,COMMA not connected .PERIOD and then ,COMMA if we want to connect five and zero .PERIOD then ,COMMA as usual we'll connect ,COMMA the entry corresponding to both five and six to zero .PERIOD seven and two ,COMMA union seven and two .PERIOD that's an easy one .PERIOD and union ,COMMA six and one so there is three entries that have to get changed .PERIOD all those zeros have to get changed to ones .PERIOD so ,COMMA that's a quick demo of quick -DASH find .PERIOD now next we'll look at the code for implementating that .PERIOD okay ,COMMA with this concrete demo in mind then moving to coding up this algorithim is pretty straight forward .PERIOD although it's an interesting programming exercise that a lot of us would get wrong the first time .PERIOD so let's start with the constructor ,COMMA well we have a ,COMMA a private integer array .PERIOD that's our id array .PERIOD that's the data structure that's going to support this implementation .PERIOD the constructor has to create the array and then go through and set the value corresponding to each index i to i .PERIOD that's straight forward .PERIOD the find operation ,COMMA or connected operation .PERIOD that's the easy one  .PERIOD this is the quick -DASH find algorithm .PERIOD so it simply takes its two arguments ,COMMA p and q ,COMMA and checks whether their id entries are equal ,COMMA and returns that value .PERIOD if they're equal ,COMMA it returns true .PERIOD if they're not equal ,COMMA it returns false .PERIOD the more complicated operation implement is a union .PERIOD and there ,COMMA we find first the id corresponding with the first argument ,COMMA and then the id corresponding to the second argument .PERIOD and then we go through the whole array ,COMMA and looking for the entries whose ids are equal to the id of the first argument ,COMMA and set those to the id of the second argument .PERIOD that's a pretty straightforward implementation .PERIOD and i mentioned that a lot of us would get us wrong .PERIOD the mistake we might make is to put id of p here rather than first picking out ,COMMA that value .PERIOD and you can think about the implications of that .PERIOD that's an insidious bug .PERIOD so ,COMMA that's a fine implementation of quickfind so the next thing to decide is how effective or efficient that algorithm is going to be and we'll talk in some detail about how to do that but for this it's sufficient to just think about the number of times the code has to access the array .PERIOD as we saw when doing the implementation ,COMMA both the initialized and union operations involved the for -DASH loop that go through the entire array .PERIOD so they have to touch in a constant proportional to n times after touching array entry .PERIOD find operation is quick ,COMMA it's just to a constant number of times check array entries .PERIOD and this is problematic because the union operation is too expensive .PERIOD in particular if you just have n union commands on n objects which is not unreasonable .PERIOD they're either connected or not then that will take quadratic time in squared time .PERIOD and one of the themes that we'll go through over and over in this course is that quadratic time is much to slow .PERIOD and we can't accept quadratic time algorithms for large problems .PERIOD the reason is they don't scale .PERIOD as computers get faster and bigger ,COMMA quadratic algorithms actually get slower .PERIOD now ,COMMA let's just talk roughly about what i mean by that .PERIOD a very rough standard ,COMMA say for now ,COMMA is that people have computers that can run billions of operations per second ,COMMA and they have billions of entries in main memory .PERIOD so ,COMMA that means that you could touch everything in the main memory in about a second .PERIOD that's kind of an amazing fact that this rough standard is really held for 50 or 60 years .PERIOD the computers get bigger but they get faster so to touch everything in the memory is going to take a few seconds .PERIOD now it's true when computers only have a few thousand words of memory and it's true now that they have billions or more .PERIOD so let's accept that as what computers are like .PERIOD now ,COMMA that means is that ,COMMA with that huge memory ,COMMA we can address huge problems .PERIOD so we could have ,COMMA billions of objects ,COMMA and hope to do billions of union commands on them .PERIOD and ,COMMA but the problem with that quick find algorithm is that ,COMMA that would take ten^18th operations ,COMMA or ,COMMA say array axises or touching memory .PERIOD and if you do the math ,COMMA that works out to 30 some years of computer time .PERIOD obviously ,COMMA not practical to address such a problem on today's computer .PERIOD and ,COMMA and the reason is ,COMMA and the problem is that quadratic algorithms don't scale with technology .PERIOD you might have a new computer that's ten times as fast but you could address a problem that's ten times as big .PERIOD and with a quadratic algorithm when you do that .PERIOD it's going to be ten times as slow .PERIOD that's the kind of situation we're going to try to avoid by developing more efficient algorithms for solving problems like this .PERIOD 
now ,COMMA we're going to look at depth -DASH first search ,COMMA which is a classical graph processing algorithm .PERIOD it's actually maybe one of the oldest algorithms that we study ,COMMA surprisingly .PERIOD one way to think about depth first search ,COMMA is in terms of mazes .PERIOD it's a pretty familiar way to look at ,COMMA look at it .PERIOD and ,COMMA so ,COMMA if you have a maze like the one drawn on the left ,COMMA you can model it with a graph .PERIOD by creating a vertex for every intersection .PERIOD in the maze .PERIOD and an edge for every passage connecting two intersections .PERIOD and .PERIOD so .PERIOD if you're at the entrance to this maze and you want to find a pot of gold somewhere .PERIOD what you're gonna need to do is .PERIOD explore every intersection .PERIOD or explore ,COMMA explore every edge .PERIOD in the maze .PERIOD so .PERIOD we're gonna talk about the .PERIOD explore every intersection .PERIOD option .PERIOD so that's our goal .PERIOD to have an algorithm for doing that .PERIOD by the way ,COMMA this is a famous graph that some of you might recognize .PERIOD that's the graph for the pac -DASH man game .PERIOD okay ,COMMA so one method classic method that predates computers for exploring a maze is called the tr maux maze exploration algorithm .PERIOD the idea is to think about having a ball of string .PERIOD and what you do is when you walk down a passage ,COMMA you unroll the string behind you .PERIOD and you also ,COMMA mark ,COMMA every place that you've been .PERIOD so actually ,COMMA i have a ball of string and some chalk ,COMMA maybe .PERIOD so in this case ,COMMA maybe we walk down this passage here .PERIOD and now we have some choices about where we might go .PERIOD so say we go down here .PERIOD so we unroll our ball of string and mark it .PERIOD and so now ,COMMA the next time ,COMMA at this intersection ,COMMA we have no choice but to go up here .PERIOD we go up here and we say ,COMMA oh ,COMMA we've already been there .PERIOD so we're not gonna go there .PERIOD and we come back .PERIOD and ,COMMA we have our ball of string .PERIOD so we can unroll it to figure out where we were .PERIOD and we go back until we have some other choice .PERIOD which is this ,COMMA this place ,COMMA now .PERIOD and we mark that we've been in these other places ,COMMA and so now ,COMMA we take another option and say ,COMMA go down this way .PERIOD and here ,COMMA we take another option ,COMMA go that way .PERIOD and then finally again we go up this a way and we see that we've been there so we back up and take the last option and then that gets us to the last vertex in the graph .PERIOD so mark each visited intersection and each visited package ,COMMA passage ,COMMA and retrace our steps when there's no unvisited option .PERIOD again this is a classical algorithm that was studied centuries ago and in fact some argued the first youth was when theseus entered the labyrinth and was trying to find the minotaur and ,COMMA and rodney didn't want ''em to get lost in the maze .PERIOD so she instructed theseus to use a ball of string to find his way back out .PERIOD that's the basic algorithm that we're gonna use .PERIOD and has been studied by many ,COMMA many scientists in the time since theses .PERIOD and in fact ,COMMA claude shannon ,COMMA founder of information theory ,COMMA did experiments on mazes with mice to see if they might understand maze exploration ,COMMA this might help .PERIOD okay ,COMMA so here's what it look like in its typical maze .PERIOD now one of the things to remember is in a computer representation normally we're just looking at the vertices and the set of associated edges .PERIOD we don't see anything other than that .PERIOD though ,COMMA it's sometimes frustrating watching me you know that it turned the wrong way and it's gonna get trapped here .PERIOD but ,COMMA the computer doesn't really know that ,COMMA so it has to back up along here now and it continues to back up to find another option untill it gets free again .PERIOD and finds a some place to go .PERIOD sometimes its very frustrating .PERIOD its seems to be quite close to the goal like appear and it turns a wrong way .PERIOD so we an see its gonna take a long way but no way the program could really know that .PERIOD again ,COMMA all the programs we're working with is vertex instead of edges associated with that vertex and there it finally get to the goal .PERIOD here's a bigger one going faster .PERIOD the king thing is not so much ,COMMA its getting lost and the key thing is not going anywhere twice .PERIOD and that's the whole thing .PERIOD we have to have the string to know to go back where we came from .PERIOD and we have to be able to mark where we have been .PERIOD and with those two things we are ,COMMA algorithm is ,COMMA able to avoid going the same place twice .PERIOD if you weren't marking ,COMMA if you tried to do this randomly or some other way it might take you a while to get to the goal .PERIOD so it doesn't seem like much of accomplishment maybe for a maze but actually to be able to get there with going ,COMMA without going any place thrice ,COMMA twice is sort of a ,COMMA profound idea and leads to an efficient algorithm .PERIOD okay .PERIOD so ,COMMA our idea is ,COMMA given in this ,COMMA medicode ,COMMA to do ,COMMA depth research ,COMMA that is ,COMMA to ,COMMA visit ,COMMA all the places you can get to from a vertex ,COMMA v .PERIOD what we're gonna do is this simple re ,COMMA recursive algorithm .PERIOD mark the vertex as visited and then recursively visit all unmarked vertices ,COMMA w that are adjacent to v .PERIOD that's a very simple description ,COMMA and it leads to very simple codes .PERIOD it's so simple actually ,COMMA it really belies the profound idea underneath this algorithm .PERIOD so ,COMMA again ,COMMA there's lots of applications .PERIOD and ,COMMA for example ,COMMA this is one way to find whether there exists a path between two vertices .PERIOD or to find all the vertices connected to a given source vertex .PERIOD and we'll consider some less abstract applications ,COMMA once we've looked at the code .PERIOD so ,COMMA so how to implement .PERIOD well here's what we're gonna do for our design pattern for graph processing .PERIOD it's our first example .PERIOD so what we did ,COMMA when we defined an api for graph was to decouple the graph data type from graph processing .PERIOD the idea is we're gonna create a graph object using that api which we know allows us to represent a big graph within the computer .PERIOD and gives us the basic operations that we're gonna need for graph processing .PERIOD and then we use that api within a graph processing routine .PERIOD and the basic idea is that ,COMMA that graph ,COMMA graph processing routine will go through the graph and collect some information .PERIOD and then a client of that routine will query the it's api to get information about the graph .PERIOD so in the case of ,COMMA depth first search .PERIOD here's a potential possible api .PERIOD so the idea is that what this ,COMMA what we're gonna implement is a program that can find paths in a graph from a given source .PERIOD so we give a graph and a vertex .PERIOD and that the constructor is gonna do what it needs in order to be able to answer ,COMMA these two queries .PERIOD first one is ,COMMA give a vertex ,COMMA client will give a vertex .PERIOD is there a path in the graph ,COMMA from the source to that vertex ?QUESTIONMARK you wanna be able to ,COMMA answer that efficiently .PERIOD and then ,COMMA the other thing is to just give the path .PERIOD what's the path from ,COMMA has to be giving all the vertices on the path ,COMMA in time proportional to its length .PERIOD so here's a client of ,COMMA this ,COMMA api .PERIOD so ,COMMA it's gonna take a source ,COMMA a source vertex s .PERIOD and it's gonna build a pathfinder ,COMMA or a path object .PERIOD and that object is gonna do the processing it needs to be able to efficiently implement haspathto .PERIOD and then what this does is for every vertex in the graph .PERIOD if there's a path from s to that vertex .PERIOD it'll print it out .PERIOD so it prints out all the vertices connected to x .PERIOD and that's just one client ,COMMA of this ,COMMA data type .PERIOD you could ,COMMA print out the pass or whatever else you might .PERIOD so that's our design pattern that we're gonna use over and over again ,COMMA for ,COMMA a graph processing routine .PERIOD and it's important to understand why we use a design pattern like this .PERIOD we're decoupling the graph representation from the processing of it .PERIOD as i mentioned ,COMMA there's hundreds of routines for ,COMMA or algorithms that have been developed for processing graphs .PERIOD an alternative might be to put all of those algorithms in one big data type .PERIOD that's a so called fat interface .PERIOD and that would be a ,COMMA a bad plan ,COMMA cuz these things maybe are not so well related to each other .PERIOD and actually all of them really are just iterating through the graph ,COMMA and doing different types of processing .PERIOD with this way we're able to separate out .PERIOD the ,COMMA and i articulate what the graph processing clients are doing .PERIOD and then the real applications can be clients ,COMMA of these graph processing routines .PERIOD and everybody's taken advantage of an efficient representation ,COMMA that we already took care of .PERIOD okay .PERIOD so now let's look at a demo of how depth -DASH first search is gonna work and then we'll take a look at the implementation .PERIOD okay .PERIOD so here's a demo of depth -DASH first search in operation on our sample graph .PERIOD again ,COMMA to visit a vertex we're gonna mark it ,COMMA and then recursively visit all unmarked verti -DASH  ,COMMA vertices that are adjacent .PERIOD so this is a sample graph .PERIOD and so the first thing we do is realize that we're gonna need a vertex index array to keep track of which vertices are more .PERIOD so that will just be an array of bullions and we'll initialize that with all false .PERIOD we're also gonna keep another data structure .PERIOD a ,COMMA a vertex indexed array of ints .PERIOD that for every vertex gives us the vertex that took us there .PERIOD so ,COMMA let's get started and you'll see how it works .PERIOD so this is depth -DASH first search staring at vertex zero .PERIOD so now to visit vertex zero ,COMMA we wanna mark it so that's ,COMMA our mark zero is true .PERIOD that's the starting points we know anything with edge two .PERIOD and now what we're gonna do is .PERIOD we're going to need to check all the vertices that are adjacent to zero .PERIOD so that's six ,COMMA two ,COMMA one ,COMMA and five .PERIOD the order in which they're checked depends on the representations in the bag .PERIOD we don'tr really ,COMMA necessarily care about that .PERIOD most of the algorithms are going to check them all .PERIOD and it doesn't matter that much about the order .PERIOD although ,COMMA in some cases it's wise to be mindful .PERIOD and maybe use a bag that takes them out in random order .PERIOD okay this is zero .PERIOD now we have to check ,COMMA six ,COMMA two ,COMMA one ,COMMA and five so ,COMMA lets go ahead and do that .PERIOD so in this case six ,COMMA six is the first thing to get checked .PERIOD and so now ,COMMA we mark ,COMMA six is visited so now we are going to recursively do a search starting from six .PERIOD the other difference when we visit six from zero .PERIOD we're going to put a zero in this edge to entry to say that when we first got the six the way we got there ,COMMA was from zero .PERIOD and that's going to be the data structure that'll help us ,COMMA implement the client query and give us the path back to zero from any path .PERIOD from any vertex .PERIOD so okay what do we have to do to visit six .PERIOD well six has two adjacent vertices zero and four .PERIOD so we're gonna have to check them .PERIOD so first we check zero and that's already marked .PERIOD so we don't really have to do anything .PERIOD we're only suppose to recursively visit unmarked vertices .PERIOD and then we check four .PERIOD and four is unmarked ,COMMA so we're going to have to recursively visit is .PERIOD the next thing we do is visit four .PERIOD mark four as having been visited .PERIOD where the true and the marked array ,COMMA fourth entry is a marked array .PERIOD and we fill an edge two saying we got to four from six .PERIOD and so now to visit four ,COMMA we have to recursively check five ,COMMA six and three ,COMMA and again ,COMMA that order is where they happen to be in our bag .PERIOD so first we check five .PERIOD five is not marked so we're going to visit five .PERIOD we're gonna mark it .PERIOD say we got there from four ,COMMA and then go ahead and visit three ,COMMA four and zero ,COMMA in that order .PERIOD from first we visit three .PERIOD that one also is not yet marked ,COMMA so we're gonna recursively visit it .PERIOD so it's marked three .PERIOD say we got there from five and then go ahead and to visit three recursively ,COMMA we have to check five and four .PERIOD check five .PERIOD well we just came here it's mark ,COMMA so we don't have to do anything .PERIOD check four ,COMMA that's also ,COMMA been marked so we don't have to do anything .PERIOD so now finally ,COMMA this is the first time and that requires a call that we're ready to return ,COMMA we're done with that first search from three .PERIOD so now we're done with three .PERIOD and we can unwinding the recursion ,COMMA we can now continue our search from five .PERIOD and the next thing we have to do from five ,COMMA we had already checked three ,COMMA so now we're gonna check four .PERIOD and we've already visited four ,COMMA so we don't have to do anything .PERIOD that's already marked .PERIOD and we checked zero ,COMMA and that one's already marked .PERIOD so now we're done with five ,COMMA and we can back one more level up in the recursion .PERIOD so now ,COMMA for four ,COMMA we have to go through ,COMMA and look at six and three .PERIOD six is mar ,COMMA marked ,COMMA so we don't have to do anything .PERIOD three is marked ,COMMA so we don't have to do anything ,COMMA and so we're gonna be done with four .PERIOD so that after finishing four we're done with six .PERIOD and so now we're in the recursion back at zero .PERIOD and we've already checked six .PERIOD so now we gotta check two next .PERIOD we checked two ,COMMA and so we rehearse and go there .PERIOD mark two ,COMMA and then say we got there from zero ,COMMA and now to visit two ,COMMA all we check is zero and that's a marks ,COMMA so we don't have to do anything ,COMMA and we're done with two .PERIOD then check one ,COMMA visit one ,COMMA that's the last vertex we're visiting .PERIOD check zero ,COMMA it's already marked so we don't do anything .PERIOD we return .PERIOD now ,COMMA we're at the last ,COMMA step is to ,COMMA from zero ,COMMA five is on it's list ,COMMA we have to check if we've been there .PERIOD we can see that it's marked and we have been there so we're one with zero .PERIOD so that's a depth -DASH first search from vertex zero ,COMMA and we have visited all the vertices that are reachable from zero .PERIOD number one and number two for each one of those vertexes we kept track of how we got there from zero .PERIOD so if we now want to know for any one of those vertices how to get back to zero we have the information that we need .PERIOD for example say we want to find the path from five back to zero .PERIOD we know we got the five from four ,COMMA we know we got the four from six ,COMMA we know we got the six from zero so we can go back through using that edge to array to find .PERIOD the path ,COMMA so the depth for search calculation built in data structures ,COMMA and now clients ,COMMA whose data structures built in a constructor serve as the basis for ,COMMA being able to .PERIOD officially answer client queries .PERIOD that's a depth -DASH first search demo .PERIOD so ,COMMA this is just a summary of the thing i talked about ,COMMA during that demo .PERIOD our goal is to find all the vertices connected to different vertex at .PERIOD and also a path ,COMMA in order to be able to answer client query .PERIOD on the algorithm we're going to use is based on like maze exploration where we use excursion ,COMMA mark each vertex ,COMMA keep track of the edge we took to visit it and return when there's no unvisited options .PERIOD we're using ,COMMA two data structures ,COMMA to implement this .PERIOD both vertex indexed arrays .PERIOD one named mark that will tell us which vertices we've been to .PERIOD and another one ,COMMA edge two that maintains that tree of paths .PERIOD where edge 2w = v means that vw was taken ,COMMA the first time that we went to w .PERIOD so now ,COMMA let's look at the code ,COMMA that ,COMMA given all of this background .PERIOD the code for implementing depth first search is remarkably compact .PERIOD so here's our private instance variables .PERIOD the marked and edgedto vertex and mix arrays ,COMMA and the source s .PERIOD and the constructor just goes through and ,COMMA creates ,COMMA the arrays and initializes them .PERIOD and we won't repeat that code .PERIOD and so here's the ,COMMA the last thing the constructor does after it creates the arrays ,COMMA is does a dfs on the graph ,COMMA from the given source .PERIOD and it's a remarkably ,COMMA compact implementation to do depth -DASH first search ,COMMA from a vertex v .PERIOD what we do is mark v ,COMMA let's say mark it true .PERIOD then for everybody adjacent to v .PERIOD we check if it's marked .PERIOD if it's not marked ,COMMA then we do a recursive call .PERIOD and we set edge to w equals v .PERIOD again remarkably compact code that gets the job done .PERIOD so now let's look at some of the properties of depth -DASH first search .PERIOD so first thing is we wanna be sure that convince ourselves that it marks all the vertices connected to s in time proportional to some of their degrees ,COMMA well ,COMMA depth -DASH first graph is going to be small .PERIOD so s -DASH  ,COMMA so first thing is ,COMMA convince yourself that if you mark the vertex ,COMMA then there has to be a way to get to that vertex from s .PERIOD so well that's easy to see ,COMMA because the only way to mark vertex is get there through a sequence of recursive calls ,COMMA and every recursive calls corresponds to an edge on a path from svw .PERIOD but you also have to be able to show that you get to ,COMMA every vertex that's connected to s .PERIOD and that's a little more intricate .PERIOD and this diagram is ,COMMA supposed to help you out in understanding that .PERIOD if you had ,COMMA some unmarked vertex ,COMMA then ,COMMA maybe there's ,COMMA a bunch of unmarked vertices .PERIOD and so .PERIOD .PERIOD .PERIOD and it's connected to s and it's not marked ,COMMA so that means there has to be an edge on a path from s to w ,COMMA that goes from a marked vertex to an unmarked one .PERIOD but the design of the algorithm says that there's no such edge if you're on a marked vertex then you're gonna go through and look at all the adjacent ones and if it's not marked ,COMMA you're gonna mark it .PERIOD so that's an outline of the proof that dfs marks all the vertices .PERIOD and in the running time ,COMMA it only visits each marked vertex once or each vertex connected as once .PERIOD and so ,COMMA for each one of them ,COMMA it goes through all the adjacent vertices .PERIOD so that's the basic properties of depth -DASH first search .PERIOD so now ,COMMA the other thing that is important is that a client who has ,COMMA uses this algorithm after the depth -DASH first search ,COMMA after the constructor has done the depth -DASH first search and built these data structures ,COMMA client can find the vertices connected to the source in constant time .PERIOD and can find a path ,COMMA 2s if one exists in time proportional to its length .PERIOD well ,COMMA the marked array provides the first part .PERIOD and the second part is just the property of the edge to array .PERIOD it's a ,COMMA what's called a parent link representation of a tree rooted at s .PERIOD so if a vertex is connected to s then its edge two is parent in a tree .PERIOD so this code here .PERIOD is going to for a given ,COMMA well has path too so that's just return mark ,COMMA that's the first part .PERIOD and then to actually get the path to a given vertex so ,COMMA here's the code for doing that .PERIOD we actually use a stack to keep track of the path'cause we get it in reverse order .PERIOD if there's no path ,COMMA we return null .PERIOD otherwise we keep a variable x and we just follow up through the edge to array pushing the vertex on to the stack and then moving up the tree in the ray ,COMMA then finally push ,COMMA push as itself on to the path and then we have a stack which is edible which will give us our path .PERIOD so that's in time ,COMMA time proportional to the length of the path and forth while to check your understanding of how stacks in real works ,COMMA irreversible to take a look at this code to see that it does the job .PERIOD so that's depth -DASH first search .PERIOD now it's not .PERIOD of the optimal graph searching method for all applications .PERIOD and here's an ,COMMA an amusing representation of how depth first search can maybe create problems sometimes .PERIOD so ,COMMA i'm getting ready for a date ,COMMA what situations do i prepare for ?QUESTIONMARK well ,COMMA medical emergency ,COMMA dancing ,COMMA food too expensive .PERIOD okay ,COMMA what kind of medical emergencies could happen ?QUESTIONMARK well ,COMMA i could be snake bite or a lightning strike or a fall from a chair .PERIOD well ,COMMA what about snakes ,COMMA i have to worry about corn snakes or garder .PERIOD say for copperhead .PERIOD and then well ,COMMA i better make a straight .PERIOD i better study snakes .PERIOD and then the date says ,COMMA i'm here to pick you up .PERIOD you're not dressed .PERIOD and well ,COMMA so i really need to stop using depth -DASH first search .PERIOD so we're gonna look at other graph searching algorithms .PERIOD but if you always try to expand the next thing that you come to ,COMMA that's depth -DASH first search .PERIOD and there's a lot of natural ,COMMA situations where that naturally comes to mind .PERIOD here's another example .PERIOD i took this photo of the taj mahal a couple of years ago and i didn't like the color of the sky .PERIOD so i used photoshop's magic wand to make it more blue .PERIOD and the implementation ,COMMA now this is a huge graph .PERIOD this picture's got millions of pixels .PERIOD and the way that the flood filled the magic wand works ,COMMA is to build ,COMMA from a photo ,COMMA what's called a grid graph ,COMMA where every vertex is a pixel and every edge connects two pixels that are the same color ,COMMA approximately the same color .PERIOD and it builds a blob of all the pixels that have the same color as the given pixel .PERIOD so when i click on one ,COMMA it does the depth -DASH first search to find all .PERIOD all the connected pixels and therefore change them to the new color that's a fine example of depth per search on a huge graph that people use everyday .PERIOD so that's our first nontrivial graph processing algorithm depth -DASH first search .PERIOD 
all right so quickfind is too slow for huge problems .PERIOD so ,COMMA how are we going to do better ?QUESTIONMARK our first attempt is an alternative called ,COMMA quick -DASH union .PERIOD this is so called lazy approach to algorithm design where we try to avoid doing work until we have to .PERIOD it uses the same data structure or array id with size m but now it has a different interpretation .PERIOD we are going to think of that array as representing a set of trees that's called a forest as depicted at right .PERIOD so ,COMMA each entry in the array is going to contain a reference to its parent in the tree .PERIOD so ,COMMA for example ,COMMA 3's parent is four ,COMMA 4's parent is nine .PERIOD so 3's entry is four and 4's entry is nine in the array .PERIOD now each entry in the array has associated with it a root .PERIOD that's the root of its tree .PERIOD elements that are all by themselves in just ,COMMA in their own connected component ,COMMA point to themselves ,COMMA so one points to itself but also nine points to itself .PERIOD it's the root of the tree ,COMMA containing two ,COMMA four and three .PERIOD so ,COMMA from this data structure we can associate with each item a root ,COMMA which is representative ,COMMA say ,COMMA of it's connected component .PERIOD so that's the root of three is nine ,COMMA going up that root .PERIOD now ,COMMA once we can calculate these roots ,COMMA then we can implement the find operation just by checking whether the two items that we're supposed to check with are connective where they have the same root .PERIOD that's equivalent to saying ,COMMA are they in the same connective component ?QUESTIONMARK so that's some work ,COMMA going to find the roots of each item but the union operation is very easy .PERIOD to merge components containing two different items .PERIOD two items that are in different components .PERIOD all we do is set the id of p's route to the id of q's route .PERIOD let's make p's tree point to q .PERIOD so in this case ,COMMA we would change the entry of nine to be six to merge three and five .PERIOD the components containing three and five .PERIOD and with just changing one value in the array we get the two large components emerged together .PERIOD that's the quick -DASH union algorithm .PERIOD because a union operation only involves changing one entry in the array .PERIOD find operation requires a little more work .PERIOD so let's look at the implementation ,COMMA a demo of that one in operation first .PERIOD so again we ,COMMA we start out the same way but now the idea array entry really means that every one of these things is a little tree where the one node each everyone pointing to itself .PERIOD it's the root of it's own tree so now if we have to put four and three in the same component ,COMMA then all we do is we take the root ,COMMA of the component containing the first item and make that a child of the root of the component ,COMMA component containing the second item .PERIOD in this case we just make four as parent three .PERIOD so now three and eight .PERIOD so again ,COMMA we take the first item and make it a child of the root of the tree containing the second item .PERIOD so now three ,COMMA four ,COMMA and eight are in the same component .PERIOD six and five six goes below five .PERIOD nine and four ,COMMA so now four is the root of the tree containing four is eight .PERIOD and the root of tree containing nine is nine .PERIOD and so we make nine a child of eight .PERIOD two and one ,COMMA that's an easy one .PERIOD now if we get our ,COMMA our eight and nine connected ,COMMA we just checked that they have the same root and they both have the same root eight and so they're connected .PERIOD five and four 4's root is eight .PERIOD 5's root is five .PERIOD they're different .PERIOD they're not connected .PERIOD five and zero .PERIOD five goes to be a child of zero .PERIOD seven and two seven goes to be a child of 2's root which is one .PERIOD six and one .PERIOD 6's route is zero 1's its own route ,COMMA so zero becomes a child of one .PERIOD each one of these union operations just involves changing one entry in the array .PERIOD and finally ,COMMA seven and three .PERIOD so seven's root is one ,COMMA three's root is eight ,COMMA one becomes a child of eight .PERIOD okay and now we have one connected component with all the items together .PERIOD alright ,COMMA so now let's look at the code for implementing quick -DASH union .PERIOD the constructor is the same as the other one .PERIOD we create the array and then set each element to be it's own root .PERIOD now we have a private method that implements this process of finding the root by chasing parent pointers until we get to the point where i is equal to id of i ,COMMA and if it's not equal ,COMMA we just move i up one level in the tree ,COMMA set i equals id of i and return it .PERIOD so starting at any node ,COMMA you just follow id equals id of i until they're equal and then you're at a root and that's a private method that we can use to implement the find operation or the connected operation .PERIOD you just find the root of p and the root of q and if you check if they're equal .PERIOD and then the union operation is simply find the two roots i and then set the idea the first one could be the second one .PERIOD actually less code than for quick find ,COMMA no fore loops .PERIOD there's this one wild loop that we have to worry about a little bit .PERIOD but that's a quick and elegant implementation of code to solve the dynamic connectivity problem called quick -DASH union .PERIOD so now we're going to have to look at can this code be effective for large problems ?QUESTIONMARK well unfortunately quick -DASH union is faster but it's also too slow .PERIOD and it's a little different kind of too slow then for quick find ,COMMA there's times when it could be fast ,COMMA but there's also times when it could be too slow .PERIOD and the defect for quick -DASH union is that the trees can get too tall .PERIOD which would mean that the find operation would be too expensive .PERIOD you could wind up with a long skinny tree .PERIOD of each object just pointing to next and then to do a find operation for object at the bottom would involve going all the way through the tree .PERIOD costing involving in the ray axises just to do the find operation and that's going to be too slow if you have a lot of operations .PERIOD 
next we are going to talk about breadth -DASH firsth search ,COMMA which is a completely different way to process all the vertices connected to a given vertex .PERIOD it'll get the job done ,COMMA but it has totally different properties that are useful in different ways for different applications .PERIOD so ,COMMA to understand a breadth -DASH first search ,COMMA we'll start right out with a demo .PERIOD so ,COMMA a breadth -DASH first search is not a recursive algorithm .PERIOD it uses a q as a auxiliary data structure .PERIOD and it's also is quite similar quite simple to explain .PERIOD so what we're going to do is we're going to put the source vertex on a queue and then repeat the following until the queue is empty .PERIOD remove the next vertex from the queue in fifo order then add to the queue all unmarked vertices that are adjacent to v and mark them and just keep doing that until the queue is empty .PERIOD let's see how that works on our example .PERIOD this is a smaller example ,COMMA just a six vertex graph with eight edges .PERIOD so ,COMMA add zero to the queue .PERIOD so we just ,COMMA take zero and put it on the queue ,COMMA that's where we start .PERIOD and now go into repeat until queue after remove a vertex ,COMMA add all the marked vertex adjacent to mark'em .PERIOD so ,COMMA we do qeue zero .PERIOD and then ,COMMA in order to process zero ,COMMA we need to check all its adjacent vertices .PERIOD so in this case ,COMMA it's two ,COMMA one and five .PERIOD and again ,COMMA the order depends on ,COMMA how the ,COMMA how the bag was constructed for ,COMMA vertices adjacent to zero .PERIOD so ,COMMA we check two ,COMMA and that is ,COMMA not marked .PERIOD so we have to add it to the queue .PERIOD we check then we check one ,COMMA that's not marked ,COMMA so we add it to the queue .PERIOD then we check five ,COMMA and that's not marked ,COMMA so we add it to the queue .PERIOD so ,COMMA that's ,COMMA we finished ,COMMA processing zero ,COMMA zero is done .PERIOD so now ,COMMA remove the next vertex from the queue .PERIOD in this case it's two .PERIOD we're going to take two off the queue ,COMMA and process this by adding to the queue all the unmarked vertices that are adjacent .PERIOD so the process two ,COMMA we have to check zero ,COMMA one ,COMMA three ,COMMA and four .PERIOD we check zero ,COMMA that's already marked ,COMMA so we don't do anything .PERIOD we check one ,COMMA that's also already marked ,COMMA so we don't do anythin .PERIOD in fact ,COMMA it's on the queue .PERIOD we check three ,COMMA and that one is unmarked so we mark it and add it to the queue .PERIOD and then we check four ,COMMA that one's unmarked ,COMMA so we mark it and add it to the queue .PERIOD so by the way i didn't mention but we're also keeping track of two ,COMMA auxiliary data structures for this .PERIOD one is the edge two array ,COMMA which is the same as before .PERIOD what edge did we use to get to this ,COMMA so four .PERIOD and we got to four from two .PERIOD and two ,COMMA we got to two from zero .PERIOD so again ,COMMA that's going to be a tree that gives us a path back to the source .PERIOD and instead of marked ,COMMA we also keep ,COMMA we keep a more ,COMMA detailed information ,COMMA which is ,COMMA the length of the path ,COMMA cuz it's ,COMMA we do it ,COMMA 'cause it's easy to do it .PERIOD okay ,COMMA so four ,COMMA we checked four ,COMMA and added it to the queue ,COMMA and now we're done with two .PERIOD so now we have one ,COMMA five ,COMMA three ,COMMA and four all on the queue ,COMMA and we're going to process them .PERIOD and since we've marked everything all we're going to be doing now is checking vertices that are marked .PERIOD so for one ,COMMA we check zero and that's marked .PERIOD then we check two and that's marked ,COMMA so then we're done with one .PERIOD next thing off the queue is five ,COMMA and we check three and that's marked ,COMMA and we check zero and that's marked ,COMMA so we're done with five .PERIOD and then three ,COMMA we got to check five ,COMMA and then four ,COMMA and then two and they're all marked ,COMMA and now we're done with three .PERIOD and then finally the last one ,COMMA always the last one everybody else has marked ,COMMA so connected ,COMMA check three ,COMMA check two ,COMMA and it's marked and we're done .PERIOD so what this process the result of this computation again is a three rooted at the source and we can follow back through the three to get past from each node to the source .PERIOD not only that ,COMMA we can get the distance the number of edges on the path from each node to the source .PERIOD so that's a demo of breadth -DASH first search .PERIOD and next we'll take a look at properties ,COMMA of this algorithm .PERIOD alright .PERIOD so now we've considered two different methods for processing all vertices in a graph .PERIOD and actually ,COMMA they're quite closely related ,COMMA even though the computations are quite different .PERIOD essentially ,COMMA breadth -DASH first search uses recursion to corresponds to putting unvisited vertices on a stack .PERIOD breadth -DASH first search explicitly ,COMMA we put the invert ,COMMA visited vertices on the queue .PERIOD and actually ,COMMA breadth -DASH first search solves ,COMMA another problem that ,COMMA you know ,COMMA often we want to solve ,COMMA called the shortest path problem .PERIOD actually ,COMMA the path that you get back from breadth -DASH first search is the path from the source to the given vertex that uses the fewest number of edges .PERIOD and we'll look at that ,COMMA in just a minute .PERIOD and the idea is that the breadth -DASH first search examines the vertices in the graph and increasing distance from the source .PERIOD so ,COMMA let's take a look at that .PERIOD so breadth -DASH first ,COMMA breadth -DASH first search computes shortest path ,COMMA that is it builds the data structure that we can answer the shortest path queries from the source with ,COMMA from s to all other vertices in the graph and time proportial to e plus v ,COMMA then [inaudible] vertices .PERIOD and so let's look at why that is the case .PERIOD so the first thing is ,COMMA how does ,COMMA how do we know it competes ,COMMA computes shortest paths ?QUESTIONMARK well ,COMMA the intuition is and ,COMMA you ,COMMA you can fill in the details ,COMMA the queue always contains ,COMMA some vertices of distance k from the source followed by some vertices of distance k plus one .PERIOD so they're on a queue we're processing them in first in first out order .PERIOD so say we're at a state when all of these vertices are ,COMMA are on the queue .PERIOD we're going to have process vertex zero ,COMMA as soon as we get this one we'll delete vertex zero from the queue ,COMMA and then when we're putting these adjacent ones on ,COMMA we're adding the ones of distance two .PERIOD but we're not going to process any of those until we're done with the ones of distance one and so forth .PERIOD so it's not hard to show that always you have either one of the two distances from ,COMMA from the source on the queue ,COMMA and that means the first time we get to a vertex ,COMMA that's the shortest path to that vertex .PERIOD and again ,COMMA the running time we only visit vertices once cuz we mark them .PERIOD so it's time proportional to the number of vertices plus the number of edges in the graph .PERIOD so that's breadth -DASH first search properties and then here's the implantation ,COMMA which is simply code for the basic method that we outlined in pseudocode .PERIOD so our private instance variables are marked or in the demo ,COMMA we used this to ,COMMA but just for simplicity ,COMMA let's use marked edge two ,COMMA then ,COMMA is how we get to the first vertex and then the source .PERIOD and so ,COMMA we have a constructor that builds those arrays same way as before and then calls bfs .PERIOD so bfs builds a queue ,COMMA that's what it's going to use .PERIOD then queues the source and marks the source .PERIOD and then ,COMMA this is just in code what we said in words before ,COMMA while the queue is not empty ,COMMA we pull off the next vertex from the queue ,COMMA call it v .PERIOD for everybody adjacent to v ,COMMA we go ahead and check if it's marked ,COMMA we ignore it and move to the next .PERIOD if it's not marked then we put it on the queue mark it ,COMMA and remember the edge .PERIOD and again this is an example of the power of extraction and the utility of our design pattering ,COMMA pattern .PERIOD all we're doing in terms of the graph data type is being a client to go through all the adjacent vertices .PERIOD but it allows us to implement this completely different algorithm in ,COMMA in ,COMMA in ,COMMA really an accessible way .PERIOD so that's the implementation of breadth -DASH first search .PERIOD then the client for getting the pass back as be saying this as for ,COMMA as for breadth -DASH first search .PERIOD so here's an old application of breadth -DASH first search in ,COMMA in computer networks .PERIOD that's very important when you're communicating from one place to another ,COMMA you want to get there in the fewest number of hops .PERIOD this is the arpanet .PERIOD the ,COMMA the predecessor of the ,COMMA internet ,COMMA as of july 1977 .PERIOD and things were slow and computers were ,COMMA computers were small and slow .PERIOD it's important to do these things in small number of hops .PERIOD and with breadth -DASH first search ,COMMA you could take this graph and figure out ,COMMA the shortest way to get from ,COMMA one place to another .PERIOD that's a typical application of breadth -DASH first search .PERIOD and here's another one ,COMMA so called kevin bacon numbers .PERIOD and nowadays actually you can type bacon and an actor's name ,COMMA and get the answer to this .PERIOD so there's if ,COMMA if you're not ,COMMA not familiar with it you can become familiar with it by kevin bacon numbers .PERIOD the idea is you have a graph ,COMMA where ,COMMA the vertices are actors ,COMMA and the edge ,COMMA and think of an edge connecting two actors ,COMMA if they are in a movie together .PERIOD and so what you wabt to find is given an actor how ,COMMA what's the shortest way to get to kevin bacon ,COMMA connected by ,COMMA so ,COMMA edges were actors and edges were movies ,COMMA in connection of actors in the movie .PERIOD so buzz mauro and tatiana ramirez were in sweet dreams together ,COMMA and these two actors were in this movie together and so forth .PERIOD and you get a way to kevin bacon from any actor .PERIOD and this is another pop culture application ,COMMA this is so called six degrees ,COMMA which you can get to anyone in six steps in this way .PERIOD so that's all implementation of .PERIOD breadth first search on the kevin bacon graph ,COMMA where we include one vertex for each performer ,COMMA one vertex for each movie .PERIOD connect the movie to all performers that appear in the aovie and the shortest path from kevin bacon to every actor ,COMMA if you follow through ,COMMA back through that path ,COMMA you get .PERIOD to .PERIOD you ,COMMA you get the proof of the kevin bacon number for each actor and we have implementation of that on the book side .PERIOD so that's another example .PERIOD and actually there's maybe even older or similar age example that mathematicians are fond of and that is called the ,COMMA so called erdos number .PERIOD so in this one it's mathematicians ,COMMA the nodes are mathematicians ,COMMA and there's an edge if the two mathematicians have co -DASH authored a paper .PERIOD and paul erdos was a ,COMMA a very productive hungarian mathematician who traveled the world co authoring papers with people all over the world .PERIOD a ,COMMA a very interesting and prolific character ,COMMA who actually did quite a bit of research on properties of graphs .PERIOD and maybe even more so than kevin bacon .PERIOD the idea is he was so prolific that pretty much every mathematician has a pretty low ,COMMA erdos number .PERIOD so that's our second example of a graph -DASH processing algorithm breadth -DASH first 
okay .PERIOD so ,COMMA we've looked at the quick union and quick find algorithms .PERIOD both of which are easy to implement .PERIOD but simply can't support a huge dynamic connectivity problems .PERIOD so ,COMMA how are we going to do better ?QUESTIONMARK that's what we'll look at next .PERIOD a very effective improvement ,COMMA it's called weighting .PERIOD and it might have occurred to you while we are looking at these algorithms .PERIOD the idea is to when implementing the quick union algorithm take steps to avoid having tall trees .PERIOD if you've got a large tree and a small tree to combine together what you want to try to do is avoid putting the large tree lower ,COMMA that's going to lead to long tall trees .PERIOD and there's a relatively easy way to do that .PERIOD what we'll do is we'll keep track of the number of objects in each tree and then ,COMMA we'll maintain balance by always making sure that we link the root of the smaller tree to the root of the larger tree .PERIOD so ,COMMA we ,COMMA we avoid this first situation here where we put the larger tree lower .PERIOD in the weighted algorithm ,COMMA we always put the smaller tree lower .PERIOD how we ,COMMA let's see how we implement that .PERIOD let's see a demo first .PERIOD okay ,COMMA so again start out in our normal starting position ,COMMA where everybody's in their own tree .PERIOD and for when there's only two items to link it ,COMMA it works ,COMMA works the same way as before .PERIOD but now ,COMMA when we have eight to merge with four and three ,COMMA we put the eight as the child ,COMMA no matter which order their arguments came ,COMMA because it's the smaller tree .PERIOD so ,COMMA six and five doesn't matter ,COMMA whichever one goes down doesn't matter .PERIOD nine and four ,COMMA so now ,COMMA nine is the small one four is the big one .PERIOD so ,COMMA nine is going to be the one that goes down below .PERIOD two and one ,COMMA five and zero .PERIOD so now ,COMMA five and zero five is in the bigger tree so zero goes below .PERIOD seven and two ,COMMA two is in the bigger tree so seven goes below .PERIOD six and one they're in equal size trees .PERIOD and seven and three ,COMMA three is in the smaller tree so it goes below .PERIOD so ,COMMA the weighted algorithm always makes sure that the smaller tree goes below .PERIOD and again ,COMMA we wind up with a single tree representing all the objects .PERIOD but this time ,COMMA we h ave some guarantee that no item is too far from the root and we'll talk about that explicitly in a second .PERIOD so ,COMMA here's an example that shows the effect of doing the weighted quick union where we always put the smaller tree down below for the same set of union commands .PERIOD this is with a hundred sites and 88 union operations .PERIOD you can see in the top the big tree has some trees ,COMMA some nodes ,COMMA a fair distance from the root .PERIOD in the bottom ,COMMA for the weighted algorithm all the nodes are within distance four from the root .PERIOD the average distance to the root is much ,COMMA much lower .PERIOD let's look at the java implementation and then we'll look in more detail at ,COMMA at that quantitative information .PERIOD so ,COMMA we used the same data structure except ,COMMA now we need an extra array ,COMMA that for each item ,COMMA gives the number of objects in the tree routed at that item .PERIOD that will maintain in the union operation .PERIOD find implementation is identical to for quick union ,COMMA you're just checking whether the roots are equal .PERIOD for the union implementation ,COMMA we're going to modify the code to check the sizes .PERIOD and link the root of the smaller tree to the root of the larger tree in each case .PERIOD and then after changing the id link ,COMMA we also change the size array .PERIOD if we make id ,COMMA i a child of j ,COMMA then we have to increment the size of j's tree by the size of i's tree .PERIOD or if we do the other way around ,COMMA then we have to increment the size of i's tree by the size of j's tree .PERIOD so ,COMMA that's the full code in white for implementing quick union .PERIOD so ,COMMA not very much code but much ,COMMA much better performance .PERIOD in fact we can analyze the running time mathematically and show that defined operation ,COMMA it takes time proportional to how far down the trees are in the node in the tree ,COMMA the nodes are in the tree ,COMMA but we can show that it's guaranteed that the depth of any node in the tree is at most the logarithm to the base two of n .PERIOD we use the notation lg always for logarithm to the base two .PERIOD and ,COMMA and ,COMMA so for ,COMMA if n is a thousand ,COMMA that's going to be ten ,COMMA if n is a million that's twenty ,COMMA if n is a billion that's 30 .PERIOD it's a very small number compared to n .PERIOD so ,COMMA let's look at the proof of that .PERIOD we do some mathematical proofs in ,COMMA in this course when they're critical such as this one .PERIOD and why is it true that the depth of any node x is ,COMMA at most ,COMMA log base two of n ?QUESTIONMARK well ,COMMA the key to understanding that is to ,COMMA take a look at exactly when does the depth of any node increase ?QUESTIONMARK when does it go down further in the tree ?QUESTIONMARK well .PERIOD the x's depth will increase by one ,COMMA when its tree ,COMMA t1 in this diagram ,COMMA is merged into some other tree ,COMMA t2 in this diagram .PERIOD well ,COMMA at that point we said we only do that if the size of t2 was bigger than the or equal to size of t1 .PERIOD so ,COMMA when the depth of x increases ,COMMA the size of its tree at least doubles .PERIOD so ,COMMA that's the key because that means that the size of the tree containing x can double at most log n times because if you start with one and double log n times ,COMMA you get n and there's only n nodes in the tree .PERIOD so ,COMMA that's a sketch of a proof that the depth of any node x is at most log base two of n .PERIOD and that has profound impact on the performance of this algorithm .PERIOD now instead of the initialization always takes time proportional to n .PERIOD but now ,COMMA both the union and the connected or find operation takes time proportional to log base two of n .PERIOD and that is an algorithm that scales .PERIOD if n grows from a million to a billion ,COMMA that cost goes from twenty to 30 ,COMMA which is quite not acceptable .PERIOD now ,COMMA this was very easy to implement and ,COMMA and we could stop but usually ,COMMA what happens in the design of algorithms is now that we understand what it is that gains performance ,COMMA we take a look and see ,COMMA well ,COMMA could we improve it even further .PERIOD and in this case ,COMMA it's very easy to improve it much ,COMMA much more .PERIOD and that's the idea of path compression .PERIOD and this idea is that ,COMMA well ,COMMA when we're trying to find the root of the tree containing a ,COMMA a given node .PERIOD we're touching all the nodes on the path from that node to the root .PERIOD while we're doi ng that we might as well make each one of those just point to the root .PERIOD there's no reason not to .PERIOD so when we're looking ,COMMA we're trying to find the root of ,COMMA of p .PERIOD after we find it ,COMMA we might as well just go back and make every node on that path just point to the root .PERIOD that's going to be a constant extra cost .PERIOD we went up the path once to find the root .PERIOD now ,COMMA we'll go up again to just flatten the tree out .PERIOD and the reason would be ,COMMA no reason not to do that .PERIOD we had one line of code to flatten the tree ,COMMA amazingly .PERIOD actually to make a one liner code ,COMMA we use a ,COMMA a simple variant where we make every other node in the path point to its grandparent on the way up the tree .PERIOD now ,COMMA that's not quite as good as totally flattening actually in practice that it actually is just about as good .PERIOD so ,COMMA with one line of code ,COMMA we can keep the trees almost completely flat .PERIOD now ,COMMA this algorithm people discovered rather early on after figuring out the weighting and it turns out to be fascinating to analyze quite beyond our scope .PERIOD but we mentioned this example to illustrate how even a simple algorithmah ,COMMA can have interesting and complex analysis .PERIOD and what was proved by hopcroft ulman and tarjan was that if you have n objects ,COMMA any sequence of m union and find operations will touch the array at most a c (n + m lg star n) times .PERIOD and now ,COMMA lg n is kind of a funny function .PERIOD it's the number of times you have to take the log of n to get one .PERIOD and the way to think ,COMMA it's called the iterated log function .PERIOD and in the real world ,COMMA it's best to think of that as a number less than five because lg two^ 65536 is five .PERIOD so ,COMMA that means that the running time of weighted quick union with path compression is going be linear in the real world and actually could be improved to even a more interesting function called the ackermann function ,COMMA which is even more slowly growing than lg<i> .PERIOD and another point about this is it< /i> seems that this is</i> so close to being linear that is t ime proportional to n instead of time proportional to n times the slowly growing function in n .PERIOD is there a simple algorithm that is linear ?QUESTIONMARK and people ,COMMA looked for a long time for that ,COMMA and actually it works out to be the case that we can prove that there is no such algorithm .PERIOD so ,COMMA there's a lot of theory that goes behind the algorithms that we use .PERIOD and it's important for us to know that theory and that will help us decide how to choose which algorithms we're going to use in practice ,COMMA and where to concentrate our effort in trying to find better algorithms .PERIOD it's amazing fact that was eventually proved by friedman and sachs ,COMMA that there is no linear time algorithm for the union find problem .PERIOD but weighted quick union with path compression in practice is ,COMMA is close enough that it's going to enable the solution of huge problems .PERIOD so ,COMMA that's our summary for algorithms for solving the dynamic connectivity problem .PERIOD with using weighted quick union and with path compression ,COMMA we can solve problems that could not otherwise be addressed .PERIOD for example ,COMMA if you have a billion operations and a billion objects i said before it might take thirty years .PERIOD we can do it in six seconds .PERIOD now ,COMMA and what's most important to recognize about this is that its the algorithm design that enables the solution to the problem .PERIOD a faster computer wouldn't help much .PERIOD you could spend millions on a super computer ,COMMA and maybe you could get it done in six years instead of 30 ,COMMA or in two months but with a fast logarithm ,COMMA you can do it in seconds ,COMMA in seconds on your own pc .PERIOD 
next we're going to look at a slightly different graph processing application .PERIOD but it's a ,COMMA a ,COMMA a graph processing algorithm that's useful in many applications we'll see in a minute .PERIOD and slightly different than ,COMMA depth and breadth first search .PERIOD it's called computing connected components .PERIOD now i mentioned this a little bit when we talked about basic definitions .PERIOD so the idea is that if there's a path between two vertices we say they're connected .PERIOD and what we want to do is reprocess the graph that is ,COMMA build a data type that can answer queries of the form ,COMMA is v connected to w in constant time .PERIOD now ,COMMA we want to be able to do that for a huge ,COMMA sparse graph of the type that appears in practice .PERIOD so we can't use the ,COMMA if we could use the adjacency matrix data structure ,COMMA maybe we could do that but we can't .PERIOD so we're going to build a class that uses our standard representation ,COMMA that will enable clients to find connective components .PERIOD it's really interesting to think about this one .PERIOD we're getting the job done that we could get done if we get a huge ,COMMA sparse matrix .PERIOD but if we have billions of vertices ,COMMA there's no way we can have billions squared in the matrix .PERIOD so we have to find another way to do it .PERIOD so here's the data type that we want to implement .PERIOD so it's called and it's going to the constructor is going to build the data structure that finds the connected components in the given graph to be able to efficiently answer these connectivity queries .PERIOD it'll also be able to count the number of connective components .PERIOD and it also assigns an identifier from zero to count minus one ,COMMA that identifies the connective component that every vertex is in .PERIOD now if you maybe ,COMMA this sounds a little bit similar to what we did for the union sign problem .PERIOD so when you union find problem we're ,COMMA we're taking edges and we wanted to have queries that ,COMMA that ,COMMA well ,COMMA well union is like adding edge to the graph and then find is like are these things connected yet .PERIOD now with union find ,COMMA we found that we couldn't quite answer the thing in constant time .PERIOD are members are very slow growing on questions constant practical terms ,COMMA but not ,COMMA not really .PERIOD so it's less efficient than the algorithm that we're going to talk about cause it doesn't quite get constant time .PERIOD on the other hand in another way it's better than the algorithm we're going to talk about because you can either mix the unions and fines .PERIOD and in this case ,COMMA because we're working with the graph it's like we're taking all the unions and then we are handling fine requests .PERIOD so anyway what we're going to use to implement this is a depth first search approach .PERIOD so we'll do the depth first search ,COMMA we'll just keep different data then we did ,COMMA than when we were findings paths .PERIOD so the algorithm is based on the notion that connection is an equivalence relation .PERIOD so recall an equivalence relation has these three properties .PERIOD every vertex is connected to itself .PERIOD if v is connected to w then w is connected to v .PERIOD and if v is connected to w and w to x then v is connected to x .PERIOD and those basic operations underlie the algorithm that we're going to talk about .PERIOD so the equivalence relation is a ,COMMA a general mathematical concept that implies ,COMMA in graph theory in this case .PERIOD and as i already mentioned ,COMMA in the case of graph ,COMMA it implies that .PERIOD the vertices divide up into connected components which are maximal sets of connected vertices .PERIOD so our sample graph has three connected components .PERIOD and what we'll do is assign identifiers to each one of the components in that will for every vertex .PERIOD give us an identifier number for that vertex .PERIOD and that's the data structure then our depth for search is going to built ,COMMA and that immediately gives the constant time implementation of the connectivity queries .PERIOD given two vertices you look up their id and if they're equal ,COMMA they're in the same connected component ,COMMA if they're different they're not .PERIOD so that's the data structure that we're going to build it's like a unifying tree ,COMMA where there's just ,COMMA all the trees are flat .PERIOD so that's where i just said ,COMMA given connected components ,COMMA we can answer queries in constant time .PERIOD so here's a big graph ,COMMA a big grid graph that we use in when we're talking about union find and turns out that this one's got 63 connected components .PERIOD and again when you really think about it it's kind of amazing that we can do this computation in linear time even for a huge graph .PERIOD and it's really important to be able to do so for the very huge graph that we talked about in so many applications .PERIOD if you can process all the edges you can also find out the connective components and be set up to answer connect ,COMMA connectivity queries .PERIOD this is a simple algorithm but really it's ingenious .PERIOD okay .PERIOD so let's look at the implementation .PERIOD so our goal is to petition the vertices into connected components .PERIOD so we're going to use dfs in marking .PERIOD and so what we're going to do is for a general graph .PERIOD for every unmarked vertex ,COMMA we'rere going to run dfs to find all the vertices that are connected to that one .PERIOD they are going to be part of the same component .PERIOD so we used the marking to help control the dfs but also to control the connective components that the vertices that already have been processed and known to be in a given connective component .PERIOD so let's look at a demo to understand how this algorithm works .PERIOD so again ,COMMA we're going to use depth for search and there ,COMMA summary of depth for search ,COMMA divisative vertex ,COMMA we mark it as visitive and then recursively visit all the unmarked vertices that are adjacent .PERIOD so in this case so we'll start we're going to visit all the vertices in the graph in order to identify the connected component .PERIOD so we'll start by visiting zero .PERIOD to visit zero ,COMMA we have to check six ,COMMA two ,COMMA one ,COMMA and five so we start by checking six .PERIOD we mark it as visited .PERIOD so that's entry six in the ray and now we're going to keep this other vertex indexed array which is the id the connected component number .PERIOD so or we're saying by putting a zero and that entry is that six and zero are in the same connected component .PERIOD every vertex that we encounter during the depth per search from zero we're going to assign a value of zero .PERIOD okay so ,COMMA so what do we have to do to visit six .PERIOD we have to check zero and then we have to check four so and four is unmarked so we're going to recourse and visit four .PERIOD to visit four ,COMMA we have to check five ,COMMA five is unmarked .PERIOD so we recourse to visit five .PERIOD and to visit five we have to check three ,COMMA four ,COMMA and zero .PERIOD three is unmarked .PERIOD this is same depth per search that we did before .PERIOD but now we're just keeping track of the connective component number ,COMMA and we're assigning every vertex that we encounter with the same idea as zero .PERIOD okay so ,COMMA now ,COMMA we have to visit three .PERIOD to visit three we have to check five and four .PERIOD five was marked and nothing to do .PERIOD four was marked ,COMMA nothing to do .PERIOD so we're done with three .PERIOD done with three ,COMMA we can continue the depth per search from five .PERIOD we have to check four and zero .PERIOD four was marked .PERIOD zero was marked .PERIOD so we're done .PERIOD and now we could continue with the depth per search of four .PERIOD we have to check six -DASH  three .PERIOD six was marked .PERIOD three was marked and we're done .PERIOD and we can ,COMMA now six is done .PERIOD and now we can continue with zero and we have to check two .PERIOD check two it's not marked .PERIOD so we mark it and give it a connected component number of zero .PERIOD to visit two ,COMMA all we do is check zero which is marked ,COMMA so we're done .PERIOD and then we do the same thing with one ,COMMA unmarked .PERIOD so we visit it ,COMMA i guess assign it zero .PERIOD and then visit one .PERIOD and to do that ,COMMA we check zero ,COMMA which is marked .PERIOD so we're done with one .PERIOD and then ,COMMA to finish zero we have to check five .PERIOD and that's ,COMMA marked so we don't have to do anything .PERIOD and we're done with zero .PERIOD so ,COMMA now we're done with the first connected component .PERIOD but ,COMMA we're not done with the whole graph .PERIOD so what we want to do is ,COMMA go look for ,COMMA so that's a connected component ,COMMA corresponding to zero .PERIOD now we want ,COMMA what we want to do is go look for an unmarked vertex .PERIOD so ,COMMA we started at zero and we check one ,COMMA two ,COMMA three ,COMMA four ,COMMA five ,COMMA and six .PERIOD and they're all marked .PERIOD and so the next unmarked vertex that we find in the graph is seven .PERIOD so once we return from the depth first search for zero ,COMMA we increment ,COMMA counter .PERIOD which is our ,COMMA how many connected components have we seen .PERIOD and now ,COMMA we're going to assign that number to everything that's connected to seven on the depth -DASH first search on seven .PERIOD so what do we do to depth per research and sum we check eight .PERIOD 8s on the mark .PERIOD and so we go visit it .PERIOD so we assign it ,COMMA connect the component of number of one same as seven .PERIOD and mark it .PERIOD and then go ahead and recourse to visit eight .PERIOD we check seven which is marked .PERIOD so there is nothing to do .PERIOD we're done with eight .PERIOD and then we're done with seven .PERIOD so now we're done with all the vertices that were connected to seven .PERIOD we increment our counter of number of components to two ,COMMA and look for another vertex .PERIOD so now we check eight ,COMMA which we already know is marked ,COMMA connected to seven .PERIOD so now nine is unmarked so we're going to do a dfs from nine .PERIOD so everybody connected to nine is going to get assigned a connected component number of two .PERIOD so at nine ,COMMA we have to check eleven and that was unmarked .PERIOD so we visit it .PERIOD give it a two .PERIOD to visit eleven ,COMMA we have to check nine ,COMMA which is marked .PERIOD so nothing to do .PERIOD and twelve ,COMMA which is unmarked .PERIOD so we visit it and ,COMMA give it a number of two .PERIOD to visit twelve ,COMMA we have to check eleven ,COMMA which is marked and nine which is also marked .PERIOD and then we're done with twelve .PERIOD and then we're done with eleven .PERIOD and then ,COMMA to finish doing nine ,COMMA we have to check ten and twelve .PERIOD ten is unmarked .PERIOD so we mark it and give it a number of two .PERIOD to visit ten ,COMMA we check nine which is marked ,COMMA so we're done .PERIOD and then finally ,COMMA to finish ,COMMA the dfs .PERIOD we check ,COMMA twelve from nine ,COMMA and that's marked .PERIOD so we're done with nine .PERIOD and now we keep looking .PERIOD and we find that ,COMMA ten ,COMMA eleven ,COMMA twelve ,COMMA are all marked .PERIOD so we've completed the .PERIOD computation .PERIOD and for every vertex we have a connected component number .PERIOD and for any given query we can test whether their in the same connected component simply by looking up that number and seeing if it's equal .PERIOD that's a demo of connected components computation .PERIOD okay ,COMMA so here's the code for finding connected components with dfs .PERIOD which is ,COMMA another straightforward dfs implementation .PERIOD just like the other one .PERIOD and it just keeps ,COMMA slightly ,COMMA different ,COMMA data structure .PERIOD so ,COMMA the we keep the marked data structure ,COMMA which is the vertices that we visited .PERIOD and then we keep this vertex index array id which gives the identifier ,COMMA the component containing v ,COMMA i think we call it on the demo .PERIOD and then a count of the number of components that we've seen .PERIOD so the constructor creates ,COMMA the ,COMMA marked array and it creates this idea array .PERIOD but now the constructor does more work than a single call on dfs .PERIOD what it does is it goes through ,COMMA this is the constructor .PERIOD goes through every vertex in the array in the graph .PERIOD and if it's not marked ,COMMA it does the dfs .PERIOD and that dfs will mark a lot of other vertices .PERIOD but when it's done that's all of those are going to get assigned a value of count .PERIOD and we're going to increment count ,COMMA then go and look for another unmarked vertex .PERIOD anything that wasn't marked by that first dfx ,COMMA dfs ,COMMA we'll do a dfs from that one ,COMMA and mark all its vertices with the next value for the id .PERIOD so now let's look at the implementation of dfs .PERIOD it's recursive array just like the one that we did .PERIOD for ,COMMA for path finding .PERIOD except all that we do ,COMMA when we mark a vertex .PERIOD we also simply set its id to the current component name .PERIOD so all the vertices that are discovered in the same call of dfs have the same id .PERIOD and to visit a vertex you go through all its adjacent vertices .PERIOD and any that are not marked you give a recursive dfs call .PERIOD again ,COMMA this code is amazingly compact and elegant .PERIOD when we're going through the demo step by step maybe you ,COMMA you can see that the underlying computation is actually kind of complex .PERIOD but ,COMMA but ,COMMA recursion and the graph -DASH processing api that we set up provides a compact and easy to understand implementation .PERIOD so that's using dfs to find connector components and then to return the idea of a given vertex ,COMMA just look at up in the array and to return then our components just you can count and then you can build up the needed connectivity api from those .PERIOD so that's depth first search to find connected components .PERIOD i will just talk briefly about two applications from scientific applications .PERIOD so here's an application of sexually transmitted diseases at a high school .PERIOD and ,COMMA simply the vertices are people ,COMMA blue are men and pink are women .PERIOD and you i have an edge between if there was a contact .PERIOD and so it's obvious that you're going to be interested in connective components of this graph .PERIOD to be able to properly study sexually transmitted diseases .PERIOD these individuals had no contact with these .PERIOD then ,COMMA the ,COMMA whichever one has the disease ,COMMA maybe it won't spread .PERIOD or if you add a new edge ,COMMA then maybe you have a problem .PERIOD that's just one example of studying the spread of disease .PERIOD here's another example that we use ,COMMA for ,COMMA for that's similar to the flood fill example .PERIOD and this is processing data from a scientific experiment .PERIOD and in ,COMMA in this case this image is comes from a photograph .PERIOD and the white things are particles that are moving .PERIOD and all we get is a image where it's a grey scale image .PERIOD and so ,COMMA what we'll do to do this processing is ,COMMA we want to identify the movement of these particles over time .PERIOD and the way we do it is build a grid graph ,COMMA like the one for the flood fill application and do an edge connecting two vertices .PERIOD if they're different ,COMMA he said their gray scale values is greater than less than some threshold .PERIOD and so then if you do that ,COMMA and then find the connective components ,COMMA then you can identify blobs which correspond to real particles in this simulation .PERIOD and they do that every frame in a movie ,COMMA then you can track moving particles over time .PERIOD so these are maybe fairly high resolution images .PERIOD these are graphs with lots and lots of edges ,COMMA and you need to be able to do this computation quickly in order to do this scientific experiment .PERIOD and we'd use this as an example .PERIOD example in our first year programming course it is based on computing connected components using depth -DASH first search .PERIOD so that's our third example of a graph processing algorithm .PERIOD 
alright .PERIOD now that we've seen efficient implementations of algorithms that can solve the unifying problem for huge problem instances let's look to see how that might be applied .PERIOD there's a huge number of applications of union -DASH find .PERIOD we talked about dynamic connectivity in networks there's many other examples in our computational infrastructure .PERIOD down at the bottom is one of those important one is in image processing for understanding how to label areas in images .PERIOD we'll see later kruskal's minimum spanning tree algorithm ,COMMA which is a graph processing algorithm which uses union -DASH find as a subroutine .PERIOD there's algorithms in physics for understanding physical phenomenon that we'll look at an example and many others on this list .PERIOD so ,COMMA the one we're going to talk about now is called percolation .PERIOD that's a model for many physical systems i'll give an abstract model and then just talk briefly about how it applies to physical systems .PERIOD so let's think of an n by n grid of squares that we call sites .PERIOD and we'll say that each site is open .PERIOD that's white in the diagram with probably p or blocked ,COMMA that's black of the diagram with probability one  -DASH  p and we define a system to ,COMMA we say that a system is percolated if the top and the bottom are connected by open sites .PERIOD so the system at the left ,COMMA you can find a way to get from the top to the bottom through white squares ,COMMA but the system to the right does not percolate ,COMMA there's no way to get from the top to the bottom through white squares .PERIOD so ,COMMA that's a model for many systems .PERIOD you can think of for electricity .PERIOD you could think of a vacant site as being a conductor and ,COMMA and a block site as being insulated .PERIOD and so if there's a conductor from top to bottom then the thing conducts electricity .PERIOD or ,COMMA you could think of it as ,COMMA as water flowing through a porous substance of some kind .PERIOD where a vacant side is just empty and a block side has got some material ,COMMA and either the water flows through from top to bottom ,COMMA or not .PERIOD or you could think of a social network where it's people connected and either there's a c onnection between two people or not and these are a way not to get from one group of people to another communicating through that social network .PERIOD that's just a few examples of the percolation model .PERIOD so if we ,COMMA we are talking abouta randomized model where the sites are vacant with the given probability .PERIOD and so it's pretty clear that if it's .PERIOD probability that a site is vacant is low as on the left ,COMMA two examples on the left in this diagram ,COMMA it's not going to percolate .PERIOD there's not enough open site for there to be a connection from the top to the bottom .PERIOD if the probability is high and there is a lot of open sides ,COMMA it definitely is going to percolate .PERIOD there would be lots of ways to get from the top to the bottom .PERIOD but in the middle ,COMMA when it's medium ,COMMA it's questionable whether it percolates or not .PERIOD so the scientific question ,COMMA or the ,COMMA mathematical question from this model is ,COMMA how do we know ,COMMA whether it's going to percolate or not ?QUESTIONMARK in this problem and in many similar problems ,COMMA there's what's called a phase transition .PERIOD which says that ,COMMA you know ,COMMA when it's low ,COMMA it's not going to percolate .PERIOD when it's high ,COMMA it is going to percolate .PERIOD and actually ,COMMA the threshold between when it percolates and when it doesn't percolate is very sharp .PERIOD and actually there is a value as n gets large that if you're less than that value it almost certainly will not percolate ,COMMA if you're greater it almost certainly will .PERIOD the question is what is that value .PERIOD this is an example of a mathematical model where the problem is ,COMMA is very well articulated .PERIOD what's that threshold value but ,COMMA nobody knows the solution to that mathematical problem .PERIOD the only solution we have comes from a computational model ,COMMA where we run simulations to try and determine the value of that probability .PERIOD and those simulations are only enable by fast union find algorithms ,COMMA that's our motivating example for why we might need fast union find algorithms ,COMMA so let's look at that .PERIOD so what we're going to run is called a so called monte carlo simulation .PERIOD where we initialize the whole grid to be block ed all black and then we randomly fill in open sites .PERIOD and we keep going .PERIOD and every time we add an open site ,COMMA we check to see if it makes the system percolate .PERIOD and we keep going until we get to a point where the system percolates .PERIOD and we can show that the vacancy percentage at the time that it percolates is an estimate of this threshold value .PERIOD so what we want to do is run this experiment millions of times ,COMMA which we can do in a computer ,COMMA as long as we can ,COMMA efficiently do the calculation of does it percolate or not .PERIOD that's a monte carlo simulation ,COMMA a computational problem that gives us a solution to this ,COMMA scientifc problem where ,COMMA mathematical problems nobody knows how to solve yet .PERIOD so ,COMMA let's ,COMMA look in a little bit more detail of how we're going to use our dynam -DASH  ,COMMA dynamic connectivity model to do this .PERIOD so ,COMMA it's clear that ,COMMA we'll create an object corresponding to each site .PERIOD and we'll give'em a name ,COMMA from zero to n^2 -DASH 1 as indicated here .PERIOD and then we'll connect them together .PERIOD if they're connected by open sites .PERIOD so the percolation model on the left corresponds to the ,COMMA connection model on the right ,COMMA according to what we've been doing .PERIOD now ,COMMA you might say ,COMMA well ,COMMA what we want to do is ,COMMA connect ,COMMA check whether any site in the bottom row is connected to any site in the top row ,COMMA and use union find for that .PERIOD problem with that is ,COMMA that would be a brute force algorithm .PERIOD would be quadratic ,COMMA right on the face of it .PERIOD because it would have n^2 ,COMMA calls to find ,COMMA to check whether they're connected .PERIOD for each site on the top ,COMMA i'd check each site on the bottom .PERIOD much too slow .PERIOD instead ,COMMA what we do is create a virtual site on the top and on the bottom .PERIOD and then ,COMMA when we want to know whether this system percolates ,COMMA we just check whether the virtual top site is connected to the virtual bottom site .PERIOD so how do we model opening a new site ?QUESTIONMARK well to open a site we just connect it to all it's adjacent open sites .PERIOD so that's a few calls to union but that's easy to implement .PERIOD and then with that ,COMMA simple ,COMMA relationship we can use the exactly the code that we developed to go ahead and run a simulation for this connectivity problem .PERIOD and that's where we get the result that ,COMMA by running enough simulations for a big -DASH enough n ,COMMA that this ,COMMA percolation threshold is about  .PERIOD592746 .PERIOD with this fast algorithm we can get an accurate answer to the scientific question .PERIOD if we use a slow union -DASH find algorithm we won't be able to run it for very big problems and we won't get a very accurate answer .PERIOD so in summary ,COMMA we took an important problem .PERIOD the ,COMMA the dynamic connectivity problem .PERIOD we modeled the problem to try to understand precisely what kinds of data structures and algorithms we'd need to solve it .PERIOD we saw a few easy algorithms for solving the problem ,COMMA and quickly saw that they were inadequate for addressing huge problems .PERIOD but then we saw how to improve them to get efficient algorithms .PERIOD and then left us with ,COMMA applications that ,COMMA could not be solved without these efficient algorithms .PERIOD all of this involves the scientific method .PERIOD for algorithm design where we try to develop mathematical models that help us understand the properties of the algorithms that we're developing .PERIOD and then we test those models through experimentation enabling us to improve algorithms iterating ,COMMA developing better algorithms and more refined models until we get what we need to solve the practical problems that we have of interest .PERIOD that's going to be the overall architecture for studying algorithms that we're going to use throughout the course .PERIOD 
okay .PERIOD now that we ,COMMA that we've discussed breadth -DASH first search and depth -DASH first search in connected components three .PERIOD very useful graph processing algorithm for all sorts of real applications .PERIOD now we're gonna go back to the idea of the different problems that might arise when doing graph processing ,COMMA and what are ,COMMA what are our intuition i -DASH  ,COMMA with this experience ?QUESTIONMARK and what types of problems are difficult ,COMMA and what types of problems are easy ?QUESTIONMARK it's not that i have any real answers to that but we wanna keep coming back to this issue ,COMMA so that we can appreciate a great algorithm when we see it .PERIOD so ,COMMA here's a challenger or an example of a challenge .PERIOD so ,COMMA here's a problem that comes up in plenty of applications .PERIOD so you want to know if a given graph is bipartite .PERIOD so what bipartite means is you can divide the edges into two subsets ,COMMA divide the vertices into two subsets with the property that every edge connects a vertex in one subset to a vertex in another .PERIOD so in this case ,COMMA we can assign zero ,COMMA three ,COMMA and four to be red vertices .PERIOD and if we do that ,COMMA then every edge connects a red to a white vertex .PERIOD that's a bipartite graph and we saw an example of bipartite graph the kevin bacon graph .PERIOD we had movies and performers ,COMMA two different types of vertices ,COMMA and every edge went from a movie to a performer .PERIOD and in general and other applications ,COMMA so we want to know is a graph bipartite .PERIOD so by graph processing challenge ,COMMA i mean is how difficult is this problem ?QUESTIONMARK and so what do you think ,COMMA based on our experience ?QUESTIONMARK is this a problem that any programmer could do ?QUESTIONMARK or maybe you need to be a typical diligent student in this course ,COMMA or maybe it's difficult enough that you ought to pay somebody to do it .PERIOD or ,COMMA actually maybe it's even an expert couldn't do it ,COMMA and we'll talk about the precise meaning of that later on .PERIOD or maybe we don't even know how difficult it is ,COMMA or maybe we can show that it's impossible to solve this problem .PERIOD these are pretty broad categories ,COMMA and you'd like to think that we could categorize problems in these kinds of categories .PERIOD so what about biparting ?QUESTIONMARK we'll do this for a bunch of problems ,COMMA but what about bipartitenes ?QUESTIONMARK .PERIOD well the answer for that one is that you can use dfs to get this done .PERIOD i wouldn't think that any programmmer can do it .PERIOD ask a friend .PERIOD but with dfs ,COMMA you can see in the book ,COMMA a pretty simple dfs based solution ,COMMA that to this problem .PERIOD that'll tell you whether a graph is bipartite ,COMMA by labeling vertices in such a way .PERIOD if it is bipartite ,COMMA that ,COMMA all the edges have the property to go from one set ,COMMA one vertex to another .PERIOD so definitely a good exercise after this lecture is to try to write a program that test whether a graph is bipartites or not .PERIOD okay ,COMMA let's ,COMMA oh ,COMMA here's another application of this by the way .PERIOD that dating graph for the sexual transmitted diseases so there's males and females ,COMMA is that one gonna be bipartite ?QUESTIONMARK i think maybe this one is but ,COMMA nowadays maybe not in general .PERIOD okay ,COMMA what about this one ,COMMA does a graph contain a cycle or not ?QUESTIONMARK so in this case ,COMMA there's a cycle ,COMMA zero to five to four to six back to zero ,COMMA and this other cycle's two ,COMMA zero ,COMMA one ,COMMA three ,COMMA two there are two ,COMMA four ,COMMA six those are all cycles .PERIOD so how hard is it to find a cycle in a graph in these categorizations well that one ,COMMA it's very simple .PERIOD this one ,COMMA maybe any programmer could do .PERIOD maybe .PERIOD you have to have the graph representation ,COMMA but you have to use dfs .PERIOD well ,COMMA you could figure out a way to do it without ,COMMA probably ,COMMA but anyway it's really simple with dfs .PERIOD you ,COMMA you don't even need to hire an expert for finding a cycle .PERIOD alright here's a classic graph processing problem that dates back to the eighteenth century .PERIOD so it's this town in konigsberg in prussia at the time where there's an island ,COMMA and the river kinda comes in and branches around the island and then goes out in two branches .PERIOD and there's a bunch of bridges ,COMMA five bridges onto the island ,COMMA two from the banks and one across ,COMMA to the this third peninsula and then there's two bridges crossing that way ,COMMA so a total of seven bridges one ,COMMA two ,COMMA three ,COMMA four ,COMMA five ,COMMA six ,COMMA seven .PERIOD and euler who's a famous mathematician would go out on sunday stroll in this place and came up with the idea .PERIOD you know could anyone find a way to go on a sunday stroll and cross each one of these bridges exactly once .PERIOD so that's ,COMMA often talked of as ,COMMA the ,COMMA original graph processing problem .PERIOD so ,COMMA in terms of graphs ,COMMA it's is there a cycle that uses every edge exactly once .PERIOD given a graph ,COMMA is there a cycle that uses every edge exactly once ?QUESTIONMARK a and actually ,COMMA a euler ,COMMA proved ,COMMA a let's say first theorem in graph theory ,COMMA a if its connected ,COMMA and all the vertices have even degree ,COMMA you can always do it .PERIOD in this case you can't because there's a vertex with odd degree .PERIOD so that's ,COMMA that's the answer to the existence ,COMMA is there a cycle .PERIOD but suppose you wanted to find the cycle .PERIOD so you can go ahead and check the degree of every vertex .PERIOD we looked at easy code for that to know that there exists a cycle but how about finding one that uses every edge exactly once .PERIOD so in this case ,COMMA here's the cycle that uses every edge exactly once .PERIOD and this graph every vertex has even degree ,COMMA and if you go zero ,COMMA one ,COMMA two ,COMMA three ,COMMA four ,COMMA two ,COMMA zero ,COMMA six ,COMMA four ,COMMA five ,COMMA zero you get to every edge exactly once .PERIOD that's an eulerian cycle .PERIOD so how about that one ?QUESTIONMARK is that any programer a or do you have to hire an expert ,COMMA or is it impossible ?QUESTIONMARK well this one we have it listed as a typical ,COMMA diligent algorithm student can do it .PERIOD but it's a ,COMMA it's a ,COMMA a bit of a challenge .PERIOD it's a ,COMMA an interesting program and again once you get through the bipartite graph on you can think about this one .PERIOD a it makes some sense what the algorithm does ,COMMA but it might take you a few tries to get the code debugged ,COMMA let's say then you'll find code for it ,COMMA it looks like .PERIOD alright .PERIOD so that's a eulerian cycle what about if you want to visit every vertex exactly once ?QUESTIONMARK so ,COMMA you don't care about going over all the edges ,COMMA you just want to get to all the places .PERIOD that's called the ,COMMA in this case there is a way .PERIOD for this graph zero ,COMMA five ,COMMA three ,COMMA four ,COMMA six ,COMMA two ,COMMA one ,COMMA zero .PERIOD so that's a way to get to every vertex exactly once .PERIOD this is sometimes called the traveling salesperson problem on graphs .PERIOD if the sales ,COMMA traveling salesperson has to get to every city and wants to just go there once without retracing steps .PERIOD so how about that one ?QUESTIONMARK the ,COMMA every edge is more to visit ,COMMA it might seem more challenging .PERIOD and ,COMMA actually ,COMMA maybe if you have any experience with this ,COMMA you realize that this one is intractable .PERIOD that's called the hamiltonian cycle problem ,COMMA and it's a classical np -DASH complete problem .PERIOD we'll be talking about np -DASH complete problems at the end of the course ,COMMA but basically the idea is that nobody knows an efficient solution to this problem for large graphs .PERIOD and it's a frustrating situation that we'll talk about .PERIOD but ,COMMA you definitely not gonna ,COMMA solve it by just being a diligent algorithm student a and not even hiring an expert will get it solved ,COMMA no matter how much the expert charges .PERIOD so the intuition on finding a cycle that visits every edge once .PERIOD yeah ,COMMA you could do it .PERIOD find a cycle that visits every vertex once ,COMMA probably not .PERIOD that's the kind of challenge that we face when addressing applications of graph processing .PERIOD here's another example .PERIOD problem is ,COMMA given two graphs you want to know are they identical except for the way that we need the vertex .PERIOD so here's an example of ,COMMA a these two graphs don't look all that identical ,COMMA at all .PERIOD but if you ,COMMA take zero here and rename it four and one and rename it three and like that ,COMMA then sorry zero here and name it four and one and rename it three and like that .PERIOD then you'll see that they are the same graph .PERIOD they represent the same connections .PERIOD and in so many applications where ,COMMA maybe the vertex names are ,COMMA are a bit arbitrary or you just wanna know .PERIOD really the interest is in the structure of the connections ,COMMA you might wanna know if just the way that i name the vertex makes the graph different ?QUESTIONMARK or if i have two classes that have two different kinds of interactions ,COMMA is it the same interactions that's independent of the people or scientific experiment studying a property of the universe or whatever ,COMMA you might wanna know ,COMMA is that connection structure the same or not ?QUESTIONMARK that's called the graph isomorphism problem .PERIOD how difficult you think that one is ?QUESTIONMARK so ,COMMA you know ,COMMA you could ,COMMA there you can try all possible ways of renaming the vertices ,COMMA but there's really a lot of ways ,COMMA in factorial ways .PERIOD way too many to try for a huge graph .PERIOD is there efficient way to do it ,COMMA or is it intractable like the hamiltonian path problem .PERIOD where it's in this category that nobody knows an efficient algorithm for but there could be one .PERIOD actually for graph isomorphism ,COMMA that's one that's stumped mathematicians and computer scientists for many years .PERIOD nobody knows even how to classify this problem .PERIOD we don't know if it's easy or if it's in a class of problems that are ,COMMA we don't know how to solve but there could be a solution .PERIOD we can't show that it's impossible or guaranteed to be difficult .PERIOD nobody knows how to classify this problem .PERIOD again ,COMMA pointing out that ,COMMA even for a relatively simple problem to state .PERIOD the state of our knowledge and understanding the properties of algorithms to solve such problems ,COMMA is ,COMMA it's incomplete for sure .PERIOD so one last one ,COMMA here's a graph processing challenge .PERIOD so this graph ,COMMA when it's laid out it's got two edges that cross between ,COMMA between three and four and zero and five .PERIOD and in general if you have a graph that you've got ,COMMA so say the social networking graph of a small class ,COMMA you want to study that graph and look at it ,COMMA you want to draw it on the plane and maybe you don't want ,COMMA you want to do it without having edges crossed .PERIOD so in this case there is a way to place the vertices in the plain so that when you draw the edges no two of them cross .PERIOD so ,COMMA how difficult is that problem ,COMMA even is it possible to do or not .PERIOD so ,COMMA that's a classic problem in graph -DASH processing that ,COMMA came up ,COMMA from ,COMMA the first time that people were ever sending graphs in computers .PERIOD and the answer to this one is also ,COMMA interesting to contemplate .PERIOD there's a linear time algorithm known for this based on dfs .PERIOD so that means the running times ,COMMA you could run it on huge graphs .PERIOD you could know ,COMMA whether or not you could lay it out in the plane .PERIOD it was discovered ,COMMA by tarjan in the 1970's .PERIOD and you heard that name come up again ,COMMA in graph processing .PERIOD based on dfs ,COMMA but ,COMMA if you really wanna get this done ,COMMA you need to hire an expert ,COMMA 'cause that is quite a complex algorithm ,COMMA and probably ,COMMA beyond ,COMMA what a diligent algorithm student ,COMMA or a professor ,COMMA might accomplish .PERIOD so ,COMMA that's the kind of another point on this range of difficulty of graph processing problems .PERIOD so there's no question that graph processing is challenging .PERIOD and this introductory lecture gave us numerous useful graph processing algorithms .PERIOD but still leaves us with the feeling that there's plenty more to know and we'll cover some more in later lectures .PERIOD 
welcome back .PERIOD today we're going to do some math and some science .PERIOD not a lot ,COMMA but we need to have a scientific basis for understanding the performance of our algorithms to properly deploy them in practise .PERIOD so today we're going to talk ,COMMA about how to ,COMMA observe performance characteristics of algorithms .PERIOD we're going to look at how to make mathematical models and how to classify algorithms according to the order of growth of their running time .PERIOD we'll talk a bit about the theory of algorithms and also how to analyze memory usage .PERIOD so to put this all in perspective ,COMMA we're going to think about these issues from the point of view of different types of characters .PERIOD so the first one is the programmer who needs to solve a problem and get it working and get it deployed .PERIOD second one is the client who wants to use the whatever program did to get the job done .PERIOD third one is the theoretician ,COMMA that's somebody who really wants to understand what's going on .PERIOD and ,COMMA and the last one is kind of a team ,COMMA this basic blocking and tackling sometimes necessary to get ,COMMA you know ,COMMA all these things done .PERIOD so ,COMMA there's a little bit of each one of these in today's lecture .PERIOD and actually when you're a student you have to think that you might be playing any or all of these roles some day .PERIOD so ,COMMA it's pretty important to understand the different points of view .PERIOD so ,COMMA the key that we'll focus on is running time .PERIOD and actually the idea of understanding the running time of a computation goes way back even to babbage and probably before .PERIOD and here's a quote from babbage ,COMMA "as soon as an analytical engine exists ,COMMA it will necessarily guide the future course of the science .PERIOD whenever any result is sought by its aid ,COMMA the question will arise by what course of calculation can these results be arrived at by the machine in the shortest time" .PERIOD if you look at babbage's machine called the analytic engine ,COMMA it's got a crank on it .PERIOD and literally the concern that babbage had in knowing how long a computation would take is ,COMMA how m any times do we have to turn the crank .PERIOD it's ,COMMA it's not that different ,COMMA in today's world .PERIOD the crank may be something electronic that's happening a billion times a second .PERIOD but still ,COMMA we're looking for ,COMMA how many times does some discreet operation have to be performed in order to get a computation done .PERIOD so ,COMMA there are lot of reasons to analyse algorithms .PERIOD in the context of this course we are mainly interested in performance prediction .PERIOD and we also want to compare the performance of different algorithms for the same task ,COMMA and to be able to provide some guarantees on how well they perform .PERIOD along with this ,COMMA is understanding some theoretical basis for how algorithms perform .PERIOD but primarily ,COMMA the practical reason that we want to be analyzing algorithms and understanding them is to avoid performance bugs .PERIOD we want to have some confidence that our algorithms going to complete the job in the amount of time ,COMMA that ,COMMA that we think it will .PERIOD and it's very ,COMMA very frequent to see ,COMMA in today's computational infrastructure ,COMMA a situation where the client gets bad performance ,COMMA because the programmer did not understand the performance characteristics of the algorithm .PERIOD and today's lecture is about trying to avoid that .PERIOD now ,COMMA we're going to focus on performance and comparing algorithms in this course .PERIOD there's later courses in typical computer science curricula that have more information about the theoretical basis of algorithms and i'll mention a little bit about that later on .PERIOD but our focus is on being able to predict performance and comparing algorithms .PERIOD now there's a long list of success stories in designing algorithm with better performance in ,COMMA in enabling the solution of problems that would otherwise not be solved .PERIOD and i'll just give a couple of examples .PERIOD one of the first and most famous is the so called fft algorithm .PERIOD that's an algorithm for breaking down the wave form of n samples of a signal into periodic components .PERIOD and that's at the basis for dvds and jpegs and ,COMMA and many other appl ications .PERIOD there's an easy way to do it that takes time proportional to n^2 .PERIOD but the fft algorithm ,COMMA takes only n log n steps .PERIOD and the difference between n log n and n^2 is ,COMMA is the difference between being able to solve a large problem and not being able to solve it .PERIOD a lot of the digital technology ,COMMA digital media technology that we have today is enabled by that fast algorithm .PERIOD another example was actually developed by andrew appel ,COMMA who's now the chair of computer science here at princeton .PERIOD and it was developed when he was an undergraduate for his senior thesis .PERIOD it's a fast algorithm for the n body simulation problem .PERIOD the easy algorithm takes time proportional to n^2 ,COMMA but appel's algorithm was an n log n algorithm that again ,COMMA meant that scientists can do n body simulation for huge values of n .PERIOD and that enables new research .PERIOD s0 ,COMMA o the challenge is that we usually face is ,COMMA will my program be able to solve a large practical input ?QUESTIONMARK and ,COMMA and actually ,COMMA the working programmer is actually faced with that all the time .PERIOD why ,COMMA why is my program running so slowly ?QUESTIONMARK why does it run out of memory ?QUESTIONMARK and that's faced programmers for a really long time and the insight to address this .PERIOD deuter kanoof ,COMMA in the 1970s ,COMMA was that ,COMMA we really can use the scientific method to understand the performance of algorithms in operation .PERIOD maybe we're not unlocking new secrets of the universe but ,COMMA we can use the ,COMMA scientific method ,COMMA and treat the computer ,COMMA as something to be studied in that way and come to an understanding of how our program are going to perform .PERIOD and let's take a look at that in more detail .PERIOD so this just a quick summary of what we mean by the scientific method ,COMMA which has ,COMMA been successful for a couple of centuries now .PERIOD so ,COMMA what we're going to do is ,COMMA observe from some feature of the natural world .PERIOD in this case ,COMMA it's going to be the running time of our program on a computer .PERIOD then we're going to develop hypothesis some model that's consistent with the observations ,COMMA and we're going to hope that ,COMMA that hypothesis is good enough that it'll allow us to predict something .PERIOD usually predict a running time for larger problem size ,COMMA or on a different computer .PERIOD and then we'll verify the predictions by making more observations ,COMMA and validate until we're comfortable that our model hypothesis and observations all agree .PERIOD that's a way to get comfort that we understand the performance of our programs .PERIOD now ,COMMA the within the scientific method ,COMMA there's some basic principles and the ,COMMA the first is that if you're going to run experiments ,COMMA you should expect that somebody else should be able to run experiments and get the same result .PERIOD and also the hypotheses have to have a specific property that the experiment can show the hypothesis to be wrong .PERIOD so ,COMMA it has to be carefully crafted ,COMMA and we'll be sure to try to do that .PERIOD so ,COMMA and again the future of the natural world that we're studying is some particular computer that exists in the natural world .PERIOD it changes the algorithm from an abstraction to a ,COMMA some ,COMMA some kind of actual physical thing happening like electrons racing around inside the computer .PERIOD 
today ,COMMA we're ,COMMA we're going to look at the vector graphs ,COMMA which is another graph processing model that's very useful in many applications .PERIOD it's very similar to the undirected grpah model that we looked at last time ,COMMA but there are some really profound differences .PERIOD after introducing the concept and looking at the api ,COMMA we'll look at three important classic algorithms for processing directed graphs .PERIOD the intro ,COMMA introduction has to deal with just explaining the concept and seeing what it does to our graph processing problems like the ones that we talked about for undirected graphs last time .PERIOD so ,COMMA the idea isn't that the edges now have direction .PERIOD a directed graph or a digraph is a set of vertices that are connected pairwise by directed edges .PERIOD so ,COMMA it's list of pairs of vertices where the order of the pair matters .PERIOD so ,COMMA an edge we say an edge goes from one vertex to another one .PERIOD whereas ,COMMA in undirected graphs ,COMMA we just talked about connections .PERIOD when we're processing such graphs or travelling around them ,COMMA we have to follow edges in the given direction .PERIOD so ,COMMA for example ,COMMA if we talk about a path in the diagram there's ,COMMA it looks like there's a connection between two and zero ,COMMA but it only goes from two to zero .PERIOD if you want to go from zero to two ,COMMA you have to follow the edges in direction going from zero to five to four and then to two .PERIOD in the directed graph ,COMMA in this digraph you can see two directly from zero .PERIOD similarly ,COMMA a directed cycle follows the edges around the direction to get back to the original vertex .PERIOD also vertices have in -DASH degree and out -DASH degree in digraphs .PERIOD and the out -DASH degree ,COMMA obviously ,COMMA is the number of variables leaving the vertex and in the in -DASH degree is the number of variables coming into the vertex .PERIOD those are the basic definitions .PERIOD let's look at a couple of applications one obvious one is road networks where we put a vertex according to intersection in an edge for roads .PERIOD and we look at a situation where most ,COMMA where the roads are one way or can be one way .PERIOD so ,COMMA if you've driven in lower manhattan ,COMMA you're very familiar with this map ,COMMA which has lots of one -DASH way streets .PERIOD and it's not always clear how to get from one place to another .PERIOD you can have some two -DASH way streets that have edges in both directions .PERIOD but with digraphs ,COMMA we allow the abstraction of one -DASH way streets .PERIOD here's another more abstract example .PERIOD this is the political blogosphere with connections .PERIOD if ,COMMA if blogs have links to one another as you can see ,COMMA most of the links go from blue to blue or from red to red .PERIOD although there are some orange links that go from blue to red and a few purple ones that go from red to blue .PERIOD and this gives some insight to the in the political blogosphere at least in 2004 .PERIOD here's another one .PERIOD this is a study of the crash in 2008 ,COMMA and it was a graph that showed the structure of banks lending to one another .PERIOD an edge corresponds from an overnight loan and a vertex corresponds to the bank .PERIOD and from studying this diagram ,COMMA experts can see how the banks divided into groups and were therefore vulnerable in these groups and we'll look at a more detailed definitions of how these groups are defined a little later on .PERIOD this is just an example of the use of a digraph .PERIOD and it's a digraph ,COMMA the bank .PERIOD one bank lends money to another ,COMMA that's not the same as the banks being connected ,COMMA in some as in an undirected graph .PERIOD the direction really matters .PERIOD this is another one from logic where the vertices correspond to boolean variables and the edges correspond to implication .PERIOD and people use graphs like this to study in ,COMMA in logical verification ,COMMA and also studying electric circuits .PERIOD electric circuits themselves can be diagraphs where circuit elements have input and output .PERIOD and so ,COMMA the edge of course takes the output of one element to the input of another .PERIOD trying to understand the behavior of such a circuit involves processing a digraph .PERIOD here's another abstraction so -DASH called wordnet graph .PERIOD where vertices correspond in what is called synsets and edges correspond to hypernym relationships where a ,COMMA a word is an instance of another one .PERIOD so ,COMMA there's a lot of different events like a miracle or human activity and so forth .PERIOD and graphs of this type are very useful in studying applications involving meanings ,COMMA meanings in human languages .PERIOD here's a famous one .PERIOD general mcchrystal said that once we understand this graph the war in afghanistan will be over .PERIOD so ,COMMA with all these types of applications and there's many ,COMMA many others just as with graph processing .PERIOD now ,COMMA the digraph as it ,COMMA as it is modeled distinct from graph processing is important .PERIOD there's many direct applications where we have connections between objects but the direction of the connection matters .PERIOD so ,COMMA what about digraph processing algorithms .PERIOD well ,COMMA we're going to look at many problems that are very similar to the ones that we looked at for undirected graphs .PERIOD but you can see that they are going to be a bit more complicated .PERIOD even a human has trouble looking at a diagraph trying to figure out a simple problem like ,COMMA is there a path from s to t in this ,COMMA in this diagraph .PERIOD seems like there's quite a few possibilities to consider to convince yourself whether or not there's a path .PERIOD and for the huge diagraphs examples that i looked at before obviously we're going to need a computer program .PERIOD and we're going to have a bit of a challenge figuring what's going on .PERIOD of course ,COMMA you might want to know the shortest directed path from s to t for example ,COMMA if you are driving around lower manhattan and certainly ,COMMA i want to have a solution to that problem .PERIOD then ,COMMA there's another problem called the topological sort problem which is a general model that's useful in all kinds of applications where were scheduling events that involve precedence constraints .PERIOD in the graph obstruction or the digraph obstruction ,COMMA it amounts to the problem of trying to draw the digraph so that all the edges point up .PERIOD that's called topological sorting .PERIOD and then ,COMMA connectivity is more complicated for digraphs than for undirected graphs .PERIOD there's the concept of strong connectivity ,COMMA which means for any given pair of vertices u and v ,COMMA you want to know is there going to be a directed path from u to v and another directed path from v to u .PERIOD that's a much more complicated problem than connectivity in undirected graphs .PERIOD and ,COMMA a generalization of ,COMMA of that or a query related to strong connectivities ,COMMA so -DASH called transitive closure .PERIOD and for that ,COMMA you just want to be able answer the query given vertices v and w as their path from w to v ,COMMA a transitive closure .PERIOD and actually ,COMMA you're familiar with the web is a gigantic directed graph .PERIOD if there's a link from page a to page b ,COMMA b ,COMMA that's a directed edge .PERIOD and digraph processing is used in famous page rank algorithm to determine the importance of a web page .PERIOD those are just a couple of examples of digraph processing problems that introduce the idea .PERIOD 
okay ,COMMA so the first step is to be able to make some observations about the running time of the programs .PERIOD and for analysis of algorithms that's easier than in a lot of scientific disciplines ,COMMA as we'll see .PERIOD for a running example we're going to use the so -DASH called 3 -DASH sum problem .PERIOD and it's an easy to state problem .PERIOD if you've got n distinct integers ,COMMA how many triple sum to exactly zero ?QUESTIONMARK for example in this file 8ints .PERIODtext .PERIOD text which has eight integers in it .PERIOD there's four triples that sum to zero .PERIOD 30  -DASH  40 ,COMMA ten .PERIOD 30  -DASH  twenty  -DASH  ten and so forth and so our goal is to write a program that can compute this quantity for any input file ,COMMA any set of n integers .PERIOD this is actually a ,COMMA an extremely important computation that's deeply related to many problems in computational geometry which is a branch of computer science that covers the algorithms and underlying science related to graphics and movies and geometric models of all sort .PERIOD so this is a actually an important practical problem .PERIOD but it's a simple one to write code for in a view you could write down this program without much effort .PERIOD it's a ,COMMA got a static method count that is going to go ahead and take a integer array as an argument .PERIOD and ,COMMA is that ,COMMA that's a number of integers ,COMMA that's the length of the array .PERIOD we will start with a variable count equals zero ,COMMA and then a triple for loop ,COMMA that checks each triple i j k ,COMMA we go i from one and j from i+1 to n ,COMMA and k from j+1 to n ,COMMA so that we get each triple just once .PERIOD and then if i+j ,COMMA ai + aj + ak = zero ,COMMA we increment the count .PERIOD alright .PERIOD and after that triple four loop ,COMMA we return the count .PERIOD and then the main method ,COMMA in this simple class just reads in ,COMMA all the integers ,COMMA and prints out the count .PERIOD so that's a brute force algorithm that is a fine method for solving the three sum problem ,COMMA now what we're interested in is how much time does this take as a function of' n ?QUESTIONMARK well ,COMMA one to time our program is to is just look at the watch .PERIOD if you have a stopwatch ,COMMA or look at the clock or your phone ,COMMA or whatever you might need you can just go ahead and time it if you want or we have ,COMMA java has this part of it's standard library ,COMMA a stopwatch class that will go ahead and compute a lapse time .PERIOD so ,COMMA in order ,COMMA anytime you run a program ,COMMA if it is setup to easily take input of different sizes ,COMMA a natural thing to do ,COMMA is just run it for bigger sizes .PERIOD so for eight ints this program takes not too much time ,COMMA for 1000 ints it takes half a second .PERIOD for 2 ,COMMA000 .PERIOD takes more time .PERIOD that's 3 .PERIOD7 seconds run it again ,COMMA still takes 3 .PERIOD7 seconds for 4 ,COMMA000 ,COMMA so each time we're doubling the size of the input and it's definitely taking more time each time .PERIOD and actually as we'll see if programmers who get in the habit of testing or any time on their program in this way can get so that you can actually pretty easily and quickly evaluate when it's going to finish .PERIOD in fact .PERIOD while you're waiting for it to finish you can often figure it out .PERIOD so that one took 30 seconds for 4k and definitely we could figure it out how long it's going to take for 8k before it finishes ,COMMA and you'll see how in just a second .PERIOD i'm not going to wait right now .PERIOD you can think about what you think .PERIOD okay so [cough] that's empirical analysis ,COMMA analysis .PERIOD run it for various input sizes and measure their running time .PERIOD now if this were some scientific problem where we were counting something that happen in the natural world .PERIOD the number of ants in an ant hill or whatever then we'd have only a few data points and we would try to understand whats was going on by doing a plot of or running time with quite interested in on the y axis and problem size with the x axis .PERIOD hit a curve like this and actually whats science usually do because of some many problems fall into out of this class is do the plot as a lg ,COMMA lg plot .PERIOD if you do it as a lg ,COMMA lg plot very often you'll get a straight line .PERIOD and the slope of the straight line is the key to what's going on .PERIOD in this case ,COMMA the slope of the straight line is three and so you can run what's called a regression to fit a late ,COMMA the straight line through the data points .PERIOD and then ,COMMA it's not difficult to show to do the math to show that if you get a straight line and the slope is b ,COMMA then your function is proportional to a ,COMMA n^b .PERIOD that's called the power law .PERIOD and that's true of many ,COMMA many scientific problems including most algorithms .PERIOD so here's a little bit of the math for that .PERIOD so the straight line means that since we did a lg ,COMMA lg plot with powers of two ,COMMA that lg(t(n) = b lg n + c .PERIOD and we have our empirical values of b and c and then if you raise both sides of that equation to two to that power then you get t(n) = a constant times n^b .PERIOD so right away just from observation we have a pretty good model for the running time for our program ,COMMA we can figure and do the math and figure out that it seems as though the running time is about ten^ -DASH 10 n^3 seconds .PERIOD we can use that hypothesis to go ahead and make predictions .PERIOD just plug in for different values of n and it says it will take us 400 seconds for 16 ,COMMA000 .PERIOD 400 seconds is plenty of time but now we can go ahead and invest and run that experiment and sure enough we're pretty close to that 408 seconds when we run it .PERIOD and now we can make a prediction for 32 ,COMMA000 or for or for whatever else we might be interested in .PERIOD the model helps us do predictions without investing the expense to run the experiments .PERIOD in fact ,COMMA in this situation if there is a power law ,COMMA and again in a very great majority of computer algorithm running times is going to be a power law .PERIOD what we can do is just double the size of the input each time the way we were and take the ratio of the running times for n and 2n .PERIOD and if you do that ,COMMA that ratio going to converge to a constant .PERIOD and in fact the log of the ratio is going to converge to that constant ,COMMA which is the exponent of n and the running time .PERIOD and you just need a little math to check that one ,COMMA but that's a very easy and natural way to go ahead and predict running times .PERIOD so that's what i said before is ,COMMA so we have this quick way to estimate b in the power law relationsh ip .PERIOD how do we estimate a ?QUESTIONMARK well we can just run it and solve for a .PERIOD so once we've decided that ,COMMA that exponent is three let's run it for some big n and we get pretty close model to the one we had from plotting things .PERIOD so it's almost identical hypothesis and we just got it by running the program double n each time .PERIOD okay so there is a lot of effects in trying to understand the running time of a program on ,COMMA on your machine .PERIOD [cough] so .PERIOD key effects are independent of what computer it is .PERIOD and that's the algorithm you're using and what's the data .PERIOD and that's going to really determine the exponent in the power law .PERIOD and then there's a lot of ,COMMA system dependent effects .PERIOD what kind of hardware do you have ?QUESTIONMARK do you have a fast computer or a slow one ?QUESTIONMARK what kind of software ?QUESTIONMARK what's going on in your computer ?QUESTIONMARK all of those things really determine the constant a in the power law .PERIOD so .PERIOD in modern systems it is so much going on in the hardware and software ,COMMA it's sometimes difficult to get really precise measurements .PERIOD but on the other hand we don't have to sacrifice animals ,COMMA or fly to another planet the way they do in other sciences ,COMMA we can just run a huge number of experiments and usually take care of understanding these kind of effects .PERIOD 
 .PERIOD to develop .PERIOD digraph processing algorithms ,COMMA we're going to need an a .PERIODp .PERIODi .PERIOD we'll use the same design pattern that we use for undirected graphs ,COMMA where we develop an a .PERIODp .PERIODi .PERIOD for building graphs that can serve as a client for all our graph processing algorithms .PERIOD and it's very similar ,COMMA it's not close to identical to the undirected graph a .PERIODp .PERIODi .PERIOD ,COMMA except the class is named digraph .PERIOD and other than that .PERIOD it's got add edge ,COMMA where we add a directed edge .PERIOD but now ,COMMA we're saying it's an edge from v to w .PERIOD and then an iterator .PERIOD that gives the vertices that point from the given vertex .PERIOD so we're getting ,COMMA those were the edges we can travel along to get around the graph .PERIOD we have v and e .PERIOD and another new method that is not relevant for undirected graphs is the reverse .PERIOD so that's ,COMMA a ,COMMA a method that returns a di -DASH graph where all the edges are reversed .PERIOD and we'll see that's an important method to have for one of the algorithms that we'll talk about today .PERIOD so here's a typical client very similar to the one that we did for undirected graphs ,COMMA where we read the diagram from input stream ,COMMA so that's pairs of edges ,COMMA pairs of vertices where ,COMMA that represent an edge from or one vert ,COMMA first vertex to the second one and then for every vertex we'd print out .PERIOD for every edge that you can get to from that verte -DASH  ,COMMA for every other vertex you get to from that vertex ,COMMA we put out a ,COMMA ,COMMA print out a little graphical representation of the edge v2w ,COMMA where the little arrow we use a minus sign and a greater than .PERIOD so for example with the input file tinydg .PERIODtxt for directograph ,COMMA the one's got thirteen vertices ,COMMA 22 edges .PERIOD it's got an edge from four to two ,COMMA from to two to three ,COMMA three to two and so forth and if we execute this sample client ,COMMA we get the edges printed out .PERIOD it builds the graph and then prints out the edges .PERIOD by the way ,COMMA the order in which they come out is in order of vertex and order in which the judge comes out depends on the representation just these four graphs .PERIOD we'll skip through the possibilities of keeping a list of edges ,COMMA or using a matrix for ,COMMA diagr aphs ,COMMA cause again .PERIOD impractical problems ,COMMA the graphs are huge and sparse ,COMMA so the average vertex degree in -DASH degree and out -DASH degree is low .PERIOD we can't afford ,COMMA to ,COMMA keep space proportional to the number of possible vertices ,COMMA that a vertex can connect to for each vertex .PERIOD so ,COMMA it's very similar to or exactly the same ,COMMA really ,COMMA to the one that we use for undirected graphs .PERIOD we keep a vertex indexed array .PERIOD where ,COMMA for each vertex ,COMMA we can keep a bag of all the vertices that you can get to from that vertex .PERIOD so vertex six ,COMMA has out degree four .PERIOD and there's four vertices on its list .PERIOD nine ,COMMA four ,COMMA eight ,COMMA and zero .PERIOD and when we process the graph ,COMMA we're gonna visit those vertices ,COMMA in that order .PERIOD which is just determined by the order in which they appeared in the input .PERIOD so here's the implementation that we used for un -DASH directed graphs last time .PERIOD and you'll see that the only difference for die graphs is we change graph to die graph and we only have one representation of each edge ,COMMA v goes to w .PERIOD for undirected graphs we had w goes to v as well ,COMMA otherwise the code's exactly the same ,COMMA we have an iterator for the vertices adjacent to v but that .PERIOD it's the difference between directed graphs and undirected graphs .PERIOD so again the reason we do that is that we can get basic graph processing processed in a reasonable amount of time .PERIOD where every time we deal with a vertex we can get to its neighbors are the places you can get to from that vertex in time proportional to the number of vertices .PERIOD you simply can't afford to do that with other representations .PERIOD so that's the digraph api .PERIOD which is virtually identical to the graph api .PERIOD 
observing what's happening as we did in the last section it gives us a ,COMMA a way to predict performance but it really doesn't help us understand what the algorithm's doing .PERIOD so next ,COMMA we're going to look at mathematical model .PERIOD a way to get a better concept of what's really happening .PERIOD again ,COMMA this concept was really developed and popularized by don knuth starting in the late 60s .PERIOD at that time ,COMMA computer systems were really becoming complicated for the first time .PERIOD and computer scientists were concerned about whether we really were going to be able to understand what's going on .PERIOD and knuth was very direct in saying that this is something that we certainly can do .PERIOD we can calculate the total running time of a program by identifying all the basic operations ,COMMA figuring out the cost ,COMMA figuring out the frequency of execution and summing up the cost times frequency for all the operations .PERIOD you have to analyze the program to determine what set of operations and the cost depends on the machine and the computer in the system is what we talked about before .PERIOD the frequency leads us to mathematics because it depends on the algorithm and input data .PERIOD knuth has written a series of books that give very detailed and all exact analyses within a particular computer model for a wide range of algorithms .PERIOD so ,COMMA from knuth ,COMMA we know that in principle ,COMMA we can get accurate mathematical models for the performance of algorithms or programs and operation .PERIOD all right .PERIOD so what ,COMMA what does this process look like ?QUESTIONMARK well you can ,COMMA if you want run experiments .PERIOD in ,COMMA in ancient times ,COMMA we would actually look at the computer manual and every computer came with a manual that said precisely how long each instruction would take .PERIOD but nowadays ,COMMA it's a little more complicated .PERIOD so ,COMMA we run experiments and ,COMMA and you can go ahead and do a billion ads and figure out that maybe on your computer ,COMMA an ad takes 2 .PERIOD1 nano seconds .PERIOD or you can do more complicated function s like computer sign or an arc tangent although that's already getting close to the analysis of algorithms .PERIOD so ,COMMA there's some way to determine the costs of the basic operations .PERIOD and so ,COMMA we'll just in most ,COMMA most of the cases we'll just postulate that it's some constant and you can figure out what the constant is .PERIOD although when we're working with a collection of objects ,COMMA of anobjects there are some things that takes time proportional to n like if you're going to allocate a array of size n it takes time proportional to n because in java the default is that all the elements in the array initialize to zero .PERIOD in other operations it depends on the system implementation and an important one is string concatenation .PERIOD if you concatenate two strings the running time is proportional to the length of the string .PERIOD in many novices programming in java ,COMMA make a mistake of assuming that's a constant time operation when its not .PERIOD alright ,COMMA so that's the cost of each operation .PERIOD more interesting is the frequency of operation ,COMMA of execution of the operations .PERIOD so this is a ,COMMA a ,COMMA it's a very simple variant of the three sum problem .PERIOD that's the one sum problem .PERIOD that's how many numbers are actually equal to zero ?QUESTIONMARK how many single numbers add up to zero ?QUESTIONMARK so ,COMMA that one ,COMMA it's just one four loop ,COMMA and we go through ,COMMA and we tested the number zero and increment or count .PERIOD and by analyzing that code you can see that i and count have to be declared and then they have to be assigned to zero .PERIOD there's compares of i against n and there's n + one of them .PERIOD there's compares of a(i) against zero ,COMMA there's n of those ,COMMA n array axises and the number incremented is number of times there's an increment is variable .PERIOD i has incremented n times ,COMMA but count could be incremented any number from zero to n times .PERIOD and so that frequency is dependent on the input data .PERIOD or we might need a model for describing that or maybe there's other operations that are more e xpensive and we won't need to worry about that .PERIOD so ,COMMA let's look at the next more complicated problem is what about the frequency of execution of instructions in this program which is the two sum problem ,COMMA how many pairs of integers sum to zero ?QUESTIONMARK well ,COMMA in this case ,COMMA you have to do a little bit of math to see that when we when i goes from zero to n ,COMMA and j goes from i + a to n the number of compares that we do work ,COMMA plus array axises that we do is two for each time the if statement is executed for ai and aj and that time is ,COMMA thing is executed n  -DASH  one times the first time through the loop and n  -DASH two^2 and so forth .PERIOD it's the sum of the integers from zero up to n  -DASH  one which is a simple discrete sum one -DASH half n ,COMMA (n  -DASH  one) and since ,COMMA and since we're doing it twice the number of array axises is n ,COMMA n  -DASH  one .PERIOD so ,COMMA we can go ahead and get these actual exact counts .PERIOD but already ,COMMA it's getting a little bit tedious to do that .PERIOD and as far back as turing who also knew that and as well as babbage did ,COMMA that we want to have a measure of the amount of work involved in the process .PERIOD he recognized that you didn't want to necessarily go through and do it in full detail .PERIOD it's still helpful to have a crude estimate .PERIOD so ,COMMA you could count up the number of times that every operation is applied ,COMMA give it weights and ,COMMA and count the [inaudible] and so forth .PERIOD but maybe we should just count the ones that are most expensive that's what turing said in 1947 ,COMMA and realistically that's what we do nowadays .PERIOD so rather than going in and counting every little detail ,COMMA we take some basic operation that's maybe the most expensive and or and or the one that's executed the most often .PERIOD the one that cost and frequency is the highest and use that as a proxy for running time .PERIOD essentially ,COMMA making the hypothesis that the running time is ,COMMA is going to grow like a constant times [inaudible] ,COMMA so ,COMMA in this case ,COMMA were going to pick array axises .PERIOD so ,COMMA that's the first simplification .PERIOD and the second simplification is that we're going to ignore low order terms in the formulas that we derive .PERIOD and there's an easy way to do that .PERIOD it's called the tilde notation and ,COMMA and the idea is when n is large in a formula like this the n^3 term is much ,COMMA much higher than the n term or sixteen .PERIOD in fact ,COMMA so much so that we wouldn't even hardly notice these low order terms .PERIOD so ,COMMA all of these formulas are tilde one -DASH sixth n^3 and that's a fine representative or approximate ,COMMA approximation to these quantities .PERIOD and it greatly simplifies their calculations to for a ,COMMA through a way to lower ,COMMA lower to terms like this .PERIOD so ,COMMA by focusing on one operation and  ,COMMA throwing away the tildes ,COMMA the lower the terms and this is the technical definition of tilde .PERIOD it's just ,COMMA f(n) tilde g (n) means the limit as fn or gn equals one ,COMMA and you can check that that's going to hold in these kinds of situations .PERIOD so ,COMMA that greatly simplifies the frequency counts .PERIOD and if we're only picking one thing we're just talking about tilde n^2 and maybe another tilde n^2 for the increment for the two sum problems ,COMMA okay .PERIOD so again ,COMMA when n is large ,COMMA the terms are negligible and when n is really small ,COMMA they're not negligible but we don't really care because we're trying to estimate running times for large n and running times for small n are going to be small no matter what .PERIOD all right ,COMMA so now ,COMMA we're using both the cost model and the tilde notation and then we can simply say ,COMMA that this program uses tilde n^2 squared array axises and have implicit the hypothesis that we think the running time is going to be tilde ,COMMA a constant ,COMMA times n squared .PERIOD okay ,COMMA we now what about three sums ,COMMA let's do a ,COMMA a real problem .PERIOD so now ,COMMA we have the triple loop .PERIOD and then ,COMMA we have to do a more complicated combinatorial problem in is not that big a deal really we are looking at the distinct number of ways you can chose three things out of n and that 's binomial coefficient .PERIOD and again ,COMMA doing the math and using the tilde ,COMMA it's just tilde one -DASH sixth n^3 three ray axises for each triple so we can say one -DASH half n^3 .PERIOD so we're not computing and summing the costs of all operations that's too much work .PERIOD we're picking the most expensive in terms of cost times frequency and approximating that and trying to get a good model for the running time .PERIOD so now most ,COMMA we're not going to do of a full discrete mathematics in this course but there's some basic things that we'll want to use and are ,COMMA are not that difficult to understand .PERIOD so ,COMMA a lot of times we find out that we need to come up with an estimate of a discrete sum .PERIOD like we did for one + two up to n .PERIOD or some of the squares or other things like the three sum triple loop .PERIOD and so actually if you've had basic calculus ,COMMA one way to think of it as to just replace the sum with an interval ,COMMA integral .PERIOD that usually works or we can do the math and use the so -DASH called eulermaclaurin summation formula to get a true approximation .PERIOD but if you think of it this way you'll believe us when we say that ,COMMA that thing is tilde one -DASH half n^2 or sum of one+ one -DASH half + one -DASH third up to one / n .PERIOD that's like integral from x = one to n1 / x and that's natural log of n .PERIOD now even the three sum triple loop kind of if you're used to multiple integrals ,COMMA i will quickly give you the one -DASH sixth n^3 .PERIOD there's many more and other techniques that we could use for this .PERIOD and we're not going to teach all that ,COMMA but we'll sometimes refer to results of this type .PERIOD alright ,COMMA so in principle ,COMMA knuth tells us that accurate mathematical models are available in practice ,COMMA we can get really complicated formulas .PERIOD we also might need some advance mathematics that the theoretician will revel in .PERIOD but that maybe people learning algorithms for the first time might not be expected to know .PERIOD so in the end careful exact models are best ,COMMA best left for exit ,COMMA experts .PERIOD there's really a lot of things that can go on .PERIOD on the other hand approximate models are definitely worthwhile .PERIOD and for all the algorithms that we consider we'll try to communicate a reasonable approximate model that can be used to describe the running time .PERIOD sometimes we'll give the mathematical proofs and other times we'll have to just cite the work of some expert .PERIOD 
okay ,COMMA so the first step is to be able to make some observations about the running time of the programs .PERIOD and for analysis of algorithms that's easier than in a lot of scientific disciplines ,COMMA as we'll see .PERIOD for a running example we're going to use the so -DASH called 3 -DASH sum problem .PERIOD and it's an easy to state problem .PERIOD if you've got n distinct integers ,COMMA how many triple sum to exactly zero ?QUESTIONMARK for example in this file 8ints .PERIODtext .PERIOD text which has eight integers in it .PERIOD there's four triples that sum to zero .PERIOD 30  -DASH  40 ,COMMA ten .PERIOD 30  -DASH  twenty  -DASH  ten and so forth and so our goal is to write a program that can compute this quantity for any input file ,COMMA any set of n integers .PERIOD this is actually a ,COMMA an extremely important computation that's deeply related to many problems in computational geometry which is a branch of computer science that covers the algorithms and underlying science related to graphics and movies and geometric models of all sort .PERIOD so this is a actually an important practical problem .PERIOD but it's a simple one to write code for in a view you could write down this program without much effort .PERIOD it's a ,COMMA got a static method count that is going to go ahead and take a integer array as an argument .PERIOD and ,COMMA is that ,COMMA that's a number of integers ,COMMA that's the length of the array .PERIOD we will start with a variable count equals zero ,COMMA and then a triple for loop ,COMMA that checks each triple i j k ,COMMA we go i from one and j from i+1 to n ,COMMA and k from j+1 to n ,COMMA so that we get each triple just once .PERIOD and then if i+j ,COMMA ai + aj + ak = zero ,COMMA we increment the count .PERIOD alright .PERIOD and after that triple four loop ,COMMA we return the count .PERIOD and then the main method ,COMMA in this simple class just reads in ,COMMA all the integers ,COMMA and prints out the count .PERIOD so that's a brute force algorithm that is a fine method for solving the three sum problem ,COMMA now what we're interested in is how much time does this take as a function of' n ?QUESTIONMARK well ,COMMA one to time our program is to is just look at the watch .PERIOD if you have a stopwatch ,COMMA or look at the clock or your phone ,COMMA or whatever you might need you can just go ahead and time it if you want or we have ,COMMA java has this part of it's standard library ,COMMA a stopwatch class that will go ahead and compute a lapse time .PERIOD so ,COMMA in order ,COMMA anytime you run a program ,COMMA if it is setup to easily take input of different sizes ,COMMA a natural thing to do ,COMMA is just run it for bigger sizes .PERIOD so for eight ints this program takes not too much time ,COMMA for 1000 ints it takes half a second .PERIOD for 2 ,COMMA000 .PERIOD takes more time .PERIOD that's 3 .PERIOD7 seconds run it again ,COMMA still takes 3 .PERIOD7 seconds for 4 ,COMMA000 ,COMMA so each time we're doubling the size of the input and it's definitely taking more time each time .PERIOD and actually as we'll see if programmers who get in the habit of testing or any time on their program in this way can get so that you can actually pretty easily and quickly evaluate when it's going to finish .PERIOD in fact .PERIOD while you're waiting for it to finish you can often figure it out .PERIOD so that one took 30 seconds for 4k and definitely we could figure it out how long it's going to take for 8k before it finishes ,COMMA and you'll see how in just a second .PERIOD i'm not going to wait right now .PERIOD you can think about what you think .PERIOD okay so [cough] that's empirical analysis ,COMMA analysis .PERIOD run it for various input sizes and measure their running time .PERIOD now if this were some scientific problem where we were counting something that happen in the natural world .PERIOD the number of ants in an ant hill or whatever then we'd have only a few data points and we would try to understand whats was going on by doing a plot of or running time with quite interested in on the y axis and problem size with the x axis .PERIOD hit a curve like this and actually whats science usually do because of some many problems fall into out of this class is do the plot as a lg ,COMMA lg plot .PERIOD if you do it as a lg ,COMMA lg plot very often you'll get a straight line .PERIOD and the slope of the straight line is the key to what's going on .PERIOD in this case ,COMMA the slope of the straight line is three and so you can run what's called a regression to fit a late ,COMMA the straight line through the data points .PERIOD and then ,COMMA it's not difficult to show to do the math to show that if you get a straight line and the slope is b ,COMMA then your function is proportional to a ,COMMA n^b .PERIOD that's called the power law .PERIOD and that's true of many ,COMMA many scientific problems including most algorithms .PERIOD so here's a little bit of the math for that .PERIOD so the straight line means that since we did a lg ,COMMA lg plot with powers of two ,COMMA that lg(t(n) = b lg n + c .PERIOD and we have our empirical values of b and c and then if you raise both sides of that equation to two to that power then you get t(n) = a constant times n^b .PERIOD so right away just from observation we have a pretty good model for the running time for our program ,COMMA we can figure and do the math and figure out that it seems as though the running time is about ten^ -DASH 10 n^3 seconds .PERIOD we can use that hypothesis to go ahead and make predictions .PERIOD just plug in for different values of n and it says it will take us 400 seconds for 16 ,COMMA000 .PERIOD 400 seconds is plenty of time but now we can go ahead and invest and run that experiment and sure enough we're pretty close to that 408 seconds when we run it .PERIOD and now we can make a prediction for 32 ,COMMA000 or for or for whatever else we might be interested in .PERIOD the model helps us do predictions without investing the expense to run the experiments .PERIOD in fact ,COMMA in this situation if there is a power law ,COMMA and again in a very great majority of computer algorithm running times is going to be a power law .PERIOD what we can do is just double the size of the input each time the way we were and take the ratio of the running times for n and 2n .PERIOD and if you do that ,COMMA that ratio going to converge to a constant .PERIOD and in fact the log of the ratio is going to converge to that constant ,COMMA which is the exponent of n and the running time .PERIOD and you just need a little math to check that one ,COMMA but that's a very easy and natural way to go ahead and predict running times .PERIOD so that's what i said before is ,COMMA so we have this quick way to estimate b in the power law relationsh ip .PERIOD how do we estimate a ?QUESTIONMARK well we can just run it and solve for a .PERIOD so once we've decided that ,COMMA that exponent is three let's run it for some big n and we get pretty close model to the one we had from plotting things .PERIOD so it's almost identical hypothesis and we just got it by running the program double n each time .PERIOD okay so there is a lot of effects in trying to understand the running time of a program on ,COMMA on your machine .PERIOD [cough] so .PERIOD key effects are independent of what computer it is .PERIOD and that's the algorithm you're using and what's the data .PERIOD and that's going to really determine the exponent in the power law .PERIOD and then there's a lot of ,COMMA system dependent effects .PERIOD what kind of hardware do you have ?QUESTIONMARK do you have a fast computer or a slow one ?QUESTIONMARK what kind of software ?QUESTIONMARK what's going on in your computer ?QUESTIONMARK all of those things really determine the constant a in the power law .PERIOD so .PERIOD in modern systems it is so much going on in the hardware and software ,COMMA it's sometimes difficult to get really precise measurements .PERIOD but on the other hand we don't have to sacrifice animals ,COMMA or fly to another planet the way they do in other sciences ,COMMA we can just run a huge number of experiments and usually take care of understanding these kind of effects .PERIOD 
okay .PERIOD first ,COMMA we're gonna look at the search algorithm for ,COMMA digraphs and this is the finding paths ,COMMA what are all the vertices that we can get to from a given vertex along a directed path .PERIOD and again ,COMMA this is ,COMMA little more complex for a digraph it would seem ,COMMA than for a graph .PERIOD so in this case ,COMMA those are the ,COMMA that's the set of vertices that you can get to ,COMMA from the given vertex x ,COMMA s .PERIOD notice that ,COMMA this set is characterized by every edge crossing the boundary ,COMMA it goes in .PERIOD if there were an edge that went out ,COMMA that would give ,COMMA another member of the set .PERIOD .PERIOD well actually ,COMMA looks more complicated to a human ,COMMA but to the computer ,COMMA it looks exactly ,COMMA precisely the same .PERIOD in fact .PERIOD the method that we looked at for undirected graphs is actually a digraph processing algorithm .PERIOD it treats ,COMMA every connection between two vertices as two directed edges ,COMMA one in each direction .PERIOD so ,COMMA dfs ,COMMA that we looked at last time is actually a digraph algorithm .PERIOD and we used precisely the same code .PERIOD so to visit a vertex v ,COMMA we mark the vertex as visited ,COMMA and recursively visit all unmarked vertices w ,COMMA that you can get to from v .PERIOD let's look at the demo ,COMMA just to ,COMMA  .PERIOD reinforce that .PERIOD so ,COMMA here's a sample digraph with the edges over at the right .PERIOD let's look at that first search on that digraph .PERIOD so ,COMMA we're going to look at the vertices that we can get to from vertex zero in this digraph .PERIOD again ,COMMA we have two vertex index to raise .PERIOD one called marked ,COMMA which says whether we can get there from v ,COMMA and the other called edge two ,COMMA which gives us the vertex that took us there .PERIOD with that we can recover the paths from vertex zero to each vertex that can be reached from vertex zero .PERIOD so we start off by visiting vertex zero and now check the edges that are adjacent to it with directed edges going out .PERIOD so there's five and then there's gonna be one .PERIOD but five is unmarked so we have to re -DASH cursedly visit five .PERIOD so we mark five ,COMMA and we say we got there from zero .PERIOD so the path from ,COMMA to five is zero to five .PERIOD and so now we're gonna recursively visit all the unmarked vertices pointed to from five  .PERIOD in this case it's just four .PERIOD my four is unmarked so we're gonna recursively visit four and say we got there from five .PERIOD and now recursively we have to check all the unmarked vertices pointing from four .PERIOD there's three .PERIOD and two ,COMMA first we do three and that's unmarked .PERIOD so we gotta visit three .PERIOD and say that we got there from four .PERIOD and now to visit three .PERIOD we've looked at all the vertices pointing from three .PERIOD we can check five .PERIOD we've already been to five that's marked so we don't have to do anything .PERIOD and then we check two .PERIOD two is unmarked so we continue with the depth first search and visit two .PERIOD so now to visit we mark two ,COMMA and say we've got there from three .PERIOD and now we check the vertices that we can get two from two .PERIOD in this case it's zero ,COMMA which we've already been to .PERIOD and three ,COMMA which we've already been to .PERIOD so .PERIOD now we're done with vertex two .PERIOD and we can return and continue the search from three well actually that was the last one from three ,COMMA so we're done with three as well .PERIOD so now we're at four .PERIOD we still have checked the edge from four to two .PERIOD so now we do that .PERIOD and of course we've been to two ,COMMA so we don't have any further processing .PERIOD and we're done with four .PERIOD the ,COMMA  ,COMMA four was the only edge we get to from five .PERIOD so we're going to be done with five as well .PERIOD and then ,COMMA what about zero ,COMMA well we have to check one .PERIOD 1's not visited ,COMMA so we visit one ,COMMA mark it .PERIOD and we turn and then we're done with zero ,COMMA and that gives ,COMMA the set of all vertices that are reachable from zero ,COMMA and not only that the edge to array .PERIOD gives the information that we need to reconstruct the path from any of those ,COMMA from zero to any of those vertices using precisely the same method that we used before .PERIOD we get the four from five ,COMMA we get the five from zero ,COMMA so zero ,COMMA five ,COMMA four is the path to four .PERIOD and we can do that for any vertex in that cell .PERIOD okay .PERIOD so what about the code ?QUESTIONMARK the code is exactly the same as for  ,COMMA undirected graphs .PERIOD that's the code for undirected graphs .PERIOD that we looked at last time to get the code for digraphs ,COMMA we just changed the name ,COMMA its the s ame code ,COMMA otherwise .PERIOD the recursive ,COMMA the constructor ,COMMA builds the array of marked vertices ,COMMA and also builds edge too ,COMMA just to ,COMMA avoid clutter ,COMMA left that one off this slide ,COMMA and then it makes the call to dfs .PERIOD then the recursive dfs does the work .PERIOD it marks the vertex and for every adjacent vertex .PERIOD if its not marked ,COMMA it does the dfs .PERIOD and then the client can ask whether any ver -DASH  ,COMMA any given vertex is reachable from s after the constructor has done its work .PERIOD that's depth -DASH first search in directed graphs ,COMMA actually ,COMMA we already did it .PERIOD now here's just a couple of applications where this kind of code is used .PERIOD one is ,COMMA a so called program control flow analysis .PERIOD actually every program can be viewed as a digraph .PERIOD where ,COMMA the vertices are basic blocks of instructions that are just executed one after the other with no conditionals .PERIOD and then edges represent ,COMMA a ,COMMA jump .PERIOD if there's an if statement ,COMMA vertex left ,COMMA two edges going out of it ,COMMA or ,COMMA or a loop ,COMMA which involves a conditional .PERIOD so ,COMMA  ,COMMA analyzing a program ,COMMA people write systems in analyse program ,COMMA to look at their structure by studying their diagrams ,COMMA for example .PERIOD one thing that happens often is there's unreachable code .PERIOD another ,COMMA another thing you might want to do is determine whether you can get to this exit or not ,COMMA by doing this digraph processing .PERIOD so that's actually a widely used technique in ,COMMA in developing software ,COMMA software development .PERIOD to try to improve code by doing this kind of digraph -DASH processing .PERIOD and ofcourse these digraphs can be huge .PERIOD another classic use of depth for search in digraphs is garbage collection that is used in systems like java where data structures or digraphs .PERIOD we build objects and then we create references to other objects .PERIOD and so the data that any programs use is really set as a digraph .PERIOD so there's the idea of roots ,COMMA so your program has e -DASH  .PERIOD some .PERIOD live objects ,COMMA that it can access through ,COMMA whatever state ,COMMA it's in ,COMMA but ,COMMA a language like java ,COMMA there's ,COMMA automatic garbage collection ,COMMA which means the programmer ,COMMA when it's done with an object ,COMMA maybe it overwrites one of these pointers or something .PERIOD there's gonna be some ,COMMA blocks ,COMMA that ,COMMA are not directly accessible by the program .PERIOD and so ,COMMA what's interesting is ,COMMA the set of reachable objects that ,COMMA can be indirectly access .PERIOD by the program starting and following a chain of pointers .PERIOD so those are the ones that can't be collected or reclaimed by the system for reusing the memory .PERIOD but all the other ones ,COMMA the gray ones that can't be reached by the program there's no reason to  .PERIOD keep them live ,COMMA you may as well collect them and return them for use ,COMMA re -DASH use .PERIOD so there's a so -DASH called marked and sweep out rhythm that actually dates back to 1960 ,COMMA where .PERIOD we run dfs to mark all ritual objects .PERIOD and then go through and sweep through all possible objects .PERIOD and if it's object is unmarked it's garbage so add it to the list of free memory .PERIOD and that's a classic method that's still widely used .PERIOD it uses an extra bit per object'cause you have to have to have that for the mark .PERIOD but still ,COMMA it's effective and useful digraph solution .PERIOD so dfs with reachability that we've just showed and path finding is similar .PERIOD and there's a couple of other simple digraph problems that we'll consider .PERIOD these are so far examples .PERIOD but it's also interesting that dfs is the basis for solving digraph problems that are not so simple or immediate to solve .PERIOD and this was pointed out 40 years ago by bob tarjan in a seminal paper that showed that .PERIOD first search ,COMMA can allow us to solve problems that seem pretty complicated actually ,COMMA in linear time ,COMMA and we're gonna look at an example of that later on .PERIOD so that's depth for search .PERIOD what about breadth for search .PERIOD well in the same way that we saw for depth for search every undirected graph is actually a digraph that has edges in both direction .PERIOD so bfs is really a directed graph algorithm and we can use exactly the same code to find shortest paths from a source to any given vertex .PERIOD so we use a que .PERIOD we put the source on a que and mark it as visited and .PERIOD and as long as the queue is non -DASH empty ,COMMA we remove the least recently added vertex and add to the que ue and mark as visited all the unmarked vertices that you can get to from that vertex .PERIOD and the same proof shows that bfs computes shortest paths ,COMMA the ones with the fewest number of edges from s to each other vertex in the digraph in time proportional to in linear time .PERIOD so you want the gps in your car ,COMMA you bfs when you're driving around lower manhattan .PERIOD so ,COMMA let's look at the demo again just to see ,COMMA the distinction between ,COMMA breadth first search ,COMMA in digraphs and see how it works .PERIOD so this is a ,COMMA a small graphing ,COMMA a smaller digraphic and with six vertices and eight edges .PERIOD we take a q and we take a source vertex and put on the q to get started .PERIOD then ,COMMA q is not empty ,COMMA so remove zero and we check all ,COMMA all vertices that are adjacent that we get to .PERIOD so .PERIOD we're gonna ,COMMA in zero was zero distance ,COMMA from zero ,COMMA so first we will check two .PERIOD and that one is not marked ,COMMA so we mark it and put it on the queue .PERIOD and then we'll check one .PERIOD and that one's not marked ,COMMA so we mark it and put it on the queue .PERIOD then we're done with zero .PERIOD now queue's not empty so we pull the least recently added off ,COMMA that's two .PERIOD and now we're going to check the vertices ,COMMA you can get from two .PERIOD i noticed both one and two are distance one from zero .PERIOD and now ,COMMA since we're going from two ,COMMA everything that we encounter will be distance two from the source .PERIOD so we find four ,COMMA it's distance two from the source ,COMMA and we get there from vertex two .PERIOD unmarked ,COMMA so we fill in those data structures and put it on the queue .PERIOD and then we're done with two ,COMMA so we go back to the queue ,COMMA and 1's on the queue .PERIOD so we pull one off and it's distance one from zero .PERIOD remember the first showed that everything in the queue is one of two distance ,COMMA either k or k plus one .PERIOD in this case ,COMMA we've got one at distance one ,COMMA four at distance two .PERIOD so now we're going to pull one off the queue .PERIOD m -DASH  and look at the edges you can get to ,COMMA places you can get to from one .PERIOD now we check two but that's already marked so we ignore it .PERIOD and then we're done with one .PERIOD now four is left on the q so we pull it off and check adjacent vertices .PERIOD in this case three ,COMMA it's unmarked so we put it on the q .PERIOD then we're done with four .PERIOD then from three we check five and that's unmarked and it's one more distance from the source so we put it on the q .PERIOD and then finally .PERIOD oh we check two which we already visited so we don't have to ,COMMA to do anything .PERIOD and then finally we pull five off the q .PERIOD check .PERIOD or you get two from five and it's zero ,COMMA which is marked ,COMMA so we're done .PERIOD and so that's breadth -DASH first search whig ,COMMA which gives us this directed tree from the source .PERIOD which gives the shortest path to all the vertices that you can get to from that source .PERIOD you can use a version of this to solve a more general problem known as the multiple -DASH source shortest paths problem .PERIOD in this problem you're given a digraph and a set of source vertices ,COMMA and you want to find the shortest path from any vertix in the set to each other vertix .PERIOD so for example ,COMMA in this case if the set is one ,COMMA seven ,COMMA and ten ,COMMA what's the shortest path to four ?QUESTIONMARK from one of those vertices .PERIOD well ,COMMA it turns out in this case to be seven ,COMMA six to four .PERIOD shortest path to five is seven ,COMMA six ,COMMA zero ,COMMA five .PERIOD shortest path to twelve is ten to twelve .PERIOD that's a more general problem but it's actually easy to solve .PERIOD how do we implement this ?QUESTIONMARK we just use a different constructor .PERIOD we just use bfs but initialize by ,COMMA put all the source vertices on the queue to get started .PERIOD so that is every vertex is ,COMMA so you put those on the queue and they're zero from the desired source .PERIOD and then any vertex you can get to from any one of those is going to be .PERIOD one and so forth ,COMMA so the results still gives away .PERIOD the edge to array will still give a way to get from any vertex ,COMMA the shortest way to get from any vertex to each of the sour -DASH  ,COMMA source vertices .PERIOD here's an application of depth -DASH first search .PERIOD let's say you want to crawl the whole web ,COMMA well ,COMMA all the web that you can access from some starting web page ,COMMA say like princeton's starting webpage .PERIOD again ,COMMA the digraph model ,COMMA each vertex is a webpage ,COMMA each edge is a link on that webpage to some other webpage .PERIOD and so all we want to do is get to all the other vertices on the web .PERIOD and ,COMMA so solution is ,COMMA well ,COMMA we don't actually build the digraph we just use an implicit digraph ,COMMA because for every web page we can find the links to other web pages on it and we'll just build those as we encounter them .PERIOD so we're gonna start with a source ,COMMA which is the root web page .PERIOD we're gonna have a queue of the sites that we still need to explore .PERIOD what we're going to do is also have a set of discovered websites ,COMMA this corresponds to our marked array but since we don't know how many vertices there are on the web all we're going to do is keep track of the ones that we've been to .PERIOD so this is ,COMMA don't use the vertex indexed array we don't even bother with because we'll just use the vertex names and do the look up as indicated we could do .PERIOD so all we do is in the ,COMMA is but for a search the same method is if the queue's not empty .PERIOD take a website off of the cue .PERIOD and just add to the queue all the websites to which it links .PERIOD but all of those websites ,COMMA you check whether they're in the set of the ones that you've seen already .PERIOD now ,COMMA you might run out of space ,COMMA for this set before you get to the whole web .PERIOD but anyway ,COMMA conceptually ,COMMA this is a way that you could go .PERIOD one thing to think about is why not use dfs for this .PERIOD well one reason is you ,COMMA you're gonna go far away in your search for the web .PERIOD maybe ,COMMA maybe that's what you want ,COMMA but the real problem ,COMMA in point of fact is there's some web pages that would trap such a search by creating new web pages and make links to'em the first time that you visit'em .PERIOD so ,COMMA they ,COMMA trap searches like that by ,COMMA cuz dfs would always go to a new web page like that and it'd keep creating new ones and you wouldn't get very far .PERIOD with breadt -DASH first search you're taking a wide search of the pages that are close .PERIOD and that's often maybe what you want for such a search .PERIOD and ,COMMA just to how simple the idea is ,COMMA this is complete code for a ,COMMA it's kind of a bare bones web crawler but it'll get to a lot of websites .PERIOD so let's look at ,COMMA do this example because again it really indicates the power of using appropriate abstractions to implement the algorithms that we're interested in .PERIOD so this one we're gonna use a cue .PERIOD queue of strings so that's the websites that we have to still yet to go to .PERIOD and then a set of strings is gonna be the ones that we've already been to that's equivalent to the marked array .PERIOD we'll start with princeton's website .PERIOD add it to the queue of places we have to go and also mark it .PERIOD discovered that ad just means mark it .PERIOD so now ,COMMA while the queue's not empty .PERIOD what we're going to do is read the raw html from the next website in the queue .PERIOD so this is code using our input library that gets that job done .PERIOD and then ,COMMA this is a little fooling around with regular expressions .PERIOD we'll talk about algorithms like this later on ,COMMA that essentially tries to find all urls within the text of that website .PERIOD and for all of those url's .PERIOD and we'll .PERIOD look at workers behind this code later on in this course .PERIOD for all those url's it's gonna check .PERIOD if it's marked that's discovered doc contains and if it's not marked it'll say it will mark it and put it on the queue .PERIOD a very s -DASH  simple program with a very powerful effect that illustrates breadth -DASH first search .PERIOD 
observing what's happening as we did in the last section it gives us a ,COMMA a way to predict performance but it really doesn't help us understand what the algorithm's doing .PERIOD so next ,COMMA we're going to look at mathematical model .PERIOD a way to get a better concept of what's really happening .PERIOD again ,COMMA this concept was really developed and popularized by don knuth starting in the late 60s .PERIOD at that time ,COMMA computer systems were really becoming complicated for the first time .PERIOD and computer scientists were concerned about whether we really were going to be able to understand what's going on .PERIOD and knuth was very direct in saying that this is something that we certainly can do .PERIOD we can calculate the total running time of a program by identifying all the basic operations ,COMMA figuring out the cost ,COMMA figuring out the frequency of execution and summing up the cost times frequency for all the operations .PERIOD you have to analyze the program to determine what set of operations and the cost depends on the machine and the computer in the system is what we talked about before .PERIOD the frequency leads us to mathematics because it depends on the algorithm and input data .PERIOD knuth has written a series of books that give very detailed and all exact analyses within a particular computer model for a wide range of algorithms .PERIOD so ,COMMA from knuth ,COMMA we know that in principle ,COMMA we can get accurate mathematical models for the performance of algorithms or programs and operation .PERIOD all right .PERIOD so what ,COMMA what does this process look like ?QUESTIONMARK well you can ,COMMA if you want run experiments .PERIOD in ,COMMA in ancient times ,COMMA we would actually look at the computer manual and every computer came with a manual that said precisely how long each instruction would take .PERIOD but nowadays ,COMMA it's a little more complicated .PERIOD so ,COMMA we run experiments and ,COMMA and you can go ahead and do a billion ads and figure out that maybe on your computer ,COMMA an ad takes 2 .PERIOD1 nano seconds .PERIOD or you can do more complicated function s like computer sign or an arc tangent although that's already getting close to the analysis of algorithms .PERIOD so ,COMMA there's some way to determine the costs of the basic operations .PERIOD and so ,COMMA we'll just in most ,COMMA most of the cases we'll just postulate that it's some constant and you can figure out what the constant is .PERIOD although when we're working with a collection of objects ,COMMA of anobjects there are some things that takes time proportional to n like if you're going to allocate a array of size n it takes time proportional to n because in java the default is that all the elements in the array initialize to zero .PERIOD in other operations it depends on the system implementation and an important one is string concatenation .PERIOD if you concatenate two strings the running time is proportional to the length of the string .PERIOD in many novices programming in java ,COMMA make a mistake of assuming that's a constant time operation when its not .PERIOD alright ,COMMA so that's the cost of each operation .PERIOD more interesting is the frequency of operation ,COMMA of execution of the operations .PERIOD so this is a ,COMMA a ,COMMA it's a very simple variant of the three sum problem .PERIOD that's the one sum problem .PERIOD that's how many numbers are actually equal to zero ?QUESTIONMARK how many single numbers add up to zero ?QUESTIONMARK so ,COMMA that one ,COMMA it's just one four loop ,COMMA and we go through ,COMMA and we tested the number zero and increment or count .PERIOD and by analyzing that code you can see that i and count have to be declared and then they have to be assigned to zero .PERIOD there's compares of i against n and there's n + one of them .PERIOD there's compares of a(i) against zero ,COMMA there's n of those ,COMMA n array axises and the number incremented is number of times there's an increment is variable .PERIOD i has incremented n times ,COMMA but count could be incremented any number from zero to n times .PERIOD and so that frequency is dependent on the input data .PERIOD or we might need a model for describing that or maybe there's other operations that are more e xpensive and we won't need to worry about that .PERIOD so ,COMMA let's look at the next more complicated problem is what about the frequency of execution of instructions in this program which is the two sum problem ,COMMA how many pairs of integers sum to zero ?QUESTIONMARK well ,COMMA in this case ,COMMA you have to do a little bit of math to see that when we when i goes from zero to n ,COMMA and j goes from i + a to n the number of compares that we do work ,COMMA plus array axises that we do is two for each time the if statement is executed for ai and aj and that time is ,COMMA thing is executed n  -DASH  one times the first time through the loop and n  -DASH two^2 and so forth .PERIOD it's the sum of the integers from zero up to n  -DASH  one which is a simple discrete sum one -DASH half n ,COMMA (n  -DASH  one) and since ,COMMA and since we're doing it twice the number of array axises is n ,COMMA n  -DASH  one .PERIOD so ,COMMA we can go ahead and get these actual exact counts .PERIOD but already ,COMMA it's getting a little bit tedious to do that .PERIOD and as far back as turing who also knew that and as well as babbage did ,COMMA that we want to have a measure of the amount of work involved in the process .PERIOD he recognized that you didn't want to necessarily go through and do it in full detail .PERIOD it's still helpful to have a crude estimate .PERIOD so ,COMMA you could count up the number of times that every operation is applied ,COMMA give it weights and ,COMMA and count the [inaudible] and so forth .PERIOD but maybe we should just count the ones that are most expensive that's what turing said in 1947 ,COMMA and realistically that's what we do nowadays .PERIOD so rather than going in and counting every little detail ,COMMA we take some basic operation that's maybe the most expensive and or and or the one that's executed the most often .PERIOD the one that cost and frequency is the highest and use that as a proxy for running time .PERIOD essentially ,COMMA making the hypothesis that the running time is ,COMMA is going to grow like a constant times [inaudible] ,COMMA so ,COMMA in this case ,COMMA were going to pick array axises .PERIOD so ,COMMA that's the first simplification .PERIOD and the second simplification is that we're going to ignore low order terms in the formulas that we derive .PERIOD and there's an easy way to do that .PERIOD it's called the tilde notation and ,COMMA and the idea is when n is large in a formula like this the n^3 term is much ,COMMA much higher than the n term or sixteen .PERIOD in fact ,COMMA so much so that we wouldn't even hardly notice these low order terms .PERIOD so ,COMMA all of these formulas are tilde one -DASH sixth n^3 and that's a fine representative or approximate ,COMMA approximation to these quantities .PERIOD and it greatly simplifies their calculations to for a ,COMMA through a way to lower ,COMMA lower to terms like this .PERIOD so ,COMMA by focusing on one operation and  ,COMMA throwing away the tildes ,COMMA the lower the terms and this is the technical definition of tilde .PERIOD it's just ,COMMA f(n) tilde g (n) means the limit as fn or gn equals one ,COMMA and you can check that that's going to hold in these kinds of situations .PERIOD so ,COMMA that greatly simplifies the frequency counts .PERIOD and if we're only picking one thing we're just talking about tilde n^2 and maybe another tilde n^2 for the increment for the two sum problems ,COMMA okay .PERIOD so again ,COMMA when n is large ,COMMA the terms are negligible and when n is really small ,COMMA they're not negligible but we don't really care because we're trying to estimate running times for large n and running times for small n are going to be small no matter what .PERIOD all right ,COMMA so now ,COMMA we're using both the cost model and the tilde notation and then we can simply say ,COMMA that this program uses tilde n^2 squared array axises and have implicit the hypothesis that we think the running time is going to be tilde ,COMMA a constant ,COMMA times n squared .PERIOD okay ,COMMA we now what about three sums ,COMMA let's do a ,COMMA a real problem .PERIOD so now ,COMMA we have the triple loop .PERIOD and then ,COMMA we have to do a more complicated combinatorial problem in is not that big a deal really we are looking at the distinct number of ways you can chose three things out of n and that 's binomial coefficient .PERIOD and again ,COMMA doing the math and using the tilde ,COMMA it's just tilde one -DASH sixth n^3 three ray axises for each triple so we can say one -DASH half n^3 .PERIOD so we're not computing and summing the costs of all operations that's too much work .PERIOD we're picking the most expensive in terms of cost times frequency and approximating that and trying to get a good model for the running time .PERIOD so now most ,COMMA we're not going to do of a full discrete mathematics in this course but there's some basic things that we'll want to use and are ,COMMA are not that difficult to understand .PERIOD so ,COMMA a lot of times we find out that we need to come up with an estimate of a discrete sum .PERIOD like we did for one + two up to n .PERIOD or some of the squares or other things like the three sum triple loop .PERIOD and so actually if you've had basic calculus ,COMMA one way to think of it as to just replace the sum with an interval ,COMMA integral .PERIOD that usually works or we can do the math and use the so -DASH called eulermaclaurin summation formula to get a true approximation .PERIOD but if you think of it this way you'll believe us when we say that ,COMMA that thing is tilde one -DASH half n^2 or sum of one+ one -DASH half + one -DASH third up to one / n .PERIOD that's like integral from x = one to n1 / x and that's natural log of n .PERIOD now even the three sum triple loop kind of if you're used to multiple integrals ,COMMA i will quickly give you the one -DASH sixth n^3 .PERIOD there's many more and other techniques that we could use for this .PERIOD and we're not going to teach all that ,COMMA but we'll sometimes refer to results of this type .PERIOD alright ,COMMA so in principle ,COMMA knuth tells us that accurate mathematical models are available in practice ,COMMA we can get really complicated formulas .PERIOD we also might need some advance mathematics that the theoretician will revel in .PERIOD but that maybe people learning algorithms for the first time might not be expected to know .PERIOD so in the end careful exact models are best ,COMMA best left for exit ,COMMA experts .PERIOD there's really a lot of things that can go on .PERIOD on the other hand approximate models are definitely worthwhile .PERIOD and for all the algorithms that we consider we'll try to communicate a reasonable approximate model that can be used to describe the running time .PERIOD sometimes we'll give the mathematical proofs and other times we'll have to just cite the work of some expert .PERIOD 
now ,COMMA fortunately when we analyze algorithms ,COMMA actually not too many different functions arise and actually that property allows us to really classify algorithms according to their performance as the problem size grows .PERIOD so that's what we'll talk about next .PERIOD so the good news is there's only these few functions turn up about the algorithms that we are interested in .PERIOD we can craft things that have other functions and there are counter examples to this .PERIOD but really a great number of the algorithms that we consider are described by these few functions and that are plotted here .PERIOD and [cough] the when we are talking about the order of growth ,COMMA we are not talking about the leading constant .PERIOD normally we'll say the running time of the algorithm is proportional to n log n .PERIOD that means we that we think that our hypothesis is that the running time is tilde c lg n ,COMMA n lg n ,COMMA where c is some constant .PERIOD and in these plots ,COMMA these are lg ,COMMA lg plots that not really give a good idea of what's going on .PERIOD if a order of growth is logarithmic or constant ,COMMA doesn't matter how big the thing is .PERIOD it's going to be fast of the running time for is t for say a thousand ,COMMA and for half a million it will be pretty close to t .PERIOD if it's linear ,COMMA if it's auto growth is proportional to n then as the running time ,COMMA as the size increases the running time increases correspondingly .PERIOD and the same is true ,COMMA almost ,COMMA if it's n log n .PERIOD so those are the algorithms that we strive for .PERIOD they scale with the input size .PERIOD as the input grows ,COMMA so grows the running time .PERIOD and that's ,COMMA a reasonable situation to be in .PERIOD as we talked about when we talked about union -DASH find .PERIOD if it's quadratic ,COMMA the running time grows much faster than the input size .PERIOD and it's not feasible to use such an algorithm for large inputs .PERIOD and qubic is even worse .PERIOD so what we find is for many algorithms our first task is really ,COMMA simply ,COMMA make sure it's not quadratic or qubit .PERIOD and these order of growth classifications actually come from kind of simple patterns in terms of the code that we write .PERIOD so if our code has no loops in it ,COMMA then the order of growth is going to be constant .PERIOD if our code has some kind of loop where the input's divided in half ,COMMA and so binary search algorithm is an example of that .PERIOD then our order growth will be logarithmic and we'll take a look at that analysis and but if you do the doubling test ,COMMA it grows almost linearly ,COMMA if you have a huge input and you double the size it's ,COMMA it's still going to be i'm sorry ,COMMA not linearly ,COMMA constant just like if it's constant .PERIOD you'll hardly notice that lg n .PERIOD if you have a loop where you touch everything in your input .PERIOD than the running time is linear ,COMMA proportional to end so a typical example of that would be find the maximum ,COMMA or to count the number of zeros .PERIOD our one some problem .PERIOD a very interesting category is a so -DASH called n lg n algorithms or linear rhythmic algorithms .PERIOD and those are the ones that arise from a particular algorithms design technique called the divide and conquer .PERIOD and the mergesort algorithm ,COMMA which we'll talk about in a couple of weeks ,COMMA is a prime example of that .PERIOD and then if you have double four loops like our two sum algorithm ,COMMA that's going to be time proportional to n^2 .PERIOD as we saw ,COMMA that's quadratic ,COMMA or triple four loop like our 3 -DASH sum algorithm ,COMMA that's going to be cubic or time proportional to n^3 .PERIOD for a quadratic algorithm or a cubic algorithm ,COMMA the doubling factor is four or eight as the input size double for cubic algorithm ,COMMA the running time goes up by a factor of eight ,COMMA and that's the kind of calculation that you can do in your head while waiting for a program to finish .PERIOD there's also a category of algorithms who's running time is exponential and in those algorithms n doesn't get very large at and we'll talk about those at the end part two of the course .PERIOD so these are some practical implications of ,COMMA of the order growth .PERIOD and we really dwell on this too much ,COMMA except to come back to the point that the algorithms we are really interested in ,COMMA that can solve huge problems ,COMMA are the linear and n lg n algorithms .PERIOD because even now a quadr atic algorithm on a typical fast computer could only solve problems and saying that tens of thousands in a cubic algorithm only in the size of thousands .PERIOD and nowadays those are just not useful because the amount of data that we have is more like the millions or billions or trillions .PERIOD that fact is becoming more and more evident as time wears on the ancient times would have some discussion about whether quadratic algorithm might be useful but the situation gets worse as the time goes on ,COMMA so we need better algorithms .PERIOD to illustrate the process of developing a mathematical model for describing a performance through an algorithm ,COMMA we'll look at a familiar algorithm called binary search .PERIOD it's ,COMMA the goal is that you have a sorted array of integers ,COMMA say and you're given a key .PERIOD and you want to know ,COMMA is that key in the array ?QUESTIONMARK and if it is ,COMMA what ,COMMA what's its index ?QUESTIONMARK and a fast algorithm for doing this is known as binary search ,COMMA where we compare the key against the middle entry .PERIOD in this case ,COMMA if we're looking for 33 ,COMMA we compare it against 53 .PERIOD if its smaller we know its in the left half of the array ,COMMA if it's larger we know it's in the right half of the array ,COMMA if it's equal ,COMMA we found it .PERIOD and then we apply the same algorithm recursively .PERIOD so let's quickly look at a demo .PERIOD so we're looking for 33 in this array ,COMMA compare it against the middle entry in the array .PERIOD 53 and it's less so we go left ,COMMA so now we can concentrate just on the left half of the array ,COMMA now we look in the middle of this half ,COMMA that's 25 ,COMMA 33 is bigger so we go right .PERIOD and now we concentrate on the right half or the left half and we have a smaller sub array .PERIOD look at the middle ,COMMA 33 is less so we go left and now we have only the one element to look at and we found our key 33 in the array and we return that index four .PERIOD if we're looking for something that's not in the array ,COMMA we do the same process .PERIOD so ,COMMA say ,COMMA we're looking for 34 .PERIOD it's going to be the same .PERIOD look in the left half ,COMMA look in the right half .PERIOD look to the left of the 43 .PERIOD now ,COMMA there's only one key to look at .PERIOD a nd it's not 34 ,COMMA so we say ,COMMA it's not there .PERIOD so that's binary search .PERIOD so here's the code for binary search .PERIOD actually ,COMMA binary search although it's a simple algorithm ,COMMA its notoriously tricky to get every detail right .PERIOD in fact one paper claimed ,COMMA that the first bug free binary search wasn't published until 1962 ,COMMA and even in 2006 ,COMMA a bug was found in java's implementation of binary search ,COMMA just an indication of the care that we have to take in developing algorithms especially for libraries that are going to be used by millions of people .PERIOD so here's an implementation .PERIOD it's not recursive although often we can implement this recursively .PERIOD and it's just reflexing code ,COMMA what i described in words ,COMMA we have to find .PERIOD a key ,COMMA whether a key's in an array .PERIOD and we use two pointers ,COMMA low and high ,COMMA to ,COMMA indicate the part of the array we are interested in ,COMMA as long as low is less and equal to high ,COMMA we compute the middle .PERIOD and then we compare our key against the middle ,COMMA actually its a three way compare ,COMMA see its less or greater or if its equal ,COMMA we ,COMMA we return that mid index .PERIOD if its less we reset the high pointer ,COMMA if its greater ,COMMA we reset the low pointer ,COMMA and we keep on going until the pointers are equal .PERIOD if they are equal and we haven't found it then we return  -DASH one .PERIOD and it's easy to persuade ourselves that this program works as advertised by thinking about this invariant ,COMMA if the keys in the array ,COMMA then it's between low and high in the array .PERIOD alright ,COMMA so that's a program that ,COMMA you are probably familiar with .PERIOD lets look at the mathematical analysis of that program .PERIOD and this a ,COMMA a theorem that we are going to prove easily .PERIOD we want to a lot of proofs but this is one worth doing .PERIOD so its say that binary search uses at most one + lg base two event compares ,COMMA to complete a search ,COMMA in a sorted array of size f .PERIOD so we do that ,COMMA to setup the problem by defining ,COMMA a variable t(n) ,COMMA which is the number of compares that binary search needed for its array size and .PERIOD and then we write down a recurrence relation that is reflex the code .PERIOD and what the code does is ,COMMA it divides the problem size in half so that .PERIOD if the event is less or equal to the event over two plus depending on how you count what the compare is think of it as a two way compare so divided in half by doing one compare and that's true as long as n is bigger than one .PERIOD if it's equal to one the solution is one .PERIOD so it's a recurrent relation describing the computation .PERIOD and so we ,COMMA we can go ahead and ,COMMA solve this recurrence by applying the recurrence itself ,COMMA to the first term on the right .PERIOD now that's called telescoping .PERIOD so if this is true and we can apply the same thing to t(n/2) .PERIOD and throw out another one and if that's ,COMMA this is true ,COMMA apply the same thing to n over four ,COMMA and throw out another one and so forth until we get down to just one .PERIOD in which case we have lg n ones left .PERIOD now this is a true sketch you might have noticed that ,COMMA that this proof actually only holds if n is a power of two .PERIOD because we nearly specify in this recurrence what we mean if n is odd .PERIOD but it's possible to go ahead and sorry ,COMMA possible to go ahead and take care of that detail as well and show that binary search running time is logarithmic always .PERIOD all right ,COMMA so given that fact we can develop a faster algorithm for a threesome .PERIOD it's a sorting based algorithm .PERIOD and so what we're going to do is we're going to take the numbers that we have as input and sort them .PERIOD we'll talk about sorting algorithms next week .PERIOD and we get that time in time proportional to n lg n but that's not the main part of the computation .PERIOD the main part of the computation is to after the numbers are sorted ,COMMA we'll go through and for each pair of numbers ai and aj .PERIOD we'll do a binary search for  -DASH ai + ij .PERIOD if we find it then we'll have three numbers that sum to zero .PERIOD so if we [cough] sort our numbers and then go through for each pair do a binary search to see if it's there ,COMMA so  -DASH 40 ,COMMA zero .PERIOD minus that is 40 ,COMMA we do a binary search that's in there so we have one solution to the 3 -DASH sum problem .PERIOD and do that for all pairs of numbers .PERIOD then a quick analysis says the order of growth of running time is going to be n^2 lg n .PERIOD then you need a good sort ,COMMA well ,COMMA you could use the elementary insertion sort the first one we talk about but the running time of the binary search for each of the pairs ,COMMA each of the n^2 pairs or n^2/2 pairs we're going to do the binary search ,COMMA so we get a n^2 lg n running time .PERIOD so ,COMMA a quick example of how we could improve the performance ,COMMA we could find an imroved algorithm to solve a problem .PERIOD n^2 lg n is much less than n^3 for large n .PERIOD and so ,COMMA we're implicitly making the hypothesis that if we do this ,COMMA do the sort base thing and use binary search ,COMMA we're going to have a faster program .PERIOD and ,COMMA sure enough we can go ahead and run some experiments and find that whereas it took us 50 seconds to solve the problem for 8 ,COMMA000 numbers before .PERIOD it's taking less than a second now .PERIOD in 50 seconds we can solve up to 64 ,COMMA000 .PERIOD so typically we expect that better order of growth means .PERIOD faster in practice and but when it comes to examining the algorithms in detail we can ,COMMA we can go ahead and do the tests and figure out which algorithm is faster .PERIOD and certainly going from n^3 to n^2 lg n we're going to expect that we're going to have a much better algorithm .PERIOD 
now ,COMMA fortunately when we analyze algorithms ,COMMA actually not too many different functions arise and actually that property allows us to really classify algorithms according to their performance as the problem size grows .PERIOD so that's what we'll talk about next .PERIOD so the good news is there's only these few functions turn up about the algorithms that we are interested in .PERIOD we can craft things that have other functions and there are counter examples to this .PERIOD but really a great number of the algorithms that we consider are described by these few functions and that are plotted here .PERIOD and [cough] the when we are talking about the order of growth ,COMMA we are not talking about the leading constant .PERIOD normally we'll say the running time of the algorithm is proportional to n log n .PERIOD that means we that we think that our hypothesis is that the running time is tilde c lg n ,COMMA n lg n ,COMMA where c is some constant .PERIOD and in these plots ,COMMA these are lg ,COMMA lg plots that not really give a good idea of what's going on .PERIOD if a order of growth is logarithmic or constant ,COMMA doesn't matter how big the thing is .PERIOD it's going to be fast of the running time for is t for say a thousand ,COMMA and for half a million it will be pretty close to t .PERIOD if it's linear ,COMMA if it's auto growth is proportional to n then as the running time ,COMMA as the size increases the running time increases correspondingly .PERIOD and the same is true ,COMMA almost ,COMMA if it's n log n .PERIOD so those are the algorithms that we strive for .PERIOD they scale with the input size .PERIOD as the input grows ,COMMA so grows the running time .PERIOD and that's ,COMMA a reasonable situation to be in .PERIOD as we talked about when we talked about union -DASH find .PERIOD if it's quadratic ,COMMA the running time grows much faster than the input size .PERIOD and it's not feasible to use such an algorithm for large inputs .PERIOD and qubic is even worse .PERIOD so what we find is for many algorithms our first task is really ,COMMA simply ,COMMA make sure it's not quadratic or qubit .PERIOD and these order of growth classifications actually come from kind of simple patterns in terms of the code that we write .PERIOD so if our code has no loops in it ,COMMA then the order of growth is going to be constant .PERIOD if our code has some kind of loop where the input's divided in half ,COMMA and so binary search algorithm is an example of that .PERIOD then our order growth will be logarithmic and we'll take a look at that analysis and but if you do the doubling test ,COMMA it grows almost linearly ,COMMA if you have a huge input and you double the size it's ,COMMA it's still going to be i'm sorry ,COMMA not linearly ,COMMA constant just like if it's constant .PERIOD you'll hardly notice that lg n .PERIOD if you have a loop where you touch everything in your input .PERIOD than the running time is linear ,COMMA proportional to end so a typical example of that would be find the maximum ,COMMA or to count the number of zeros .PERIOD our one some problem .PERIOD a very interesting category is a so -DASH called n lg n algorithms or linear rhythmic algorithms .PERIOD and those are the ones that arise from a particular algorithms design technique called the divide and conquer .PERIOD and the mergesort algorithm ,COMMA which we'll talk about in a couple of weeks ,COMMA is a prime example of that .PERIOD and then if you have double four loops like our two sum algorithm ,COMMA that's going to be time proportional to n^2 .PERIOD as we saw ,COMMA that's quadratic ,COMMA or triple four loop like our 3 -DASH sum algorithm ,COMMA that's going to be cubic or time proportional to n^3 .PERIOD for a quadratic algorithm or a cubic algorithm ,COMMA the doubling factor is four or eight as the input size double for cubic algorithm ,COMMA the running time goes up by a factor of eight ,COMMA and that's the kind of calculation that you can do in your head while waiting for a program to finish .PERIOD there's also a category of algorithms who's running time is exponential and in those algorithms n doesn't get very large at and we'll talk about those at the end part two of the course .PERIOD so these are some practical implications of ,COMMA of the order growth .PERIOD and we really dwell on this too much ,COMMA except to come back to the point that the algorithms we are really interested in ,COMMA that can solve huge problems ,COMMA are the linear and n lg n algorithms .PERIOD because even now a quadr atic algorithm on a typical fast computer could only solve problems and saying that tens of thousands in a cubic algorithm only in the size of thousands .PERIOD and nowadays those are just not useful because the amount of data that we have is more like the millions or billions or trillions .PERIOD that fact is becoming more and more evident as time wears on the ancient times would have some discussion about whether quadratic algorithm might be useful but the situation gets worse as the time goes on ,COMMA so we need better algorithms .PERIOD to illustrate the process of developing a mathematical model for describing a performance through an algorithm ,COMMA we'll look at a familiar algorithm called binary search .PERIOD it's ,COMMA the goal is that you have a sorted array of integers ,COMMA say and you're given a key .PERIOD and you want to know ,COMMA is that key in the array ?QUESTIONMARK and if it is ,COMMA what ,COMMA what's its index ?QUESTIONMARK and a fast algorithm for doing this is known as binary search ,COMMA where we compare the key against the middle entry .PERIOD in this case ,COMMA if we're looking for 33 ,COMMA we compare it against 53 .PERIOD if its smaller we know its in the left half of the array ,COMMA if it's larger we know it's in the right half of the array ,COMMA if it's equal ,COMMA we found it .PERIOD and then we apply the same algorithm recursively .PERIOD so let's quickly look at a demo .PERIOD so we're looking for 33 in this array ,COMMA compare it against the middle entry in the array .PERIOD 53 and it's less so we go left ,COMMA so now we can concentrate just on the left half of the array ,COMMA now we look in the middle of this half ,COMMA that's 25 ,COMMA 33 is bigger so we go right .PERIOD and now we concentrate on the right half or the left half and we have a smaller sub array .PERIOD look at the middle ,COMMA 33 is less so we go left and now we have only the one element to look at and we found our key 33 in the array and we return that index four .PERIOD if we're looking for something that's not in the array ,COMMA we do the same process .PERIOD so ,COMMA say ,COMMA we're looking for 34 .PERIOD it's going to be the same .PERIOD look in the left half ,COMMA look in the right half .PERIOD look to the left of the 43 .PERIOD now ,COMMA there's only one key to look at .PERIOD a nd it's not 34 ,COMMA so we say ,COMMA it's not there .PERIOD so that's binary search .PERIOD so here's the code for binary search .PERIOD actually ,COMMA binary search although it's a simple algorithm ,COMMA its notoriously tricky to get every detail right .PERIOD in fact one paper claimed ,COMMA that the first bug free binary search wasn't published until 1962 ,COMMA and even in 2006 ,COMMA a bug was found in java's implementation of binary search ,COMMA just an indication of the care that we have to take in developing algorithms especially for libraries that are going to be used by millions of people .PERIOD so here's an implementation .PERIOD it's not recursive although often we can implement this recursively .PERIOD and it's just reflexing code ,COMMA what i described in words ,COMMA we have to find .PERIOD a key ,COMMA whether a key's in an array .PERIOD and we use two pointers ,COMMA low and high ,COMMA to ,COMMA indicate the part of the array we are interested in ,COMMA as long as low is less and equal to high ,COMMA we compute the middle .PERIOD and then we compare our key against the middle ,COMMA actually its a three way compare ,COMMA see its less or greater or if its equal ,COMMA we ,COMMA we return that mid index .PERIOD if its less we reset the high pointer ,COMMA if its greater ,COMMA we reset the low pointer ,COMMA and we keep on going until the pointers are equal .PERIOD if they are equal and we haven't found it then we return  -DASH one .PERIOD and it's easy to persuade ourselves that this program works as advertised by thinking about this invariant ,COMMA if the keys in the array ,COMMA then it's between low and high in the array .PERIOD alright ,COMMA so that's a program that ,COMMA you are probably familiar with .PERIOD lets look at the mathematical analysis of that program .PERIOD and this a ,COMMA a theorem that we are going to prove easily .PERIOD we want to a lot of proofs but this is one worth doing .PERIOD so its say that binary search uses at most one + lg base two event compares ,COMMA to complete a search ,COMMA in a sorted array of size f .PERIOD so we do that ,COMMA to setup the problem by defining ,COMMA a variable t(n) ,COMMA which is the number of compares that binary search needed for its array size and .PERIOD and then we write down a recurrence relation that is reflex the code .PERIOD and what the code does is ,COMMA it divides the problem size in half so that .PERIOD if the event is less or equal to the event over two plus depending on how you count what the compare is think of it as a two way compare so divided in half by doing one compare and that's true as long as n is bigger than one .PERIOD if it's equal to one the solution is one .PERIOD so it's a recurrent relation describing the computation .PERIOD and so we ,COMMA we can go ahead and ,COMMA solve this recurrence by applying the recurrence itself ,COMMA to the first term on the right .PERIOD now that's called telescoping .PERIOD so if this is true and we can apply the same thing to t(n/2) .PERIOD and throw out another one and if that's ,COMMA this is true ,COMMA apply the same thing to n over four ,COMMA and throw out another one and so forth until we get down to just one .PERIOD in which case we have lg n ones left .PERIOD now this is a true sketch you might have noticed that ,COMMA that this proof actually only holds if n is a power of two .PERIOD because we nearly specify in this recurrence what we mean if n is odd .PERIOD but it's possible to go ahead and sorry ,COMMA possible to go ahead and take care of that detail as well and show that binary search running time is logarithmic always .PERIOD all right ,COMMA so given that fact we can develop a faster algorithm for a threesome .PERIOD it's a sorting based algorithm .PERIOD and so what we're going to do is we're going to take the numbers that we have as input and sort them .PERIOD we'll talk about sorting algorithms next week .PERIOD and we get that time in time proportional to n lg n but that's not the main part of the computation .PERIOD the main part of the computation is to after the numbers are sorted ,COMMA we'll go through and for each pair of numbers ai and aj .PERIOD we'll do a binary search for  -DASH ai + ij .PERIOD if we find it then we'll have three numbers that sum to zero .PERIOD so if we [cough] sort our numbers and then go through for each pair do a binary search to see if it's there ,COMMA so  -DASH 40 ,COMMA zero .PERIOD minus that is 40 ,COMMA we do a binary search that's in there so we have one solution to the 3 -DASH sum problem .PERIOD and do that for all pairs of numbers .PERIOD then a quick analysis says the order of growth of running time is going to be n^2 lg n .PERIOD then you need a good sort ,COMMA well ,COMMA you could use the elementary insertion sort the first one we talk about but the running time of the binary search for each of the pairs ,COMMA each of the n^2 pairs or n^2/2 pairs we're going to do the binary search ,COMMA so we get a n^2 lg n running time .PERIOD so ,COMMA a quick example of how we could improve the performance ,COMMA we could find an imroved algorithm to solve a problem .PERIOD n^2 lg n is much less than n^3 for large n .PERIOD and so ,COMMA we're implicitly making the hypothesis that if we do this ,COMMA do the sort base thing and use binary search ,COMMA we're going to have a faster program .PERIOD and ,COMMA sure enough we can go ahead and run some experiments and find that whereas it took us 50 seconds to solve the problem for 8 ,COMMA000 numbers before .PERIOD it's taking less than a second now .PERIOD in 50 seconds we can solve up to 64 ,COMMA000 .PERIOD so typically we expect that better order of growth means .PERIOD faster in practice and but when it comes to examining the algorithms in detail we can ,COMMA we can go ahead and do the tests and figure out which algorithm is faster .PERIOD and certainly going from n^3 to n^2 lg n we're going to expect that we're going to have a much better algorithm .PERIOD 
in fact the order of growth classifications are so important they've led to enormous amount of research in recent years and just talk briefly about that now .PERIOD so there is ,COMMA life is a little bit more complicated than pointed out in the last example and one problem is that the inputs can cause the performance of the algorithm to vary widely .PERIOD so often we have to think about different ways of analyzing the algorithm depending on the input .PERIOD so ,COMMA the running time is going to be somewhere between the best case and the worst case .PERIOD best case is the lower bound on cost it .PERIOD it provides something that the running time is going to be bigger than that always or not less than that and then there's the worst case which is the most difficult input .PERIOD if we analyze that then we can guarantee that the running time in the algorithms not going to be bigger than that .PERIOD and then in a lot of situations we might consider our input to be random .PERIOD well we need to ,COMMA someway to model ,COMMA what we mean by random for the problem that we're solving but there is a lot of situations where we can do that and then we have a way to predict performance even when the input might vary widely .PERIOD so for example for 3 -DASH sum ,COMMA it's kind of always the same .PERIOD with the tilde notation ,COMMA the only variability in that algorithm is the number of times the counter is incremented and that's in low order terms so it doesn't need to chew up in our analysis .PERIOD for binary search it's ,COMMA you might find the thing right away in which case is constant time and we can show that the average and the worst case are both lg based two(n) .PERIOD there's other ,COMMA in another examples that be much more variability even .PERIOD so ,COMMA we have this different types of analysis depending on the input .PERIOD and but the question is ,COMMA what about the actual problem that the client is trying to solve ?QUESTIONMARK so we have to understand that two in order to be able to understand performance of the algorithm .PERIOD and there's two approaches that are ,COMMA or successful in this .PERIOD one is to design for the worst case .PERIOD just to make sure that your algorithm are ,COMMA always runs quickly and that's definitely ideal .PERIOD another is to ,COMMA if you can't do that is to randomize and then depend on some kind of probabilistic guarantee and we'll see examples of both of these as we go through the course .PERIOD now ,COMMA those kinds of considerations ,COMMA you know the idea of order of growth leads to discussion of ,COMMA what's called ,COMMA what i call the theory of algorithms .PERIOD and here our goals are ,COMMA we have a problem to solve like solve the 3 -DASH sum problem and we want to know how difficult it is .PERIOD we want to find the best algorithm for solving that problem .PERIOD the approach that the computer scientist use for this is to try to suppress as many details as possible in the analysis .PERIOD and so just analyze the running time to or within a constant factor .PERIOD that's what order of growth is getting at and also i want to ,COMMA not worry about the input model at all .PERIOD and so we focused on worst case design and we can talk about performance of algorithms just in turn of the order of growth and it's actually possible ,COMMA it's actually possible to do that in a very rigorous way that it's taught us a lot about the difficulty of solving problems .PERIOD and our goal is to find an optimal algorithm where we can guarantee to within a constant factor certain performance for any input cuz we discovered the worst case but we also can have approved that didn't know algorithm could provide a better performance guarantee .PERIOD i'll give a couple of easy examples of this .PERIOD now in order to do this they're ,COMMA these commonly used notations called the big theta ,COMMA big o and big omega notations .PERIOD so the and those definitions are given here .PERIOD so big theta notation is just the way to describe the order of growth .PERIOD theta(n)^2 is kind of short hand for anything n^2 .PERIOD it's bounded above and below by constant time n^2 and that's what we really use to classify algorithms .PERIOD and then ,COMMA there is big o notation which is upper bounds on performance .PERIOD when we say o(n^2) ,COMMA we mean that it's less than some constant time n^2 as n grows .PERIOD and big omega is used for lower bounds means greater than some constant time n^2 as n grows .PERIOD so those three notations were able to use to classify algorithms and i'll show them in the following .PERIOD so ,COMMA examples from our 1 -DASH sum ,COMMA 2 -DASH sum ,COMMA and 3 -DASH sum are easy to articulate so our goals are to establish the difficulty of the problem and to develop an optimal algorithm .PERIOD so ,COMMA the 1 -DASH sum problem is 00 in the array .PERIOD well ,COMMA an upper bound on the difficulty of the problem is some specific algorithm .PERIOD so ,COMMA for example ,COMMA the brute force algorithm that looked ,COMMA that looks at every array entry is a specific algorithm and it means that and that takes o(n) time .PERIOD we have to look at every ,COMMA it's less than a constant time n for some constant .PERIOD so ,COMMA the running time of the optimal algorithm has to be o(n) that is that's specific algorithm provides an upper bound on the running time of the optimal algorithm .PERIOD and but in this case it's also easy to develop a lower bound ,COMMA that's a proof that no algorithm can do better .PERIOD well ,COMMA for 1 -DASH sum you have to examine all entries in the array .PERIOD if you miss one ,COMMA then that one might be zero so that means that the optimal algorithm has to have a running time at least some constant times n where we say the running time is omega of n .PERIOD now in this case ,COMMA the upper bound and the lower bound match .PERIOD so ,COMMA doing the constant factor so ,COMMA that's a proof that the brute force algorithm for 1 -DASH sum is optimal .PERIOD it's running time is theta(n) .PERIOD it's both omega and o(n) .PERIOD that's ,COMMA for that simple problem it was okay to get the optimal algorithm .PERIOD for a more complicated problems it's going to be more difficult to get upper balance and lower balance and particularly upper balance and lower balance that match .PERIOD for example let's look at 3 -DASH sum .PERIOD so ,COMMA upper bound for 3 -DASH sum ,COMMA say our first brute force algorithm ,COMMA say that the proof ,COMMA was a proof that the running time of the optimal algorithm is o(n^3) but we found a better improved algorithm .PERIOD whose running time is o(n^2) lg n .PERIOD so ,COMMA that's a better upper bound .PERIOD lower bound well ,COMMA we have to examine all entries cuz again ,COMMA we might miss one that makes 3 -DASH sum = zero and that's a proof that the running time in the optimal algorithm is omega(n) but nobody knows higher or lower bound for 3 -DASH sum .PERIOD so there's a gap between the upper bound and the lower bound and open problems .PERIOD is there an optimal algorithm for 3 -DASH sum ?QUESTIONMARK we don't know what it is .PERIOD we don't even know if there's a algorithm whose running time is < o(n^2) or we don't know higher lower bound and linear .PERIOD so that's an example of an open problem in the theory of algorithms we don't know how difficult it is to solve the 3 -DASH sum problem .PERIOD now ,COMMA this point of view has been extremely successful in recent decades .PERIOD we have a new problem ,COMMA develop some algorithm ,COMMA proves some lower bound .PERIOD if there's a gap ,COMMA we look for new algorithm that will lower the upper bound or we try to find a way to raise the lower bound .PERIOD usually it's very difficult to prove non -DASH trivial or lower bounds .PERIOD trivial or lower bound like look at every input items is not so hard non -DASH trivial lower bounds like for example ,COMMA the proof that we're talking about for union -DASH find problem are much more difficult .PERIOD and in the last several decades people have learned about the computational difficulty of problems by examining steadily decreasing upper bounds so the algorithms were better worst case running times for lots and lots of important problems and plenty of optimal algorithms and plenty of gaps still remain .PERIOD it's a fascinating field of research that many people are engaged in .PERIOD now there is a couple of caveats on this on the context to this course .PERIOD and the first one is maybe it's overly pessimistic to be focusing on the worst case .PERIOD we've got data out there .PERIOD we've got problems to solve .PERIOD maybe it's not worst case data and lots of fields of engineering and science .PERIOD we don't focus on the worst case .PERIOD the worst case for this course would be lightning to strike and it would be over so we don't plan for that .PERIOD and since similar it's true for algorithms .PERIOD maybe we should be focusing on understanding prope rties of the input and finding algorithms that are efficient for that input .PERIOD and the other thing is in order to really predict performance and compare algorithms we need to do a closer analysis than to within a constant factor .PERIOD so we talked about the tilde notation in the big theta ,COMMA big o ,COMMA and big omega ,COMMA omega that are used in the theory of algorithms .PERIOD and really there's so much published research in the theory of algorithms that a lot of people make the mistake of interpreting the big o results that are supposed to give improved upper bounds on the difficulty of the problem as approximate models for the running time and that's really a mistake .PERIOD so in this course ,COMMA we're going to focus on approximate models by ,COMMA you know making sure that we use the tilde notation and we'll try to give specific results for certain quantities of interest and the constant ,COMMA any unspecified constant in the running time .PERIOD we'll have to do with properties in the machine and in the system so they will be able to use these results to predict performance and to compare algorithms .PERIOD 
now ,COMMA we'll look at topological sorting .PERIOD a digraph processing application that doesn't quite have a parallel with undirected graphs .PERIOD and it's a very general model that is ,COMMA is very widely ,COMMA widely used and here's the simplest example of it called ,COMMA precedence scheduling .PERIOD so the idea is that you've got a set of tasks that need to be completed ,COMMA but there's precedence constraints ,COMMA and you want to know in what order should you schedule the tasks .PERIOD so ,COMMA you might think that this is like courses in a university curriculum .PERIOD for ,COMMA so is the model we'll us the vertices will be the task and the edges will be the precedence constraint .PERIOD and all these says is there's an edge from three to six ,COMMA that means you have to take introduction to computer science before you take advance programming .PERIOD and so there's so ,COMMA all of these source of constraints in a graph .PERIOD and so what you want is ,COMMA a what's called a feasible schedule ,COMMA so that's just an order in which you can take the linear order ,COMMA in which you can take the courses one after the other that respects the precedence .PERIOD so ,COMMA that corresponds to drawing the graph ,COMMA such that all the edges point upwards .PERIOD and this model is used to study manufacturing processes and many other applications .PERIOD so ,COMMA that's the topological sorting problem .PERIOD so ,COMMA first thing is topological sort works on a dag ,COMMA so called dag .PERIOD that's a digraph that has no cycles .PERIOD if you have a cycle there's no way you're going to be able to solve the problem .PERIOD in fact we'll ,COMMA simpler hraph processing problem is just find out if a graph has a cycle .PERIOD and we'll talk about that in a second ,COMMA but let's do topological sort first .PERIOD so we know that the graph has no cycles .PERIOD it's a directed ,COMMA acyclic graph ,COMMA graph ,COMMA and what we want to do is ,COMMA find a way to redraw the dag ,COMMA so that all the edges point upwards ,COMMA yh ,COMMA or give ,COMMA a bottom to top order so that all the edges are pointing upward .PERIOD that's called a topological order of the graph .PERIOD and ,COMMA that'll give ,COMMA in this case ,COMMA an order in which maybe you could take the courses or perform the manufacturing process or whatever else .PERIOD so ,COMMA that's the problem .PERIOD so how are we going to solve it ?QUESTIONMARK well ,COMMA we're going to use dfs .PERIOD in fact ,COMMA one of the lessons for particularly for digraph processing is dfs is going to provide a way to solve it .PERIOD it might be hard to find a different way .PERIOD so let's look at a demo of topological sort .PERIOD and all of this is just run dfs ,COMMA but there is a particular point in which we ,COMMA we want to take the vertices out to get the order ,COMMA and that's called reverse dfs post -DASH order .PERIOD so ,COMMA lets look at how that works .PERIOD what we do is ,COMMA when we do the dfs ,COMMA when we are done with the vertex we put it on a stack or put it out ,COMMA so ,COMMA lets look at how that works .PERIOD so ,COMMA we had just run dfs the same as before ,COMMA but we're not keeping track of anything ,COMMA except the vertices that we're done with .PERIOD so ,COMMA visit ,COMMA visit ,COMMA vertex zero .PERIOD we have to check the places that you can get to it from zero .PERIOD it's one ,COMMA two ,COMMA and five .PERIOD so we check one ,COMMA one is unmarked ,COMMA so we're going to mark it and recursively visit one .PERIOD so we do that and we have to check four and four again is unmarked ,COMMA so we recurse .PERIOD but now both of the edges to four are in ,COMMA so there's nowhere to go from four ,COMMA so we're done with four .PERIOD when we're done with four ,COMMA we output it ,COMMA actually put it on a stack .PERIOD so that's order ,COMMA the order in which we're done with the vertices .PERIOD that's called postorder .PERIOD so now ,COMMA once we're done with four ,COMMA now we're done with one ,COMMA there's no where else to go so we put it on the post order .PERIOD and now ,COMMA we're back at zero and we have to check the other vertices that we get to from zero .PERIOD so ,COMMA here's two and get two from two ,COMMA and ,COMMA it's unmarked ,COMMA so we visit it .PERIOD but there's no place to go ,COMMA so we're done with it .PERIOD so we put it on the postorder and go back to zero .PERIOD then we go to five ,COMMA unmarked ,COMMA so we visit it .PERIOD then we check two ,COMMA which is marked ,COMMA so nothing to do .PERIOD and then we're done with five .PERIOD and ,COMMA once we're done with five ,COMMA then we're done with zero .PERIOD and that's the postorder of the vertices that you can get to it from zero .PERIOD so now we have to check all the other vertices in the graph ,COMMA but we have to find some other place ,COMMA and so we just check the vertices in order .PERIOD next one that we find that's unmarked is three .PERIOD and so to visit three ,COMMA we have to check ,COMMA two ,COMMA four ,COMMA five ,COMMA and six .PERIOD and two ,COMMA four ,COMMA and five ,COMMA are all marked ,COMMA so nothing to do .PERIOD six is unmarked ,COMMA so we go visit six .PERIOD when we visit six ,COMMA zero and four are ,COMMA already ,COMMA marked ,COMMA so there's nothing to do .PERIOD then we're done with six ,COMMA and finally ,COMMA we're done with three .PERIOD and we're done with the vertex .PERIOD we'd put it out .PERIOD that's or if we put it on a stack ,COMMA and then we get reverse postorder and that turns out is the answer that we need .PERIOD so the code is pretty simple but we'll have to look a little more carefully to be convinced that it works .PERIOD so it's depth -DASH first search but we have additional data structure ,COMMA which is a stack of integers ,COMMA which is the vertices and reverse postorder .PERIOD the constructor just creates that stack ,COMMA and then the only thing we change to dfs is when we're done with the vertex ,COMMA before exiting ,COMMA we put that vertex on the reverse post stack .PERIOD and then the client simply gets the stack returned ,COMMA that's inevitable .PERIOD and iterating through that will give the vertices in the reverse dfs postorder which is the order you which is the topologically sorted order .PERIOD it's a very simple and compelling use of dfs .PERIOD actually this is an amazingly simple algorithm ,COMMA but it went undiscovered for many years .PERIOD people were using much more complicated algorithms for this problem .PERIOD okay .PERIOD so ,COMMA reverse dfs postorder of a dag is the topological order .PERIOD that's ,COMMA the correctness proof ,COMMA that we have to consider .PERIOD this diagram over here ,COMMA is a record of the recursive calls ,COMMA for that example that we just did .PERIOD to visit zero ,COMMA we probably visit one ,COMMA and then we visit four .PERIOD and then we're done with four ,COMMA and then we're done with one .PERIOD and then we visit two ,COMMA down with two ,COMMA then do five ,COMMA which checks two ,COMMA and five down and so forth .PERIOD so this gives a record of the calls ,COMMA just ,COMMA for reference in this proof for that example .PERIOD alright .PERIOD so now ,COMMA we want to consider any edge where v points to w and we want to consider the point where dfs of v is called .PERIOD and there's a bunch of cases .PERIOD so one case is that dfs w ,COMMA has already been called and returned .PERIOD so in this example ,COMMA when v equals three ,COMMA w equals two ,COMMA four ,COMMA or five ,COMMA they were already done .PERIOD so ,COMMA if we put out ,COMMA those vertex numbers ,COMMA before we put ,COMMA three out ,COMMA then the arrow from v to w is going to point up .PERIOD they were already done .PERIOD so that's case one .PERIOD that's an easy case .PERIOD case two ,COMMA they're all easy cases .PERIOD [laugh] case two is ,COMMA dfs w hasn't ,COMMA been called yet ,COMMA but if there's an edge from v to w we're going call it and then recurse ,COMMA it's going to finish before we're done with three .PERIOD so again ,COMMA the edge from v to w is going to point out ,COMMA three to six .PERIOD and the only other possible case might be that ,COMMA dfs w is already been called but not returned .PERIOD but that can't happen ,COMMA in ,COMMA because there's no cycles .PERIOD if d ,COMMA dfs w had been called but not yet returned ,COMMA then the function call stack is going to ,COMMA from it's ,COMMA it's going to have path from w to v on it .PERIOD and so .PERIOD if we have an edge v -DASH w ,COMMA that would give a cycle ,COMMA but there is no cycles .PERIOD so from those observations we know that all vertices pointing from three are done before three is done ,COMMA so they appear after three in the topological order ,COMMA or they point up if we put the vertices in reverse topological order .PERIOD so that's the correctness proof for topological order .PERIOD so ,COMMA a similar ,COMMA process ,COMMA is ,COMMA to detect a cycle .PERIOD a topological sort doesn't work if a graph's got a cycle ,COMMA so one of the things we might want to do is ,COMMA just ,COMMA find cycles in digraphs .PERIOD now ,COMMA if you're a college and you put out a curriculum that's got a directed cycle ,COMMA you have your problem so you might want to process that first .PERIOD so ,COMMA if there's a directed cycle ,COMMA you can't have a topological order .PERIOD if there's no directed cycle then we've just found it .PERIOD so ,COMMA one thing you might want ,COMMA is given a digraph ,COMMA find a directed cycle .PERIOD and how are you going to do that ?QUESTIONMARK you're going to use dfs and that's a simple algorithm that you might want to think about and ,COMMA it's in a few lines in the book .PERIOD so ,COMMA precedence scheduling is a ,COMMA an excellent example of the use of search directed graph ,COMMA and ,COMMA this is the cycle of length one .PERIOD of course ,COMMA that requires itself as a prerequisite .PERIOD and ,COMMA this is just an example of a very widely computation .PERIOD and it really has many ,COMMA many applications .PERIOD so for example ,COMMA the java compiler actually does cycle con ,COMMA detection .PERIOD if you have a class a extends b ,COMMA and another one b extends c ,COMMA and another one c extends a ,COMMA that's going to create a problem .PERIOD class hierarchies are not supposed to have cycles ,COMMA and it'll actually ,COMMA the java compiler will actually give a ,COMMA an error message saying there's cyclic inheritance .PERIOD you're not allowed to do that .PERIOD so there's many applications that involve essentially digraphs that aren't supposed to add cycles .PERIOD another example is microsoft excel .PERIOD so if you do cyclic reference like this in excel ,COMMA which in a big spreadsheet ,COMMA now you can imagine might  .PERIOD .PERIOD that's ,COMMA that's an error ,COMMA and not only this microsoft excel flag the error .PERIOD it says you have ,COMMA created a circular reference ,COMMA try one of the following ,COMMA and it's actually got a circular reference toolbar ,COMMA that will help you figure out ,COMMA what to do ,COMMA in that case .PERIOD so ,COMMA cycle detection and topological sorting are important applications in depth -DASH first and digraphs .PERIOD 
so far ,COMMA we've been talking about running time .PERIOD now we have to talk about the memory requirements over our programs as well .PERIOD well ,COMMA the basics are we want to know how many bits the program use or bytes ,COMMA eight bits at a time .PERIOD and actually ,COMMA we'll be talking in terms of millions of bits or billions of bits and actually surprisingly there is a controversy about even these basic definitions .PERIOD computer scientists think of a million bits is two^20 and a billion is two^30 because that's a number of possible things that you can fit into 30 bits and everything is consistent with our calculations .PERIOD other scientists stick to one million or one billion for a lots of reasons we'll usually use two^20 ,COMMA i mean ,COMMA a megabyte .PERIOD now an old computers we used to for many years ,COMMA we use a 32 -DASH bit machine so that pointers were four bytes .PERIOD just in recent years we've mostly switched to a model where machines are 64 -DASH bits and pointers are eight bytes .PERIOD that allows us to address much more memory but pointers use much more space and actually this transition caused a lot of problems initially because programs were using way more space than people thought they should .PERIOD you're not going to have to go through this kind of transition the way that we did because 64 bits is definitely enough to address anything that you might need to address ,COMMA two^64 is really a huge number .PERIOD so in terms of bytes we have to start out with typical memory usage .PERIOD now ,COMMA again ,COMMA this is very dependent on machine and implementation but these numbers are reasonable and are found on typical implementations .PERIOD so a boolean ,COMMA it will be nice of a boolean just took a bit cuz that's just true or false but actually ,COMMA usually we have to count for a byte for a boolean .PERIOD all byte is a byte .PERIOD character nowadays is two byte ,COMMA 16 -DASH bit characters .PERIOD not that a long ago we used eight bit for chars .PERIOD integer regular int is four bytes or 32 bits and a float is also four bytes long int is eight and a double is eight .PERIOD usually ,COMMA we use double for floating point and ints for integers in most applications .PERIOD so ,COMMA that's for primitive types .PERIOD and then for arrays there's a certain amount of overhead for making an array and then if there's n items ,COMMA it's whatever the cost of the primitive type times n so an array of doubles is say 8n + 24 .PERIOD and two -DASH dimensional array then well ,COMMA we can go ahead and compute the exact thing but now ,COMMA now ,COMMA it's time to use ,COMMA the tilde notation .PERIOD and then for arrays we could say a double is tilde 8n for one -DASH dimensional .PERIOD for two -DASH dimensional ,COMMA two -DASH dimensional array of doubles is tilde 8mn .PERIOD and there's extra terms for the over head but for large m and n that's going to be pretty accurate .PERIOD so ,COMMA that's our basic usage for primitive types and arrays in a typical java implementation .PERIOD now ,COMMA a lot of our programs and objects like link list and so forth .PERIOD so ,COMMA we have to also factor in object overhead to crossover reference and also there's padding built in ,COMMA in typical implementations to make it so that each object has used a multiple of eight bytes .PERIOD so ,COMMA for example if you have a date object that had three int instance variables then that object would take a total of 32 bytes .PERIOD each int takes four bytes ,COMMA object overhead is sixteen bytes .PERIOD it needs four bytes for padding so it's a total of 32 bytes .PERIOD so and the other one that often comes up is a string and the string is a little bit more complicated than a than an array but the typical implementation of a string in java has a ,COMMA a reference out to an array of characters and then ,COMMA its got int values for offset count in a hash value and then some padding and adding it all together the [cough] cost of the string is about 2n + 64 bytes .PERIOD so ,COMMA these are the basics that we need to analyze the memory usage for a typical java program .PERIOD a h ,COMMA so for primitive ,COMMA for data type value ,COMMA if it's a primitive type it's four for an eight ,COMMA and eight for a double ,COMMA and so forth .PERIOD if it's a reference ,COMMA it's going to be eight bytes and that's for the pointer takes array 24 bytes plus the memory for each entry in an object sixteen bytes plus the memory for the instance variable plus if there's an inner class  ,COMMA it's another eight bytes as we talked about with nodes for link list .PERIOD and then there's the padding .PERIOD so then we have to ,COMMA to think about who is responsible for referenced objects ,COMMA you know ,COMMA in ,COMMA in some cases .PERIOD and we'll take care of that when we get to these situations .PERIOD so ,COMMA as an example ,COMMA a simple example of memory use analysis ,COMMA let's take a look at how much memory are rated quick union uf function from a ,COMMA a few lectures ago ,COMMA uses as a function of n .PERIOD and there's only a couple of memory elements and each one of them are easily analyzed using the basics that we just gave it's an object so the sixteen bytes of object overhead there's two int arrays .PERIOD each one of them have array overhead of 24 plus and then 4n for the n entries .PERIOD each and vn entries takes four bytes and there's four bytes for the count and there's four bytes for the padding and if you add it altogether it gets 8n + 88 which is tilde 8n and again ,COMMA all that's saying is when n is large ,COMMA all we are going to care about in terms of analyzing the memory is that we've got [cough] 2n integers two arrays of size n each one of which takes four bytes for a grand total of 8n bytes .PERIOD okay .PERIOD so ,COMMA in summary we really can figure out how many times we have to turn the crank on modern computers .PERIOD we can do it with empirical analysis where we actually execute the program ,COMMA can do experiments and use [inaudible] power law ,COMMA formulate hypothesis and make predictions .PERIOD but we can do more ,COMMA we can do mathematical analysis where we can identify the most costly operations ,COMMA analyze the frequency of execution of those operations and using the tilde notation to simplify analysis .PERIOD we can actually explain the behavior ,COMMA not just predict it .PERIOD and this is a fine example of the use of the scientific method to understand the artifacts that we're studying ,COMMA the algorithms .PERIOD our mathematical models are usually independent of a particular computer system and even implied to machines that are not yet built .PERIOD but we always validate our mathematical models by running experiments on real machines so that we can be confident where we're making predictions and analyzing algorithms .PERIOD 
as our final digraph processing algorithm ,COMMA we'll take a look at computing strong components .PERIOD so the definition two vertices ,COMMA v and w ,COMMA in a digraph are strongly connected if there's a directed path from v to w and another directed path from w to v .PERIOD and the thing about strongly connected is that it's unequivalence relation .PERIOD that is each vertex is strongly connected to itself .PERIOD if v is connected to w ,COMMA strongly ,COMMA and w is strongly connected to ,COMMA to ,COMMA then w is strongly connected to v .PERIOD that just means that paths ,COMMA directed paths connecting them .PERIOD and it's also transitive .PERIOD if v is connected to w and w to x ,COMMA ,COMMA then v is strongly connected to x .PERIOD how to get from v to x ?QUESTIONMARK you go from w ,COMMA v to w and w to x ,COMMA and get from x to v ,COMMA you go from x to w and w to v .PERIOD so ,COMMA that means that since it's an equivalence relation ,COMMA it divides the digraph up into components ,COMMA into sets called strongly connected components that have the property that there's directed paths connecting each pair of vertices in the set .PERIOD so ,COMMA for example nine and twelve are strongly connected ,COMMA there's a path from twelve to nine ,COMMA another one from nine to twelve and so forth .PERIOD so the ,COMMA our challenge is to compute the strong components in diagraphs .PERIOD and it's worth comparing this to what we did for connected components in undirected graphs .PERIOD so ,COMMA this is just a quick review .PERIOD in an undirected graph ,COMMA if there's a path between two vertices that are connected ,COMMA that's an equivalence relation ,COMMA divides them up into connective components .PERIOD and what we did was ,COMMA our design pattern is to build our graph processing algorithm as a constructor that takes a graph and does the pre -DASH processing to create a table like this one which assigns a unique id to all the vertices in each given component .PERIOD so ,COMMA that we can have a constant time client query to check whether two given vertices are in the same connected component or not .PERIOD so ,COMMA linear time processing ,COMMA pre -DASH processing in the constructor to build the table ,COMMA constant time client queries .PERIOD and that's as good performance as we can expect to have for a graph for a graph processing algorithm .PERIOD remarkably ,COMMA now ,COMMA we're able to do the same thing for strong connectivity .PERIOD it's a ,COMMA it's a much more sophisticated algorithm but the design pattern and the bottom line for the client is the same .PERIOD there's a constructor ,COMMA it processes the graph in linear time .PERIOD and it assigns a unique id to each one of the strongly connected components in the graph .PERIOD so ,COMMA once in the component by itself ,COMMA zero ,COMMA two ,COMMA three ,COMMA four ,COMMA and five six ,COMMA and eight ,COMMA seven ,COMMA and nine ,COMMA ten ,COMMA and twelve ,COMMA there's five different strongly connected components in this graph .PERIOD the constructor builds that array and the client gets to in constant time ,COMMA know whether two vertices are strongly connected or not .PERIOD it's quite amazing that we can solve this problem in this way .PERIOD and as i'd mentioned it's got an interesting history that we'll talk about in a second .PERIOD so ,COMMA here's an example of strong component application .PERIOD so ,COMMA the food web graph ,COMMA this is a very small subset of that graph .PERIOD the vertices are all the ,COMMA species and an edge goes from producer to consumer .PERIOD so ,COMMA if animal a eats animal b ,COMMA there's an edge from a to b .PERIOD and what a strong component corresponds to in this graph is a kind of a subset of species that ,COMMA have a common energy flow .PERIOD they naturally eat each other .PERIOD and that's extremely important in ecological studies .PERIOD another example is again ,COMMA in processing software big software is made up of modules .PERIOD and the vertices are ,COMMA are ,COMMA are ,COMMA are the modules .PERIOD and edges is if one depends on another .PERIOD and so a strong component in this graph is a subset of mutually interacting modules .PERIOD and in a huge program like internet explorer you want to know what the strong components are so that you can package them together and maybe improve the design .PERIOD so again ,COMMA software you know ,COMMA can ,COMMA these graphs can be huge .PERIOD and this kind of graph processing can be extremely important in improving the design of software .PERIOD now again this algorithm has an interesting history ,COMMA ,COMMA it along with scheduling and other things that's a core problem in operations research that was widely studied ,COMMA but really not understood how difficult it was .PERIOD in tarjan's paper in 1972 was a big surprise that this could be solved in linear time with depth research .PERIOD now this algorithm had a couple of other data structures and this i guess ,COMMA a diligent student in this class could understand it with quite a bit of work .PERIOD but it really demonstrated the importance of depth -DASH first search in great graph processing .PERIOD now ,COMMA the algorithm that we're going to talk about today actually was invented in the 80s' by kosaraju and ,COMMA and independently by sharir .PERIOD the story goes that kosaraju had to go lecture about tarjan's algorithms and he forgot his notes .PERIOD and he had taught it a number of times ,COMMA he was trying to figure out what tarjan's algorithm did and he developed this other algorithm that's extremely simple ro implement .PERIOD that's what we're going to look at today ,COMMA today .PERIOD and actually in the 1990s gabow and mehlhorn and particularly ,COMMA melhorn had to implement this algorithm for a big software package and he found another simple linear time algorithm .PERIOD now ,COMMA so ,COMMA this story indicates even from fundamental problems in graph processing there's algorithms out there still waiting to be discovered and this ,COMMA this algorithm is a good example of that .PERIOD so we give the intuition in the code and you see how the algorithm works fully convincing yourself or proving why it works is a bit more of a challenge .PERIOD now ,COMMA we'll leave that mostly for the book .PERIOD but let's describe what it is .PERIOD so ,COMMA the first idea is to think about the reverse graph .PERIOD so if we take a graph and we reverse the sense of all the edges we're going to get the same ,COMMA strong components .PERIOD we need edges in both directions .PERIOD so ,COMMA if we switch the directions ,COMMA we're still going to have edges in both directions .PERIOD the ,COMMA the second concept is called the ,COMMA the ,COMMA the kernel dag .PERIOD and what that does ,COMMA is it kind of ,COMMA you think about contracting each strong component into a single vertex .PERIOD and then ,COMMA just to worry about the edges that go from one strong component to another .PERIOD so the digraph that you get that way ,COMMA turns out to be a cyclic .PERIOD if it was cyclic ,COMMA it would involve ,COMMA it would create a bigger strong component ,COMMA a couple of strong components into one .PERIOD so if we think about that processing that kernel dag ,COMMA that's the edges that go between strong components and we get a dag and we know how to deal with a dag so ,COMMA the idea of the algorithm is to go ahead and compute the topological order or the reverse post order in the kernel dag .PERIOD at least put up the edges of the original digraph in order so that all the edges in the kernel dag point from right to left ,COMMA that's like a topological sort .PERIOD and then we run dfs but instead of considering the vertices in ,COMMA in numerical order for the dfs ,COMMA we consider them in that reverse topological order .PERIOD so it's extremely easy to implement this algorithm .PERIOD of course ,COMMA we're going to use dfs .PERIOD so let's look at a demo at how the algorithm works .PERIOD ,COMMA okay ,COMMA so ,COMMA this is a digraph ,COMMA and our goal is to compute the strong components .PERIOD and we're going to do it in two phases ,COMMA two dfss .PERIOD one is to compute the reverse post order and the reverse of the graph .PERIOD and the other is to run the dfs but for the other in which we visit the vertices ,COMMA we use that reverse post order that we've computed .PERIOD so here goes .PERIOD so ,COMMA first ,COMMA we'll do the dfs and the reverse graph .PERIOD so that's the graph ,COMMA that's the reverse graph .PERIOD remember ,COMMA these two has the same strong component .PERIOD so ,COMMA there's our marked array .PERIOD we will do the dfs ,COMMA and reverse post order means that when we are done with the vertex ,COMMA we'll put it out .PERIOD so checked six unmarked ,COMMA checked eight unmarked checked six ,COMMA it's marked .PERIOD so we're done with a answer ,COMMA that's the reverse post order .PERIOD and again ,COMMA as before ,COMMA put it on a stack and but we'll just list them in reverse order in this demo .PERIOD so ,COMMA eight is done .PERIOD so ,COMMA six lots of places to go from six .PERIOD so ,COMMA let's check seven .PERIOD that's unmarked ,COMMA so we go to seven .PERIOD no place to go from seven ,COMMA so we're done with seven .PERIOD we put it on the reverse post order list .PERIOD we're also done with six .PERIOD cuz four and nine are coming in ,COMMA in this example ,COMMA so i put it on the list .PERIOD next place to go from zero is two ,COMMA so we checked two that's unmarked so we mark it and recurse and we checked the vertices adjacent to two .PERIOD first ,COMMA four ,COMMA that's unmarked .PERIOD so ,COMMA then we recurse and go to four .PERIOD we gotta got to ,COMMA to eleven first and recurse so now we're at eleven .PERIOD and ,COMMA and from eleven ,COMMA we go to nine ,COMMA which is unmarked .PERIOD so we have a pretty long recursive stack right here .PERIOD so ,COMMA from nine ,COMMA there's we have to check a bunch of things ,COMMA we'll check twelve first and then visit twelve .PERIOD it's unmarked from twelve ,COMMA we checked eleven which is marked ,COMMA nowhere to go .PERIOD then ,COMMA we checked ten .PERIOD that's unmarked ,COMMA so we go to ten .PERIOD visit ten it's ,COMMA it's unmarked so we recurse and then go to nine .PERIOD and that's marked and that's everywhere we get from ten .PERIOD so ,COMMA we're done with ten ,COMMA so we put it on the list and return .PERIOD and now ,COMMA where done with twelve ,COMMA so we put it on the list and return .PERIOD and now ,COMMA at nine ,COMMA we have to check seven ,COMMA which is marked ,COMMA and six ,COMMA which is marked .PERIOD and then ,COMMA we're done so we put it on the list .PERIOD then ,COMMA we're done with eleven we put it on the list .PERIOD then we're finished with four ,COMMA so we checked six which is marked ,COMMA then we checked five ,COMMA which is unmarked so we recurse to five .PERIOD from five ,COMMA we checked three which is unmarked so we recurse .PERIOD then ,COMMA we checked four which is mark ,COMMA we checked two which is mark .PERIOD and then we're done with three ,COMMA so we put it on the list .PERIOD and then from five we checked zero it's marked so we're done with five ,COMMA we put it on the list .PERIOD and that means that we're now done with four .PERIOD and then ,COMMA we're also done with two ,COMMA after checking three .PERIOD and then ,COMMA we go to zero and put it on the list .PERIOD so ,COMMA that's all the vertices that ,COMMA you know ,COMMA you get through from zero .PERIOD so ,COMMA we look for more vertices and it's one and it's marked so that's the last one in the reverse post order .PERIOD so ,COMMA that's a reverse post order of the reverse graph .PERIOD and all we're going to do is take that order and use that order to check vertices at the top level in the depth -DASH first search of our regular graph .PERIOD we have to check all the other vertices to make sure we are done .PERIOD so ,COMMA that's phase one .PERIOD so now ,COMMA we'll just do a dfs in the original graph ,COMMA using that order that we just computed .PERIOD so ,COMMA we don't start with zero ,COMMA the way we always have ,COMMA now we start with one .PERIOD we visit one ,COMMA its unmarked and now all the vertices that we visit during that dfs are going to be in that same strong component ,COMMA that's the theorem that makes this algorithm work ,COMMA in this case ,COMMA this is only the one ,COMMA so vertex one is its own ,COMMA is in its own strong component with label zero .PERIOD so now ,COMMA we've got to start ,COMMA once all done ,COMMA so now ,COMMA we have to start with looking for another vertex to search from .PERIOD in this case ,COMMA it's zero that's second on the list .PERIOD so that's where we start ,COMMA with zero .PERIOD and now ,COMMA all the vertices that we can reach from zero are going to have strong ,COMMA in this graph ,COMMA are going to have strong component label one .PERIOD so ,COMMA we do the dfs .PERIOD so ,COMMA first ,COMMA we get to five .PERIOD that's in the same strong component we checked four .PERIOD and it's unmarked .PERIOD so ,COMMA we label it .PERIOD we checked three ,COMMA it's unmarked .PERIOD we checked five ,COMMA which is marked .PERIOD we checked two ,COMMA which is unmarked .PERIOD so now we have shown that zero ,COMMA two ,COMMA three ,COMMA four ,COMMA and five are all in the same strong component .PERIOD and now we're going to find both vertices we can get three from two or mark .PERIOD so we're done with two then we're done with three .PERIOD four ,COMMA we have to check two ,COMMA which is marked .PERIOD and then ,COMMA we're done with four and five .PERIOD from zero we can check one but that's already marked so that's not relevant for this search and then we're done with zero .PERIOD and we've established that zero ,COMMA two ,COMMA three ,COMMA four ,COMMA and five are all in the same strong component .PERIOD  ,COMMA so that's the second one .PERIOD so now ,COMMA we continue and we check all of those and they're all marked .PERIOD so ,COMMA the next vertex in the reverse post order of the reverse graph is eleven so we visit eleven .PERIOD checked four ,COMMA it's already marked .PERIOD checked twelve ,COMMA it's not so aj .PERIOD we mark it ,COMMA and these are the third strong component .PERIOD they get labeled with two .PERIOD then ,COMMA we get to nine .PERIOD from nine ,COMMA we check eleven and nowhere to go .PERIOD then ,COMMA we checked ten ,COMMA and so that's seems a strong component .PERIOD from ten ,COMMA we checked twelve ,COMMA which is marked .PERIOD we're done with ten ,COMMA were done with nine ,COMMA were done with twelve ,COMMA and were done with eleven .PERIOD so ,COMMA that's our second strong or third strong component nine ,COMMA ten ,COMMA eleven and twelve .PERIOD so we're done with those and now we go through the list to find another unmarked vertex .PERIOD nine is marked ,COMMA twelve is marked ,COMMA ten is marked .PERIOD we get to six from six nine is already marked .PERIOD four is four is already marked .PERIOD eight is not marked so we go there .PERIOD from eight ,COMMA we get to six and that's it .PERIOD zero is already marked so we can only get to eight from six at this point ,COMMA and so that's a strong component .PERIOD and then finally ,COMMA we finish up by doing seven .PERIOD so the end of the computation gives us the strong component array ,COMMA which is a unique id for each of the vertices so that two vertices in the same strong component have the same id .PERIOD and that supports constant time strong connectivity checks for clients .PERIOD and so ,COMMA the bottom line is that this algorithm is a very simple even though it might be mysterious algorithm for computing the strong component .PERIOD first ,COMMA run dfs on the reverse graph to compute the reverse post order .PERIOD then ,COMMA run dfs on the original graph considering the vertices in the order given by the first dfs .PERIOD and so these ,COMMA these diagrams give a summary of the computation .PERIOD i'm not going to spend too much time explaining why and how it works in this lecture .PERIOD but these kinds of diagrams give the detail that can give some intuition about how and why the algorithm works .PERIOD the for the proof it requires some mathematical sophistication and find it in the book .PERIOD but the programming of it is quite simple and proved that it's efficient is and all it does is run dfs twice but to really see the correctness proof you want to look a the second printing of the textbook .PERIOD we got it wrong in the first printing .PERIOD and ,COMMA but look at the implementation so ,COMMA this is connected components and in the undirected graph with dfs that we did last time and i'm sure many of you thought that it was one of the simplest algorithms that we looked at .PERIOD we just marked the vertices and do recursive and that's the end of it .PERIOD if you take that code and just had i'll change the names .PERIOD and then just instead of going for the vertices from zero through v minus one if you first compute the depth -DASH first order that you get by running doing that first search of the reverse graph and then you iterate through the vertices in that order ,COMMA you get an algorithm for strong connectivity .PERIOD it's really remarkable that just changing that one line will perform this computation that was thought to be difficult for ,COMMA ,COMMA for many years ,COMMA and ,COMMA and people were learning quite difficult codes for ,COMMA for many ,COMMA many years .PERIOD so ,COMMA that's a quick summary of digraph processing .PERIOD we talked about single source reachability getting the paths from a vertex to any vertex that can be reached from that vertex with a directed path .PERIOD we talked about topological sort in graphs that have no cycles and that uses dfs .PERIOD and we talked about computing strong components in a digraph with two dfss .PERIOD digraph processing is really h ,COMMA a testimony to the ingenuity that's possible in algorithm and graph processing .PERIOD 
in fact the order of growth classifications are so important they've led to enormous amount of research in recent years and just talk briefly about that now .PERIOD so there is ,COMMA life is a little bit more complicated than pointed out in the last example and one problem is that the inputs can cause the performance of the algorithm to vary widely .PERIOD so often we have to think about different ways of analyzing the algorithm depending on the input .PERIOD so ,COMMA the running time is going to be somewhere between the best case and the worst case .PERIOD best case is the lower bound on cost it .PERIOD it provides something that the running time is going to be bigger than that always or not less than that and then there's the worst case which is the most difficult input .PERIOD if we analyze that then we can guarantee that the running time in the algorithms not going to be bigger than that .PERIOD and then in a lot of situations we might consider our input to be random .PERIOD well we need to ,COMMA someway to model ,COMMA what we mean by random for the problem that we're solving but there is a lot of situations where we can do that and then we have a way to predict performance even when the input might vary widely .PERIOD so for example for 3 -DASH sum ,COMMA it's kind of always the same .PERIOD with the tilde notation ,COMMA the only variability in that algorithm is the number of times the counter is incremented and that's in low order terms so it doesn't need to chew up in our analysis .PERIOD for binary search it's ,COMMA you might find the thing right away in which case is constant time and we can show that the average and the worst case are both lg based two(n) .PERIOD there's other ,COMMA in another examples that be much more variability even .PERIOD so ,COMMA we have this different types of analysis depending on the input .PERIOD and but the question is ,COMMA what about the actual problem that the client is trying to solve ?QUESTIONMARK so we have to understand that two in order to be able to understand performance of the algorithm .PERIOD and there's two approaches that are ,COMMA or successful in this .PERIOD one is to design for the worst case .PERIOD just to make sure that your algorithm are ,COMMA always runs quickly and that's definitely ideal .PERIOD another is to ,COMMA if you can't do that is to randomize and then depend on some kind of probabilistic guarantee and we'll see examples of both of these as we go through the course .PERIOD now ,COMMA those kinds of considerations ,COMMA you know the idea of order of growth leads to discussion of ,COMMA what's called ,COMMA what i call the theory of algorithms .PERIOD and here our goals are ,COMMA we have a problem to solve like solve the 3 -DASH sum problem and we want to know how difficult it is .PERIOD we want to find the best algorithm for solving that problem .PERIOD the approach that the computer scientist use for this is to try to suppress as many details as possible in the analysis .PERIOD and so just analyze the running time to or within a constant factor .PERIOD that's what order of growth is getting at and also i want to ,COMMA not worry about the input model at all .PERIOD and so we focused on worst case design and we can talk about performance of algorithms just in turn of the order of growth and it's actually possible ,COMMA it's actually possible to do that in a very rigorous way that it's taught us a lot about the difficulty of solving problems .PERIOD and our goal is to find an optimal algorithm where we can guarantee to within a constant factor certain performance for any input cuz we discovered the worst case but we also can have approved that didn't know algorithm could provide a better performance guarantee .PERIOD i'll give a couple of easy examples of this .PERIOD now in order to do this they're ,COMMA these commonly used notations called the big theta ,COMMA big o and big omega notations .PERIOD so the and those definitions are given here .PERIOD so big theta notation is just the way to describe the order of growth .PERIOD theta(n)^2 is kind of short hand for anything n^2 .PERIOD it's bounded above and below by constant time n^2 and that's what we really use to classify algorithms .PERIOD and then ,COMMA there is big o notation which is upper bounds on performance .PERIOD when we say o(n^2) ,COMMA we mean that it's less than some constant time n^2 as n grows .PERIOD and big omega is used for lower bounds means greater than some constant time n^2 as n grows .PERIOD so those three notations were able to use to classify algorithms and i'll show them in the following .PERIOD so ,COMMA examples from our 1 -DASH sum ,COMMA 2 -DASH sum ,COMMA and 3 -DASH sum are easy to articulate so our goals are to establish the difficulty of the problem and to develop an optimal algorithm .PERIOD so ,COMMA the 1 -DASH sum problem is 00 in the array .PERIOD well ,COMMA an upper bound on the difficulty of the problem is some specific algorithm .PERIOD so ,COMMA for example ,COMMA the brute force algorithm that looked ,COMMA that looks at every array entry is a specific algorithm and it means that and that takes o(n) time .PERIOD we have to look at every ,COMMA it's less than a constant time n for some constant .PERIOD so ,COMMA the running time of the optimal algorithm has to be o(n) that is that's specific algorithm provides an upper bound on the running time of the optimal algorithm .PERIOD and but in this case it's also easy to develop a lower bound ,COMMA that's a proof that no algorithm can do better .PERIOD well ,COMMA for 1 -DASH sum you have to examine all entries in the array .PERIOD if you miss one ,COMMA then that one might be zero so that means that the optimal algorithm has to have a running time at least some constant times n where we say the running time is omega of n .PERIOD now in this case ,COMMA the upper bound and the lower bound match .PERIOD so ,COMMA doing the constant factor so ,COMMA that's a proof that the brute force algorithm for 1 -DASH sum is optimal .PERIOD it's running time is theta(n) .PERIOD it's both omega and o(n) .PERIOD that's ,COMMA for that simple problem it was okay to get the optimal algorithm .PERIOD for a more complicated problems it's going to be more difficult to get upper balance and lower balance and particularly upper balance and lower balance that match .PERIOD for example let's look at 3 -DASH sum .PERIOD so ,COMMA upper bound for 3 -DASH sum ,COMMA say our first brute force algorithm ,COMMA say that the proof ,COMMA was a proof that the running time of the optimal algorithm is o(n^3) but we found a better improved algorithm .PERIOD whose running time is o(n^2) lg n .PERIOD so ,COMMA that's a better upper bound .PERIOD lower bound well ,COMMA we have to examine all entries cuz again ,COMMA we might miss one that makes 3 -DASH sum = zero and that's a proof that the running time in the optimal algorithm is omega(n) but nobody knows higher or lower bound for 3 -DASH sum .PERIOD so there's a gap between the upper bound and the lower bound and open problems .PERIOD is there an optimal algorithm for 3 -DASH sum ?QUESTIONMARK we don't know what it is .PERIOD we don't even know if there's a algorithm whose running time is < o(n^2) or we don't know higher lower bound and linear .PERIOD so that's an example of an open problem in the theory of algorithms we don't know how difficult it is to solve the 3 -DASH sum problem .PERIOD now ,COMMA this point of view has been extremely successful in recent decades .PERIOD we have a new problem ,COMMA develop some algorithm ,COMMA proves some lower bound .PERIOD if there's a gap ,COMMA we look for new algorithm that will lower the upper bound or we try to find a way to raise the lower bound .PERIOD usually it's very difficult to prove non -DASH trivial or lower bounds .PERIOD trivial or lower bound like look at every input items is not so hard non -DASH trivial lower bounds like for example ,COMMA the proof that we're talking about for union -DASH find problem are much more difficult .PERIOD and in the last several decades people have learned about the computational difficulty of problems by examining steadily decreasing upper bounds so the algorithms were better worst case running times for lots and lots of important problems and plenty of optimal algorithms and plenty of gaps still remain .PERIOD it's a fascinating field of research that many people are engaged in .PERIOD now there is a couple of caveats on this on the context to this course .PERIOD and the first one is maybe it's overly pessimistic to be focusing on the worst case .PERIOD we've got data out there .PERIOD we've got problems to solve .PERIOD maybe it's not worst case data and lots of fields of engineering and science .PERIOD we don't focus on the worst case .PERIOD the worst case for this course would be lightning to strike and it would be over so we don't plan for that .PERIOD and since similar it's true for algorithms .PERIOD maybe we should be focusing on understanding prope rties of the input and finding algorithms that are efficient for that input .PERIOD and the other thing is in order to really predict performance and compare algorithms we need to do a closer analysis than to within a constant factor .PERIOD so we talked about the tilde notation in the big theta ,COMMA big o ,COMMA and big omega ,COMMA omega that are used in the theory of algorithms .PERIOD and really there's so much published research in the theory of algorithms that a lot of people make the mistake of interpreting the big o results that are supposed to give improved upper bounds on the difficulty of the problem as approximate models for the running time and that's really a mistake .PERIOD so in this course ,COMMA we're going to focus on approximate models by ,COMMA you know making sure that we use the tilde notation and we'll try to give specific results for certain quantities of interest and the constant ,COMMA any unspecified constant in the running time .PERIOD we'll have to do with properties in the machine and in the system so they will be able to use these results to predict performance and to compare algorithms .PERIOD 
so far ,COMMA we've been talking about running time .PERIOD now we have to talk about the memory requirements over our programs as well .PERIOD well ,COMMA the basics are we want to know how many bits the program use or bytes ,COMMA eight bits at a time .PERIOD and actually ,COMMA we'll be talking in terms of millions of bits or billions of bits and actually surprisingly there is a controversy about even these basic definitions .PERIOD computer scientists think of a million bits is two^20 and a billion is two^30 because that's a number of possible things that you can fit into 30 bits and everything is consistent with our calculations .PERIOD other scientists stick to one million or one billion for a lots of reasons we'll usually use two^20 ,COMMA i mean ,COMMA a megabyte .PERIOD now an old computers we used to for many years ,COMMA we use a 32 -DASH bit machine so that pointers were four bytes .PERIOD just in recent years we've mostly switched to a model where machines are 64 -DASH bits and pointers are eight bytes .PERIOD that allows us to address much more memory but pointers use much more space and actually this transition caused a lot of problems initially because programs were using way more space than people thought they should .PERIOD you're not going to have to go through this kind of transition the way that we did because 64 bits is definitely enough to address anything that you might need to address ,COMMA two^64 is really a huge number .PERIOD so in terms of bytes we have to start out with typical memory usage .PERIOD now ,COMMA again ,COMMA this is very dependent on machine and implementation but these numbers are reasonable and are found on typical implementations .PERIOD so a boolean ,COMMA it will be nice of a boolean just took a bit cuz that's just true or false but actually ,COMMA usually we have to count for a byte for a boolean .PERIOD all byte is a byte .PERIOD character nowadays is two byte ,COMMA 16 -DASH bit characters .PERIOD not that a long ago we used eight bit for chars .PERIOD integer regular int is four bytes or 32 bits and a float is also four bytes long int is eight and a double is eight .PERIOD usually ,COMMA we use double for floating point and ints for integers in most applications .PERIOD so ,COMMA that's for primitive types .PERIOD and then for arrays there's a certain amount of overhead for making an array and then if there's n items ,COMMA it's whatever the cost of the primitive type times n so an array of doubles is say 8n + 24 .PERIOD and two -DASH dimensional array then well ,COMMA we can go ahead and compute the exact thing but now ,COMMA now ,COMMA it's time to use ,COMMA the tilde notation .PERIOD and then for arrays we could say a double is tilde 8n for one -DASH dimensional .PERIOD for two -DASH dimensional ,COMMA two -DASH dimensional array of doubles is tilde 8mn .PERIOD and there's extra terms for the over head but for large m and n that's going to be pretty accurate .PERIOD so ,COMMA that's our basic usage for primitive types and arrays in a typical java implementation .PERIOD now ,COMMA a lot of our programs and objects like link list and so forth .PERIOD so ,COMMA we have to also factor in object overhead to crossover reference and also there's padding built in ,COMMA in typical implementations to make it so that each object has used a multiple of eight bytes .PERIOD so ,COMMA for example if you have a date object that had three int instance variables then that object would take a total of 32 bytes .PERIOD each int takes four bytes ,COMMA object overhead is sixteen bytes .PERIOD it needs four bytes for padding so it's a total of 32 bytes .PERIOD so and the other one that often comes up is a string and the string is a little bit more complicated than a than an array but the typical implementation of a string in java has a ,COMMA a reference out to an array of characters and then ,COMMA its got int values for offset count in a hash value and then some padding and adding it all together the [cough] cost of the string is about 2n + 64 bytes .PERIOD so ,COMMA these are the basics that we need to analyze the memory usage for a typical java program .PERIOD a h ,COMMA so for primitive ,COMMA for data type value ,COMMA if it's a primitive type it's four for an eight ,COMMA and eight for a double ,COMMA and so forth .PERIOD if it's a reference ,COMMA it's going to be eight bytes and that's for the pointer takes array 24 bytes plus the memory for each entry in an object sixteen bytes plus the memory for the instance variable plus if there's an inner class  ,COMMA it's another eight bytes as we talked about with nodes for link list .PERIOD and then there's the padding .PERIOD so then we have to ,COMMA to think about who is responsible for referenced objects ,COMMA you know ,COMMA in ,COMMA in some cases .PERIOD and we'll take care of that when we get to these situations .PERIOD so ,COMMA as an example ,COMMA a simple example of memory use analysis ,COMMA let's take a look at how much memory are rated quick union uf function from a ,COMMA a few lectures ago ,COMMA uses as a function of n .PERIOD and there's only a couple of memory elements and each one of them are easily analyzed using the basics that we just gave it's an object so the sixteen bytes of object overhead there's two int arrays .PERIOD each one of them have array overhead of 24 plus and then 4n for the n entries .PERIOD each and vn entries takes four bytes and there's four bytes for the count and there's four bytes for the padding and if you add it altogether it gets 8n + 88 which is tilde 8n and again ,COMMA all that's saying is when n is large ,COMMA all we are going to care about in terms of analyzing the memory is that we've got [cough] 2n integers two arrays of size n each one of which takes four bytes for a grand total of 8n bytes .PERIOD okay .PERIOD so ,COMMA in summary we really can figure out how many times we have to turn the crank on modern computers .PERIOD we can do it with empirical analysis where we actually execute the program ,COMMA can do experiments and use [inaudible] power law ,COMMA formulate hypothesis and make predictions .PERIOD but we can do more ,COMMA we can do mathematical analysis where we can identify the most costly operations ,COMMA analyze the frequency of execution of those operations and using the tilde notation to simplify analysis .PERIOD we can actually explain the behavior ,COMMA not just predict it .PERIOD and this is a fine example of the use of the scientific method to understand the artifacts that we're studying ,COMMA the algorithms .PERIOD our mathematical models are usually independent of a particular computer system and even implied to machines that are not yet built .PERIOD but we always validate our mathematical models by running experiments on real machines so that we can be confident where we're making predictions and analyzing algorithms .PERIOD 
 .PERIOD today ,COMMA we're gonna talk about minimum spanning trees .PERIOD this is a terrific topic for this course ,COMMA because it combines a number of classic algorithms with modern data structures to solve a variety of huge problems that are important in practical applications nowadays .PERIOD we'll start with a brief introduction .PERIOD what is a minimal spanning tree ?QUESTIONMARK well it's a defined on a graph now we generalized the idea of a graph one more time to allow weights on the edges ,COMMA so these are positive numbers associated with each edge .PERIOD and let say the graph is connected ,COMMA so we have a connected graph with weighted edges ,COMMA now a spanning tree of a graph .PERIOD is a subgraph that is connected and has no cycles .PERIOD so ,COMMA out of all the spanning trees ,COMMA we want to find one that has minimum wait .PERIOD so ,COMMA that's not a spanning tree ,COMMA cause it's not connected .PERIOD this set of black edges is not a spanning tree cause it's not a cyclic .PERIOD but here's one that is a spanning tree .PERIOD and if you add up the weights of all the edges ,COMMA four+6+8+5+11+9+7 that's 50 .PERIOD and you could see ,COMMA maybe you could get another spanning tree by removing this edge and adding that edge that'd have slightly higher weight .PERIOD and so the goal is to find a spanning tree of minimum weight .PERIOD now ,COMMA there is a bird force algorithm that is impractical ,COMMA impractical and probably would be difficult even to growth up .PERIOD and that is ,COMMA let's try all possible spanning trees .PERIOD now ,COMMA certainly ,COMMA we wanna do better than that .PERIOD here are some examples of some huge spanning trees that are being worked on in practice nowadays .PERIOD this is a bicycle route's in seattle .PERIOD and it kind of gives a quick way from downtown out to the suburbs .PERIOD you can see .PERIOD this is ,COMMA the idea of an mst as a model of natural phenomenon .PERIOD and there are many observed natural phenomenon that ,COMMA seem to be well modeled by spanning trees .PERIOD this is a purely random graph .PERIOD and ,COMMA a minimal spanning tree of that random graph .PERIOD and this is ,COMMA the ,COMMA a image that came up in cancer research ,COMMA having to do with the arrangement of nuclei and epithelium .PERIOD and you can see that this tree that's observed in nature is quite similar in character to the msd of the random graph ,COMMA so that's another example .PERIOD this is an example from image processing .PERIOD a process known as dithering ,COMMA to remove fuzziness in medical and other images .PERIOD in computing the msd of a huge graph built from such images is yet another application .PERIOD so it's ,COMMA bottom line for this introduction is ,COMMA mst is easily defined .PERIOD it's the ,COMMA minimum weight set of edges that now connect the vertices in a way to graph .PERIOD and its got the verse applications from dithering ,COMMA and face verification ,COMMA to road networks and satellite imagery ,COMMA to ethernet networks into network designs of all kind ,COMMA and it goes back a long way ,COMMA to the ,COMMA even early twentieth century for electrical and hydraulic networks ,COMMA so that's an introduction to the idea of a minimum spanning tree .PERIOD 
welcome back .PERIOD today we're going to talk about algorithms and data structures for implementing some fundamental data types called bags ,COMMA queues and stacks .PERIOD you maybe somewhat familiar with these ,COMMA but today we're going to take a careful and close look at them .PERIOD the idea is that in many applications ,COMMA we have collections of objects that we want to maintain .PERIOD and the operations are very simple .PERIOD we want to add something to the collection ,COMMA maybe remove something from the collection and iterate through the objects in the collection performing some operation on them ,COMMA and of course ,COMMA test if it's empty .PERIOD now for most of these ,COMMA the intent is very clear .PERIOD the key is when it comes to removing an item ,COMMA which item do we remove ?QUESTIONMARK the two fundamental classic data structures for this ,COMMA the stack and the queue differ in the way in which the item to be removed is chosen .PERIOD for the stack ,COMMA we take out the item that was most recently added for ,COMMA the terminology that we used is push to insert an item and pop to remove the item most recently added .PERIOD that's also called the lifo discipline last -DASH in -DASH first -DASH out .PERIOD for queue ,COMMA we examine the item least recently added and those operations to distinguish them we call inqueue to insert an item and dequeue to remove an item and that's also called the fifo discipline ,COMMA first in ,COMMA first out .PERIOD so now we're going to take a look today on how to implement these things .PERIOD our subtext today is all about modular programming .PERIOD and that's going to be a discipline that we're going to follow up carefully throughout this course .PERIOD the idea is to completely separate the interface and the implementation .PERIOD so ,COMMA when we have these types of data structures and data types that are precisely defined like stacks and queues and so forth ,COMMA what we want to do is completely separate the details of the implementation from the client .PERIOD the client has ,COMMA can have many different implementations from which to choose but the client code should only perform the basic operations .PERIOD the implementation on the other hand ,COMMA can't know the details of the client needs ,COMMA all it's supposed to do is implement those operations .PERIOD in that way ,COMMA many clients can reuse the same implementation .PERIOD so this allows us to create modular reusable libraries of algorithms and data structures that we can use to build more complicated algorithms and data structures .PERIOD it also allows us to focus on performance when appropriate .PERIOD again ,COMMA this is a modular programming style that's enabled by object oriented programming languages such as java and we'll be very disciplined in our use of this style .PERIOD alright .PERIOD so to begin ,COMMA we'll talk about the stacks .PERIOD [cough] stacks are familiar ,COMMA many of you probably implemented stacks in an introductory programming course but we'll do a thorough introduction to implementations right now .PERIOD as a warm up ,COMMA let's suppose that we have string ,COMMA a collection of strings .PERIOD they might be short ,COMMA they might be long and what we want to have is the ability to save away a collection of strings and remove and return the most recently added string periodically ,COMMA and also test if it's empty .PERIOD so that's our api .PERIOD we have a constructor to create an empty stack ,COMMA we have for insert and we have a method called push that takes a string as argument .PERIOD and for remove ,COMMA we have a method pop that returns to the string most recently added .PERIOD and we have these empty test which returns a boolean .PERIOD also in some applications ,COMMA we would include the size as well .PERIOD so again ,COMMA as always ,COMMA we'll first read a client and then look at implementations and our client ,COMMA simple client is to take some strings on standard input and some pop commands which are indicated with hyphens .PERIOD and so ,COMMA it'll this client reads strings from standard input .PERIOD if the string is equal to the hyphened character ,COMMA it'll pop the string at the top of the stack and print it .PERIOD otherwise ,COMMA if it's a string that's not equal to the hyphen character ,COMMA it'll just push it on to the stack .PERIOD so in the example down below here if we have this file called tobe .PERIODtxt then what we'll ,COMMA what the client will do is push to be or not to all in the stack then when it comes to this hyphen it'll pop the most recently inserted item which is two in this case then it'll put b in the top of the stack and then pop the top item on the stack which is now b and then pop the item most recently added ,COMMA b is gone ,COMMA two is gone so the next is not and so forth .PERIOD so ,COMMA this is a simple test client that we can use to test our implementations .PERIOD so now ,COMMA let's look at the code for implementing a stack .PERIOD now ,COMMA the first implementation that we'll look at ,COMMA uses link list .PERIOD if you're not familiar with the link list you'll need to review that in section 1 .PERIOD3 ,COMMA 1 .PERIOD3 at the book or in our introduction to programming java book .PERIOD even if you are familiar with link list ,COMMA it's worth taking a look at this code because it's the style of coding that we'll use throughout the coarse for much more complicated data structures .PERIOD so the idea is to keep a link list where which is consists of nodes that have strings in them and references to the next item in the link list and to ,COMMA to implement a stack when we do a ,COMMA a push operation ,COMMA we insert a new node at the beginning of the link list and we do a pop operation where we move the first node from the beginning of the link list ,COMMA that's the most recently added items .PERIOD so ,COMMA let's look at what that code looks like .PERIOD we use to implement link list in all linked data structures through out the course .PERIOD we use what's called an inner class in java and that's just a way to describe that we're going to be manipulating node objects that consist ,COMMA each consist of a string and a reference to another node .PERIOD so ,COMMA the pop operation for link list is very easy to implement .PERIOD [cough] first ,COMMA we ,COMMA we're going to need to return the first item on the list so we save that away .PERIOD take first that item and save that in the variable item .PERIOD a h ,COMMA then ,COMMA to get rid on the first node ,COMMA we just advance our pointer to the first item on the list to point two of the next item and then that first node is ready to be reclaimed by the garbage collector .PERIOD and then ,COMMA the last thing we need to do is just return the item that we saved away .PERIOD okay ,COMMA so that's the pop operation .PERIOD what about the push operation ?QUESTIONMARK [cough] push operation ,COMMA we want to add a new node at the beginning of the link list .PERIOD so ,COMMA first thing we do is save a way the pointer to the beginning of the list .PERIOD that's a little first thing first .PERIOD then we'll create a new node ,COMMA that's going to be the new node that we put at the beginning of the list ,COMMA that's first equals new node .PERIOD and then we said it's instance variables .PERIOD it's items is the string that we want to put at the beginning of the list ,COMMA in this case ,COMMA not .PERIOD and it's next is the old first item of the list which is now the second item of the list .PERIOD so ,COMMA after this operation ,COMMA we are first pointing to the beginning of the list and we have the items on the list in decreasing order of when they were put on to the stack .PERIOD so that also is a four liner to implement the stack push operation .PERIOD so this is a complete link list implementation of all the code to implement a link list for a stack of strings in java .PERIOD it's ,COMMA it's a class the constructor doesn't have to do anything ,COMMA there's no constructor .PERIOD we have this inner class that we use to build the items in the link list and we make them an inner class so we can directly refer to those instance variables .PERIOD and then the only instance variable of a stack is a reference to the first node on ,COMMA on the list and that starts out being null .PERIOD then it's empty is just testing whether the first node on the list is null and then push is the four lines of code that i gave on the previous slide and pop is the three lines of code that i gave on the slide before that .PERIOD tha t's a complete implementation for the link list that'll work with as a fine push down stack implementation for any client .PERIOD so now we can analyze the performance of that so that we can provide clients with information and how well the algorithm data structure will perform .PERIOD in this case ,COMMA it's easy to see that every operation takes constant time in the worst case .PERIOD there is only a few instructions for each one of the operations ,COMMA there's no loops .PERIOD so that's obviously a very desirable characteristic .PERIOD then how about space units ,COMMA usage ?QUESTIONMARK well ,COMMA that depends very much on the implementation in machines so this a typical java implementation that we'll do the analysis for and contest this out for different types of environments easily in this representative .PERIOD so ,COMMA in java ,COMMA an inter class there's for every object there is sixteen bytes of over head .PERIOD there are some extra over head ,COMMA eight bytes because that's an inter class and then there is two references that we built in our ,COMMA in ,COMMA in our class node .PERIOD one to string and another one to a node and those are each eight bytes .PERIOD so ,COMMA we have 40 bytes per stack node ,COMMA if we have a stack of size n ,COMMA we have about 40 n bytes .PERIOD that's a little extra first but that's about an overhead for the whole stack but when n is large ,COMMA 40n is a very close estimate to the amount of space needed .PERIOD this does not include the space for the strings themselves which are owned by the client .PERIOD but with that ,COMMA we can properly asses the research usage of this implementation for different client programs .PERIOD now it's constant time but there's faster implementations of stack and since stack is used inner loop of some algorithms it's important to think about even faster implementations .PERIOD and another ,COMMA natural way to implement a stack is to use an array to store the items on a stack so let's take a look at that .PERIOD this alternative of choosing between length structures and arrays is fundamental and it's go ing to come up again and again when we consider more complicated data structures in algorithms .PERIOD so ,COMMA we want to be sure to analyze it in the simple case for stacks to set the stage for more complicated applications later on .PERIOD alright ,COMMA so the use in array we just keep the n items on the stack in the array and the array location within the n is the place the top of the stack where the next item is going to go .PERIOD so ,COMMA to push we just add a new item at s(n) into pop we remove the item that's at s(n)  -DASH  one and decrement n .PERIOD now there is a fundamental defect in using an array and that is that you have to declare the size of array ahead of time and so the stack has a certain capacity .PERIOD and if there is more items on the stack than the capacity we have to deal with that problem and that's a fundamental problem that we have to deal with in array implementations in all sorts of algorithms and data structures .PERIOD so again ,COMMA considering it for the simple case we'll pay off later on .PERIOD alright ,COMMA so here's the full implementation of stack for using an array to represent the stack .PERIOD so now we have an instance variable which is an array of strings and or variable n which is both the size of the stack and the index of the next position ,COMMA next open position on the stack .PERIOD this one has a constructor and the constructor creates the array .PERIOD now ,COMMA we are cheating in this implementation to keep it simple and we'll take care of this cheat in a little while by requiring the client to provide the capacity of a stack .PERIOD in a few applications this might be fine but in many ,COMMA many applications that's two owners are requirement and client really can't know how big the stack is .PERIOD client might have a lot of stacks that need to be maintained simultaneously and then maybe they reached their maximum capacities at different times and various other things .PERIOD so ,COMMA we need to remove this cheat and will .PERIOD but the code is nearly trivial .PERIOD if we have the capacity to check if it's empty we check if n is zero .PERIOD to push an item we use n to index into the array put the item there and then increment n ,COMMA that's the short cut in many programming languages nowadays for use the index and then increment it .PERIOD and to pop we decrement the index and then use it to return the item in the array .PERIOD so each of the operations is a one liner and this is a fine implementation for some clients .PERIOD that's array implementation of stack but it breaks the api by requiring the client to provide the capacity .PERIOD so what are we going to do about that ?QUESTIONMARK well ,COMMA there are a couple of things that we didn't consider .PERIOD we didn't put in a code to throw an exception if the client pops from an empty stack .PERIOD probably should do that and for overflow ,COMMA what happens when the client does too much well ,COMMA we're going to talk about an approach called resizing that will allow us to avoid overflow for clients .PERIOD there's another issue about whether clients can insert null items into the data structure .PERIOD in this case ,COMMA we do allow the client to insert null items but we do have to worry about in java about a problem called loitering and that is the idea that we have references to an object in our array implementation and the stack array and we are not really using it .PERIOD so ,COMMA when we decrement that value in ,COMMA there's still a pointer to the thing that we took off the stack in that array even though we know we're not using it .PERIOD the java system doesn't know that .PERIOD so to avoid that and really allow most efficient use of memory it's best to set that .PERIOD [cough] removed item entry to null so there's no reference to the old item left there and then the garbage collector can reclaim the memory since there's no outstanding references .PERIOD so that's a ,COMMA a detailed but an important one that we have to take care of and or implementations to make sure that we're getting most efficien t use of memory .PERIOD 
to introduce the algorithms for minimum spanning tree ,COMMA we're going tp look at a general algorithm called a greedy algorithm .PERIOD it's a good example of a general principle in algorithm design that will help us ,COMMA prove correctness of our algorithms .PERIOD to begin we'll make some simplifying assumptions .PERIOD first we assume that the edge weights are all distinct ,COMMA and that the graph is connected .PERIOD and this is just to simplify the presentation .PERIOD as a consequence of these two exhumptions we know that the minimum spanning tree exists and is unique .PERIOD our algorithms will still work when edge winks are not distinct .PERIOD and if the graph is not connected ,COMMA it'll find spanning trees or components .PERIOD but these two assumptions simplify the presentation .PERIOD now ,COMMA to understand our algorithms we're going to start with a general operation on graph called making a cut .PERIOD so a cut in a graph is a partition of its vertices into two non -DASH empty sets ,COMMA and we'll indicate that just by coloring some of the vertices grey and others white .PERIOD so that's a partition of the two sets :COLON the grey vertices and the white vertices .PERIOD every vertex is either grey or white ,COMMA and there's at least one in each set .PERIOD now ,COMMA given a cut ,COMMA the crossing edge connects a vertex in one set with a vertex in the other .PERIOD so every edge that connects a grey vertex to a white vertex is a crossing edge .PERIOD so that's ,COMMA a second definition .PERIOD that gives us a way to talk about ,COMMA inches and graphs when we compete them into a spanning tree .PERIOD so an important property that is relevant to mst algorithms is that ,COMMA given any cut at all ,COMMA the cut defines a set of crossing edges .PERIOD the minimum weight crossing edge is in the mst .PERIOD remember no two edges have the same weight so there's a single edge that has minimum weight from the edges in the edges in the cut .PERIOD so in this case the thick red edge is the minimum weight ,COMMA it's the shortest edge connecting a grey vertex to the white one and that ,COMMA that edge has to be in the mst .PERIOD that's the cut property .PERIOD so here's a ,COMMA just a quick proof of that property .PERIOD i'll hand wave a bit through the discussions of the proof .PERIOD it's a .PERIOD usually not appropriate to fully dimension proofs in the lectures .PERIOD so you should look at the book and the underlined materials to be sure that you understand the proofs or ,COMMA or re -DASH read these slides .PERIOD but i'll try to give all the steps .PERIOD so ,COMMA we're trying to prove the cut property .PERIOD giving any cut the crossing edge in many ways to mst .PERIOD so let's suppose the contradiction .PERIOD so suppose that we have a minimum -DASH weight crossing edge that's not in the mst .PERIOD so ,COMMA in this case ,COMMA that edge e ,COMMA suppose it's not in the mst .PERIOD so it means that some ,COMMA one of the other crossing edges has to be in the mst .PERIOD otherwise the mst wouldn't be connected .PERIOD then if you add e to the mst you get a cycle .PERIOD and some other edge in that cycle has to be a crossing edge .PERIOD that's the way to think about it .PERIOD remember mst is a minimal way to connect the graph .PERIOD and if you add an edge to a ,COMMA a tree you get a cycle .PERIOD and then some other edge that has to be a crossing edge .PERIOD but if you remove that edge and add e then you're going to get a spanning tree .PERIOD and that spanning tree is smaller than the one that you had .PERIOD so ,COMMA that ,COMMA supposition had to be a contradiction .PERIOD so ,COMMA it has to be that the minimum weight crossing edge is in the mst .PERIOD so that's the ,COMMA cut property .PERIOD so ,COMMA and now given that property ,COMMA we can develop what's called a greedy algorithm ,COMMA which is the easiest algorithm ,COMMA we can come up with .PERIOD so what we're going to do is start with ,COMMA all edges colored grey .PERIOD find any cut that has no black crossing edges .PERIOD the algorithm's going to color some of the edges black .PERIOD and color the minimum -DASH weight edge of that cut black ,COMMA and just repeat the algorithm .PERIOD finding any cut with no black crossing edges ,COMMA color the minimum -DASH weight edge black ,COMMA and keep going until you have v minus one edges that are colored back .PERIOD and the claim is that that's going to compute an mst .PERIOD let's look at a demo of that ,COMMA just to make sure that we follow what's going on .PERIOD so we start with all edges colored gray .PERIOD we're supposed to find a cut with no black crossing edges and colors minimum weight edge black .PERIOD well ,COMMA that could be any cut .PERIOD in this case ,COMMA we'll take the cut that ,COMMA has three ,COMMA two ,COMMA and six on one side and ,COMMA one ,COMMA zero ,COMMA zero ,COMMA one ,COMMA four ,COMMA five ,COMMA seven on the other side .PERIOD look at all the crossing edges .PERIOD minimum white crossing edge is the one from zero to two ,COMMA so the ,COMMA that's the one that we'll color black .PERIOD so now we have zero ,COMMA two and the mst is color black .PERIOD so again ,COMMA any cut that doesn't have a black crossing edge ,COMMA so in this case ,COMMA let's do the cut that just has five on one side and all the odds on the other side .PERIOD in this case ,COMMA there's three crossing edges ,COMMA the smallest one is five ,COMMA seven ,COMMA color that one black .PERIOD again ,COMMA any cut that has no black crossing edges .PERIOD so let's just take six the cut that has six on one side and all the others and the other .PERIOD two ,COMMA six is the minimum crossing edge so six ,COMMA two .PERIOD and so we put that one on the mst .PERIOD as we get more and more black edges it's going to be harder to find a cut with no black crossing edges .PERIOD but we press on .PERIOD so now let's do the cut with zero ,COMMA two ,COMMA four ,COMMA and six on one side colored white .PERIOD and one ,COMMA three ,COMMA five ,COMMA and seven on the others .PERIOD so there's a lot of crossing edges that cut .PERIOD but the smallest one is the one between zero and seven ,COMMA so that's the one that we color black and add to the mst .PERIOD so now we have four edges ,COMMA and our next cut now one and three on one side .PERIOD a smallest edge in that ,COMMA right ,COMMA the smallest crossing edge for that cut is two ,COMMA three .PERIOD now one more ,COMMA now let's put one and four ,COMMA now almost all the edges left are crossing edges .PERIOD so one and four are one side ,COMMA all the rest are in the other .PERIOD and ,COMMA the minimum weight crossing edge is the one from one to seven .PERIOD now notice ,COMMA in this case ,COMMA we got the nodes in the tree on one side of the kit ,COMMA cut .PERIOD and the nodes not in the tree on the other side of the cut .PERIOD one of our algorithms will always have that property .PERIOD so now ,COMMA we add one to seven .PERIOD seven in seven to that ,COMMA and now the last thing ,COMMA is to .PERIOD the only cut that ,COMMA has no black edges is the one that puts four on one side ,COMMA and all the rest on the other .PERIOD and the minimum way of crossing edge for that one is ,COMMA five ,COMMA four .PERIOD so now ,COMMA we've got .PERIOD eight vertices ,COMMA and seven vertices in the seven edges in the mst .PERIOD so we found the mst .PERIOD we've got v minus one edge is color black and we found the mst .PERIOD so the greedy algorithm was a very general algorithm .PERIOD we're allow to find any cut at all that has no black cras crossing edges .PERIOD so let's do the correctness proof .PERIOD and then we'll look at some specific instances of the greedy algorithm .PERIOD so .PERIOD first of all since we took the minimum crossing edge of a cut always to color black any black edge is in the mst .PERIOD that's the cut property .PERIOD do a cut no black crossing edges you can color black ,COMMA that's in the mst .PERIOD so that's first observation .PERIOD now when we have .PERIOD fewer than v minus one black edges .PERIOD there has to be a cut that has no black crossing edges .PERIOD that is the algorithm doesn't get stuck .PERIOD and so the way to think about that is just take the verticies in one of the connected components ,COMMA and make that the cut .PERIOD then there's gonna be ,COMMA since that's a connected component there's gonna be no black edges in the crossing edges for ,COMMA for that cut .PERIOD so the algorithm doesn't get stuck .PERIOD if the ,COMMA if you don't have an mst yet ,COMMA there's going to be some cut with no black crossing edges .PERIOD and that's it .PERIOD the greedy algorithm computes the mst .PERIOD any edge colored black is in the mst ,COMMA and you can always add to the set of black edges .PERIOD now if you don't have v minus one once you have v minus one you've got v minus one edges that are in the mst .PERIOD the mst has v minus one edges greedy algorithm computes mst .PERIOD so now what we want to do is implementations of the greedy algorithm or ,COMMA or specializations of it really that differ first of all in the way that they choose the cut .PERIOD which cut are we going to use ?QUESTIONMARK and also ,COMMA the way in which they find the minimum weight edge in the cut .PERIOD again ,COMMA those could both be ,COMMA expensive operations .PERIOD and prohibitively ,COMMA prohibitively expense ,COMMA expensive for huge graphs .PERIOD what we're going to look at is ,COMMA two classic implementations called kruskal's algorithm and prim's algorithm .PERIOD although ,COMMA in both cases ,COMMA we use modern data structures to make them efficient for huge graphs .PERIOD and there's another interesting algorithm called boruvka's algorithm ,COMMA that ,COMMA that kind of combines the two briefly mentioned .PERIOD now before getting to those ,COMMA what about removing the two simplifying assumptions ?QUESTIONMARK so what happens if you have ,COMMA a situation where the edge weights are not all distinct ?QUESTIONMARK so in this ,COMMA case ,COMMA 1 -DASH 2 and 2 -DASH 4 .PERIOD both have the same edge weight .PERIOD well so also do one three and three four .PERIOD and so it means there's multiple msts .PERIOD so in this case the ,COMMA there's two different msts .PERIOD so the greedy algorithm is still correct ,COMMA it turns out ,COMMA our correctness proof doesn't quite work ,COMMA but that can be fixed with a little bit of work .PERIOD so the fact is it's still correct .PERIOD and if the graph is not connected ,COMMA as i mentioned ,COMMA then what we'll get is what's called a minimum spanning forest ,COMMA which is the mst of each component .PERIOD essentially it's like independently computing the msts of the components .PERIOD but .PERIOD basically what the greedy algorithm gives us is an easy way to prove correctness for specific algorithms .PERIOD all we have to show is that they're finding a cut and taking a minimum weight edge from that cut .PERIOD and then we can prove correctness of a more complicated algorithm .PERIOD in general ,COMMA in algorithm design this is proven to be affective in all kinds of domains .PERIOD trying to come up with a general algorithm that you can prove works efficiently and then using that to help design specific ones .PERIOD the point is ,COMMA ladies and gentlemen ,COMMA that greed ,COMMA for lack of a better word ,COMMA is good .PERIOD greed is right .PERIOD greed works .PERIOD greed clarifies ,COMMA cuts through and captures the essence of the evolutionary spirit .PERIOD greed in all of it's forms .PERIOD greed for life ,COMMA for money ,COMMA for love ,COMMA knowledge ,COMMA has marked the upward surge of mankind .PERIOD and greed ,COMMA you mark my words ,COMMA will not only save teldar paper ,COMMA but that other malfunctioning corporation called the usa .PERIOD thank you very much .PERIOD  .PERIOD great ,COMMA great .PERIOD fly me to the moon ,COMMA and let me play among the stars .PERIOD  .PERIOD 
okay ,COMMA our basic array implementation of stacks had the defect where we required clients to provide us the maximum capacity of the stack ahead of time .PERIOD now ,COMMA we're going to look at technique for resolving that problem .PERIOD how do we ,COMMA we do not implementing the api .PERIOD the api says we should just be able to create a stack and it should be able to grow and shrink to any size .PERIOD so ,COMMA how do we going to go and shrink the array ?QUESTIONMARK well ,COMMA first thing you might think of is when the client pushes a new item onto the stack increase the size of the array by one and when pops ,COMMA decrease the array by one .PERIOD that's easy to code up but not worth it because it's much too expensive to do that .PERIOD the reason is that you have to create a new array ,COMMA size one bigger and copy all the items to that new array .PERIOD so inserting the first n items would take time proportional if the text ,COMMA stacks is size n  -DASH  one ,COMMA it's going to take time n .PERIOD and when it's two time n  -DASH  one so the first n items will take the sum of the first n integers which we know is about n^2 / two .PERIOD quadratic time to insert n items into a stack that kind of performance is unacceptable for large problems as we've seen ,COMMA as we will see many times .PERIOD so ,COMMA the challenge is to do the resizing .PERIOD but somehow ensured that it happens and frequently .PERIOD so ,COMMA the well end technique for doing that called repeated doubling is to when the array fills up ,COMMA create a new array of twice the size and copy all the items over .PERIOD then we don't create new arrays all that often so here's the implementation of that .PERIOD we start with an array of size one .PERIOD if we have a full stack ,COMMA which we know by testing n which is the number of items in the stack versus the rail length ,COMMA then we just re -DASH size the array into one of twice the length before inserting the item .PERIOD and how do we re -DASH size to a new capacity ?QUESTIONMARK we create a new array of that capacity and just go ahead and copy our current stack into that ,COMMA into the first half of that and then retu rn it .PERIOD and that will reset our instance variable which is our stack to this new bigger array .PERIOD so ,COMMA the idea and the consequence of this is if you insert n items into an array ,COMMA into a stack with this array representation ,COMMA the time will be proportional to n not n^2 .PERIOD and the reason is that you only create a new array every time it doubles but by the time that it doubles ,COMMA you've inserted that many items into the stack so on average ,COMMA it's just like adding one operation to cost of one to each operation .PERIOD so ,COMMA if we just ,COMMA if we just calculate the cost and inserting the first n items you're going to have ,COMMA instead of the sum of the integers from one end ,COMMA you're going to have the sum of the powers of two from one to end and that will give a total cost of about 3n .PERIOD so ,COMMA that's an array axises .PERIOD for the copy ,COMMA there's two array axis .PERIOD so ,COMMA to insert an item ,COMMA its about three array axises .PERIOD this plot is another way of looking at it which is the number of array axis its taken as you implement push operations .PERIOD every time you hit a power of two ,COMMA you take that many array axises but in the sense you've already paid for them by putting those items on the stack .PERIOD so that's called amortize analysis ,COMMA where we consider the total cost averaged overall operations and this is a ,COMMA a fine example and useful example of amortize analysis to get efficiency in a stack implementation .PERIOD now we ,COMMA we have ,COMMA what about the pop ?QUESTIONMARK we have to think about how to shrink the array .PERIOD so ,COMMA we might think ,COMMA well ,COMMA we doubled it when it was full ,COMMA when do we cut it in half when it gets to be half full .PERIOD we don't want to get the array to get two empty .PERIOD well ,COMMA that one ,COMMA one doesn't exactly work because of a ,COMMA a phenomenon called trashing .PERIOD if you ,COMMA if the client happens to do push ,COMMA pop ,COMMA push ,COMMA pop alternating when the array is full then ,COMMA it's going to be doubling ,COMMA halving ,COMMA doubling ,COMMA halving and creating new arrays on every operation to take time proportional to n for every operation and therefore ,COMMA quadratic time for everything so i don't want to do that .PERIOD the efficient solution is to wait until the array gets one quarter full before you have it .PERIOD and that's very easy to implement .PERIOD we'll just test if the arrays one quarter full ,COMMA if it is ,COMMA we re -DASH size it to half full .PERIOD and so ,COMMA then at that point ,COMMA it's half full and you can either grow by adding stuff or shrink by subtracting stuff but there won't be another resizing array operation until ,COMMA i guess totally full or half again full .PERIOD so the invariant of that is the arrays always between 25 percent and a 100 percent full ,COMMA number one and number two that every time you re -DASH size ,COMMA you've already paid for it in the amortize sense by inserting pushing or popping .PERIOD so ,COMMA here's just a what happens to the array for our small client example and you can see at the beginning ,COMMA it doubles from one to two to four but once it gets to four ,COMMA it stays once it gets to eight ,COMMA it stays to that size for a while even though there's some of the operations it doesn't shrink back to four until after there's only two items in there and then it shrinks and so forth .PERIOD so ,COMMA array resizing doesn't happen that often but it's a very effective a way of implementing the stack api with an array where the client does not have to provide this maximum capacity of the stack but still were guaranteed that the amount of memory that we use is always only a constant multiple of the number of items actually on the stack .PERIOD so the analysis now says that the average running time per operation for whatever the sequence of operations is the average running time is going to be proportional to a constant .PERIOD now ,COMMA there is a worst case that is at the point when the stack doubles ,COMMA it takes time proportional to n so it's not quite as good performance as we might like but it's what we the advantage that we get is ve ry fast pushes and pops just access array and increment it and very efficient for most operations .PERIOD and for many ,COMMA many clients that's an effective trade off to make .PERIOD so what about memory usage ?QUESTIONMARK well ,COMMA this is the analysis of memory usage for stacks and it's actually less memory than for strings the amount used is between 8n and 32n depending on how full the array is and just a quick analysis of the amount of space that arrays take in java .PERIOD so ,COMMA again this analysis is just for the stack itself not for the strings which the client wants .PERIOD so ,COMMA what are the trade offs between using a re -DASH sizing array versus a link list .PERIOD there's a two different implementations and the same api and the client can use them interchangeably ,COMMA which one is better ?QUESTIONMARK in many situations ,COMMA we're going to have multiple implementation of apis and depending on properties of the client program you're going to have to choose which one is the better one to use .PERIOD so ,COMMA for link list every operation takes constant time in the worst case that's a guarantee but we have to use a little extra time and space to deal with the links .PERIOD so ,COMMA it's going to be slower .PERIOD resizing array implementation we have a good amortized time so total average over the whole process is good .PERIOD we have less wasted space and probably faster implementation of each operation .PERIOD and so ,COMMA for some clients ,COMMA maybe that makes a difference perhaps ,COMMA you wouldn't want to use a re -DASH sizing array implementation at the moment that your plane is coming in for a landing and you wouldn't wanted to all of the sudden ,COMMA not implement some operations quickly .PERIOD if you need that kind or maybe in an internet switch where packets are coming through at a great rate ,COMMA you wouldn't want to be in the situation where you're missing some data because something got slow all of the sudden .PERIOD so ,COMMA that's a trade off that the client can make if i want that guaranteed ,COMMA if i want to be sure that eve ry operation is going to be fast use a link list and if i don't need that guarantee ,COMMA if i just care about the total amount of time i'll probably use the resizing array because the total will be much less because individual operations are fast .PERIOD so ,COMMA even with these simple data structures ,COMMA we have really important trade offs that actually make a difference in lots of practical situations .PERIOD 
so ,COMMA before we can develop code for our implementations we need to settle on an api for edge weighted graphs .PERIOD now this actually needs a bit of discussion .PERIOD it would seem to be simple to add weights .PERIOD but there's a few technicalities that it's easy to understand .PERIOD but it's going to take a little explanation .PERIOD so ,COMMA the whole idea is that we need an edge abstraction .PERIOD before for directed graphs ,COMMA undirected graphs ,COMMA we're talking about graphs in terms of connections ,COMMA and the edges were really implicit .PERIOD so ,COMMA for a vertex ,COMMA we would keep a bag of vertices that its connected to but we wouldn't explicitly represent edges .PERIOD for weighted edges ,COMMA we're going to need to do that .PERIOD so we're going to start out with an the just for processing edges .PERIOD now ,COMMA it's simple .PERIOD the constructor is just going to create an edge .PERIOD so ,COMMA what is an edge ?QUESTIONMARK a weighted edge is two vertices that they connect ,COMMA that ,COMMA it connects and then a double value ,COMMA which is the weight .PERIOD so that's clearly one thing we have to do is ,COMMA is construct the edge .PERIOD now what do we want to do when we process edges ?QUESTIONMARK well ,COMMA one thing we want to do is compare two edges ,COMMA so that is ,COMMA we want to compare the weights in ,COMMA in a typical compare and return a negative value of less than zero if equal and a positive value of one just like any other compare .PERIOD so we have one the method that takes an edge as argument and compares that edge to this edge for sure .PERIOD we want to be able to extract the weight and have a string representation of the edge .PERIOD but then ,COMMA what about getting the vertices out of the edge ?QUESTIONMARK well ,COMMA the fact is that the ,COMMA usually in the ,COMMA in the algorithm ,COMMA we're holding on ,COMMA to a vertex .PERIOD and generally ,COMMA what we want to do is get the other vertex .PERIOD so ,COMMA if we have a vertex v that we're holding on to ,COMMA what we want is the other vertex .PERIOD so well that's the way that will get the vertex to that a given edge .PERIOD we're on a vertex and we have an edge we want to get the edge that ,COMMA that ,COMMA the vertex that ,COMMA that connects to ,COMMA we just call the other method .PERIOD and if we have an idiom ,COMMA we're just getting started then ,COMMA then we are happy to take either vertex .PERIOD so we have either and other for getting the vertices out of the edges and we almost always do this kind of idiom where we pick out and we ,COMMA we have an edge e that we have to process .PERIOD we pick out either edge ,COMMA and we put that in v ,COMMA and we pick out the other edge ,COMMA and put that in w .PERIOD so that's just a ,COMMA a code for getting us the v and w without adopting some convention on how to use those names that might be required if you tried to access the instance variables directly or through gutter methods .PERIOD so ,COMMA that's the edge api .PERIOD so it's easy to implement .PERIOD so ,COMMA now we're going to have instance variables for v and w in the weight .PERIOD the constructor just sets those instance variables .PERIOD either just returns v arbitrarily ag ,COMMA then other ,COMMA given a vertex that vertex is v ,COMMA v or returns w ,COMMA otherwise ,COMMA it turns v ,COMMA so that's easy .PERIOD and then ,COMMA compared to is straightforward ,COMMA just using the weight instance variable of this ,COMMA which is the keyword referring to this object and that which is the argument edge that we're given .PERIOD so ,COMMA that's a complete implementation of the weighted edge api and now our mst algorithms can be clients of that .PERIOD so well first ,COMMA first we need a graph api that has weighted edges .PERIOD so we're going to use edge -DASH weighted graph .PERIOD and it's going to have the same characteristics of the graph and undirected graph api that we articulated before .PERIOD so we're going to create empty graph with a certain number of vertices and we do that so we can use vertex index arrays as internal data structures .PERIOD we'll have a created a weighted graph from an input stream then the main operation to build graphs is just to add edges .PERIOD and then the key operation that all the algorithms want to perform as usual is uniterable but give all the edges adjacent to a given vertex .PERIOD so now ,COMMA we want the edges themselves cuz they have the weights .PERIOD not just the vertex that it's connected to .PERIOD so ,COMMA this ,COMMA with the edge api ,COMMA the edge abstraction we get the edge ,COMMA which gives us the weight and the other vertex at the same time .PERIOD since we're using edges as distinct entities it's easy to allow self loops in parallel edges in the graph api and it doesn't have any impact on the mst algorithms .PERIOD so ,COMMA we'll go ahead and do that .PERIOD how do we represent edge -DASH weighted graphs ?QUESTIONMARK i ,COMMA well ,COMMA it's the straightforward extension of what we did for undirected graphs .PERIOD we're going to maintain a vertex index array of edge lists .PERIOD so for every vertex we have a list of the edges connected to that vertex .PERIOD for example in this graph weighted graph ,COMMA there is an edge the ones connected to vertex zero ,COMMA or an edge that connects and six and zero and has a weight 0 .PERIOD58 and an edge that connects two and zero and has 0 .PERIOD26 ,COMMA zero and four has 0 .PERIOD38 ,COMMA zero and seven has 0 .PERIOD16 .PERIOD as with our undirected graph representations each edge object is going to appear twice .PERIOD once for each vertex that it connects .PERIOD and it's actually not an object ,COMMA it's a reference to an object in java .PERIOD so ,COMMA a graph is a vertex index array of bags of edges .PERIOD since it's undirected each edge is going to appear twice .PERIOD so ,COMMA when we build a graph just as with undirected unweighted graphs we have to add ,COMMA ,COMMA if ,COMMA if we have an edge that connects v and w we have to add that edge to both v and w's adjacency list .PERIOD otherwise it's quite similar to r code for graph .PERIOD we have a bag of edges instead of a bag of integers ,COMMA which were vertex indices .PERIOD constructor builds the bag .PERIOD and builds the array and then fills the bag associated ,COMMA associated with each vertex as a new empty bag .PERIOD and then add ,COMMA add edge ,COMMA adds the edge to both v and w's bag .PERIOD and interval just returns the bag associated with the given vertex and that's all the edges that are incident on that vertex .PERIOD and that's a bag which is interval .PERIOD so ,COMMA again ,COMMA as for all the algorithms that we've been looking at ,COMMA the clients will just iterate .PERIOD usually ,COMMA you have a vertex ,COMMA and it'll iterate through the edges adjacent to that vertex .PERIOD so that's the representation of the graph .PERIOD what about representing the mst ?QUESTIONMARK well ,COMMA usually the client of an mst algorithm is going to want to have us compute the mst for a given edge -DASH weighted graph .PERIOD so ,COMMA we'll just do that in a class named mst and make that the constructor .PERIOD so then ,COMMA as usual ,COMMA in our graph processing paradigm ,COMMA the constructor will do all the work .PERIOD and then the client can ask queries about what happened .PERIOD and in this case ,COMMA what's relevant is ,COMMA what are the edges in the mst ?QUESTIONMARK and the mst client is just going to want to iterate through those edges .PERIOD it might also want the total weight of the mst ,COMMA so we can provide that ,COMMA too .PERIOD so for example if we take a ,COMMA an example with our tiny edge -DASH weighted graph ,COMMA we're going to have the number of vertices ,COMMA the number of edges and then ,COMMA a list of vertex pairs ,COMMA which are the edge connections and the associated weights .PERIOD ahm the what we'll want is the this is the test client is just going to print the edges in the mst the middle -DASH weight edges that connect them all instead the edges on mst and the weight .PERIOD and this is the code for that test client .PERIOD so we build an input stream which is given the argument ,COMMA so that's the filename .PERIOD and then ,COMMA we use the constructor from the stream to build an edge -DASH weighted graph .PERIOD then we do an mst calling the mst constructor with that graph is an argument that creates an mst .PERIOD and then ,COMMA we use the iterator .PERIOD that mst .PERIODedges will give us some interval set of the edges that are in the mst that it computed in the constructor .PERIOD and it will print out the edges using two -DASH string for edge and then print out the weight .PERIOD so that's the code that gives the test client for this mst api .PERIOD so ,COMMA for that graph ,COMMA we get that output with that code .PERIOD so ,COMMA that's a ,COMMA the quick introduction to the api ,COMMA apis we use for msts .PERIOD 
okay ,COMMA next ,COMMA we'll briefly consider queue implementations using the same basic underlying data structures .PERIOD so ,COMMA here is the corresponding api for queue of strings .PERIOD actually you know it's the same api for stacks just the names are different .PERIOD instead of push we have enqueue instead of pop ,COMMA we have dequeue .PERIOD and the semantics is different .PERIOD for enqueue we add an item say at the end of the queue and for dequeue we remove an item from the beginning .PERIOD it's as if you're waiting in line to buy a ticket .PERIOD when you're enqueue you're at the end and when that's been in there the longest is the one that comes off .PERIOD so let's look at how we implement those first using linked list and then arrays .PERIOD so ,COMMA now our representation of a queue with the linked list ,COMMA we need to maintain two pointers references .PERIOD one to the first item in the list and the other to the last item in the list .PERIOD when we insert we're going to add the item at the end of the list instead of the beginning and when we remove we'll do the same and we'll take it off the front .PERIOD so here's the implementation of dequeue .PERIOD it's identical to the code for pop for a stack .PERIOD we save away the item .PERIOD we delete the first note by advancing the reference and then we return the item ,COMMA so identical .PERIOD to add a node or enqueue ,COMMA add a new node to a linked list ,COMMA we want to put it at the end so that would be the last one return .PERIOD so we ,COMMA to add it at the end so first thing we need to is save a link to the last node .PERIOD we're going to need that because we need to change its reference from null to point to the new node .PERIOD then we'll create a new note for the end of the list will populate its fields and then that old link will change that from null to a pointer to the new node .PERIOD so again just a few lines of code .PERIOD that's basic linked list processing .PERIOD actually years ago when we taught courses in algorithms and data structures much of the course would be about this kind of pointer manipulation but nowadays that's restricted to just a few implementations like stack and queue and a few other fundamental data structures .PERIOD so we don't need so much anymore general programs for manipulating linked list .PERIOD we encapsulate them in basic data types like these .PERIOD alright ,COMMA so let's go back to our full implementation and this is just taking care of collecting a curve from the previous slides but also taking care of special cases when the queue is empty to make sure that if the queue is empty after we remove an item ,COMMA we're going to last at null and make sure that both first and last always are what we want them to be .PERIOD so those are details that are easy to check .PERIOD okay ,COMMA what about arrays ?QUESTIONMARK well ,COMMA we want to do the details but it's not difficult to implement queues with resizing arrays as well and not difficult but definitely a tricky programming exercise that people are welcome to try .PERIOD so we'll maintain two pointers .PERIOD the first item in the queue and the tail which is the position for the next item to appear so for enqueue you add a new item at tail and for dequeue you remove an item for head .PERIOD and the trick is that once you get past the capacity ,COMMA you have to reset back to zero and so that's a little extra code and then you have to add the resizing capability as well to implement data structure the same as for stack .PERIOD and we'll leave that as an exercise .PERIOD 
next we're going to consider addressing another fundamental defect in the implementations we've considered so far that those implementations are only good for strings .PERIOD what if we want to have queues and stacks of other types of data ?QUESTIONMARK and that brings us to the topic of generics .PERIOD alright .PERIOD so ,COMMA we implemented stack of strings but in applications we have all different types of data that we might want to implement like stack of int say or urls or cars or vans or whatever data that we might be processing .PERIOD so how are we going to implement stacks and queues for that types of data .PERIOD well ,COMMA first thing that we might that we might consider and actually we're forced to consider this one in lots of programming environment ,COMMA is to implement a separate stack class for each type of data that we're using .PERIOD that really seems unsatisfactory .PERIOD we have our carefully crafted code that does array resizing and so forth and we're going to copy that code and change the data type string to the data type van or int to everywhere .PERIOD and what if we have hundreds of different types of data that we're processing .PERIOD we have hundreds of different implementations .PERIOD unfortunately that situation at the beginning of java where we stuck with that and there are plenty of programming languages where basically we're stuck with that so what we want to look at is a modern approach to avoiding having multiple implementations for each type of data .PERIOD so the a quick hack that is widely used is to use casting to implement to reuse the code for different data types .PERIOD so ,COMMA we make our implementation with type object so everything in java is a sub type of object and then the client ,COMMA when the client comes to use it ,COMMA will simply cast the result to the corresponding type .PERIOD i don't want to spend a lot of time with this cuz i think this is a unsatisfactory solution .PERIOD so ,COMMA in this example we have two types with two stacks one of apples and one of oranges .PERIOD and then ,COMMA it's up to the client when it pops something off the apple stacks to cast at the apple to keep the type checking system happy .PERIOD the problem with this is that the client code has to do this ,COMMA this casting and it's kind of an insidious bug if it doesn't quite get it .PERIOD so ,COMMA the third attempt that we're going to talk about uses generics .PERIOD and that way the client code doesn't do casting .PERIOD we can discover mistakes in typed mismatches at compile -DASH time instead of at run -DASH time .PERIOD so ,COMMA in this case ,COMMA we put ,COMMA with generics ,COMMA we can have a type parameter on our class and that include ,COMMA that's inside angle brackets in this code and then ,COMMA we can [cough] if we have a stack of apples and we tried to push an orange unto a stack of apples then we're going to get a compile -DASH time error because that's stack was declared to only consist of ,COMMA of apples .PERIOD and just the guiding principal in good modular programming is that we should welcome compile -DASH time errors and avoid run -DASH time errors because if we can detect an error at compile -DASH time ,COMMA then we can ship our product or deploy our implementation our implementation of an api and have some confident that it's going to work for any client whereas ,COMMA the error is not going to get discovered until run -DASH time it might occur with some client development .PERIOD now ,COMMA years after ,COMMA we have to deploy our software and be extremely difficult on everyone .PERIOD okay .PERIOD so actually with a good generic implementation it's not difficult to simply [cough] ,COMMA take every place that we used string and replace it with a generic type name as in this code here .PERIOD on the left is our implementation of a stack of strings using link list .PERIOD on the right is a generic implementation .PERIOD so ,COMMA every place that we used string type on the left we used the word item on the right .PERIOD and at the top ,COMMA the class declaration we declared an angle brackets that item is the generic type that we're going to use .PERIOD the implementation could hardly be more straightforward and it's an excellent way to solve the problem of handling multiple types of data with one implementation .PERIOD with arrays ,COMMA it doesn't quite work and again all programming languages and ,COMMA you know ,COMMA many programming languages nowadays have difficulties with this and java's got a particular difficulty .PERIOD so ,COMMA what we would like to do is just declare a new array using our generic name item as in the highlighted line here .PERIOD otherwise it's the same .PERIOD unfortunately ,COMMA java does not allow generic array creation .PERIOD so there's various technical reasons for that and you can read ,COMMA read extensive debates about this on the web that's going to go beyond our scope .PERIOD for now ,COMMA what we need to do is put a cast in to make this work .PERIOD so ,COMMA we create an array of objects and then we cast it down to an array of items .PERIOD now in my view ,COMMA a good code has zero cast .PERIOD so ,COMMA we want to avoid cast as much as possible because it ,COMMA it ,COMMA it really is declaring some kind of weakness in what we're doing .PERIOD but in this case we have to put in this one cast and so what we've heard about that is the ugly cast it doesn't ,COMMA it doesn't make you feel good about the code .PERIOD it's not something that you will come up with on your own and that's ,COMMA and that's an undesirable feature ,COMMA i think for codes so simple as this .PERIOD but fortunately ,COMMA we can get through pretty much everything that we're going to do in this course just knowing about this one of lay cast .PERIOD so now ,COMMA when we compile this program we get a ,COMMA a warning message from java .PERIOD it says that we're using unchecked or unsafe operations and we should recompile with a minus  -DASH xlint equals unchecked for details .PERIOD so ,COMMA we can go ahead and do that and it says that you have put in ,COMMA in your code an unchecked cast and we're warning you about that cuz you shouldn't be putting in unchecked cast .PERIOD and okay ,COMMA that's fine and you're going to see that when you do compiles using code like these .PERIOD i ,COMMA i think maybe they might have added to this warning statement "we apologize for making you do this" .PERIOD it's  had to do that cuz of your requirement  arrays .PERIOD so with that note please don't  code if you follow our prescriptive and ,COMMA  it's one of the detail that java takes  types [cough] so the generic type that  we're casting down from array of objects .PERIOD  have to use java's wrapper object types .PERIOD  for int and so forth and many of you were  process called auto -DASH boxing which  and wrappers so all of that handles of  types ,COMMA kind of behind the scenes .PERIOD and the  api for generic stacks that works for any  implementations ,COMMA link list and arrays  any type of data using the ,COMMA the resizing  
okay .PERIOD there's another facility that java provides that leads to very elegant compact client code that's definitely worthwhile to add to our basic data types and that's iteration ,COMMA that's what we're going to talk about now .PERIOD so ,COMMA what we want to do is to allow the client to iterate through the items in the collection .PERIOD but we don't have the client to know whether we're using an array or link list or whatever internal representation we might have in mind .PERIOD it's not relevant to the client .PERIOD and a lot of clients only want to do is just iterate through the stuff in the collection .PERIOD but java does provide a nice a solution to this called iteration .PERIOD so what we're going to do is look at how to make our stack ,COMMA and queue ,COMMA and other data structures that we consider later on implement the so -DASH called iterable interface and it will work for client code no matter which implementation we used so let's take a look at the details of that .PERIOD so what's an iterable ?QUESTIONMARK well ,COMMA in java lingo what an iterable is ,COMMA it's ,COMMA it's a class that has a method that returns an iterator .PERIOD and so what's an iterator ?QUESTIONMARK well an iterator is something ,COMMA a class that has methods hasnext() and next() .PERIOD the java also allows remove() .PERIOD we think that one is bad news ,COMMA we don't use it can lead to insidious debug ,COMMA bug debugging problems .PERIOD so ,COMMA it's hasnext() and next() and so to make the data structure iterable ,COMMA we're going to implement those things .PERIOD it seems like a lot of baggage to carry around and the reason that we do it ,COMMA why do we go to the trouble doing it is that we can ,COMMA if we have a data structure that's iterable we can use a very compact and elegant client code in java ,COMMA the so called for -DASH each statement .PERIOD so if we have a stack we can say  -DASH  (for string s  :COLON stack) .PERIOD it means for each string in the stack  -DASH  print it out .PERIOD and if we didn't have that we would now ,COMMA if we're using iterators ,COMMA we could go ahead and write this longhand code but nobody would ever do that cuz it's equivalent to the shorthand or we might have to write client code that does a lot of unnecessary pushes and pops just to do this iteration .PERIOD so that's the key is to be able to have client code that is so compact for iterating through items in the data structure so we're going to provide iteration for all our basic data structures and it's not too hard to do definitely worthwhile the effort .PERIOD so here's what it looks like for link list .PERIOD so it's got to implement iterable so what does that mean implement iterable ?QUESTIONMARK it's got to have a ,COMMA a method iterator() that returns an iterator .PERIOD so what's an iterator ?QUESTIONMARK so ,COMMA we're going to use an inner class .PERIOD in this case ,COMMA we'll call it listiterator that implements iterator and it's generic .PERIOD and basically what this thing has to do is implement these methods hasnext() and next() .PERIOD and the semantics just clear from the names .PERIOD hasnext() is supposed to if ,COMMA if we're done is supposed to return false .PERIOD if we're not done we're supposed to return true and the next() is supposed to give the next item in the iteration .PERIOD so if the thing is a linked list we're going to start out at first .PERIOD we have that's the ,COMMA our first item in the list and we're going to maintain an instance variable current inside this iterator which is the current thing that we're iterating .PERIOD so ,COMMA get the next one just like if we want to remove the first .PERIOD we pull out the current item and then advance the current reference and return item .PERIOD moving current to the next place .PERIOD the client is always going to be testing hasnext() as i showed as i showed and that stub code before and so when it gets to null it will return false in the iterational stop .PERIOD but for our iteration ,COMMA we just have to worry about implementing next() and hasnext() and perhaps using a local instance variable to get it done .PERIOD we have to probably to make bullet proof code  -DASH  throw exceptions if a client tries to call next() with no items there and tries to call remove() at all ,COMMA we're not going to support remove() .PERIOD for ,COMMA and for array ,COMMA it's even simpler .PERIOD so now with the iterator we have control over which order we go through the items and so that's going to go along with the semantics and the data structure so probably in a stack you want to get the things in stack order like the order that come out of the stack so that's reverse order in the array so in this case then next() is just decrement and return the next one and our instance variable is an index in the array .PERIOD and then hasnext() is okay as long as that thing is positive .PERIOD so a little java [cough] code to provide this iteration facility but actually within this framework not too much to do and you can see how to implement this for your own data type and we'll use this paradigm for every basic data type that we ,COMMA that involves collections of objects that we'll encounter .PERIOD alright ,COMMA and in fact ,COMMA it leads us to actually for a lot of clients it doesn't really matter what order we get the items .PERIOD really often what we're doing is just inserting items into a collection and then ,COMMA later on ,COMMA iterating through the items that we have .PERIOD that data structure is called a bag and so let's look at what that api looks like .PERIOD order doesn't matter so all we want to do is add an item maybe you want to know the size and we want to iterate through all the items in the bag .PERIOD so this is a simpler ,COMMA narrower api but still it expresses an important little collection of operations and ,COMMA and we'll use this one and we've already seen the implementations .PERIOD you just take stack and remove the pop ,COMMA or queue and remove the dequeue [cough] and you have fine implementation of a useful data structure .PERIOD 
so we're going to complete our study of mst algorithms by considering some context both as an unsolved problem in theoretical computer science and as a practical problem .PERIOD so the unsolved problem in theoretical computer science that has defied researchers for many decades is ,COMMA it is possible to find a linear -DASH time mst algorithm ?QUESTIONMARK is there an algorithm that only examines each edge at most once on the average ?QUESTIONMARK now ,COMMA this doesn't have .PERIOD that much practical comp .PERIOD consequence since the versions of primm's algorithm that we've talked about can get the running time down quite low for the sparse graphs ,COMMA the huge sparse graphs that we encounter in practice .PERIOD but it's still ,COMMA its .PERIOD .PERIOD .PERIOD like union find ,COMMA it's a tantalizing problem .PERIOD unlike union find ,COMMA it hasn't been resolved yet .PERIOD union find remember ,COMMA we couldn't get a linear algorithm but at least tarjan proved that no such algorithm exists .PERIOD for mst ,COMMA we're not even there yet .PERIOD and a lot of people have worked on it .PERIOD so let's go with the simple model where what you get to do is compare edges .PERIOD compare weights on edges .PERIOD in 1975 yao proved that there exists an algorithm that's worst case running time is e log ,COMMA log v .PERIOD in 1976 ,COMMA cheriton and tarjan came up with another such algorithm .PERIOD and then fredman and tarjan found the e plus e log v algorithm or e log star v for mst's in'84 .PERIOD here's another one .PERIOD e log ,COMMA log star v .PERIOD now remember ,COMMA log star v is the number of times you take log to get to one .PERIOD so it's ,COMMA less than ,COMMA six ,COMMA in the natural universe .PERIOD so these are very ,COMMA very close to linear algorithms .PERIOD the names in orange are people who work at princeton .PERIOD so ,COMMA we're now trumpeting princeton a little bit here .PERIOD in'97 ,COMMA chazelle showed that ,COMMA its close to the ,COMMA inverse ackerman function .PERIOD that ,COMMA even more slowly growing than log star v .PERIOD in 2000 ,COMMA got rid of the log factor ,COMMA so very ,COMMA very close to linear .PERIOD that now .PERIOD in 2002 ,COMMA optimal ,COMMA well ,COMMA let's ,COMMA talk about that .PERIOD they ,COMMA they ,COMMA they showed an ,COMMA an algorithm that it ,COMMA better not to talk about the theory of that .PERIOD [laugh] .PERIOD and that the ,COMMA still ,COMMA the open question is ,COMMA is there ,COMMA an algorithm whose worst case running time is guaranteed to be proportional to e ?QUESTIONMARK or could ,COMMA someone prove that no such algorithm exists ?QUESTIONMARK it's one of the most ,COMMA tantalizing open questions in computer science .PERIOD as we get into ,COMMA graph algorithms in more detail .PERIOD we'll see some other examples of problems for which we know pretty good algorithms but would like to know whether there are better algorithms or not .PERIOD and mst is a fine example of that .PERIOD that's the orange means princeton .PERIOD there is a randomized linear time algorithm that was discovered in 1995 ,COMMA but that's not the same as solving it worst case in linear time .PERIOD so that's one context .PERIOD mxt is an important problem that's still been studied by theoretical computer scientist and we still don't know the best algorithm .PERIOD here's another one ,COMMA so -DASH called euclidean mst .PERIOD and this one is what's appropriate in some practical situations .PERIOD so now you have points in the plane and the graph is an implicit dense graph .PERIOD that is ,COMMA we take as an edge in the graph ,COMMA the distance between this point and every other point .PERIOD so if there's n points there's n squared edges because every point's connected to every other point .PERIOD and what we want is ,COMMA in that graph ,COMMA we want to find the subset of edges that connects all the points ,COMMA that's minimal .PERIOD that's actually ,COMMA in a lot of practical problems ,COMMA that's what you want .PERIOD so as it stands ,COMMA the algorithms that we've talked about are not useful for this beacause they're going to take quadratic time ,COMMA because e's quadratic .PERIOD that's how many edges there are in the graph .PERIOD so you know ,COMMA you could just go ahead and build the graph with the n squared over two distances and run prim's algorithm .PERIOD but that's not very satisfying for a huge number of points .PERIOD it's actually not too difficult to exploit the geometry of the situation .PERIOD and get it done in time proportional to n log n .PERIOD what is typically done is to build a sub graph ,COMMA where each point is connected to a certain number of points that are close to it .PERIOD there's a particular graph called the voronoi diagram ,COMMA or the delaunay triangulation ,COMMA that does that .PERIOD and it's been proved ,COMMA number one that ,COMMA that graph has linear number of edges not ,COMMA quadratic ,COMMA and it's also the mst is a sub graph of the d -DASH linear triangulation .PERIOD so you can get it done in linear arrhythmic time for euclidean mst .PERIOD separate problem related but still a very interesting in many practical applications .PERIOD here's another application in se ,COMMA several scientific studies ,COMMA there's the idea of clustering .PERIOD and so what we wanna do is ,COMMA we have a set of objects and they're related by a distance function that specifies how close they are and what we wanna do is divide the objects into a given number k of coherent groups so that objects in different clusters are far apart .PERIOD so wanna see how things cluster together .PERIOD and here's a really old example of a application of this where there was an outbook ,COMMA outbreak of cholera deaths in .PERIOD london in the 1850s and ,COMMA if you plot where all of the deaths happened ,COMMA scientific study could find that they were clustered around certain places .PERIOD and ,COMMA actually they were able to identify well pumps that were leading to the ,COMMA the cholera just by doing clustering study .PERIOD and ,COMMA that is a very special case .PERIOD there are many ,COMMA many other applications where clustering is an important process ,COMMA an important thing to be able to compute .PERIOD so like mobile networks for web search there's an idea of the distance between doc ,COMMA documents and you wanna categorize them in clusters .PERIOD there's the ,COMMA all the objects that have been discovered in the sky ,COMMA you wanna cluster them together in a reasonable way .PERIOD and all kinds of .PERIOD of processing having to do with huge data bases ,COMMA trying to get information that seems close together to be close together into a relatively small number of clusters .PERIOD so there's ,COMMA a ,COMMA a approach called single link clustering .PERIOD where you talk about the single length ,COMMA the distance between two clusters equaling the distance between the two closest objects ,COMMA one in each cluster .PERIOD and so ,COMMA so -DASH called single length clustering is given at integer k .PERIOD find the k clustering that maximizes the distance between the two closest clusters .PERIOD so that's a well defined computational problem .PERIOD and there's a very well -DASH known algorithm ,COMMA in the science literature for this problem ,COMMA signal ,COMMA signal -DASH link clustering .PERIOD form of e -DASH clusters ,COMMA find the closest pair of objects such that each object's in a different cluster ,COMMA and merge the two clusters .PERIOD and repeat until they're exactly k -DASH clusters .PERIOD you'll find this algorithm in the scientific literature .PERIOD what's amazing is that ,COMMA this is crussical's algorithm ,COMMA just stop when you found the k -DASH connected components ,COMMA so that ,COMMA the ,COMMA or another thing you could do is just run prim's algorithm and then after you've run prim's algorithm get rid of the largest edges until you're left with k -DASH clusters .PERIOD so out of all the efficient algorithms that we've talked about are gonna apply for single -DASH link clustering .PERIOD and actually scientists who also know some computer science now are able to handle huge problems that would not be possible without efficient algorithms .PERIOD this is just one ,COMMA one example where a ,COMMA a cancer study where experiments are connecting genes with the way they're expressed in different parts of the body ,COMMA and trying to cluster together tumors in similar tissues .PERIOD and again ,COMMA such experimental results can amount ,COMMA result in huge amounts of data ,COMMA and mst algorithms are playing a role in scientific research of this type .PERIOD that's our context for minimal spanning trees .PERIOD 
okay .PERIOD those are some basic data structures and implementations and it seem quite elementary and simple but actually right away we can get to some very sophisticated applications of these basic concepts and that's what we're going to consider next .PERIOD now ,COMMA first thing to mention is that often the kinds of data types and data structures that we implement or found in a java library .PERIOD so ,COMMA that's true in many programming environments .PERIOD so ,COMMA for example stacks and queues you can find those words mentioned in the java library so there's a java collection library and the so -DASH called list interface which is displayed here .PERIOD so java has general api for sequences of items and its got things like a ,COMMA append at the end ,COMMA remove from the beginning ,COMMA and so forth .PERIOD any uses of the resizing array ,COMMA so many of the principles that we consider does also a ,COMMA a link list interface .PERIOD so ,COMMA why not just use those ?QUESTIONMARK why use our own implementations ?QUESTIONMARK well ,COMMA the problem is often in such library code is kind of designed by committee phenomenon that more and more operations get added and the api becomes too broad or bloated .PERIOD it's not a good idea to have lots and lots of ,COMMA you know ,COMMA operations in the same api .PERIOD and we'll see example in a second .PERIOD the problem ,COMMA the real problem is that when you do that you can't know much about the performance or you can't assume much about the performance .PERIOD and so you can kind of immediately arrive at that performance even for simple clients .PERIOD so our best practice that we recommend is so few that these basic data structures that we use and there's so simple is to go ahead and use the implementations that we've just discussed for these fundamental data structures .PERIOD maybe later ,COMMA later on ,COMMA after an experienced programmer who knows what he or she is doing could use some of these library collections effectively .PERIOD but inexperienced programmers often have trouble with it .PERIOD here's a war story from students programming assignments not that long ago .PERIOD so ,COMMA we have an assignment where you need to generate a random open sites in a percolation system .PERIOD we have one student who was paying attention to what we're saying and uses an array and can pick the indices into that array at random check whether they're open and ,COMMA and repeat .PERIOD and so the array is n by n ,COMMA it's n^2 things and it takes about n^2 time ,COMMA which is actually a linear time for this application .PERIOD but then we have another student who had some java before coming to us and considered himself an expert and said ,COMMA well ,COMMA i'm going to use linked list because i could use java's library and i don't have to worry about downloading your stupid code .PERIOD and so ,COMMA i'll just use that one and pick an index at random and delete and that program took quadratic time and poor kenny ,COMMA when trying to run his program for the huge instance that we asked found out that it wasn't finishing .PERIOD and the reason is that the java linked list implementation takes a linear time to find an item with a given index .PERIOD not constant time like an array .PERIOD and that's difficult for kenny to think about and difficult to drive that information from the implementation so program is just too slow .PERIOD and with the swiss knife implementation with so many operations it's hard to know whether or not the particular set of operations that your client needs is efficiently implemented .PERIOD so our insistence in this course is that students should not use the library until we've implemented it in class .PERIOD at least that some indication that you understand the performance characteristics .PERIOD so now ,COMMA let's look at some applications then of ,COMMA of stacks .PERIOD there's the stacks are really actually fundamental underlying computation because they implement  ,COMMA recursion and so ,COMMA you use stacks often everyday when you wrote ,COMMA use the back button in the web browser ,COMMA the places that you've been are saved on a stack .PERIOD right now we will look at two examples .PERIOD one ,COMMA having to deal with compiling from a programming language or interpreting into an actual computation and then the other one is the postscript language which is widely used for ,COMMA for printing and publishing .PERIOD so ,COMMA so the way the compilers implement functions is using stacks .PERIOD when there's a function call the whole local environment is pushed and then along with the return address and then the function returned is pop the return address in the local environment .PERIOD so there is the stack there that contains all that information and whether the function calls itself or not is not relevant .PERIOD the stack contains the recursion .PERIOD in fact ,COMMA you can always use an explicit stack to make a recursive program non -DASH recursive .PERIOD so ,COMMA this is so when we have the gcd function ,COMMA computing the greatest common denominator ,COMMA greatest common denominator p and q is greatest common denominator of q and p mod q and it just calls itself until q gets to be zero .PERIOD and as this graphic integrates ,COMMA it just does it by saving the information on a stack .PERIOD now a specific example that really shows this off and also will illustrate the utility of being able to process multiple types of data with the same code is this example is dijkstra's two -DASH stack algorithm for arithmetic expression evaluation .PERIOD so the goal is ,COMMA you got an arithmetic expression this is just actually like a simple stand in for a program and we'll talk about that in a second but let's say ,COMMA arithmetic expressions .PERIOD we have operands and operators and you want to evaluate it .PERIOD and dijkstra's algorithm is very simple to express .PERIOD you processes through the expression from left to right .PERIOD if you see a value ,COMMA you put it ,COMMA you maintain two stacks and if you see a value ,COMMA you put it on the value stack and if you see an operator ,COMMA you put on the operator stack .PERIOD left parenthesis you ignore .PERIOD right parenthesis ,COMMA you pop the operator and two values and push the result .PERIOD now that's a lot of words let's look at a demo .PERIOD so we start out with the empty value stack and operator stack and we're going to move from left to right .PERIOD so ,COMMA and those are the a top is summarize the four type of things that we could wind up with and what to do so the left parenthesis we've ignored ,COMMA a value we put on to the value stack .PERIOD so ,COMMA that one goes right in to the value stack .PERIOD operator ,COMMA we put on to the operator stack .PERIOD and plus it goes on the operator stack .PERIOD left parenthesis you ignore .PERIOD it seems strange to be ignoring parenthesis and we'll get back to that in a second .PERIOD value ,COMMA put in the value stack .PERIOD operator ,COMMA put on the operating stack .PERIOD doesn't seem like we're doing much except putting stuff on stacks and now ,COMMA when we come to our right parenthesis and that's when it gets interesting .PERIOD what it says is to you have the top operator and the top two values and that's what you want to do .PERIOD supply that operator to those values and put the resulting value that you get back on to the operation stack .PERIOD so ,COMMA we take off the top two things ,COMMA we do the operation and then we put the thing that we get onto the value stack .PERIOD and that's right parenthesis .PERIOD so now continuing along we put a star on .PERIOD left parenthesis ,COMMA we ignore .PERIOD four on ,COMMA star .PERIOD the right goes to the value stack and now we got a lot of stuff on the stacks and we got through right parenthesis and that's going to finish up the computation ,COMMA take the top two items off the stack and the top operator off the operator stack ,COMMA perform the operation ,COMMA put the result back on the value stack .PERIOD another right parenthesis ,COMMA take the top two values off .PERIOD perform the operation .PERIOD put the value on to the value stack and finally ,COMMA the last right parenthesis ,COMMA take the two operators of the value stack ,COMMA operators of the value stack ,COMMA and operator of the operator stack ,COMMA perform the operation ,COMMA put the result back on the value stack .PERIOD and we're at the end of the computation and that's the result .PERIOD the value that arithmetic expression is 101 .PERIOD okay ?QUESTIONMARK yup .PERIOD here's the code that implements dijkstra's two -DASH stack algorithm .PERIOD we have two different stacks .PERIOD the operand stack the operator stack is string ,COMMA it could be characters which is just our operator .PERIOD then our value stack is doubled so that's the same stack code but with generics ,COMMA we're using ,COMMA using two different types of data .PERIOD and then simply perform dijkstra's algorithm .PERIOD if we have a left parenthesis .PERIOD .PERIOD .PERIOD read a new string .PERIOD if we have a left parenthesis ,COMMA do nothing .PERIOD if we have plus or times ,COMMA push it .PERIOD if we have a right parenthesis ,COMMA then go ahead and pop the operator .PERIOD and if it's plus ,COMMA add the result of the two values at the top of the value stack and if it's a star ,COMMA multiply the two values on the top of the stack and ,COMMA and then push the result .PERIOD so and then when you're done then simply print out the value on the stack and that's a fine and elegant implementation using stacks for any arithmetic expression .PERIOD and it's easy to extend that to handle other types of things and so ,COMMA why does this work ?QUESTIONMARK well ,COMMA when the algorithm encounters an operator ,COMMA say ,COMMA in the inside ,COMMA we got the parenthesis ,COMMA operand ,COMMA operator ,COMMA operand ,COMMA parenthesis its easy to see that what its going to do inside there is put the at the top of the stack whatever it is ,COMMA is to put the two and three on the top of the value stack and plus on the top of the operating stack and when it hits that right parenthesis ,COMMA it's going to perform the operation and it's going to proceed then exactly as if the original input where that ,COMMA where the value replaced .PERIOD so ,COMMA just go in from the inside out for every operation enclosed within parenthesis like that it's just repeat the argument that's exactly as if the original expression were (one + five) twenty and then again ,COMMA replacing that one ,COMMA one + 100 ,COMMA 101 .PERIOD that's ,COMMA that's why dijkstra's algorithm works .PERIOD actually fairly easy to understand why it works .PERIOD and you can go ahead and extend this algorithm to add functions like logs and sines or other operators and have precedence among operators ,COMMA have them associate and multiple operations ,COMMA and so forth .PERIOD and actually that's on the road to developing a compiler or a way to translate a ,COMMA a program from a programming language to a computation ,COMMA so dijkstra's algorithm that uses stack is one way for entering and understanding of the basis of computation .PERIOD 
today we're going to talk about shortest path algorithm .PERIOD this was another problem on graph that's very easy to ,COMMA to state .PERIOD we use ,COMMA again ,COMMA a slightly different graph model .PERIOD last time ,COMMA we had edge -DASH weighted graphs for computing minimum spanning trees .PERIOD now ,COMMA we're going to have edge -DASH weighted directed graphs .PERIOD so now the edges are directed ,COMMA but they're weighted .PERIOD and the problem that we're going to be looking at is to find the shortest path from one vertex to another .PERIOD so in this example ,COMMA we've got a directed graph with a variety of edges ,COMMA the directed edges .PERIOD and our goal is to find given two vertices ,COMMA say zero to six ,COMMA what's the shortest path that takes us from zero to six .PERIOD where the length of the path is the sum of it's weights .PERIOD and in this case ,COMMA the shortest distance from zero to two ,COMMA two to seven ,COMMA seven to three ,COMMA and three to six .PERIOD now ,COMMA the algorithms that we're going to look at for this are classic algorithms and this is an example where years ago we would teach these algorithms ,COMMA algorithms and say ,COMMA well ,COMMA they will be important someday ,COMMA when people have devices ,COMMA with maps on them and will want to get around .PERIOD nowadays ,COMMA of course ,COMMA everyone's familiar with these kinds of devices .PERIOD when you have a map and you want to get from one place to another or you have ,COMMA a device ,COMMA in your car that gives you directions to get from one place to another .PERIOD these devices are implementing the classic algorithms that we're going to talk about today .PERIOD not only that and even more important ,COMMA shortest path is a really interesting and important problem solving model .PERIOD there's all kinds of important practical problems that can be recast as shortest paths problems .PERIOD and because we have efficient solutions to the shortest path ,COMMA efficient algorithms for finding shortest paths ,COMMA we have efficient solutions to all these kinds of problems ,COMMA all around us .PERIOD from texture mapping ,COMMA to network routing protocols ,COMMA to pipelining ,COMMA to trucks ,COMMA to traffic planning ,COMMA we find shortest path applications and we'll look at a couple surprising examples later on today .PERIOD so one thing to think about is ,COMMA let's specify really what the problem's all about a this all different variance ,COMMA similar to many other problems we've studied .PERIOD so one thing is ,COMMA what vertices are we talking about ?QUESTIONMARK so ,COMMA of course ,COMMA the most familiar is so -DASH called source -DASH sink .PERIOD what's the shortest path from one vertex to another ?QUESTIONMARK but actually ,COMMA more useful often is so -DASH called single source shortest path ,COMMA which is all the paths from one vertex to every other .PERIOD and this is the one for example that the navigation system in your car might use .PERIOD the source is where you are and it'll compute the shortest paths to every place else .PERIOD and then when you ask for some place it'll just pick the one that you want in a manner very similar to the api that we're going to talk about .PERIOD another thing that you might do if you didn't have that many vertices is compute all pairs of shortest paths .PERIOD so ,COMMA precompute the path between all pairs of vertices .PERIOD and then immediately be able to direct answer a client query .PERIOD this is the type of thing that was used on the old map ,COMMA for example .PERIOD another thing is the edge -DASH weights .PERIOD usually ,COMMA we think of it in terms of positive edge -DASH weights cuz the maps are geometric and so the length of an edge is proportional to it's distance in the plane .PERIOD but ,COMMA actually for many problems there may be much more arbitrary and actually one of the big issues that we'll see is whether the eggs ,COMMA edge -DASH weights are positive or negative .PERIOD and those types of restrictions are going to give rise to different types of algorithms .PERIOD another issue that arises and is particular important in the presence of negative weights that we'll see at the end ,COMMA is weather or not the graph ,COMMA graph has directive cycles .PERIOD in particular whether the total length of a cycle is negative or not and we'll get to that at the end .PERIOD so ,COMMA and also ,COMMA just to reduce some clutter in our code in the slides ,COMMA we'll throughout the lecture ,COMMA make the simplifying assumption that there are paths from the source to every vertex .PERIOD we won't worry about driving to islands and other such issue .PERIOD to get started ,COMMA we have to develop our apis .PERIOD and this'll be straightforward after cuz this is the fourth variation of a graph api that we've done .PERIOD we started with ,COMMA regular undirected graphs ,COMMA then we did digraphs ,COMMA then we did weighted ,COMMA graphs ,COMMA and ,COMMA now ,COMMA we're doing weighted digraphs .PERIOD so to begin ,COMMA we're going to need a api for processing edges .PERIOD and this is actually simpler for digraphs than it was for undirected graphs ,COMMA cuz we have this concept of one of the vertices is ,COMMA where the edge goes from and the other vertex is where ,COMMA is where it goes to .PERIOD so we have our constructor that builds an edge from ,COMMA the vertex that's given it's first argument to the vertex that's given it's second argument and there's a double list of weight .PERIOD and then ,COMMA the client can ask for the from vertex or the to vertex or the weight or string representation .PERIOD and always in our code we'll use the idiom at the bottom of the slide for processing an edge .PERIOD we'll pick out v which is e .PERIODfrom and w which is e .PERIOD2 and then our code will process v and w .PERIOD the implementation of a weighted directed edge is very similar to the one for undirected graphs ,COMMA but simpler ,COMMA because ,COMMA the ,COMMA constructor ,COMMA simply sets the instance variables from its argument ,COMMA and from and to are simply getter methods as is weight .PERIOD so that's implementation of directed edge for directed weighted graphs .PERIOD so now what about the graph itself ?QUESTIONMARK so ,COMMA edge -DASH weighted digraph .PERIOD so ,COMMA as usual ,COMMA we have a constructor ,COMMA that gives ,COMMA that takes the number of vertices in the graph ,COMMA so we can build data structures that are vertex ,COMMA vertex index arrays .PERIOD or we can reterminate the input stream .PERIOD and then the key methods are add edge ,COMMA which takes in directed edge and adds it to the graph .PERIOD and then the iterable per adjacency list ,COMMA which returns an iterable of all the edges that point from a given vertex .PERIOD so since we're processing edges ,COMMA we can have self loops and parallel edges and most of our code will simply use adj method to iterate through the edges adjacent to vertices .PERIOD representation ,COMMA is very similar to the other representations ,COMMA that we've seen ,COMMA except simpler ,COMMA because it's only one representation of each edge .PERIOD so ,COMMA there's a ,COMMA the ,COMMA instance variable for the adjacency list is a vertex index array .PERIOD each entry is a bag of directed edges ,COMMA actually ,COMMA references to directed edges .PERIOD so ,COMMA the ,COMMA all the code for ,COMMA building and processing this is very straightforward version of code that we've seen before .PERIOD here's the implementation ,COMMA for ,COMMA edge -DASH weighted digraphs .PERIOD it's the ,COMMA the same as our edge -DASH weighted graph ,COMMA except ,COMMA we just replace graph with digraph ,COMMA everywhere .PERIOD and ,COMMA when we add an edge ,COMMA we only add it to the from vertices adjacency list .PERIOD so v is e .PERIODfrom ,COMMA adj v equals add ,COMMA add the edge to that .PERIOD and then to get all the vertices adjacent to a given vertex we just re -DASH used the vertex array just to get its adjacency list and return that bag which is iterable ,COMMA so that the client can iterate through all those vertices .PERIOD a very straightforward version of what we did for edge -DASH weighted graphs .PERIOD okay ,COMMA so now ,COMMA our client for that program is ,COMMA our single source shortest paths ,COMMA api .PERIOD and so ,COMMA it works in a manner very similar to others that we've done and we'll call it sp .PERIOD the constructor takes a graph and a source vertex and it'll go ahead and build the data structures .PERIOD it'll find the shortest path from the short ,COMMA from s vertext to every other vertex in the graph and build the data structures ,COMMA so that it can efficiently answer client queries of ,COMMA first ,COMMA what's the length of the shortest path from s to a given vertex ?QUESTIONMARK and second ,COMMA what's the path ,COMMA give ,COMMA an ,COMMA an iterable that gives the path from the source vertex ,COMMA from the source vertex to the given vertex ?QUESTIONMARK so this test client here will print out all the shortest paths from the given vertex s to every other vertex in the graph .PERIOD go through all the vertices .PERIOD for every vertex ,COMMA you print s to v and the distance from s to v .PERIOD and then for every edge in the path ,COMMA you simply print out the edge ,COMMA so it'll print for every vertex ,COMMA the distance from s to that vertex followed by the path .PERIOD so ,COMMA for example for the sample graph that we gave with vertex zero as the source it'll print out the path from zero to every vertex in the graph .PERIOD so that's a test client that we'll use to make sure to check and learn the operation of our algorithms .PERIOD and this api is going to be effective even for huge graphs .PERIOD so that's and introduction to our shortest paths api .PERIOD 
okay ,COMMA what are the rules that we're going to follow ?QUESTIONMARK well ,COMMA let's start with looking at a typical basic sorting problem .PERIOD say ,COMMA university has student records and for every student there is a certain amount of information .PERIOD maybe there's a class number ,COMMA there is a grade ,COMMA there's a phone number maybe an address so we refer to an item and it has a record or the information that we're going to sort .PERIOD but in particular ,COMMA there's a piece of a record called a key and what we want to do is put the records into order according to the key .PERIOD that's the sort problem .PERIOD re -DASH arrange an array of n items into ascending order according to a defined key which is part of the item .PERIOD now ,COMMA our goal is to be able to sort any type of data so let's look at a couple of client programs .PERIOD first example is to just sort some random real numbers into ascending order .PERIOD so ,COMMA here's a client that calls our insertion sort method and all it does is read numbers from standard input than into an array a then calls insertion sort and then prints them out .PERIOD and you can see on the right that the numbers are printed out in sorted order .PERIOD this seems like an artificial kind of input but actually we'll look at an application even in this lecture .PERIOD and then there are many applications where random inputs are fine model .PERIOD here's maybe a more familiar sort client that sort strings .PERIOD and in this case it reads the strings from a file using our readstrings() method in our in class that which takes a file as argument .PERIOD so we take the file name as the first command line argument ,COMMA read in array of string from that file separated by blanks ,COMMA call an insertion .PERIODsort() method again .PERIOD so ,COMMA insertion .PERIODsort is a method that takes an array a as its parameter and it ,COMMA it's the first argument and it rearranges the strings in that array to be in sorted order .PERIOD so in this case words ,COMMA words three .PERIODtext has the certain number of three letter words and this client program will result in those three letter words being rearranged into alphabetical order .PERIOD here's another client that we could use our sort program for ,COMMA if we achieved the goal of sorting any type of data .PERIOD in this one ,COMMA we're going to sort file ,COMMA file's name in a given directory .PERIOD so again we use the file class from java and we use ,COMMA we go and use the listfiles() method from that class to get an array that contains all the file names in the given directory .PERIOD that's an array with file names in it and insertion .PERIODsort() takes that array as its first argument and again sorts them and then we go ahead and use as ,COMMA go through them one by one and print them and they come out in order of file name .PERIOD so that's three different clients ,COMMA three completely different types of data .PERIOD and the first rule of the game that we have to think about is ,COMMA how can we make it so that we can implement one sort program that can be used by these three different clients to implement three different types of data .PERIOD in the way that ,COMMA that happens is a mechanism known as a callback .PERIOD so ,COMMA that's our basic question ,COMMA how can sort ,COMMA now ,COMMA how to compare data of all those different types without being given any information about the type of an item's key ?QUESTIONMARK and the answer is that what is we set up a mechanism known as a callback or reference to executable code where the client ,COMMA by passing an array of objects to the sort function .PERIOD in java ,COMMA there's an implicit mechanism that says that any such array of object is going to have the compareto() method ,COMMA then the sort function calls back the compareto() method associated with the objects in the array when it ever needs ,COMMA whenever it needs to compare two items .PERIOD there's a lot of different ways to implement callbacks and that's programming language specific .PERIOD different languages have different mechanisms .PERIOD it's all about the idea of passing functions as arguments to other functions which is the pair and gets into functional programming and thinking all the way back to turing and church .PERIOD for java ,COMMA because of the desire to check types at compile time ,COMMA the use of specific method called an interface and then ,COMMA we'll look at the details of how to implement callbacks with the java interfaces now .PERIOD it's a little bit of programming language detailed but it's ,COMMA it's really worthwhile because it allows us to use the sorts that we developed for any type of data in a type safe manner .PERIOD so we already looked at some clients .PERIOD this is the example of the client program that sorts the files in a given directory by file name .PERIOD so it just calls our sort() method with a ,COMMA an array some type of object as first argument .PERIOD now ,COMMA built in to java is the so -DASH called the comparable interface and all the comparable interface is the specification that a type ,COMMA data type that implements comparable will have a compareto() method .PERIOD and it's generic and will be compared to against a certain type of item .PERIOD now when we implement objects that are to be sorted we'll implement the comparable method .PERIOD that's up in the top class file ,COMMA implements comparable file .PERIOD and since sorting is an operation that's used in so many situations ,COMMA many of the standard java types that you would expect to involve sorts will implement comparable .PERIOD and all that means is that ,COMMA that data type has an instance method that will implement the compareto() method .PERIOD it'll compare this object against the object given as argument and depending on some complicated tests ,COMMA it'll return  -DASH 1 ,COMMA meaning less ,COMMA +1 ,COMMA meaning greater or 0 ,COMMA meaning equal .PERIOD now ,COMMA that compareto() method is really all that the sort implementation needs .PERIOD first it says that ,COMMA that it's going to take as argument an array of type comparable .PERIOD so that means ,COMMA the objects in the array are going to implement the comparable interface or that it will have a compareto() method .PERIOD and then the sort code can just use that compareto() method ,COMMA invoked in a sense of the object like an entry in the array and as argument and another instance in the object like another entry in the array to test whether the first is less than the second as in this example .PERIOD the key point is that the sort implementation has no dependence on the type of data that's handled by the comparable interface and a different comparable array will be sorted in the same way though eventually ,COMMA because of the interface mechanism ,COMMA they call back to the actual compareto() code that goes with a type of object being sorted .PERIOD now there's a few rules and there's natural rules but they're worth talking about and paying attention to that the compareto() method has to implement in the so called a total order .PERIOD in all that saying is really that it must be possible to put items in order in a sort .PERIOD so there's three properties .PERIOD first one says that if v is less than or equal to w and w is less than or equal to v then the only way for that to be true is if they're equal and then there's transitivity .PERIOD if v less than w ,COMMA w is less than x ,COMMA then v must be less than or equal to x .PERIOD in totality ,COMMA is that either v is less than or equal to w or w is less than equal to v or both they are equal .PERIOD and there's plenty of natural total orders in the types of data that we normally want to consider for sort keys .PERIOD like the integers or natural numbers or real numbers or alphabetical order for strings ,COMMA chronological order for dates or times and so forth .PERIOD the cartoon on the right shows that not all orders are necessarily total orders .PERIOD so ,COMMA rock ,COMMA paper ,COMMA scissors is intransitive .PERIOD if you know that v is less that w ,COMMA w is less than v ,COMMA you don't know that v is less than or equal to v .PERIOD i'm sorry ,COMMA v is less than w ,COMMA w less than equal to x that you don't necessarily know that v is less than or equal to x .PERIOD alright .PERIOD so the comparable api then ,COMMA by convention in java we always need to implement compareto() such that v that compared to w is a total order .PERIOD and also by convention ,COMMA it returns a negative integer for its less zero if it's equal positive its greater .PERIOD if this object is greater than the object given as argument .PERIOD if the types are incompatible or if either one is null compareto() should throw an exception .PERIOD now ,COMMA again ,COMMA many of java's standard types for numbers and dates and files and so forth implement compareto() by convention .PERIOD now if we're going to implement our own type then we have to go ahead and implement the comparable interface according to these rules .PERIOD and usually that's fairly straightforward .PERIOD so here's an example .PERIOD it's a simplified version of the date class that's implemented within java just to show the idea of implementing comparable .PERIOD so ,COMMA after the class declaration ,COMMA we write implements comparable and then we fill in the generic with the same type because we're only going to compare dates to other dates .PERIOD in this implementation ,COMMA the date class has three instance variables .PERIOD the month ,COMMA the day and the year and the constructor fills those from the arguments as you can see .PERIOD so now ,COMMA if you want to compare two different dates then the first thing to do is to check if this year is less than that year ,COMMA over that is the year given ,COMMA the date given in the argument .PERIOD if that's true then it's less return  -DASH 1 and if it's ,COMMA the year is greater ,COMMA return +1 .PERIOD otherwise ,COMMA the year ,COMMA years must be equal so we have to look at the months to do the compare and so forth down to do the days .PERIOD only if they're all equal that we return zero .PERIOD so ,COMMA that's an example of an implementation of comparable by implementing the compareto() method to put dates in order as you might expect .PERIOD so the java language helps us with this comparable mechanism so that we can sort data of any type .PERIOD when we continue to implement sorting algorithms ,COMMA we're actually even in a hide that beneath our own implementations .PERIOD so ,COMMA that are sorting algorithms actually their actual code can be used to implement sorting in many other languages .PERIOD the way we do that is to take the two primary operations ,COMMA compares and exchangers that were that were ,COMMA were used to refer the data and encapsulate them just the static methods .PERIOD so ,COMMA we're going to use a method less() that takes two comparable objects as arguments and it just returns ,COMMA v .PERIODcompareto(w) less than zero .PERIOD and then the other thing that we do when we sort items that are in an array is to ,COMMA to swap or exchange of the item at a given index i with the one at a given index j .PERIOD and that's every programmer's first introduction to assignment statements .PERIOD we save a[i] in a variable swap ,COMMA put a[j] in a[i] ,COMMA and then put swap back in a[j] .PERIOD so now our sort methods to refer the data will just use this two static methods .PERIOD and there's a good reason for that .PERIOD here's an example .PERIOD suppose we want to test if an array is sorted .PERIOD so this is a static method that is supposed to return true if the array is sorted and false if it's not .PERIOD and all it does is just go through the array from the one to the length of the array and test if each item is less than the one before .PERIOD if you have an item that's less than one before then it's not sorted you return false .PERIOD if you get all the way through the array without that happening ,COMMA then you say the array is true .PERIOD that's pretty simple code ,COMMA the question is ,COMMA if you have a sorting algorithm that passes that test ,COMMA are you sure that it correctly sorted the array ?QUESTIONMARK well the answer to that question is ,COMMA yes if ,COMMA yes if you used only the less() and exchange() methods to implement ,COMMA to refer the data because then you know because you used the exchange() method that the data in the array after the sort is the same data as was in the array before the sort ,COMMA sort .PERIOD if you have a sort method that can store any values in an array ,COMMA it could ,COMMA for example ,COMMA store zeros in every array entry that method would pass this test ,COMMA but it didn't really correctly sort the array because overwrote all the values .PERIOD so ,COMMA we use less() and exchange() to be sure that we can test that our ,COMMA our methods work with the method like this .PERIOD 
the first elementary sorting method that we're going to take a look at is an easy method known as selection sort .PERIOD the idea of selection sort ,COMMA is start out with a unsorted array and we'll use these playing cards as an example .PERIOD and in the ith iteration ,COMMA we go through the array to try to find the smallest remaining entry ,COMMA in this case ,COMMA the 2 is the smallest from any entry .PERIOD and then we'll swap that with the first entry in the array and then we know we've got one step done .PERIOD selection sort is based on iterating that idea .PERIOD okay .PERIOD so ,COMMA the basic selection sort method is to ,COMMA in the ith iteration ,COMMA find the smallest remaining entry and to the right of i or bigger index than i and then swap that with i .PERIOD so ,COMMA we start out i is at the left end and then the remaining ,COMMA all the remaining entries to the right .PERIOD we scan through and the smallest one is the two ,COMMA three entries from the right so we swap that .PERIOD so that's the first step .PERIOD now ,COMMA that part of the array to the left of i is in it's final order and we simply continue .PERIOD so now ,COMMA the smallest is the three .PERIOD swap that with i ,COMMA increment i .PERIOD so now ,COMMA we have the two and three in order ,COMMA continuing that way .PERIOD find the smallest ,COMMA the four .PERIOD swap that one with i ,COMMA increment i .PERIOD find the smallest ,COMMA it's five ,COMMA swap that with i ,COMMA increment i .PERIOD find the smallest ,COMMA swap that with i ,COMMA increment i .PERIOD  each time we have to scan through all the remaining entries in order to find the smallest .PERIOD but then ,COMMA once we found it ,COMMA we only have to swap two cards those are both key properties of selection sort .PERIOD now the eight is the smallest and we swap .PERIOD and now ,COMMA we know they're in order but the program doesn't so we have to look and decide that i and n are the same and then it swaps it with itself and does the same thing for the last .PERIOD and so ,COMMA after that process ,COMMA then we know that the entire array is in its final order ,COMMA all sorted .PERIOD alright .PERIOD so let's ,COMMA one way to understand the way that an algorithm works is to think about invariants  .PERIOD so ,COMMA for the selection sort ,COMMA we have a pointer that was our variable i ,COMMA that scans from left to right .PERIOD now ,COMMA it's indicated by a little red arrow in this representation .PERIOD the invariants are that the entries on onto the left of the arrow are never changed and they're in ascending order .PERIOD no entry to the right of the arrow is smaller than any entry to the left of it .PERIOD that's the way that we set it up .PERIOD and the algorithm maintains those invariants by finding the smallest entry to the right and exchange it with the next one .PERIOD so the code implements the invariants .PERIOD so ,COMMA to move the pointer to the right ,COMMA we increment i .PERIOD so ,COMMA now the invariant might be violated so we have to fix it .PERIOD it might be violated because you might have an element to the right of the pointer that is  smaller than some ,COMMA the element on the pointer .PERIOD so ,COMMA what we have to do is identify the index or that minimum entry and exchange it .PERIOD then once we've exchanged it ,COMMA again ,COMMA we preserved our invariant .PERIOD after that point ,COMMA no element to the left of the pointer is going to change and all the element ,COMMA there's no smaller element to the right .PERIOD [cough] and that gives us immediately our code for the selection sort implementation .PERIOD we identify the ,COMMA the length of the array that's n .PERIOD then we have a for loop that goes through every element in the array ,COMMA we keep a variable min in that is the index of the going to be the index of the smallest element to the right of pointer i .PERIOD we have an inter -DASH for loop that for j ,COMMA if it finds a smaller one ,COMMA resets min and then once we've looked at all the elements to the right of i we exchange the smallest one with i .PERIOD that's a complete implementation of selection sort .PERIOD now it's easy to develop on mathematical model for the cost of selection sort and here's the proposition that describes that .PERIOD selections or uses about n^2 / 2 compares and exactly n exchanges .PERIOD and just looking at this trace of selection sort and operation really is a proof ,COMMA visual proof of this proposition .PERIOD in this diagram ,COMMA the entries in black ,COMMA are the ones that are examined in order to find the minimum each time with the minimum in red .PERIOD entries in gray are not touched ,COMMA they're in their final position .PERIOD well ,COMMA you can see that this isn't going to be in general an n by n square and about half of the elements in the square are black or about n^2 / 2 and you can see also the exact formula (n  -DASH  1) + (n  -DASH  2) and so forth is the total number of compares used .PERIOD and then on each of the ns values of the variable i there's an exchange so that's the cost in terms of the number of exchanges .PERIOD now ,COMMA what's interesting about this proposition about selection sort is that ,COMMA it doesn't matter what order the input is .PERIOD selection sort is going to use quadratic time because it always has to go through the whole thing to look for the minimum .PERIOD and another property is that you can't sort moving less data because selection sort does just a linear number of exchanges .PERIOD every item is put in to it's final position with just one exchange .PERIOD let's look at an animation of selection sort in operation .PERIOD [cough] you can see our pointer moving from right to left every time it finds the smallest element to the right ,COMMA it exchanges it into position .PERIOD now ,COMMA if the array is partially sorted ,COMMA it doesn't matter to selection sort .PERIOD still has to go through ,COMMA even if it's totally sorted ,COMMA still has to go through to the side where that minimum element is .PERIOD that selection sort ,COMMA our first elementary sorting method .PERIOD 
to put our ,COMMA all our algorithms into context and better understand them .PERIOD what we'll do now is go through some basic properties .PERIOD of shortest paths in ,COMMA edge weighted directed graphs .PERIOD so ,COMMA what kind of data structures are gonna need ,COMMA first of all ?QUESTIONMARK our goal is to find the shortest path from s to every other vertex .PERIOD so ,COMMA the first observation is that there's gonna be a shortest paths tree solution .PERIOD well if no two paths have the same length ,COMMA then certainly ,COMMA it's gonna be ,COMMA such a solution and there's a number of ways to convince yourself ,COMMA that there's gonna be a tree .PERIOD if you've got two paths to the same vertex ,COMMA you can delete the last edge in one of them and keep going until all that's left is a tree ,COMMA for example .PERIOD so what we wanna do is compute a tree .PERIOD now ,COMMA we've done that ,COMMA in several algorithms before .PERIOD and a reasonable way to represent the shortest path's tree is to use two vertex indexed arrays .PERIOD the first one is for every vertex .PERIOD compute the length of the shortest path from s to that vertex .PERIOD so in this case ,COMMA we have this shortest pastry ,COMMA and we'll keep the length from the shortest path from the source ,COMMA zero to each vertex .PERIOD so zero two ,COMMA two ,COMMA the length of that shortest path is 26 .PERIOD 027 two ,COMMA seven ,COMMA it's 0 .PERIOD60 and like that .PERIOD and so ,COMMA because you go from zero to 2 .PERIOD36 and from two to 7 .PERIOD34 you get 60 .PERIOD ,COMMA and so forth .PERIOD and the other thing is ,COMMA we've done before is use parent link representation ,COMMA where edge 2v is gonna be the last edge that takes us to v .PERIOD and by following back through that array ,COMMA we can get the path ,COMMA as we have done several times before .PERIOD if we want the path from zero to six ,COMMA we go to edge 26 and says well ,COMMA the last thing we do is three to six then we go to three and say the way we got to three is from seven we go to seven say the way we got to seven is from two we go to two and say that's the way we got to zero and if we put all those things on a stack ,COMMA then we can return them as an noterable to the client and that gives the edges on the shortest path .PERIOD so that's the data structures that we're going to use for shortest paths .PERIOD this is ,COMMA actually the code that does ,COMMA what i just said .PERIOD the client query give me the distance ,COMMA it just ,COMMA returns ,COMMA uses v to index into the instance array and returns the distance .PERIOD and if the client asks for the path ,COMMA then we make a stack and then ,COMMA its variable e is a directed edge ,COMMA and we started edge 2v .PERIOD and as long as it's not null ,COMMA we push it onto the path and then go to the edge two entry for the vertex that we came from and that gives the vertex that we came from to get to that vertex and keep going until we run out of vertices which happens at the source .PERIOD then return to path and that's iterable that gives the client the path .PERIOD so that's the implementation of the two query method .PERIOD so ,COMMA now what we're want ,COMMA we're going to want to talk about for the rest of the lecture is the algorithms that build these data structures .PERIOD now ,COMMA all of the algorithms that we look at are based on a concept called relaxation or edge relaxation .PERIOD so ,COMMA now recall that our data structure .PERIOD so we're gonna talk about relaxing an edge from v to w and we have an example here ,COMMA from v to w .PERIOD and at the point that we're gonna relax this edge .PERIOD we'll  ,COMMA have our data structures in process in this too .PERIOD we haven't seen all edges .PERIOD we haven't seen all passes ,COMMA paths in the intermediate part of some algorithm .PERIOD so ,COMMA but we'll try to make sure that this 2v for every vertex is the length of the shortest known path to that vertex .PERIOD and that's gonna be the same for w .PERIOD so ,COMMA these are all the edges that are in edge two that we know pass from some s to some vertex .PERIOD so this 2v and this 2w will contain its shortest known path .PERIOD now ,COMMA if we in also edge 2wv is the .PERIOD edge 2w is the last edge in the shortest known path from s to w .PERIOD and the same way with extra v of course .PERIOD now ,COMMA so to relax along the edge from v to w ,COMMA essentially that means ,COMMA let's update the data structures to take that edge to an ,COMMA into account .PERIOD and what happens in this case is that the edge gives a better way to get to w so that's what relaxing is .PERIOD that edge gives us a new shortest pass so we want to include it in the data structure .PERIOD so since it has a shorte r path ,COMMA we have to update both ,COMMA disc 2w and edge 2ww that is ,COMMA we have a new way to get to w .PERIOD so we have to throw away ,COMMA throw away that old edge that came to w and we have ,COMMA a new shorter distance .PERIOD instead of 7 .PERIOD2 that came that old way ,COMMA we have 4 .PERIOD4 that gets us ,COMMA a new way .PERIOD so edge relaxation ,COMMA is a very natural operation .PERIOD when we consider a new edge ,COMMA does it give a new shortest path to that vertex or not ?QUESTIONMARK if it doesn't ,COMMA we ignore it .PERIOD if it does we update the data structures to include that edge and forget about the old edge that to took us ,COMMA took us to that vertex .PERIOD that's edge relaxation .PERIOD and this is ,COMMA easy implementation of edge relaxation in code .PERIOD so to relax and edge .PERIOD we pull out its front and two vertices in vnw according to our standard idiom ,COMMA and then we just see if the distance to w that's ,COMMA what's the shortest path before ,COMMA is bigger than the distance to v plus the weight of the edge that would take us from v to w if it's bigger ,COMMA that means we've found a new path .PERIOD if it's less than or equal we ignore it .PERIOD and if we found a new path we have to update the distance to w to be the new distance .PERIOD distance to v plus follow vw .PERIOD and then we have to update edge 2w and throw away the old version and say that our new edge from v to w is the best path to w as far as we know .PERIOD so that's easy code for edge relaxation .PERIOD now we're gonna use edge relaxation in a really fundamental way to compute shortest paths ,COMMA but there's one other important idea which is called optimality conditions ,COMMA and this is a way to know that we have shortest paths ,COMMA and we have computed all the shortest paths ,COMMA so the shortest path ,COMMA optimality conditions ,COMMA are is embodied in the ,COMMA in this proposition ,COMMA so we have an edge way to diagraph .PERIOD and we have the this two array .PERIOD let's just talk about the distances and path go with the distances .PERIOD but the key point is that this two array represents the shortest path distances from the given source s ,COMMA if and only if these two conditions hold .PERIOD so the first thing is ,COMMA if its the length for every vertex ,COMMA this 2v is the length of some path from s to the vertex ,COMMA and our algorithm always try to ensure ,COMMA will ,COMMA always ensures that .PERIOD and then ,COMMA the second thing is for every edge ,COMMA vw we have this condition that ,COMMA that this 2w that we ,COMMA have stored is less than or equal to this 2v ,COMMA plus the weight at the edge from v to w .PERIOD that's the shortest path optimality conditions .PERIOD if ,COMMA they're equal ,COMMA so sometimes ,COMMA they'll be equal .PERIOD for example ,COMMA if vw is the last edge on the shortest path .PERIOD and sometimes ,COMMA it would be great if it ,COMMA it ,COMMA never been smaller ,COMMA and never be way to get the w that we haven't found .PERIOD that's the shortest path ,COMMA optimality conditions .PERIOD and again ,COMMA just a quick proof although best way to understand proof is that we've been slowly now listen to them ,COMMA spoken quickly ,COMMA but i'll quickly outline them .PERIOD so here is the ,COMMA the necessary suppose that so ,COMMA so we wanna prove that if ,COMMA if this is true then we have shortest paths .PERIOD so to do that we assume the contrary .PERIOD suppose that the distance to w is bigger than the distance to b + e that way for some edge .PERIOD then that path is gonna give a path to w that's shorter than distance w cause v is the path and the wait's shorter .PERIOD in that is a contradiction to the idea that you have shortest paths so there can't be any ,COMMA such edge where that condition holds .PERIOD so that's necessary and then sufficient .PERIOD suppose that we have shortest path from s to w .PERIOD then now we're assuming these conditions all hold .PERIOD then ,COMMA for every edge on the path this has to all hold .PERIOD so ,COMMA so ,COMMA for ,COMMA it starts at the end .PERIOD so ,COMMA the distance to the last edge goes from vk  -DASH  one to vk .PERIOD so distance to vk is less than or equal to the distance to vk  -DASH  one plus the weight of the kth edge .PERIOD and so just continuing down that way then from the source to the first edge ,COMMA but it's a source plus the weight of the first edge is greater or equal distance to the first vertex after the source ,COMMA and all those conditions have to old .PERIOD and then ,COMMA what we can do is just add up all those weights .PERIOD and simplify it .PERIOD but and then that shows that the distance to w is equal to the length of the shortest path .PERIOD an d so it's gotta be the weight of the shortest path .PERIOD because it's the weight of some path and it's got that weight ,COMMA it's gotta be the weight of the shortest path .PERIOD so if those conditions hold we have shortest paths .PERIOD so our the ,COMMA the point of this proof ,COMMA it's a slightly complicated proof ,COMMA but it's not too bad ,COMMA it's quite natural is that all we have to know to w -DASH  ,COMMA check that we have computed shortest path .PERIOD these are these optimality conditions hold ,COMMA to prove that an algorithm computes shortest paths .PERIOD we just have to prove that it ends up with the optimality conditions and force ,COMMA and that's what we'll be doing .PERIOD and the optimality condition ,COMMA really ,COMMA it's just saying that there's no edge there that we missed .PERIOD okay so with that idea ,COMMA in fact there's a very simple ,COMMA easy to state ,COMMA generic algorithm that is going to compute shortest paths .PERIOD and it's very simple .PERIOD we start with the distance to the source being zero and the distance to every other vertex infinity .PERIOD and all we do is repeat until the optimality conditions are satisfied ,COMMA relax any edge .PERIOD just go ahead and relax edges until the optimality conditions are satisfied .PERIOD so ,COMMA that's a very general algorithm .PERIOD we don't say how to decide which edge to ,COMMA relax or how to know the optimality conditions are satisfied .PERIOD but still ,COMMA it's ,COMMA quite an amazingly simple generic algorithm .PERIOD so ,COMMA how do we know ,COMMA how can we show that it computes the sbt ?QUESTIONMARK well it's pretty simple .PERIOD throughout the algorithm .PERIOD we're making sure that because of the way that we do relax edges the distance to v is the length of a simple path from s to v ,COMMA and edge s to v is the length of a simple path from s to v and edge to v is the last edge on that path that's what relaxation does for any vertex that we touch .PERIOD and not only that ,COMMA every relaxation that succeeds decreases the distances .PERIOD and we've assumed that there's a way to get to every ,COMMA every vertex .PERIOD and there's only a finite number for paths .PERIOD so it can decrease ,COMMA at most ,COMMA a finite number of times .PERIOD so it's going to ,COMMA the algorithm's gonna terminate .PERIOD it's as simple as that .PERIOD a gain ,COMMA this is a little bit of a mind blowing concept .PERIOD but we'll leave that for more careful study and just for now realize that all we have to do is relax along edges .PERIOD and what we're going to do now is look at .PERIOD different ways of figuring out how to choose which edge to relax .PERIOD the first algorithm that we'll look at is a classic algorithm known as dijkstra's algorithm one of the most famous of all algorithms .PERIOD and that is effective when the weights are non negative .PERIOD then we'll look at an algorithm that works even with negative weights as long as there aren't any directed cycles .PERIOD and then we'll look at an even older algorithm than dykstra's ,COMMA the bellman -DASH ford algorithm .PERIOD that can ,COMMA solve the shortest path ,COMMA problem and graphs with negative weights ,COMMA as long as there's ,COMMA no negative 
now ,COMMA we look at insertion sort which is another elementary method and interestingly has quite different performance ,COMMA characteristics than selection sort .PERIOD let's look at a demo of insertion sort .PERIOD for insertion sort ,COMMA what we're going to do is we'll move an index i from left to right as before .PERIOD but now ,COMMA in the ith iteration we're going to move a(i) into position among the elements to its left .PERIOD let's look at how that works on our example with cards .PERIOD so now we start by initializing i to first card and we take the idea that everything from i to its left is going to be sorted and everything from the right ,COMMA we're not going to look at ,COMMA at all .PERIOD so ,COMMA everything to the left of i is in ascending order everything to the right we haven't seen at all yet .PERIOD so now ,COMMA when we increment i ,COMMA well ,COMMA in this case it's already an order ,COMMA we don't have anything else to do .PERIOD in the third case now ,COMMA when i at the third entry in the array .PERIOD now ,COMMA we start a index j and we move that starting at i to the left and what we need to do is just exchange the five with every element to its left that's greater .PERIOD so ,COMMA first we exchange it with the ten .PERIOD it's still not in place so we exchange it with the seven .PERIOD now ,COMMA we get to the beginning array ,COMMA of the array and once we've done that or we've hit a smaller element then we have everybody to the left of i in order .PERIOD [cough] so now we increment i again and we come to the three .PERIOD again ,COMMA we exchange as long as the card immediately to the left is greater .PERIOD and once we've done that ,COMMA then we have everything to the left of i in ascending order .PERIOD now ,COMMA in this case ,COMMA we have the eight and we only have to exchange one and now ,COMMA it's got the seven to its left and everything is in order .PERIOD so ,COMMA we've achieved putting it in order with less work in this case .PERIOD we don't always have to go all the way back to the beginning .PERIOD for exchange it with everybody to its left that's greater ,COMMA until we find a smaller element done in its ascending order .PERIOD two has to go all the way back to the begin ning [cough] .PERIOD but then the very next one ,COMMA the nine ,COMMA has to only go back one position .PERIOD and the sixth has to go about halfway back .PERIOD [cough] and then ,COMMA we have the entire array sorted .PERIOD again ,COMMA we can look at insertion sort in terms of invariants .PERIOD our pointers still scans from left to right but now ,COMMA the elements of the left of the pointer ,COMMA including it ,COMMA are in order .PERIOD but the elements to the right have not yet been seen at all .PERIOD so ,COMMA we have to look at the code that's going to maintain that invariant as the pointer increments .PERIOD move the pointer to the right ,COMMA it's incremented again .PERIOD now ,COMMA the invariant is broken because the elements the element on the pointer is not in sorted order to put it in sorted order ,COMMA we have to move from right to left exchanging it with every larger elements to its left .PERIOD and that's with the code at the bottom does starts j at i and decrements j exchanging j with the elements to its left .PERIOD a(j) with the element to its left ,COMMA a(j)  -DASH  one as long as a(j) is less than a(j)  -DASH  one or j is bigger than zero .PERIOD and that immediately gives the ,COMMA this code for insertion sort which is similar to our code for selection sort and just as simple it gets two nested for loops .PERIOD selection sort head to nested four loops a test to comparison and an exchange inside the four loop .PERIOD and that's a fine implementation of an elementary sorting method .PERIOD what about the analysis of insertion sort ?QUESTIONMARK it's more complicated .PERIOD our proposition says that insertions sort to sort randomly ordered array with distinct keys ,COMMA it'll use about one -DASH fourth n^2 compares and about the same number when one -DASH fourth n^2 exchanges on the average .PERIOD this is more complicated to prove .PERIOD it depends on the array being randomly ordered .PERIOD and again ,COMMA you can get a feeling for where the propositioning comes from by looking at this n by n trace .PERIOD again ,COMMA the black elements are the ones that we compare and actually ,COMMA there are also the exchanges .PERIOD and the red one is the one that's finally put in to place .PERIOD and you can see t hat for a large array that's randomly ordered ,COMMA the element that we put into place is going to go about half way back on the average .PERIOD so ,COMMA that means about half the elements below the diagonal are going to black on the average cuz n^2 / two below the diagonal ,COMMA half of that is n^2 / four .PERIOD the analysis ,COMMA exact analysis is not much more detailed than that .PERIOD this is a bigger trace that shows again ,COMMA about half the elements below the diagonal or involved in the sort .PERIOD [cough] let's look at in the animation .PERIOD since n^2 / four versus n^2 / two ,COMMA insertion sort is going to be about twice as fast as selection sort .PERIOD so ,COMMA we can do about twice as many items in the trace in the same amount of time .PERIOD it grabs an element ,COMMA brings it back into position ,COMMA every time .PERIOD so ,COMMA it's an animation for randomly ordered items .PERIOD now insertion sort does depend on the initial order of the data .PERIOD let's look at the best case and the worst case which are certainly outliers .PERIOD if the array happens to be already sorted all insertion sort does is really to validate that each element that's got a smaller element to its left so it does no exchanges and it gets the sorting job done with just n  -DASH  one compares .PERIOD on the other hand ,COMMA if the array is in descending order n is no duplicates ,COMMA then every element goes all the way back .PERIOD it makes n^2 / two compares and n^2 / two exchanges .PERIOD so in the first case is much ,COMMA much faster than selection sort linear instead of quadratic .PERIOD in the second case ,COMMA it's slower than an selection sort cuz it uses about the same number of compares but it uses many more exchanges .PERIOD so ,COMMA let's see that in the animation .PERIOD so ,COMMA this is when the items come in ,COMMA in reverse order .PERIOD now ,COMMA every time [cough] it ,COMMA it gets a new item ,COMMA that's to exchange it all the way back to the beginning .PERIOD same kind of dynamic characteristic is selection sort except for every step ,COMMA iit's not just comparing ,COMMA it's also exchanging which makes it even slower in practice .PERIOD so ,COMMA this is the bad case that we wouldn't like to see in th e practical application but there's also a good case that actually we take advantage of in plenty of practical applications .PERIOD and that has to do with when the array is partially sorted .PERIOD to talk about this in a quantitative way ,COMMA we define what's called an inversion .PERIOD an inversion is just a pair of keys that are out of order in the array .PERIOD so this array has six inversions ,COMMA t and r are out of order cuz r should go before t .PERIOD t and p are out of order and so forth .PERIOD this array has six inversions .PERIOD and we define array to be partially sorted if its number of inversions is linear ,COMMA if it's less than some constant times n .PERIOD and partially ,COMMA sorted arrays appear often in practice .PERIOD for example ,COMMA if you have a large array with just a few that's sorted except for just a few unsorted elements appended at the end it's going to be [cough] partially sorted .PERIOD or another case is if you only have a few entries out of place ,COMMA the array is going to be partially sorted .PERIOD these types of things rise often in practical applications and what's interesting about insertion sort is that it runs in linear time for partially sorted arrays .PERIOD and the proof is the number of comparisons and the number of exchanges is equal to the number of ,COMMA number of exchanges is equal to the number of inversions and then there's an extra compare for every element except the first .PERIOD so ,COMMA let's look at how that looks in the animation .PERIOD here's a partially sorted array and you can see that insertion sorts quickly gets the job done .PERIOD we're going to take advantage of this in a little bit later in this lecture .PERIOD that's insertion sort ,COMMA our second elementary sorting 
now we're going to look at shortest paths and edge weighted dags .PERIOD this is a very common situation and we'll see a couple of important applications .PERIOD suppose that you've got an edge weighted digraph .PERIOD that's our input to shortest paths .PERIOD but you konw there's no directed cycles .PERIOD and actually that's true and in many applications we see some .PERIOD the question is this fact that it has no directed cycles make it easier to find the surest path than in a general digraph ,COMMA and the answer is yes ,COMMA it certainly does .PERIOD so lets take a look at what happens .PERIOD and the algorithm is very simple .PERIOD what we're going to do is ,COMMA just consider the vertices in topological order .PERIOD since there's no cycles ,COMMA we know there's a topological ordering where we can lay out the graph and all the edges point to vertices that we haven't seen yet .PERIOD and so we're just relaxed all edges ,COMMA pointing from each vertex ,COMMA taking them in topological order .PERIOD again ,COMMA this'll be easy to see in an example .PERIOD alright ,COMMA so here's a edge -DASH weighted directed acyclic graph .PERIOD and the first thing that we do is sort it in topological ,COMMA sort the vertices in topological order .PERIOD and we talked about an algorithm for doing that a couple of lectures ago .PERIOD so just using that first search .PERIOD so we consider vertex zero ,COMMA and relax all the edges coming from vertex zero .PERIOD and that gives us shortest paths to one four and seven .PERIOD so next we consider vertex one .PERIOD we don't do anything except take the next vertex in topological order .PERIOD we could of also taken four in this case .PERIOD and so we're going to add that .PERIOD and then just relax along all the edges coming from that vertex .PERIOD in this case that gives us new shortest paths to two and to three .PERIOD next is four relax and that gives us new shortest paths to five and six .PERIOD next in topological left quarter is seven .PERIOD relax and that gives us a new shortest path to two ,COMMA but not to five .PERIOD the path that we had to five was better .PERIOD so next in the order is five .PERIOD relax along its edges .PERIOD and it gives us better ways to get to both two and to six .PERIOD then 2's next .PERIOD relax along its edges .PERIOD and it gives us ,COMMA new better ways to get both three and six .PERIOD then we do three ,COMMA and relax .PERIOD and that doesn't help .PERIOD and then we do six .PERIOD and ,COMMA when we're done all we did was consider the edges in topological order and relax .PERIOD then we have a shortest path tree .PERIOD from the source to every vertex in the directed acyclic weighed digraph .PERIOD so that's a demo of a simple algorithm for that case .PERIOD alright ,COMMA why does that algorithm considering the vertices and topological work for edge -DASH weighted dags .PERIOD now ,COMMA one thing that's pretty important about this is that the edge weights could even be negative doesn't matter to this algorithm .PERIOD so let's look again .PERIOD every edge is relaxed exactly once .PERIOD when ,COMMA we add a vertex to the tree we ,COMMA relax each of the edges that go from that vertex .PERIOD and ,COMMA again ,COMMA just as ,COMMA with dykestra ,COMMA after we're done with the relaxation ,COMMA we have this condition holds that ,COMMA distance to w is less than or equal to the distance to v plus the edge weight .PERIOD either it was before -DASH hand and we ignored the weight ,COMMA or we made it equal .PERIOD and so .PERIOD when we relax an edge we have that condition .PERIOD and again ,COMMA inequality holds until the algorithm terminates .PERIOD well ,COMMA first ,COMMA again ,COMMA we only .PERIOD decrease values in the distribute array .PERIOD we don't change it to increase .PERIOD so the only thing that can happen to this 2w is that it gets smaller .PERIOD and that's not going to violate the inequality .PERIOD and then the other thing is ,COMMA this 2v's not going to change because of the topological order .PERIOD when we process v ,COMMA it's in topological order .PERIOD that means we're not going to find an edge that points 2v .PERIOD so this two v's not going to change .PERIOD and edge weight doesn't change ,COMMA so the inequality holds .PERIOD and this is true even if the edge weights are negative .PERIOD so shortest path optimality conditions hold .PERIOD and so this simple algorithm finds shortest paths in edge -DASH weighted directed acyclic graphs .PERIOD whether or not the edge weights are positive or negative .PERIOD pretty easy algorithm to implement .PERIOD so this ,COMMA acyclic ,COMMA shortest path .PERIOD so ,COMMA the goal is to compute edge two and disc two .PERIOD and then we use those to respond to client queries of the length of the shortest path and the path itself .PERIOD this is the constructor .PERIOD we build the arrays .PERIOD we initialize this distances to infinity .PERIOD distance the source to zero .PERIOD then we use our topological sort algorithm on di -DASH graphs to compute an iterable that gives us the vertices in topological order .PERIOD and that's the order method in this topological class .PERIOD so that's using the api that we set up for topological sorting ,COMMA which has to be adapted to weighted di -DASH graphs .PERIOD but that's just adding some nomenclature .PERIOD so we take the vertices in topological order .PERIOD we take for every vertex in topological order ,COMMA taken in topological order .PERIOD we take every edge that emanates from that vertex and relax it .PERIOD it couldn't be simpler .PERIOD and then we're done we have the other shortest pass .PERIOD and that works even for negative edge weights .PERIOD pretty simple .PERIOD now ,COMMA as an example of a ,COMMA familiar application of ,COMMA shortest paths in dags and weighted dags we'll look at ,COMMA the idea of scene carving .PERIOD and this is a relatively recent algorithm that ,COMMA was developed that has ,COMMA important application that you'll see ,COMMA in this ,COMMA youtube film clip .PERIOD scene carving for content -DASH aware image resizing .PERIOD digital media today has the ability to support dynamic page layouts .PERIOD by changing the window or display size ,COMMA we can change the layout of a document .PERIOD however ,COMMA images imbedded in a document typically remain rigid in size and shape .PERIOD resizing is also important to put images into different displays .PERIOD current techniques ,COMMA including cropping or scaling ,COMMA are limited in their abilities to capture the image content .PERIOD we present a method for content aware resizing of images .PERIOD our technique enables resizing while adapting the image content and layout .PERIOD this is sometimes called re -DASH targeting .PERIOD we also define a flexible ,COMMA multi -DASH size representation for images that supports continuous resizing .PERIOD an image can be shrunk in a non -DASH uniform manner while preserving its features ,COMMA but it can also be extended beyond its original size .PERIOD instead of scrolling through images that do not fit in a given display ,COMMA we gracefully re -DASH size them to fit inside the window .PERIOD for example ,COMMA assume that we need to change the width of an image .PERIOD the simplest way to do this is to remove columns of pixels from the image .PERIOD the best column to remove would be the least noticeable ,COMMA or least important column .PERIOD we can search for this column by defining the importance or energy function on the image .PERIOD in this example ,COMMA we use the gradient magnitude of the image .PERIOD next ,COMMA we look for the column which contains the least energy and remove it .PERIOD however ,COMMA using such an approach quickly leads to serious artifacts .PERIOD therefore ,COMMA instead of using rigid columns ,COMMA we search for connected paths of pixels ,COMMA or seams ,COMMA from one side of the image to the other ,COMMA that contain the least energy .PERIOD this can be done using a simple dynamic programming algorithm as described in the paper in both vertical and horizontal directions .PERIOD here's another example of an image ,COMMA its energy function ,COMMA and the least noticeable horizontal and vertical seams .PERIOD by successively removing horizontal and vertical seams ,COMMA the image can be resized in a non -DASH uniform manner .PERIOD the order of seam removal in an image defines an order on the pixels on the image by storing the simple indexing information we create content to where multisize images .PERIOD so that's a amazingly powerful image processing process .PERIOD and you'll find it all over image processing applications ,COMMA from photoshop to gimp to image magic .PERIOD and actually nowadays almost any image that you see on your cell phone or your tablet .PERIOD and what really ,COMMA does that have to do with shortest paths ?QUESTIONMARK well ,COMMA it's actually a direct application of shortest paths on a directed acyclic graph .PERIOD so what we do is ,COMMA build a huge directed acyclic graph .PERIOD and this is a really huge graph .PERIOD because images now ,COMMA at high resolution ,COMMA can have millions or billions of pixels .PERIOD and so .PERIOD every pixel corresponds to a vertex in this graph .PERIOD and the edges are gonna be just directed edges from every pixel to its three downward neighbors .PERIOD and then there's ,COMMA what weight do we assign to the pixels ?QUESTIONMARK well ,COMMA there's an energy function that has to do with the image processing ,COMMA that is ,COMMA a function of the eight neighboring pixels .PERIOD every ,COMMA every pixel ,COMMA has a relationship with all its neighboring pixels .PERIOD and ,COMMA the energy function ,COMMA has it ,COMMA is ,COMMA is a image processing ,COMMA concept that ,COMMA is .PERIOD perfect for ,COMMA assigning weights ,COMMA in ,COMMA in this instance .PERIOD and so ,COMMA that gives ,COMMA the weights .PERIOD and then ,COMMA a seam is just the shortest path ,COMMA that goes from the top to the bottom .PERIOD so you can ,COMMA imagine an imaginary source that goes all to the top ones ,COMMA and ,COMMA just ,COMMA run the shortest pass algorithm that we just gave ,COMMA and ,COMMA it'll find a seam .PERIOD so that's the lowest energy ,COMMA one pixel cut ,COMMA through the image ,COMMA and then ,COMMA the resizing algorithm ,COMMA just deletes ,COMMA one ,COMMA one pixel on each row ,COMMA along that seam ,COMMA and that's the algorithm .PERIOD which .PERIOD the shortest pass algorithm ,COMMA i'im i'm sorry ,COMMA allows and enables the re -DASH sizing for a really huge graph .PERIOD and ,COMMA and it's really important to realize that you have to have an efficient implementation of the shortest pass algorithm .PERIOD because there's so many pixels .PERIOD and certainly the topological sort algorithm that we gave is extremely efficient linear time algorithm .PERIOD and you can see the effects of that efficient algorithm all around you .PERIOD here's another completely different application of shortest paths in directed acyclic graphs .PERIOD and the idea is that actually since negative weights are allowed ,COMMA we can find longest paths in edge -DASH weighted dags ,COMMA just by negating all the weights .PERIOD so what i want is i have edge .PERIOD again i have an edge weighted dag .PERIOD and what i want is ,COMMA this is with ,COMMA i guess five as the source .PERIOD i ,COMMA i don't want the shortest path from five to two .PERIOD i want the longest path from five to two .PERIOD we'll see an application why that's important in a minute .PERIOD and in order to get that ,COMMA all i do is just negate all the weights ,COMMA and the run shortest paths .PERIOD and if you add up negative weights to get the smallest negative number ,COMMA then to negate the answer that's the longest path ,COMMA and it works because the algorithm ,COMMA top logical sort algorithm ,COMMA doesn't care whether the weights are positive or negative .PERIOD in general graphs it does matter as we'll see in a minute ,COMMA but for a cyclic graph it doesn't matter ,COMMA we can find longest path in a cyclic graph just by negating all the weights ,COMMA therefore we can solve the longest paths problem .PERIOD so that's a key point .PERIOD and now ,COMMA now you can look at applications that had problems .PERIOD and there's a really important application for longest paths in edge weighted directed a -DASH cyclic graphs .PERIOD and that's called the job scheduling problem .PERIOD and this is just another example to show the importance of the shortest paths problem as a problem solving model .PERIOD this particular problem doesn't seem related to shortest paths at all .PERIOD but we'll show how to formulate it as a shortest paths problem .PERIOD and that's great ,COMMA because we have an efficient solution to the shortest paths problems .PERIOD or actually ,COMMA it's a longest paths problem in this case .PERIOD so this is just an example that arises say ,COMMA in man ,COMMA in manufacturing .PERIOD or other applica ,COMMA applications we have a complex set of interacting processes .PERIOD so this we call ,COMMA job scheduling .PERIOD parallel job scheduling .PERIOD so we've got a bunch of let's say a factory manager has a bunch of jobs to manage ,COMMA and they have .PERIOD durations and precedents constraints .PERIOD so durations just means the job takes a certain amount of time .PERIOD and precedents constraints means that you can't start job one until after job zero is done ,COMMA or seven ,COMMA or nine .PERIOD one ,COMMA seven and nine have to start sometime after jo -DASH  ,COMMA job zero .PERIOD and similarly three and eight have to start after six ,COMMA and so forth .PERIOD so maybe this is manufacturing a car .PERIOD and ,COMMA you know you can't ,COMMA paint the car until after you put the doors on .PERIOD or whatever else you can imagine .PERIOD easily ,COMMA setting up ,COMMA precedence constraints ,COMMA that are natural ,COMMA for trying to complete this whole ,COMMA set of jobs .PERIOD and so what we want to do is ,COMMA find a start time for each job .PERIOD that minimizes the completion time .PERIOD while still respecting all the precedence constraints .PERIOD so when do we start each job ?QUESTIONMARK that's the parallel job scheduling problem .PERIOD we ,COMMA we assume that we got enough workers that we can have a bunch of jobs going on at the same time ,COMMA same time .PERIOD so ,COMMA this graph model shows that we can change the job scheduling problem into a graph processing problem .PERIOD so ,COMMA what we're going to do is ,COMMA create an edge weighted directed acyclic graph the following way .PERIOD we're going to have a source and sync vortex that the source is ,COMMA begin everything and the sync is ,COMMA end everything .PERIOD and then ,COMMA well at the zero weightage from the .PERIOD for every job will have a start and a finish vertex for that job ,COMMA and then we'll have an edge ,COMMA whose weight is the duration .PERIOD and from the finished vertex of every job ,COMMA we'll have edges to the start vertex of the jobs that it has to complete before .PERIOD that's ,COMMA those are the precedence constraints .PERIOD we have a zero weight edge from ,COMMA the ,COMMA overall source to every job start ,COMMA and a zero weight edge from the overall ,COMMA from every job finish to ,COMMA the ,COMMA sink vertex .PERIOD and so ,COMMA in summary ,COMMA there's three edges for every job .PERIOD there's from the begin to the end ,COMMA the start to the finish ,COMMA weighted by the duration .PERIOD from the source to the beginning ,COMMA zero weight ,COMMA and from the end to the sync ,COMMA zero weight ,COMMA in the edges for the precedence constraints ,COMMA also have zero weight .PERIOD so that's a graph model ,COMMA we took our scheduling problem and now we have a graph .PERIOD and what relates this to what we've been talking about is the longest path from the source to each job .PERIOD it turns out to give a schedule .PERIOD so the job scheduling problem corresponds to a solution to the longest path problem in directed acyclic graph by the way this graph doesn't have any cycles because that would mean we have to do a job before another job insist that one be done after zero and that two be done after one .PERIOD we can't also insist that zero be done after two because that would be a present cycle that couldn't be satisfied at all .PERIOD and so the ,COMMA the n -DASH  ,COMMA now you have to think of this quite a while to understand why the longest path from the source .PERIOD we'll schedule each job ,COMMA but ,COMMA that's a fact in that it means ,COMMA then ,COMMA we have ,COMMA a fast ,COMMA linear time algorithm for solving this problem .PERIOD negate all the weights ,COMMA run shortest paths with topological sort ,COMMA and negate the answer ,COMMA and you have the start times for every job .PERIOD in fact ,COMMA in the book and the book site ,COMMA you'll find code that not solves ,COMMA this ,COMMA schedule ,COMMA parallel job scheduling problem using the critical path method ,COMMA again ,COMMA showing how important it is to have ,COMMA a fast and efficient solution to the shortest paths problem .PERIOD 
now ,COMMA we'll look at shellsort which is a bit elementary on the face of it but it's not at all elementary as you'll see .PERIOD the idea of shellsort is that insertion sort is inefficient because elements really move only one position at the time even when we're kind of know that they have a long way to go .PERIOD the idea behind shellsort is that we'll move entries several positions at a time and the way we're going to do it ,COMMA it's called h -DASH sorting the array .PERIOD so ,COMMA an h -DASH sorted array is h different inter leaves sorted sub -DASH sequences so in this case with h=4 if we start at l and look at every fourth element  -DASH  m ,COMMA p ,COMMA t  -DASH  then it's sorted .PERIOD if we start in the second place at e and look at every fourth element ,COMMA it's sorted .PERIOD so this is 4 interleave sequences ,COMMA that's a 4 -DASH sorted array .PERIOD and what we're going to do is implement a sorting method that h -DASH sort for decreasing sequences of values of h .PERIOD this is one of the oldest sorting methods invented by shell in 1959 .PERIOD so ,COMMA in this case ,COMMA it starts out with the input example shown and then the 13 -DASH sort  -DASH  a few items are moved ,COMMA 4 -DASH sort  -DASH  a few more are moved ,COMMA and then finally ,COMMA a 1 -DASH sort .PERIOD and the idea is that each of the sorts can be implemented with only a few exchanges given that the previous ones happened .PERIOD so first thing is how do we get an array h -DASH sorted ?QUESTIONMARK that's actually pretty easy .PERIOD we just use insertion sort but instead of going one back every time we come with a new item ,COMMA we go h back .PERIOD so for example when we come to this a in the insertion sort ,COMMA then it's ,COMMA we look at the array before that and then there was m and e in the positions three back so we exchange the a with the larger one to its left ,COMMA that's m and then the other larger one to its left ,COMMA that's e and then put it into position .PERIOD so the code is the same as insertion ,COMMA as for insertion sort ,COMMA except that when we go backwards through the array we skip by h instead of just by one .PERIOD that's how we h -DASH sort an array .PERIOD and the idea is we're going to use insertion sort because of two reasons based on our understanding of how insertion sort works .PERIOD while the first thing is if the increments are big then the size of the sub arrays that we're sorting are pretty small so any sorting method including insertion sort is going to work well .PERIOD but the other thing is if the increments are small because we've done previous h -DASH sorts for bigger values of h ,COMMA the array is partially sorted and so insertions sort is going to be fast .PERIOD you wouldn't work to use shellsort as the basis for h -DASH sorting because that always takes quadratic time no matter what order there is in the array .PERIOD so let's look at example of shellsort with increment 7 ,COMMA 3 ,COMMA and 1 .PERIOD so ,COMMA we start with this sort example and then 7 -DASH sorting it  -DASH  just involves doing insertion sort but just reaching back 7 each time .PERIOD in this case ,COMMA the 4 subfiles stretched out at seven each only have two elements in them .PERIOD and then we 3 -DASH sort .PERIOD now ,COMMA because it's 7 -DASH sorted and a 3 -DASH sort elements are either already in placed or on a go back a few strides .PERIOD on this case ,COMMA it's only the a that goes back two .PERIOD and then we 1 -DASH sort and again because of the fact that it's been 7 -DASH sorted and 3 -DASH sorted ,COMMA the arrays are almost in order when it comes time to do the 1 -DASH sort and most of the items only go back one or two positions .PERIOD so we have to do a few extra passes to do the higher sorts but the each element moves only a little bit on each path and that's how shellsort gains its efficiency .PERIOD so actually once you 1 -DASH sort ,COMMA that's insertion sort so you're going to always get a sorted result .PERIOD the only difference is how efficient is that .PERIOD now the intuition behind shellsort and actually the mathematical fact is that if you've got an array that's h -DASH sorted and then you k -DASH sort it for another value k different from h ,COMMA it's still h -DASH sorted .PERIOD this is one of those mathematical facts that seems obvious but then if you try to prove that maybe it's a little more subtle than you think .PERIOD so ,COMMA if you think of all this is ,COMMA is ,COMMA is trivial and easy ,COMMA go ahead and try to write down a proof that a g -DASH sorted array remains g -DASH sorted even after it's h -DASH sorted .PERIOD but most people will accept that and it's a fact and that's how shellsort gains efficiency .PERIOD now there's another problem is what increment sequence should we use for shellsort .PERIOD one of the first things you might think of is let's try powers of two .PERIOD actually that one doesn't work at all ,COMMA very well at all because it winds up not comparing elements in even positions with elements in the odd positions until the 1 -DASH sort which means performance can be bad .PERIOD shell's original idea is to try powers to two minus one and that works okay .PERIOD knuth when he wrote his books in the 60s proposed the increment sequence 3x + 1 .PERIOD we'll start with the 1 ,COMMA 4 ,COMMA 13 ,COMMA 40 ,COMMA 121 ,COMMA 364 like that and that's good because it's easy to compute .PERIOD when we're using in shellsort of course ,COMMA we find the largest increment less than our file size and then do the sorts for decreasing values of that increment .PERIOD but finding the best increment sequence is a research problem that has confounded people for quite a long time .PERIOD here's an increment sequence that i found after maybe a year's work and it works well but nobody knows if that's the best one .PERIOD so here's the implementation in java of shellsort for knuth's 3x + 1 increment sequence .PERIOD we'll just go ahead and compute the increments that are less than n ,COMMA n / 3 and then starting at that increment whatever it is and say ,COMMA we started 364 then next time we need an increment ,COMMA we'll just divide it by 3 ,COMMA 364 integer divide by 3 ,COMMA 364 integer / 3 it gets 121 ,COMMA 40 and so forth .PERIOD so ,COMMA this h = h / 3 gets us to the next increment .PERIOD and then ,COMMA the implementation is just insertion sort .PERIOD we just go through starting at h for i and when we do the insertion ,COMMA the j loop ,COMMA we decrement j by h each time ,COMMA otherwise the code is exactly like insertion sort .PERIOD so ,COMMA just adding this extra loop for h -DASH sorting and this extra loop to compute the increments to insertion sort ,COMMA we get a slightly more complicated piece of code but its much ,COMMA much more efficient .PERIOD here's what it looks like for a bigger array .PERIOD we start with the randomly ordered input and you can see that it gets more and more in order on each time that we h -DASH sort for the decreasing values of h .PERIOD here's an animation .PERIOD this animation does the whole h -DASH sort for each subarray .PERIOD it's a little better feeling for what's going on .PERIOD and now to do the high ones pretty quickly and now it's doing the 1 -DASH sort and again it steps through the array pretty quickly .PERIOD if it's partially sorted it doesn't make much difference  -DASH  does the higher sorts a little bit faster .PERIOD but that's simple to implement and very efficient sorting algorithm .PERIOD now ,COMMA the analysis of shellsort is still open .PERIOD now ,COMMA there's a few things that we can say .PERIOD for example we can say that the number of comparison and the worst case is o(n3/2) for the 3x + 1 increments .PERIOD but actually in practice it's much less than that .PERIOD the problem is nobody knows an accurate model for describing the number of compares taken by shellsort for any interesting increment sequence .PERIOD this seems to be with a small value ,COMMA multiple of n times the number of increments used which is some multiple maybe of n log n but nobody is been able to find an accurate model that proves that for any interesting increment sequence for shellsort .PERIOD so ,COMMA why we are interested in this algorithm ?QUESTIONMARK well ,COMMA it's a simple idea that leads to substantial performance gains .PERIOD it's very useful in practice because it's pretty fast except for very huge arrays .PERIOD it's going to beat even the classical sophisticated methods for medium sized arrays .PERIOD and it doesn't take much code .PERIOD it's often used in embedded systems or in hardware sort type systems because there's so little code involved to implement it .PERIOD and it just leads to a lot of interesting questions .PERIOD this gets to the intellectual challenge of developing algorithms .PERIOD if you think what we've been studying so far is trivial ,COMMA go ahead and find a better increment sequence .PERIOD try some technique to discover one and try to say something about the average -DASH case performance of shellsort .PERIOD people have been trying to do that for 50 years without a whole lot of success .PERIOD so ,COMMA the lesson is that we can develop good algorithms or good implementations without much code but there are some out there that are still waiting discovery .PERIOD it could be that there are some increment sequence out there that make shellsort more efficient than any other method ,COMMA any of the sorting method that we know for pratical file size ,COMMA no one can deny that .PERIOD that's shellsort or first non -DASH trivial sorting method .PERIOD 
so finally ,COMMA we're going to take a look at the implications of having negative weights in directed weighted graphs .PERIOD so the first thing to notice is that the easy solutions don't work at all .PERIOD dijkstra's algorithm just doesn't work in the presence of ,COMMA presence of negative weights .PERIOD so say ,COMMA this weight from two to three is  -DASH nine .PERIOD what dijkstra's algorithm will do is just immediately select vertex three and never revisit that decision .PERIOD saying the shortest way to get from zero to three is ,COMMA is ,COMMA is to take this edge of three which has weight two .PERIOD but the actual shortest path goes over to four and then over to one and down to two for a weight of ten .PERIOD and then a  -DASH nine makes it one .PERIOD so there's a way to get from ,COMMA zero to three with a weight path weight just one .PERIOD because of the  -DASH nine .PERIOD but dijkstra's algorithm won't find that .PERIOD so that's not going to work and you might think ,COMMA well ,COMMA why don't we just make all the weights positive by adding nine to everything .PERIOD well ,COMMA that's not going to work because a longer path will have nine added to it a lot of times ,COMMA so its just not any relation between shortest paths in this graph and shortest paths in that graph .PERIOD so ,COMMA those easy attempts ,COMMA just don't work for dealing with ,COMMA negative weights ,COMMA in general graphs .PERIOD so the conclusion is we need some different algorithm and the top logical sort one isn't going to work cuz the graph might have a cycle in it ,COMMA so there's no topological sort so we needs some different algorithm .PERIOD and the main thing to think about in terms of weighted directed graphs ,COMMA that might have cycles ,COMMA is that you can have this situation called a negative cycle .PERIOD this is a graph ,COMMA it all looks fine .PERIOD it's just got this one negative edge from five to four of weight  -DASH 0 .PERIOD66 .PERIOD and these other ones are 0 .PERIOD37 + 0 .PERIOD28 .PERIOD so that's +0 .PERIOD65 .PERIOD but if you go from five to four to seven to five ,COMMA then the distance around that is  -DASH 0 .PERIOD01 .PERIOD and if we're trying to find ,COMMA say a shortest path from zero to six ,COMMA well as soon as you hit this cycle if you want really want the shortest path ,COMMA what you could do is spin around this well an infinite number of times .PERIOD you could make the path a short as you want ,COMMA if you hit an infinite ,COMMA if you hit a negative cycle .PERIOD so ,COMMA negative cycles definitely can get in the way of trying to solve the shortest path problem .PERIOD it make somewhat specified .PERIOD so ,COMMA the first thing is if there's no negative cycles ,COMMA then there's a shortest path tree ,COMMA and if there's a shortest path tree ,COMMA there's no negative cycles assuming that you can actually get to the vertices .PERIOD so what we'll want is graphs that have no negative cycles and then we can work with those .PERIOD and is an algorithm an old algorithm known as the bellman -DASH ford algorithm that does the job .PERIOD it's only slightly more specific than the generic algorithm that we gave before .PERIOD it just says so if you have v vertices ,COMMA for just v times all you do is go through all the edges in the graph and relax each edge .PERIOD so you make v passes through relaxing all the edges in the graph .PERIOD and that's ,COMMA an algorithm that finds shortest paths ,COMMA in graphs that don't have any negative cycles .PERIOD if there's a negative cycle ,COMMA it ,COMMA you know ,COMMA we'll talk about what happens in a minute .PERIOD so lets look at that one in terms of a demo .PERIOD so we'll just take the list of edges in the graph it could be in any order ,COMMA and we'll just relax them all .PERIOD so to start out ,COMMA we ,COMMA set the distance to the source zero and everybody else's distance ,COMMA infinity as usual .PERIOD and then here's the list of edges .PERIOD so we'll relax in this case ,COMMA we start out with the edges sort of in the order that you'd get em' by walking through the whole graph so you get all the edges associated with each vertex together .PERIOD so relax zero ,COMMA one ,COMMA relax zero ,COMMA four ,COMMA relax zero ,COMMA seven ,COMMA that's kind of the way dijkstra would start out .PERIOD and then ,COMMA we go ahead and relax the edges that ,COMMA come out from one ,COMMA so one ,COMMA two takes to ,COMMA two for the first time ,COMMA one ,COMMA three takes us to three for the first time .PERIOD one ,COMMA seven is no help so we ignore it .PERIOD now we relax .PERIOD sorry ,COMMA went too far .PERIOD two ,COMMA three and two ,COMMA six and those ,COMMA that one takes us to six for the first time .PERIOD and now three ,COMMA six that does not give us a better way to six so we ignore it .PERIOD now we go to four ,COMMA five that takes us to five for the first time .PERIOD four ,COMMA six well we could get to four and nine and twenty to six so that's no help .PERIOD four ,COMMA five that's no help .PERIOD now we do the ones from five ,COMMA five ,COMMA two that's going to give a better way to two so we've improved that .PERIOD and five ,COMMA six is going to give a better way to six .PERIOD now ,COMMA seven ,COMMA five that's no help .PERIOD and seven ,COMMA two is no help .PERIOD so we've completed the first paths .PERIOD and now we're just gonna go through and relax all the edges again .PERIOD now a lot of them are really just what we did before so they're not going to improve anything ,COMMA like the ones at the beginning are not gonna improve anything .PERIOD but before too long so still no improvement .PERIOD but here ,COMMA now the second time we relax two ,COMMA three we have it gives us a better way to get to three .PERIOD in ,COMMA for the first path that didn't help us but the second path we relax two ,COMMA three to get us to three and seventeen .PERIOD now that's going to change things for three ,COMMA if we had already been through three it wouldn't ,COMMA wouldn't matter .PERIOD in this ,COMMA in this ,COMMA we'd take another path to deal with ,COMMA but in this case ,COMMA we're going to be coming through three later .PERIOD and ,COMMA there's another ,COMMA two to six gets better .PERIOD then three to six well ,COMMA two to six beat it so it doesn't help .PERIOD and now i think ,COMMA there's nothing else that helps in this example .PERIOD and in fact ,COMMA there's no further changes .PERIOD once we have the shortest path stream ,COMMA which ,COMMA we know from this example ,COMMA because it's similar to one we did before then there's going to be no ,COMMA no changes to it .PERIOD you're not going to find any edges that successfully relax .PERIOD and so ,COMMA go through and ,COMMA try them all ,COMMA and in the end we have a shortest path stream .PERIOD so that is an example of a bellman -DASH ford algorithm ,COMMA on a simple ,COMMA simple graph .PERIOD here's the visualization of the bellman -DASH ford algorithm running on a bigger graph .PERIOD and here's what it looks like after four passes ,COMMA seven ,COMMA ten ,COMMA thirteen .PERIOD and this graph has 100 something vertices .PERIOD and it finds the tree in a relatively small number of passes .PERIOD and we'll talk about the performance in a second of .PERIOD one thing is to be sure that the algorithm works .PERIOD and there's a couple of ways to prove it .PERIOD and again ,COMMA the reason the proof has to be done with care is that there could be edges with negative weights but no negative cycles .PERIOD the idea of the proof is that after you've done the i for pass ,COMMA you've found the shortest path containing at most i edges .PERIOD and ,COMMA and we'll leave that proof for the book .PERIOD now there is a couple of ways to improve the bellman -DASH ford algorithm in practice .PERIOD and ,COMMA the most important one is that if you didn't change the distance to a vertex during one pass ,COMMA then you don't have to worry about it in the next pass .PERIOD you don't have to worry about it ,COMMA it's edges in the next pass .PERIOD and so ,COMMA what we do in practice ,COMMA is if you just maintain a queue of the vertices that we found shorter paths to ,COMMA in each path .PERIOD we want to make sure that we keep ,COMMA at most ,COMMA one copy of each vertex on the queue .PERIOD otherwise ,COMMA you could wind up with situations where ,COMMA the ,COMMA queue ,COMMA size of the queue ,COMMA blows up .PERIOD but that's easy to do ,COMMA with ,COMMA a vertex index array to keep track of that .PERIOD and so ,COMMA in the worst case ,COMMA you could have all the vertices on the queue for ,COMMA and then therefore all the edges relaxed ,COMMA in every one of the v passes .PERIOD but in practice not too many vertices really get relaxed .PERIOD so ,COMMA this is a ,COMMA a quick summary of the algorithms that we've looked for ,COMMA for ,COMMA shortest paths ,COMMA and ,COMMA we didn't do the code for bellman -DASH ford .PERIOD we've done enough code today .PERIOD it's quite simple code that you'll find in the book over on the book site .PERIOD so ,COMMA probably the simplest algorithm is when there are no directed cycles .PERIOD and that's when we just topologically sort the vertices and then go through that list and relax every edge .PERIOD so that's linear time .PERIOD you relax all the edges in the graph and that's it .PERIOD and that works even if there are negative weights .PERIOD if there's no negative weights but there maybe cycles ,COMMA then dijkstra's algorithm works .PERIOD and then we looked at e log v algorithms which are slightly faster depending on what kind of heap you use .PERIOD the bellman -DASH ford algorithm which works with negative weights as long as it's no negative cycles it's if ,COMMA if you do the q you can get the in ,COMMA in practice it turns out to be linear time for the times of graphs that arise in practice .PERIOD although in principle the worst case it could be e times v which is much to slow .PERIOD so ,COMMA directed cycles make the problem harder .PERIOD you need a dijkstra instead of top logical sort .PERIOD negative weights definitely make the problem harder .PERIOD because you might need ,COMMA to ,COMMA get the worst case of bellman -DASH ford .PERIOD and negative cycles ,COMMA in the presence of negative cycles ,COMMA it actually makes the problem intractable .PERIOD and we'll talk about that a little bit at the end of the course .PERIOD one thing that you can do with the bellman -DASH ford algorithm is to at least find ,COMMA find out if there's a negative cycle .PERIOD in one practical reason to do that is maybe it has something to do with something else specified in the problem .PERIOD and so if you can detect a negative cycle and deal with it that would be useful .PERIOD and we'll look at another important practical reason for finding negative cycles in just a second .PERIOD so anyway ,COMMA since its a useful thing to do we're going to add two methods to the api .PERIOD and that is does the graph have a negative cycle and in an interval ?QUESTIONMARK if it does have a negative cycle please give it to me .PERIOD so for this graph ,COMMA it would return true .PERIOD and then it would give an iterable that would have these three edges that give me the negative cycle .PERIOD so ,COMMA the ,COMMA observation or the way to find a negative cycle is to realize that what will happen with a bellman -DASH ford algorithm if there's a negative cycle is that it'll every ,COMMA every path through ,COMMA it'll basically go around the cycle .PERIOD well not every pass in the ,COMMA in the whole length in the cycle .PERIOD it'll get stuck in a loop going around the cycle depending on the order of vertices .PERIOD and it'll update and just get stuck going around the ,COMMA around the cycle .PERIOD so by testing what happens after bellman -DASH ford is done ,COMMA even if there's negative cycles present ,COMMA we can find the negative cycles and that ,COMMA in fact ,COMMA if some vertex is updated in the last phase of the bellman -DASH ford algorithm then there's a negative cycle .PERIOD and not only that .PERIOD edge 2v is the last edge ,COMMA on that cycle .PERIOD that's the way you got to v .PERIOD and you can trace back to find the cycle .PERIOD so just run the bellman -DASH ford algorithm and if some vertex gets ,COMMA get updated ,COMMA the last time through it means there's a negative cycle .PERIOD in practice actually ,COMMA you don't have to wait till the last phase .PERIOD you can check these two entries for negative cycles ,COMMA more frequently .PERIOD but anyway ,COMMA it's possible to find a negative cycle .PERIOD and let's look at an application .PERIOD this is an application that it really motives some people to understand the shortest paths to algorithms .PERIOD and the idea is currency exchange .PERIOD and so these are typical numbers that you might see in a newspaper table ,COMMA or nowadays in an app on your mobile device that gives the exchange rates for various currencies .PERIOD so to convert a dollar to euros using factor of points 0 .PERIOD741 ,COMMA i compute euros too ,COMMA great britain pounds ,COMMA 0 .PERIOD888 ,COMMA and so forth .PERIOD so this table is a table of exchange rates .PERIOD and the problem is ,COMMA is there an arbitrage opportunity ?QUESTIONMARK so what is an arbitrage .PERIOD well arbitrage is when just by making exchanges according to the legal rates in the table you can make money .PERIOD so say we had a $1000 .PERIOD and then these are the going rates .PERIOD well we can convert that $1000 into 741 euros .PERIOD so now ,COMMA if we take those 71 euros and convert them into canadian dollars it works out that we get 1 ,COMMA012 .PERIOD206 canadian dollars .PERIOD and if we take those canadian dollars and convert them back to u .PERIODs .PERIOD dollars ,COMMA it works out that we have $1 ,COMMA007 .PERIOD well that's arbitrage and that's interesting .PERIOD if we could go ahead and do for well let say $10 ,COMMA000 then would make $70 on the deal or a $100 ,COMMA000 would make $700 or maybe a million dollars would make $7 ,COMMA000 or maybe a billion would make $7 ,COMMA000 ,COMMA000 .PERIOD no reason to stop there .PERIOD with arbitrage opportunity you're making money off the system .PERIOD so of course there's intense interest in looking for opportunities like this .PERIOD course in modern financial market .PERIOD it's there's many more things that you can trade than currencies .PERIOD and these tables are big and complex .PERIOD and the market is suppose to take care of eliminating these opportunities .PERIOD but if you are using a computer and you've got a fast algorithm for finding negative cycles in directed graphs then maybe you can find the opportunity and take advantage of it before the market .PERIOD so let's look at how it works .PERIOD what we do is again model the situation with a graph .PERIOD so we're going to have a vertex for every currency .PERIOD and then on the edge corresponding to every transaction or every entry in the table so this is actually a complete directed graph .PERIOD and the weight is equal to the exchange rate .PERIOD and what we are trying to find is a directed cycle whose product of edge weights is greater than one .PERIOD so that doesn't look like a shortest path problem although it's close .PERIOD and actually it's very close .PERIOD to convert this to a shortest path problem what we want to do is just take logs .PERIOD if instead of using the exchange rate ,COMMA we take minus the log of the exchange rate .PERIOD and then multiplying turns to addition for looking for multiplying the exchange rates .PERIOD that's the same as summing the logs .PERIOD and ,COMMA we took minus log it means that what we're looking for when we're trying to find products bigger than one .PERIOD we're looking for a directed cycle whose sum of edge weights is less than zero .PERIOD find a directed cycle whose sum of edge weights is less than zero in a complete digraph .PERIOD that's the negative cycle detection problem ,COMMA and we just saw that ,COMMA we can ,COMMA do that with the ,COMMA bellman -DASH ford algorithm .PERIOD and again ,COMMA in a huge ,COMMA directed graph in a modern trading situation ,COMMA that's an extraordinarily valuable algorithm ,COMMA and you can believe that you know ,COMMA there are people out there running these algorithms in order to detect and take advantage of arbitrage opportunities .PERIOD and if you don't have a fast algorithm ,COMMA if you're using a slow one it'll be gone before you can take advantage of it .PERIOD that's a fine example of the value of building efficient algorithm for a practical problem .PERIOD so here's our summary of short as fast today .PERIOD we've seen some great ,COMMA classic algorithms that are ,COMMA important and extraordinarily useful .PERIOD first one is dijkstra's algorithm which is ,COMMA a fine ,COMMA efficient workhorse algorithm that you see used ,COMMA every day .PERIOD and it's a ,COMMA a grass search algorithm that is ,COMMA similar to ,COMMA prim's ,COMMA depth for search and rep for search that we've seen before and we'll see again if the graphs are ,COMMA have no cycles which is a situation that arises in several important applications .PERIOD we can do better than dykstra's algorithm .PERIOD it's easier .PERIOD and also ,COMMA negative weights are no problem ,COMMA which enables us to solve scheduling problems in other examples if there's negative weights and negative cycles we can detect negative cycles .PERIOD and if there aren't any negative cycles ,COMMA we can find shortest paths .PERIOD in ,COMMA the general problem is intractable ,COMMA and we'll come back to that .PERIOD but the key point that i want people to remember from today's lecture is that shortest path is our first real example of a general problem solving model where there's a lot of important practical problems that we cast solve as shortest path problems .PERIOD number one and number two we have fast solutions to those problems ,COMMA with these classic algorithms that we've talked about 
next we're going to look at an easy application of sorting to related problem called shuffling .PERIOD so ,COMMA suppose you have a deck of cards .PERIOD one of the things that you might want to try to do is to simply rearrange those cards into random order ,COMMA that's called shuffling .PERIOD here's a way to get shuffling done using a sort and seems like the opposite .PERIOD the idea is ,COMMA just generate a random real number for every array entry and then sort using those random numbers as the keys .PERIOD that's an effective way to get things shuffled .PERIOD and it's possible to prove that ,COMMA that produces a uniformly random permutation of the input if there's no duplicate values ,COMMA assuming that you have a real numbers that are generated uniformly at random .PERIOD and that's just means that it's well shuffled that every possible way of shuffling the deck appears with the equal probability .PERIOD that's fine but it requires a sort and a sort seems like a lot of work for this problem and the question is ,COMMA can we do better ?QUESTIONMARK can we have a faster way to shuffle ?QUESTIONMARK do we really need to pay the cost of a full sort ?QUESTIONMARK the answer to that question is ,COMMA no .PERIOD there's actually a very easy way to rearrange an array so that the result is a uniformly random permutation .PERIOD it only require a linear time to get the job done .PERIOD let's look at the demo .PERIOD the idea this to pass through the array from left to right with an index i as we've been doing but now we start with the array in order .PERIOD and actually ,COMMA it doesn't matter how we start the array and every time we pick an integer between 0 and i uniformly at random and ,COMMA and swap a[i] with that integer .PERIOD so ,COMMA let's look at the beginning ,COMMA we don't do anything just swap it with itself .PERIOD now ,COMMA with i = 2 or i pointing to the second card we generate a random integer in between 0 and i ,COMMA in this case it's the one to the left and we swap those .PERIOD increment i ,COMMA generate a random integer ,COMMA this time it's going to be the first one again ,COMMA swap them .PERIOD increment i ,COMMA generate a random integer ,COMMA swap them .PERIOD increment i ,COMMA generate a random integer ,COMMA swap them .PERIOD and continue in that way .PERIOD swap .PERIOD so for every i ,COMMA we do exactly one swap .PERIOD now ,COMMA card could be involved in more than one swap but that's not an issue .PERIOD the point is that the cards to the left of i are shuffled there uniform ,COMMA randomly shuffled .PERIOD on this case ,COMMA i and r are the same .PERIOD there's no swap .PERIOD increment i ,COMMA generate a random r ,COMMA swap them .PERIOD and at the end we have the deck shuffled .PERIOD that's a linear time shuffling algorithm making use of randomness .PERIOD it was proved through actually a long time ago even before computer implementations that if you do that ,COMMA you get a uniformly random permutation and it only takes linear time .PERIOD so ,COMMA that's definitely a way to get a deck shuffled quite easily .PERIOD easy to implement .PERIOD now it's key that the uniform random number will be between 0 and i -DASH 1 .PERIOD you'll often see programmers thinking that they're implementing a shuffle and they just choose for every entry ,COMMA they just choose random place in the array to exchange it with and that doesn't really work .PERIOD you could do the items between i and n -DASH 1 ,COMMA the ones that you haven't seen yet and that would also work but doing a whole array doesn't give you a uniformly random result .PERIOD so ,COMMA with that one caveat ,COMMA this code is almost trivial .PERIOD and it's a method in our standard random class .PERIOD now if you're going to be using random methods that depend on randomness in real applications ,COMMA you do have to be careful .PERIOD so this is just an example about software security .PERIOD there's a lot of difficult and deep issues to worry about and so for our security and we're not going to worry about all of them .PERIOD but one thing that we can do is make sure that our algorithms work as advertised .PERIOD so ,COMMA here's an example of an implementation for online poker .PERIOD here's the code that you can find on the web for how to shuffle a deck of cards and that's pretty similar to our code but it's actually got a few bugs ,COMMA more than a few bugs .PERIOD so first one is the way that random works it's actually never gets to 52 which means that the last card just stays it can end up in the last place .PERIOD so ,COMMA it's definitely not shuffled because of that .PERIOD maybe that one's minor but it also is picking a random card from the whole deck as we just pointed out that's not uniform .PERIOD should be between 1 and i or between i+1 and 52 .PERIOD another problem is in this implementation that the random uses just a 32 bit seed that if you do that ,COMMA there's not enough possible shuffles .PERIOD the number of possible shuffles is ,COMMA is ,COMMA is much more ,COMMA if n ,COMMA if n is 52 ,COMMA it's 52 factorial which is a lot bigger than two to the 32nd .PERIOD so ,COMMA it's not close to a random or uniform .PERIOD and the other thing is that ,COMMA the seed is just a number of milliseconds since midnight and that cuts down the number of shuffles even more .PERIOD and in fact ,COMMA it didn't take that much hacking for someone to realize that after seeing five cards and figuring out what the server clock was doing ,COMMA you could get all the future cards in a real time in a program .PERIOD and that's a pretty tough thing to have happen if you're implementing online poker .PERIOD you might want to make sure that if you're advertising that you're doing a random shuffle ,COMMA that you go ahead and do so .PERIOD and the famous quote in this many similar quotes ,COMMA the generation of random numbers is too important to be left to chance .PERIOD so ,COMMA if your business does depend on shuffling people have looked at all sorts of options including using hardware random number generators and these various tests available to make sure that it's random and you'd better use good shuffling code that's our topic but the bottom line is don't think that it's easy to shuffle a deck of cards .PERIOD so that's shuffling  -DASH  our first non -DASH trivial sorting application .PERIOD 
>> now we'll look at an application of sorting from the field of computational geometry for an interesting computation .PERIOD if you have a set of n points in a plane .PERIOD there's a geometric object called the convex hull which is the smallest polygon that encloses all the points .PERIOD there's the convex hull for that set of points .PERIOD [cough] there's a lot of equivalent definitions of this .PERIOD some of them very mathematical ,COMMA that extend the higher dimensions .PERIOD it's the smallest convex set that contain all the points ,COMMA the smallest area of convex polygon enclosing the points .PERIOD it's a convex polygon that encloses the points whose vertices points in the set and those are all equivalent definitions .PERIOD and what we want to do is given the set of points ,COMMA we're going to have a program that can give us the convex hull .PERIOD now ,COMMA which should the output of such a program ,COMMA such a method be ?QUESTIONMARK well ,COMMA in order to be able to work with the result ,COMMA it should be a sequence of vertices that gives us that polygon if we follow it .PERIOD if we've got some points that are on the boundary but aren't really vertices they shouldn't be included .PERIOD this points out examples of how difficult computational geometry can sometimes be because degenerate cases like these are difficult to deal with in code .PERIOD we're not going to spend a lot of time on this ,COMMA in this lecture .PERIOD but it's something always to be aware of when trying to [cough] apply simple algorithms in situations like these that turn out to be maybe more sophisticated than we might think .PERIOD >> [inaudible] the large screen .PERIOD >> oh yeah ,COMMA got you .PERIOD mm -DASH hm .PERIOD well ,COMMA there's actually a way to compute the convex hull just mechanically if you put the nails around the points and put a rubber band around it ,COMMA that gives you the convex hull .PERIOD now ,COMMA we're not going to be able to really implement that in a computer program but it's surprising how well we can do .PERIOD here's an application where people want to compute the convex hull .PERIOD suppose you have a robot that wants to get from s to t and there's an obstacle that's defined by some polygon .PERIOD you wanted be able to go around the obstacle and it turns out that the shortest path ,COMMA either it's a straight line from s to t or it's part of the convex hull and is not hard to see why that might be true .PERIOD and there's plenty of other applications where people want to be able to compute the convex hull .PERIOD here's another application .PERIOD if you want to find the pair of points that are the farthest apart in the set of points in the plane ,COMMA this is sometimes important in statistical calculation or other applications .PERIOD they're on the convex hull .PERIOD if you have the convex hull ,COMMA this computation is easy .PERIOD [cough] they're ,COMMA they're going to be extreme points on the convex hull .PERIOD so ,COMMA there's a lot of geometric properties of the convex hull that we can take advantage of to develop an algorithm .PERIOD in here two properties .PERIOD now ,COMMA these are the things that have to be proven and we're not going to get into the details of geometric proof but they're intuitive and certainly have no trouble accepting that these things are true .PERIOD one thing is ,COMMA that you can traverse the convex hull by making only counter clockwise turns or left turns if you're looking at the screen here .PERIOD and the other thing is that ,COMMA so if we travel from p to point 1 then we make a left turn to go to point 5 or counterclockwise turn and then from there ,COMMA we go to point 9 and 12 and then we eventually get back to the start point .PERIOD the other thing is ,COMMA if you take the point with the lowest y coordinate .PERIOD and then if you look at the polar angle with respect for every other point with the respect to that one ,COMMA so the angle you get from of the x -DASH axis through p up to the point ,COMMA then the vertices appear in increasing order of that angle .PERIOD and again ,COMMA that's not ,COMMA not difficult to see that that's a fact .PERIOD and the algorithm that we're going to look at ,COMMA called the graham scan is based on those two facts .PERIOD it's ,COMMA the idea is to start with point p ,COMMA the one with the smallest y coordinate .PERIOD sort the points by polar angle with p where that is we're just going to consider in that order .PERIOD and then we'll just throw away the ones that do not create a counterclockwise turn and you'll see how that works when we look at the demo .PERIOD so we start at point p .PERIOD sort the points by polar angle with p so that is if we take a ,COMMA a vertical line and sweep it in a counterclockwise direction ,COMMA what order that we hit the points ?QUESTIONMARK the first thing we hit is 0 ,COMMA 1 ,COMMA and then we sweep counterclockwise ,COMMA we get the 2 and then 3 and 4 and so forth .PERIOD so ,COMMA that's the ordering of those points .PERIOD and so now we'll just consider those points in order and then take them for the convex hull .PERIOD at the beginning ,COMMA 0 -DASH >1 is a line that's on the convex hull .PERIOD so ,COMMA the point with the lowest y coordinates on the convex hull and shows the one that is the smallest polar angle that creates with the x -DASH axis .PERIOD so now what about this one  -DASH  2 ?QUESTIONMARK is that on the convex hull ?QUESTIONMARK well ,COMMA as far as we know at this point ,COMMA it could be ,COMMA it could be that the thing is a triangle and 0 is the last point in which case it would be .PERIOD but in same with 3 .PERIOD as far as we know ,COMMA that one could be on the convex hull .PERIOD but as soon as we go out to 4 that's not a counterclockwise turn .PERIOD it's going the wrong way and essentially what this means is a point 4 is evidence that point ,COMMA there is no way the point 3 can be on the convex hull .PERIOD you can [cough] convince yourself with that quite easily .PERIOD so we just throw a point 3 out .PERIOD it's not on the convex hull so ,COMMA and what about the angle from 1 to 2 to 4 ?QUESTIONMARK that's not counterclockwise either .PERIOD it's turning the wrong way and it's turning to the right .PERIOD so point 2 can't be on the convex hull either .PERIOD and indeed if you just draw the line from 1 to 4 ,COMMA you can see the 2 inside so there is no way it could be in the convex hull .PERIOD now that's essentially the proof that you have to have a counterclockwise turn .PERIOD so now ,COMMA we go on to 5  -DASH  turning the wrong way .PERIOD so ,COMMA point 4 can't be on the convex hull .PERIOD so now we go to 6 .PERIOD as far as we know ,COMMA it could be ,COMMA but as soon as we hit 7 ,COMMA we know that it can't be cuz that's a right turn .PERIOD so 6 is not there .PERIOD go to 8 ,COMMA nope .PERIOD 7 can't be on the convex hull .PERIOD go to 9 .PERIOD 8 can't be on the convex hull .PERIOD now we go to 10 and 11 .PERIOD as far as we know they could be .PERIOD if 12 weren't there ,COMMA they would be .PERIOD as soon as we hit 12 we see that 11 can't be on the convex hull and 10 can't be on the convex hull and that completes the computation of the convex hull with the graham scan .PERIOD okay .PERIOD so ,COMMA there are number of implementation challenges for the graham scan and we're not going to go into detail on this because this is a lecture on sorting algorithms not computational geometry but it is indicative of how ,COMMA even if we have a good sort ,COMMA we might have to do some extra work to actually solve our problem in an application .PERIOD so ,COMMA how do we find the point with the smallest y coordinate ?QUESTIONMARK well you could ,COMMA you could sort ,COMMA you could define an order and compare the points by y coordinate so essentially sorting is the [cough] answer to that question .PERIOD and we'll look at the next lecture of what it means the divine ordering among objects ,COMMA little more general than what we do for sorting .PERIOD how to sort the points by polar angle ?QUESTIONMARK well again we need to define what we mean when we're comparing points .PERIOD and then the next lecture again we'll look at ways to define different orderings among points and graham scan is a perfect example .PERIOD we don't want to just be able to sort things ,COMMA we don't want to just be able to sort them by defining and compared to .PERIOD we're going to be able to sort the same things in different way sometimes and this example is a fine motivation of that .PERIOD figuring out whether what we have is a counter clockwise turn that's a little exercise in geometry and we'll just talk about that briefly in the next couple of slides .PERIOD and then wow ,COMMA what are we getting the sort efficient ,COMMA done efficiently ?QUESTIONMARK well ,COMMA we could use shellsort but actually in the next couple of lectures and we'll look at classical sorts  -DASH  mergesort and quicksort  -DASH  that we could use .PERIOD the idea though is that this example illustrates that good sorting algorithm gives us a good convex hull algorithm .PERIOD that's an extremely important principle in designing good algorithms .PERIOD once we have a good algorithm ,COMMA if we have another problem we can say to ourselves ,COMMA well ,COMMA we've got a good solution to this algorithm ,COMMA can we use that solution to solve our new problem ?QUESTIONMARK convex hull ,COMMA when we have a good sorting algorithm ,COMMA it gives us a good convex hull algorithm .PERIOD because the main ,COMMA the most work in convex hull is the sort .PERIOD and then again there's all ,COMMA all kinds of difficulties in implementing convex hull in real world situations because of various degeneracies .PERIOD and these things are covered on the book site .PERIOD so the main part of computation that we haven't really talked about and we'll cover briefly is if we have three points ,COMMA a ,COMMA b and c ,COMMA and you go from a to b to c ,COMMA are you making a counterclockwise turn or not ?QUESTIONMARK so ,COMMA in the example at the left ,COMMA a to b to c is counterclockwise .PERIOD example at the right ,COMMA a to b to c is not counter clockwise .PERIOD going from a to b you turn left to get to c in the first case and you go right to get to c in the second case and we want to do a computation that distinguishes this .PERIOD now ,COMMA this computation will be pretty easy except for the degeneracies .PERIOD what do you want to count if they're all on the same line .PERIOD or if the slope is infinity .PERIOD so ,COMMA you have to just be aware that these situations have to be dealt with .PERIOD so ,COMMA the code isn't quite as simple as you might come up within the first instance that you try .PERIOD so ,COMMA there's degeneracies to deal with and floating point precision but people ,COMMA researchers in computational geometry have worked this out and actually there's not that much code at all in the end involved .PERIOD the and this is the slide that ,COMMA that gives the math and i won't talk through this math .PERIOD if you're interested in implementing this ,COMMA you can come back to the slide .PERIOD and it's essentially based on the idea of computing the slopes of the lines between a and b ,COMMA between a and c and comparing them to decide whether you're turning counter clockwise or clockwise .PERIOD and this is the specific math that gets that implemented .PERIOD so [cough] this is if we implement a point data type for computational geometry ,COMMA you can have a method ccw() that just with this little math calculation (b .PERIODx  -DASH  a .PERIODx)(c .PERIODy  -DASH  a .PERIODy) minus (b .PERIODy  -DASH  a .PERIODy)(c .PERIODx  -DASH  a .PERIODx) and we see that calculation here gives you immediately whether it's counter clockwise ,COMMA clockwise or co -DASH linear .PERIOD not much code at all .PERIOD and that method is the basis for the graham scan .PERIOD the graham scan uses a sort where we give two different ways to sort the points .PERIOD and that uses a push down stack for the hull ,COMMA it puts the points on the hull in it goes ahead and for every point considering i'm in the order of the polar sort it'll compare whether the top two points on the hull and the new point implement a ccw turn or not .PERIOD and if it's not a ccw turn ,COMMA it pops and then continues going .PERIOD very little code to implement the convex hull given that you have a sort and that's our main point for this lecture  -DASH  there is many natural applications of sorting but also will be able to develop new algorithms that use sort that gain efficiency because of the efficiency of sorting .PERIOD 
today we're gonna finish off our discussion of graph processing by looking at max flow algorithms .PERIOD this is another general problem solving model for which we have efficient algorithms ,COMMA so where at the difference between having a good algorithm and not having one makes a difference between being able to solve all kinds of practical problems and not being able to address them at all .PERIOD as an introduction we'll take a look at what the problem is and some of it's implications .PERIOD so first we'll start with what's called the mincut problem .PERIOD so this is a .PERIOD takes as input a edge weighted digraph and now we are going to assume that the edge weights are positive ,COMMA and we referred to the weight as a capacity and you will see why in just a minute .PERIOD and also we specify a source and a target vertex .PERIOD this is not an absolute requirement but it will simplify our discussion for the lecture .PERIOD so we have an edge weighted digraph where the source and target vertex and every edge has a positive capacity .PERIOD now a cut ,COMMA an st cut ,COMMA s and t are specified remember ?QUESTIONMARK is the partition of the vertices into two disjoint sets ,COMMA where s is one set and t is in the other .PERIOD and we'll indicate a cut as we've done before by coloring the vertices in one set .PERIOD so in this case ,COMMA the cut consists of s in one set ,COMMA and all the other vertices in the other .PERIOD so s is in ,COMMA one set and t is in the other ,COMMA that's an st cut .PERIOD now given a cut .PERIOD we talk about the capacity of the cut .PERIOD and that's gonna be the sum of the capacity of the edges that go from the set containing s to the set containing b if you have edge going the other way we don't count it .PERIOD so in this case ,COMMA the ,COMMA this cut with the vertex containing just s in one set has capacity 30 ten + five +fifteen .PERIOD here's another cut this one contains three vertices ,COMMA s and two at the bottom there .PERIOD again it's an st cut ,COMMA cause s is colored t is not .PERIOD and then we can look at the capacity of that cut .PERIOD again ,COMMA we count the vertic ,COMMA the edges that go from to the cut containing s to the cup containing b ,COMMA b .PERIOD in this case ,COMMA is ten + eight + sixteen that's the edges going out is 34 .PERIOD that's the capacity .PERIOD we don't count the edges that go in from the sec containing t to the sec containing s capacity of the cut is the sum of the capacities of the edges going out .PERIOD here's the third example ,COMMA and this one's got capacity 28 .PERIOD now the three cuts that we've seen you notice have different capacities :COLON 30 ,COMMA 34 ,COMMA 28 .PERIOD so the mincut problem ,COMMA clearly ,COMMA is to find the minimum capacity cut .PERIOD find a way to divide the vertices into two sets ,COMMA one containing s and the other containing t with the property that the capacity of the cut is minimized .PERIOD that's the mincut problem .PERIOD and this an important practical problem with all kinds of applications .PERIOD just for fun we take an application from the 1950's .PERIOD this is around time these sorts of problems were first articulated .PERIOD so this is ,COMMA has to do with the cold war and these are rail networks that connects the soviet union with countries in eastern europe .PERIOD this map actually wasn't declassified until 1999 .PERIOD but it shows a graph with the vertices ,COMMA directed graph with vertices corresponding to cities and edges corresponding to rail lines .PERIOD and if you look closely ,COMMA you can see that ,COMMA each of the edges is labeled with a capacity .PERIOD the goal .PERIOD so the goal of the free world say if there was gonna be a real war was to find a way to cut the soviet union from eastern europe .PERIOD and they wanna do that .PERIOD you can assume maybe the cost of cutting a rail line is proportional to its capacity .PERIOD so they wanna find the cheapest way to cut off supplies .PERIOD from soviet union ,COMMA eastern europe .PERIOD that's an example of a min cut application .PERIOD we'll look at some other applications later on .PERIOD well ,COMMA look at a future ,COMMA well maybe this is a cut for today's world .PERIOD so now you have a huge graph ,COMMA maybe a social network .PERIOD and maybe there's a government and power in some area of the world ,COMMA and the goal of that government would be to cut off the communication to some set of people .PERIOD and again ,COMMA they want to do that in the cheapest way possible .PERIOD find the minimum way to cut off communication .PERIOD and certainly ,COMMA people are writing programs to process graphs like this with such goals in mind nowadays .PERIOD these are huge ,COMMA huge graphs and certainly are going to need efficient algorithms .PERIOD in the 1950s ,COMMA the graphs were pretty huge by 1950s standards .PERIOD and it wanted efficient algorithms then too ,COMMA for sure ,COMMA 'cause computers were slower .PERIOD alright ,COMMA that's one problem .PERIOD so let's talk about a different problem ,COMMA called the max -DASH flow problem .PERIOD and it's the same setup inputs and edge weighted digraphs ,COMMA source for text s ,COMMA and a target for text t ,COMMA every edge has a positive capacity .PERIOD and now what we're gonna talk about is what's called a flow .PERIOD it's a assignment of values to the edges .PERIOD so ,COMMA we have the capacities ,COMMA and we're gonna assign another integer to each edge ,COMMA called its flow .PERIOD and then flow has to satisfy two properties .PERIOD the first one is that the flows have to be positive and they can't be greater than the capacity .PERIOD you can think of the ,COMMA edges again as a rail line containing some commodity or a pipe containing some fluid .PERIOD so the flow is how much stuff can you put through that edge ?QUESTIONMARK you can more than zero but you can't put more than capacity .PERIOD the other thing about a flow is that there has to be local equilibrium at the vertices .PERIOD and again that's a natural constraint to think about stuff flowing in on rail lines to a city and you want ,COMMA you want to keep things going the local elibrium constrains says that the stuff coming in has to equal the stuff going out at every vertex except for the source everything leaves from the source .PERIOD and the target ,COMMA everything goes to the target .PERIOD and those have the source has no inflow and the target has no outflow .PERIOD so what you want is the inflow at a vertex ,COMMA say ,COMMA in this example inflow at v ,COMMA there's five coming in on this edge and five coming in on that edge .PERIOD so that's a total of ten coming in and there has to be just ten going out .PERIOD so that's ,COMMA happens on this one edge .PERIOD and that has to be satisfied at every vertex .PERIOD so this flow's got five coming in there and five going out .PERIOD ten going in there and five going out each way and so forth .PERIOD every vertex except s and t .PERIOD and we can even make it true for s and t by drawing an edge from t all the way back to s .PERIOD so that's the max flow problem ,COMMA well ,COMMA the ,COMMA that's the definition of a flow ,COMMA and of course the max flow problem is to assign a value to the flow .PERIOD well that's how much stuff you can get to the source .PERIOD to the target .PERIOD or equivalently ,COMMA how much stuff can you push out of the source .PERIOD and so the value is how much can you get into the target .PERIOD there's lots of different ways to assign flows to the network to satisfy the capacity equilibri -DASH  ,COMMA equilibrium constraint .PERIOD which one maximizes the flow ,COMMA that's the maximum st flow problem ,COMMA or the max flow problem .PERIOD so that's two different problems .PERIOD the min cut problem .PERIOD how do we cut the graph efficiently ,COMMA with a minimal amount of work .PERIOD and the max flow problem .PERIOD what's the maximum amount of stuff that we can get through the graph ?QUESTIONMARK and again ,COMMA if we look at ,COMMA the 1950's graph .PERIOD what the soviet union wanted to do was find a way to maximize the flow of supplies to eastern europe .PERIOD now that was their goal in this case ,COMMA and again you can see in this whole map ,COMMA this is a assignment of a flow to this network that does maximize the flow for this network ,COMMA so they figured it out .PERIOD and nowadays in the huge graph ,COMMA maybe the free world wants to do the opposite .PERIOD they want to maximize the flow of information to some specified set of people .PERIOD how do we get the most information in there and is there another way to think of it ?QUESTIONMARK and again ,COMMA these are huge graphs and we want efficient algorithms .PERIOD so that's two problems both have an input weighted digraph with a specified source and target and then cut problem is to find them in capacity cut and max flow problem is find a maximum value flow .PERIOD it's a lot of computation to do for example in the max flow problem we have to assign a value to each edge .PERIOD so that's more work than just finding a path as we've done in other graph processing problems .PERIOD so it's more complicated and the amazing thing about these two problems is that they're actually pretty much the same problem .PERIOD they're what we call dual .PERIOD if you solve one you're able to solve the other .PERIOD so that's an introduction to max flow 
welcome back .PERIOD  which is one of two  critical  infrastructure .PERIOD  the  they've been developed  sorts that  years .PERIOD   10 11 00 :COLON00 :COLON30 ,COMMA470  -DASH  -DASH > 00 :COLON00 :COLON33 ,COMMA990 12 00 :COLON00 :COLON35 ,COMMA190  -DASH  -DASH > 00 :COLON00 :COLON38 ,COMMA540 13 00 :COLON00 :COLON38 ,COMMA540  -DASH  -DASH > 00 :COLON00 :COLON43 ,COMMA629 14 00 :COLON00 :COLON44 ,COMMA730  -DASH  -DASH > 00 :COLON00 :COLON46 ,COMMA750 00 :COLON00 :COLON46 ,COMMA750  -DASH  -DASH > 00 :COLON00 :COLON49 ,COMMA520 is also used in java for different 00 :COLON00 :COLON52 ,COMMA720  -DASH  -DASH > 00 :COLON00 :COLON56 ,COMMA320 alright ,COMMA so basic mergesort algorithm .PERIOD 00 :COLON00 :COLON57 ,COMMA870  -DASH  -DASH > 00 :COLON00 :COLON59 ,COMMA530 the idea is very simple .PERIOD what we're going to do is divide an array into two halves .PERIOD recursively ,COMMA recursively sort each of the halves .PERIOD and then merge the result .PERIOD   22 23 00 :COLON01 :COLON14 ,COMMA240  -DASH  -DASH > 00 :COLON01 :COLON17 ,COMMA270 24 00 :COLON01 :COLON18 ,COMMA300  -DASH  -DASH > 00 :COLON01 :COLON22 ,COMMA450 25 00 :COLON01 :COLON22 ,COMMA450  -DASH  -DASH > 00 :COLON01 :COLON25 ,COMMA300 26 00 :COLON01 :COLON25 ,COMMA300  -DASH  -DASH > 00 :COLON01 :COLON28 ,COMMA080 27 00 :COLON01 :COLON28 ,COMMA080  -DASH  -DASH > 00 :COLON01 :COLON31 ,COMMA230 28 00 :COLON01 :COLON31 ,COMMA230  -DASH  -DASH > 00 :COLON01 :COLON33 ,COMMA951 29 00 :COLON01 :COLON36 ,COMMA230  -DASH  -DASH > 00 :COLON01 :COLON40 ,COMMA220 30 00 :COLON01 :COLON41 ,COMMA328  -DASH  -DASH > 00 :COLON01 :COLON44 ,COMMA982 31 00 :COLON01 :COLON44 ,COMMA982  -DASH  -DASH > 00 :COLON01 :COLON48 ,COMMA730 32 00 :COLON01 :COLON49 ,COMMA810  -DASH  -DASH > 00 :COLON01 :COLON54 ,COMMA470 33 00 :COLON01 :COLON54 ,COMMA470  -DASH  -DASH > 00 :COLON02 :COLON01 ,COMMA420 34 00 :COLON02 :COLON01 ,COMMA420  -DASH  -DASH > 00 :COLON02 :COLON04 ,COMMA880 35 00 :COLON02 :COLON04 ,COMMA880  -DASH  -DASH > 00 :COLON02 :COLON05 ,COMMA855 00 :COLON02 :COLON05 ,COMMA855  -DASH  -DASH > 00 :COLON02 :COLON11 ,COMMA290 [cough] the method that we're going to use is based on taking an auxiliary array to hold the data .PERIOD this is a ,COMMA one of the easiest ways to implement the merge .PERIOD so the first thing we do is copy everything over to the auxiliary array .PERIOD now ,COMMA once that's done ,COMMA what we'll want to do is copy back to the original array to get it in sorted order .PERIOD in order to do that ,COMMA we're going to maintain three indices .PERIOD i ,COMMA the current entry in the left half ,COMMA j ,COMMA the current entry on the right half and k ,COMMA the current entry in the sorted result .PERIOD [cough] so the first thing we do is ,COMMA take the smaller of the two entries pointed to by i and j ,COMMA and compare those ,COMMA and take the smallest one ,COMMA and move that one to be the next item output .PERIOD and whichever one is taken ,COMMA we increment its pointer .PERIOD now we compare the minimum again ,COMMA again ,COMMA the one pointed group by j is smaller ,COMMA so we move that one to k .PERIOD  increment k .PERIOD  the first .PERIOD  position .PERIOD   55 56 00 :COLON03 :COLON36 ,COMMA300  -DASH  -DASH > 00 :COLON03 :COLON40 ,COMMA120 57 00 :COLON03 :COLON41 ,COMMA470  -DASH  -DASH > 00 :COLON03 :COLON42 ,COMMA034 00 :COLON03 :COLON42 ,COMMA034  -DASH  -DASH > 00 :COLON03 :COLON44 ,COMMA020 j's e is smaller than g .PERIOD it's the next thing that has to go in the output .PERIOD so we move that one up and increment j and k .PERIOD now the one pointed to my i ,COMMA the g  and k .PERIOD  now the last element in the left sub array  and now  all we need to do is take  part and move them back in .PERIOD  optimize by avoiding these moves .PERIOD  taking the two sorted sub -DASH halves  them out ,COMMA and  alright ,COMMA so here's the  straightforward from the demo .PERIOD   73  74  75 76 00 :COLON04 :COLON59 ,COMMA410  -DASH  -DASH > 00 :COLON05 :COLON02 ,COMMA840 77 00 :COLON05 :COLON02 ,COMMA840  -DASH  -DASH > 00 :COLON05 :COLON06 ,COMMA350 00 :COLON05 :COLON06 ,COMMA350  -DASH  -DASH > 00 :COLON05 :COLON09 ,COMMA320 part from the second ,COMMA so our conditions 00 :COLON05 :COLON09 ,COMMA320  -DASH  -DASH > 00 :COLON05 :COLON12 ,COMMA830 that from lo to mid is sorted ,COMMA and from 00 :COLON05 :COLON13 ,COMMA966  -DASH  -DASH > 00 :COLON05 :COLON17 ,COMMA278 [cough] so the merge implementation then ,COMMA 00 :COLON05 :COLON17 ,COMMA278  -DASH  -DASH > 00 :COLON05 :COLON20 ,COMMA600 it does is copy everything over to the 00 :COLON05 :COLON21 ,COMMA650  -DASH  -DASH > 00 :COLON05 :COLON23 ,COMMA220 and then that sets up for this four loop that accomplishes the merge .PERIOD we start our i pointer at the left heart on the left half .PERIOD the j pointer on the left part of the right half .PERIOD that's mid plus one .PERIOD  beginning lo .PERIOD   89  90 91 00 :COLON05 :COLON50 ,COMMA780  -DASH  -DASH > 00 :COLON05 :COLON55 ,COMMA730 92 00 :COLON05 :COLON56 ,COMMA780  -DASH  -DASH > 00 :COLON06 :COLON00 ,COMMA490 93 00 :COLON06 :COLON00 ,COMMA490  -DASH  -DASH > 00 :COLON06 :COLON02 ,COMMA690 00 :COLON06 :COLON02 ,COMMA690  -DASH  -DASH > 00 :COLON06 :COLON06 ,COMMA910 not imple ,COMMA increment k ,COMMA and that 00 :COLON06 :COLON06 ,COMMA910  -DASH  -DASH > 00 :COLON06 :COLON12 ,COMMA250 if the i pointer is exhausted ,COMMA then we 00 :COLON06 :COLON12 ,COMMA250  -DASH  -DASH > 00 :COLON06 :COLON13 ,COMMA650 if the j pointer is exhausted we move over the next ith element .PERIOD so every time we're moving a new element into k and that's the code that impelements the abstract in place merge .PERIOD now with this code ,COMMA we're also introducing the idea of making assertions just to make it easier to debug our code and to have confidence that it's correct .PERIOD in this case ,COMMA this insertion just says we want to be sure that a of lo to mid assorted and that mid plus one to high is sorted before our code and then we want to check that ,COMMA the whole thing is sorted after our code .PERIOD and generally programmers ,COMMA java programmers know that it's a good idea to try to do these assertions .PERIOD   109  110  111  112  113  114  115 116 00 :COLON07 :COLON31 ,COMMA010  -DASH  -DASH > 00 :COLON07 :COLON35 ,COMMA150 117 00 :COLON07 :COLON36 ,COMMA930  -DASH  -DASH > 00 :COLON07 :COLON42 ,COMMA990 118 00 :COLON07 :COLON42 ,COMMA990  -DASH  -DASH > 00 :COLON07 :COLON47 ,COMMA830 119 00 :COLON07 :COLON47 ,COMMA830  -DASH  -DASH > 00 :COLON07 :COLON52 ,COMMA880 120 00 :COLON07 :COLON52 ,COMMA880  -DASH  -DASH > 00 :COLON07 :COLON56 ,COMMA280 121 00 :COLON07 :COLON56 ,COMMA280  -DASH  -DASH > 00 :COLON07 :COLON57 ,COMMA850 00 :COLON07 :COLON58 ,COMMA950  -DASH  -DASH > 00 :COLON08 :COLON00 ,COMMA852 now the thing about assertions in java is that you can enable or disable them at runtime .PERIOD and that's really important ,COMMA because it means you can put them into your code to check while developing .PERIOD but it doesn't incur any extra cost at all in production code .PERIOD so by default ,COMMA insertions are disabled .PERIOD   129  130  131  132 133 00 :COLON08 :COLON39 ,COMMA870  -DASH  -DASH > 00 :COLON08 :COLON42 ,COMMA010 134 00 :COLON08 :COLON42 ,COMMA010  -DASH  -DASH > 00 :COLON08 :COLON44 ,COMMA240 135 00 :COLON08 :COLON44 ,COMMA240  -DASH  -DASH > 00 :COLON08 :COLON45 ,COMMA825 00 :COLON08 :COLON45 ,COMMA825  -DASH  -DASH > 00 :COLON08 :COLON50 ,COMMA990 alright ,COMMA so with that merge 00 :COLON08 :COLON50 ,COMMA990  -DASH  -DASH > 00 :COLON08 :COLON56 ,COMMA020 the sort implementation is a quite simple ,COMMA 00 :COLON08 :COLON57 ,COMMA840  -DASH  -DASH > 00 :COLON09 :COLON03 ,COMMA390 so we use the merge procedure we just 00 :COLON09 :COLON03 ,COMMA390  -DASH  -DASH > 00 :COLON09 :COLON07 ,COMMA250 it's recursive so ,COMMA checks that we have 00 :COLON09 :COLON07 ,COMMA250  -DASH  -DASH > 00 :COLON09 :COLON10 ,COMMA960 then it computes the value of the midpoint 00 :COLON09 :COLON10 ,COMMA960  -DASH  -DASH > 00 :COLON09 :COLON14 ,COMMA990 for a binary search .PERIOD 00 :COLON09 :COLON14 ,COMMA990  -DASH  -DASH > 00 :COLON09 :COLON17 ,COMMA810 sort the second half ,COMMA and then merge them 00 :COLON09 :COLON18 ,COMMA830  -DASH  -DASH > 00 :COLON09 :COLON24 ,COMMA080 and then the actual sort is takes just the 00 :COLON09 :COLON24 ,COMMA080  -DASH  -DASH > 00 :COLON09 :COLON29 ,COMMA370 of the array creates the auxiliary array 00 :COLON09 :COLON30 ,COMMA390  -DASH  -DASH > 00 :COLON09 :COLON36 ,COMMA300 now ,COMMA it's important to not create the 00 :COLON09 :COLON36 ,COMMA300  -DASH  -DASH > 00 :COLON09 :COLON38 ,COMMA840 the recursive routine because that could 00 :COLON09 :COLON38 ,COMMA840  -DASH  -DASH > 00 :COLON09 :COLON43 ,COMMA460 to extensive cost of extra array creation .PERIOD and you'll sometimes see mergesort performing poorly because of that bug .PERIOD otherwise this is a very straight forward implementation .PERIOD and it's actually a prototype for algorithm design that we'll see come up again and again .PERIOD   153 154 00 :COLON10 :COLON01 ,COMMA460  -DASH  -DASH > 00 :COLON10 :COLON04 ,COMMA370 155 00 :COLON10 :COLON04 ,COMMA370  -DASH  -DASH > 00 :COLON10 :COLON07 ,COMMA420 156 00 :COLON10 :COLON10 ,COMMA675  -DASH  -DASH > 00 :COLON10 :COLON15 ,COMMA450 157 00 :COLON10 :COLON15 ,COMMA450  -DASH  -DASH > 00 :COLON10 :COLON22 ,COMMA590 158 00 :COLON10 :COLON22 ,COMMA590  -DASH  -DASH > 00 :COLON10 :COLON28 ,COMMA550 159 00 :COLON10 :COLON28 ,COMMA550  -DASH  -DASH > 00 :COLON10 :COLON31 ,COMMA740 160 00 :COLON10 :COLON31 ,COMMA740  -DASH  -DASH > 00 :COLON10 :COLON34 ,COMMA660 161 00 :COLON10 :COLON34 ,COMMA660  -DASH  -DASH > 00 :COLON10 :COLON35 ,COMMA710 00 :COLON10 :COLON35 ,COMMA710  -DASH  -DASH > 00 :COLON10 :COLON38 ,COMMA110 that we actually do is just compare and exchange if necessary the first two elements .PERIOD and then we do the same thing for the next two elements .PERIOD then merge those two together to get the first four done .PERIOD and then we do the same thing for the next four in the array .PERIOD so now we have two sorted sub -DASH arrays at size four .PERIOD and we merge those together to get one of size eight .PERIOD and then we do the same thing on the right ,COMMA and eventually we have two eights that we merge together to get the final result .PERIOD   173  174  175  176 177 00 :COLON11 :COLON20 ,COMMA820  -DASH  -DASH > 00 :COLON11 :COLON23 ,COMMA040 178 00 :COLON11 :COLON24 ,COMMA160  -DASH  -DASH > 00 :COLON11 :COLON26 ,COMMA100 179 00 :COLON11 :COLON26 ,COMMA100  -DASH  -DASH > 00 :COLON11 :COLON29 ,COMMA430 180 00 :COLON11 :COLON30 ,COMMA530  -DASH  -DASH > 00 :COLON11 :COLON34 ,COMMA490 00 :COLON11 :COLON34 ,COMMA490  -DASH  -DASH > 00 :COLON11 :COLON37 ,COMMA319 in the animation because of the auxiliary 00 :COLON11 :COLON38 ,COMMA710  -DASH  -DASH > 00 :COLON11 :COLON41 ,COMMA010 let's look at it when it's in reverse 00 :COLON11 :COLON43 ,COMMA680  -DASH  -DASH > 00 :COLON11 :COLON49 ,COMMA590 again it gets the first half done now it's 00 :COLON11 :COLON49 ,COMMA590  -DASH  -DASH > 00 :COLON11 :COLON54 ,COMMA100 it gets the second half done then it goes 00 :COLON11 :COLON54 ,COMMA100  -DASH  -DASH > 00 :COLON11 :COLON58 ,COMMA180 it's just as fast in reverse order as as 00 :COLON11 :COLON59 ,COMMA910  -DASH  -DASH > 00 :COLON12 :COLON04 ,COMMA210 so you can run a mergesort on huge 00 :COLON12 :COLON04 ,COMMA210  -DASH  -DASH > 00 :COLON12 :COLON09 ,COMMA520 it's a very efficient algorithm .PERIOD 00 :COLON12 :COLON09 ,COMMA520  -DASH  -DASH > 00 :COLON12 :COLON16 ,COMMA140 what this table shows ,COMMA if you were to try 00 :COLON12 :COLON16 ,COMMA140  -DASH  -DASH > 00 :COLON12 :COLON18 ,COMMA660 file ,COMMA say a file with a billion elements ,COMMA 00 :COLON12 :COLON18 ,COMMA660  -DASH  -DASH > 00 :COLON12 :COLON21 ,COMMA770 your pc it'd take a few centuries to 00 :COLON12 :COLON23 ,COMMA380  -DASH  -DASH > 00 :COLON12 :COLON26 ,COMMA300 even on a super computer ,COMMA if you're using 00 :COLON12 :COLON26 ,COMMA300  -DASH  -DASH > 00 :COLON12 :COLON30 ,COMMA380 sort nowadays it'd maybe take a week or 00 :COLON12 :COLON30 ,COMMA380  -DASH  -DASH > 00 :COLON12 :COLON32 ,COMMA150 but if you have a good algorithm like mergesort ,COMMA and you're trying to do a billion items ,COMMA you can do it in just less than half an hour on your pc .PERIOD and a supercomputer can do it in an instant .PERIOD and smaller problems only take an instant even on your pc .PERIOD so you can spend a lot of money or a lot of time ,COMMA or you can use a good algorithm .PERIOD and that's one of our main themes in this course .PERIOD a good algorithm is much more effective than spending money or time wasting money or time using a bad one .PERIOD so let's look at the analysis of mergesort ,COMMA that's a bit of math but very instructive because this really shows the power of the divide and conquer method .PERIOD and allow us to take a problem that was taking us quadratic time with methods like insertion and selection sort ,COMMA and get it done in ,COMMA in log n time with mergesort .PERIOD so that's the proposition mergesort uses at most n lg n compares and 6 n lg n array accesses to sort any array of size n .PERIOD and the way to prove this proposition is to from examining the code ,COMMA to write down what's called a recurrence relation .PERIOD and all that is ,COMMA it's a mathematical reflection of what's going on in the code .PERIOD if we're sorting n items then let c of n denote the number of compares that we need to sort the n items .PERIOD in order to get that done ,COMMA we're sorting the left half and the right half and this notation ceiling of n over 2 and floor of n over 2 that's the n over 2 round up and n over 2 round down ,COMMA that's the size of the two sub -DASH arrays ,COMMA and we're going to call the same routine for that size ,COMMA so the number of compares you need to .PERIOD for that is c of n over 2 ,COMMA ceiling of n over 2 for the left and ceiling of ,COMMA floor of n over 2 for the right .PERIOD and then for the merge ,COMMA we need at least ,COMMA at most n compares .PERIOD if neither one exhausts ,COMMA we need exactly n compares .PERIOD and so and that's true as long as n is bigger than 1 .PERIOD if there's only one thing ,COMMA we're not  so this is a mathematical formula that we  completely describes mathematically  compares that are going to be needed .PERIOD  accesses ,COMMA if you count up the number of  merge you could be at most six in .PERIOD  there's techniques  that .PERIOD  mathematics .PERIOD  the recurrence when n is a power of 2 .PERIOD  all  the recurrence .PERIOD  which  about .PERIOD  2 let's ,COMMA let's look at this one .PERIOD   239  240  241 242 00 :COLON16 :COLON07 ,COMMA140  -DASH  -DASH > 00 :COLON16 :COLON10 ,COMMA350 243 00 :COLON16 :COLON11 ,COMMA510  -DASH  -DASH > 00 :COLON16 :COLON15 ,COMMA310 244 00 :COLON16 :COLON15 ,COMMA310  -DASH  -DASH > 00 :COLON16 :COLON18 ,COMMA140 245 00 :COLON16 :COLON18 ,COMMA140  -DASH  -DASH > 00 :COLON16 :COLON24 ,COMMA470 246 00 :COLON16 :COLON24 ,COMMA470  -DASH  -DASH > 00 :COLON16 :COLON30 ,COMMA285 247 00 :COLON16 :COLON30 ,COMMA285  -DASH  -DASH > 00 :COLON16 :COLON34 ,COMMA590 00 :COLON16 :COLON34 ,COMMA590  -DASH  -DASH > 00 :COLON16 :COLON38 ,COMMA110 each one of these we have divided into n 00 :COLON16 :COLON38 ,COMMA110  -DASH  -DASH > 00 :COLON16 :COLON43 ,COMMA130 4s and each one of those 4n over 4s has an 00 :COLON16 :COLON43 ,COMMA130  -DASH  -DASH > 00 :COLON16 :COLON48 ,COMMA980 well 2n over 2 is n ,COMMA 4n over 4 is n and we 00 :COLON16 :COLON48 ,COMMA980  -DASH  -DASH > 00 :COLON16 :COLON54 ,COMMA660 we get down to d of 2 and we always for 00 :COLON16 :COLON54 ,COMMA660  -DASH  -DASH > 00 :COLON16 :COLON56 ,COMMA940 and how many stages do we have here ?QUESTIONMARK well ,COMMA it's the number of times you divide n by 2 to get down to 2 .PERIOD that's exactly log base 2 of n ,COMMA so the grand total of all the costs for the merge ,COMMA which is where the compares are ,COMMA is log n times n ,COMMA n log n .PERIOD it's kind of a graphical proof or a proof by picture that that recurrence has that solution .PERIOD here's a little bit more mathematical one :COLON we write the recurrence down ,COMMA and then we divide both sides by n .PERIOD  n over 2 over n over 2 plus 1 .PERIOD   262  263  264  265  266 267 00 :COLON17 :COLON57 ,COMMA570  -DASH  -DASH > 00 :COLON18 :COLON00 ,COMMA450 00 :COLON18 :COLON00 ,COMMA450  -DASH  -DASH > 00 :COLON18 :COLON02 ,COMMA990 and when we've done that ,COMMA we've thrown out 00 :COLON18 :COLON02 ,COMMA990  -DASH  -DASH > 00 :COLON18 :COLON09 ,COMMA510 so we get d of n over n equals log n ,COMMA or d 00 :COLON18 :COLON09 ,COMMA510  -DASH  -DASH > 00 :COLON18 :COLON11 ,COMMA560 that's another proof by expansion .PERIOD or using either one of those techniques you could just get the idea that d of n is close to log n or you can write a program to expand the recurrence and find that .PERIOD and then once we have the idea that d of n  original formula .PERIOD  equals   277  278  279  280  281  282  283  284  285  286  287  288  289 290 00 :COLON19 :COLON40 ,COMMA948  -DASH  -DASH > 00 :COLON19 :COLON44 ,COMMA846 00 :COLON19 :COLON44 ,COMMA846  -DASH  -DASH > 00 :COLON19 :COLON47 ,COMMA630 a lot of times ,COMMA we're sorting everything 00 :COLON19 :COLON47 ,COMMA630  -DASH  -DASH > 00 :COLON19 :COLON50 ,COMMA590 we want to fill up the memory with stuff 00 :COLON19 :COLON51 ,COMMA620  -DASH  -DASH > 00 :COLON19 :COLON57 ,COMMA380 and search and selection in shellsort are 00 :COLON19 :COLON57 ,COMMA380  -DASH  -DASH > 00 :COLON20 :COLON00 ,COMMA500 but mergesort you can only sort really 00 :COLON20 :COLON00 ,COMMA500  -DASH  -DASH > 00 :COLON20 :COLON05 ,COMMA920 fit in memory ,COMMA because you need that 00 :COLON20 :COLON05 ,COMMA920  -DASH  -DASH > 00 :COLON20 :COLON08 ,COMMA910 if you want ,COMMA again ,COMMA if you think that the 00 :COLON20 :COLON08 ,COMMA910  -DASH  -DASH > 00 :COLON20 :COLON13 ,COMMA800 are easy ,COMMA think about the idea of actually 00 :COLON20 :COLON13 ,COMMA800  -DASH  -DASH > 00 :COLON20 :COLON16 ,COMMA530 people have come up with methods for 00 :COLON20 :COLON16 ,COMMA530  -DASH  -DASH > 00 :COLON20 :COLON19 ,COMMA420 so it's theoretically possible ,COMMA but the 00 :COLON20 :COLON19 ,COMMA420  -DASH  -DASH > 00 :COLON20 :COLON22 ,COMMA980 generally too complex to be useful in 00 :COLON20 :COLON22 ,COMMA980  -DASH  -DASH > 00 :COLON20 :COLON24 ,COMMA310 their not used .PERIOD but there could be out there some easy way to doing in place merge .PERIOD that's another great algorithm waiting to be discovered .PERIOD now there's a ,COMMA a number of practical improvements that we can use to make mergesort even more efficient than the simple one that we've looked at and we'll take a look of those because they're examples of techniques that we can use for other algorithms .PERIOD first thing is that mergesort is too complicated to use for tiny arrays .PERIOD so say the subarrays are only of two ,COMMA or three ,COMMA or four there's too much overhead with the recursive calls and so forth to get that done efficiently .PERIOD and what's worse is ,COMMA the recursive nature of the sort definitely means that there's going to be lots of subarrays to be sorted .PERIOD so ,COMMA one improvement that we can make is to use insertion sort ,COMMA and just cut off and use insertion sort which is simple and efficient for small subarrays .PERIOD so that's adding this one line of code to mergesort will make it quite a bit faster .PERIOD maybe 20% faster .PERIOD  that'll improve the performance  is to just   320  321  322 323 00 :COLON21 :COLON49 ,COMMA990  -DASH  -DASH > 00 :COLON21 :COLON51 ,COMMA080 00 :COLON21 :COLON51 ,COMMA080  -DASH  -DASH > 00 :COLON21 :COLON53 ,COMMA860 we just put a test in the recursive 00 :COLON21 :COLON53 ,COMMA860  -DASH  -DASH > 00 :COLON21 :COLON57 ,COMMA880 through this one line of code ,COMMA to check 00 :COLON21 :COLON57 ,COMMA880  -DASH  -DASH > 00 :COLON22 :COLON00 ,COMMA160 that way ,COMMA for example ,COMMA if you were to call mergesort for an array that's already in order it would just do this test every time and it would be done in linear time .PERIOD that's pretty helpful although not ,COMMA not totally helpful but there's a lot of situations where that's helpful .PERIOD the other thing that's possible to do and it's a little mind bending so recommended only for experts .PERIOD is to save a little bit of time you don't really have to copy over into the auxiliary array .PERIOD you can kind of switch the role of the input and the auxiliary array every time you make a recursive call .PERIOD you still need that array but  [cough]  the other one .PERIOD  the first one .PERIOD  get the job done .PERIOD  have to actually  time .PERIOD   344  345  346  347  348  349 350 00 :COLON23 :COLON34 ,COMMA765  -DASH  -DASH > 00 :COLON23 :COLON40 ,COMMA577 351 00 :COLON23 :COLON40 ,COMMA577  -DASH  -DASH > 00 :COLON23 :COLON45 ,COMMA650 
next ,COMMA we're going to look at a bottom -DASH up version of mergesort .PERIOD well ,COMMA mergesort is easy to understand as a recursive program .PERIOD this bottom -DASH up version that has no recursion ,COMMA it's also quite simple to understand and to code up .PERIOD the basic idea is to think of the array as being a little at the begining a set of little sorted sub arrays of size one .PERIOD and then what this method will do is go through and merge those little subarrays of size one together in pairs to get subarrays of size two .PERIOD then ,COMMA the whole array consists of sorted subarrays to size two ,COMMA and then we make another pass through to get size four ,COMMA and then size eight ,COMMA and so forth .PERIOD so ,COMMA as you can see in this example we start out by merging the first two sub arrays of size one to make a array of size two  -DASH  e ,COMMA m  -DASH  that's sorted ,COMMA and then do the same thing for the next two elements and the next two and so forth until eventually instead of sixteen individual elements we have eight sorted subarrays of size two .PERIOD then on another pass through ,COMMA we can take the e ,COMMA m and the g ,COMMA r and merge them together to make egmr ,COMMA and the e ,COMMA s and the o ,COMMA r merge those together to make eors ,COMMA and so forth .PERIOD and we have four subarrays of size four .PERIOD one more pass makes two subarrays of size eight ,COMMA and the last pass is just a sorted array .PERIOD the bottom line in this is sequence of passes through the whole array and there's no recursion needed at all .PERIOD it's extremely easy to code up as you can see from this code .PERIOD we use the same merge code as before and we take a nested for loop .PERIOD the first one is the size of the subarray and this loop gets executed on a log n times because each time we double the size of the subarray until we get to n .PERIOD and then we pass through picking out from low to low+size -DASH 1 ,COMMA and then the next part is low+size+size -DASH 1 until we run to the end of the array where we might not have a full subarray of size sz .PERIOD that is a fully complete industrial strength code for sorting .PERIOD the only downsize as would regular mergesort is that it uses extra space proportional to the size of the array .PERIOD but otherwise ,COMMA that's a fine method for merging .PERIOD that's a bottom -DASH up mergesort .PERIOD if you look at this visual trace you can see how it works .PERIOD the thing is totally unsorted ,COMMA then it gets sorted until subarrays to size four ,COMMA then eight ,COMMA sixteen ,COMMA and 32 .PERIOD now in this case the second subarray to be sorted is smaller but the merge routine doesn't really care about that so much .PERIOD you can merge things that are not equal in size .PERIOD and then we get a final sorted array .PERIOD whatever the size ,COMMA bottom of mergesort gets the job done in log n passes .PERIOD each pass using about n compares for a total cost of about n log n .PERIOD 
to get started ,COMMA we're going to look at a general scheme for solving max -DASH flow min -DASH cut problems ,COMMA known as the ford -DASH fulkerson algorithm ,COMMA dates back to the 1950s .PERIOD and the idea is to start with no flow anywhere .PERIOD so ,COMMA we initialize all edges to have capacity zero .PERIOD and then find any path from s to t ,COMMA so that you can increase the flow along that path .PERIOD now ,COMMA the simplest case is when the edges all go in the same direction from source to target .PERIOD we'll look at the other case in a minute .PERIOD in that case ,COMMA so there is a path ,COMMA and this is the general algorithm that works for any path and if there's a path from s to t ,COMMA go ahead and find it .PERIOD and if there's capacity left in each one of the edges ,COMMA if none of them were full ,COMMA then what we want to do is augment the flow along that path .PERIOD so we put as much flow as we can through that path .PERIOD in this case ,COMMA we can put ten units of flow through each path .PERIOD through each edge ,COMMA there's room to put ten ,COMMA and two of the edges fill up in that case but we've increased the flow in the network by ten in that case .PERIOD and the algorithm is just ,COMMA continuing that way ,COMMA finding a path .PERIOD so here's another path .PERIOD and this one also the edges all flow from source to target .PERIOD and in this case again ,COMMA we can add ten more units a flow cuz the last edge only has capacity ten .PERIOD so load up those edges with that flow ,COMMA and now ,COMMA we've got twenty units a flow in the network .PERIOD notice ,COMMA when we augment along in edge ,COMMA we're preserving the vertex equilibrium ,COMMA local equilibrium at a vertex property .PERIOD we're putting some flow in and taking the same amount of flow out .PERIOD so ,COMMA here's another augmenting path .PERIOD now ,COMMA this one has what's called a backward edge .PERIOD so notice that if ,COMMA the path going from s to t goes backwards along that edge ,COMMA and the idea is ,COMMA that you can augment flow through the whole network by removing flow in that path .PERIOD that is ,COMMA if we add five units of flow from s to this vertex ,COMMA and five units of flow from s to this vertex ,COMMA then what we can do is remove five units of flow along this edge .PERIOD that's to preserve the local equilibrium .PERIOD essentially ,COMMA that five units of flow gets transferred right through .PERIOD after we remove five units and we add five here .PERIOD that's five coming in ,COMMA there's still ten going out .PERIOD and then for the forward edges ,COMMA we add the flow .PERIOD that is ,COMMA we can augment the flow along an augmenting path ,COMMA by adding flow to forward edges and subtracting flow from backward edges .PERIOD the maximum amount of flow that we can push through is the remaining capacity in forward edges and the amount of flow in backward edges .PERIOD you can't remove more flow than is there .PERIOD in this case ,COMMA we can augment the flow in the network by five .PERIOD that ,COMMA fills up the first edge .PERIOD and so now we've got 25 units of flow in the network .PERIOD and again ,COMMA the idea of removing flow from a backward edge is very simple .PERIOD it's just a way to ensure that the local equilibrium conditions always remains satisfied as we're moving along the path .PERIOD in this case there's one more augmenting path .PERIOD okay .PERIOD and that's ,COMMA forward ,COMMA forward ,COMMA forward ,COMMA forward ,COMMA backwards along that one again and then forward ,COMMA forward .PERIOD so ,COMMA and then what's the maximum amount that we can push through in this case ,COMMA this one has got five in it and it's got a capacity of eight so we can put three more units of flow through this network .PERIOD and we get a now we have 28 units of flow going through the network .PERIOD and the algorithm terminates when there's no way to find an augmenting path from s to t .PERIOD and what's that mean ?QUESTIONMARK that means that every augmenting path ,COMMA every path from s to t contains either a full forward edge or an empty backwards edge .PERIOD we can't put more flow through a forward edge and we can't remove flow from an empty backward edge .PERIOD so when there's no more augmenting paths ,COMMA the algorithm terminates .PERIOD and so that's the algorithm .PERIOD we start with no flow .PERIOD as long as there is an augmenting path ,COMMA we ,COMMA we find that path and look through the path to find the amount ,COMMA the ,COMMA amount capacit left in the most full forward edge and the amount of flow left in the most empty back edge .PERIOD and we increase the flow in the path by that amount .PERIOD and if we can't find an augmenting path ,COMMA then we're done .PERIOD now there's a few questions about this .PERIOD so that solves the maximum flow problem .PERIOD we have to look at how to compute and min -DASH cut .PERIOD we have to figure out a way to find an augmenting path .PERIOD that's not to hard .PERIOD that's similar to many other graph processing problems that we have already solved .PERIOD and we have to ,COMMA ensure that or at least show that it always computes a max -DASH flow .PERIOD and ,COMMA there's even a question of does it actually terminate ?QUESTIONMARK maybe you could get stuck in some kind of situation where it removes flow on an edge in one path and ,COMMA adds it in another ,COMMA and so ,COMMA even analyzing how many times it does augmentation ,COMMA is actually not so straightforward .PERIOD so we'll take a look ,COMMA at these questions .PERIOD that's the ford -DASH fulkerson algorithm ,COMMA the general scheme for solving nax -DASH flow .PERIOD 
next we'll look at a proof that the ford -DASH fulkerson algorithm is valid ,COMMA known as the max -DASH flow min -DASH cut theorem .PERIOD it also proves that the two problems are equivalent .PERIOD we need a couple more definitions to ,COMMA to show ,COMMA first we want to show the relationship between a flow and a cut .PERIOD so in this case we've got a cut where t is on one side and all the other vertices are on the same side as s .PERIOD and what we talk about is the flow across the cut .PERIOD and that ,COMMA what that is ,COMMA is the sum of the flow on it's edges that go from s to t ,COMMA minus the amount that goes the other way .PERIOD that's the flow across the cut .PERIOD so this ,COMMA what's called the flow value lemma is that ,COMMA if you have a flow then for any cut .PERIOD the net flow across the cut is the value of the flow .PERIOD that's called the flow value lemma .PERIOD doesn't matter what the cut is ,COMMA this ,COMMA this is a max flow ,COMMA a flow with value 25 and every cut is going to have 25 flowing across it .PERIOD so ,COMMA this cut ,COMMA this is a more complicated cut where s and these three vertices are colored .PERIOD so the flow of a ,COMMA across that cut has to take the all the edges that go from a gray vertex to a white one .PERIOD so ,COMMA there's ten plus ten ,COMMA plus from a gray vertex to a white one ,COMMA five plus ten + 00 .PERIOD then ,COMMA we have to subtract off the edges that go from a white to a gray one .PERIOD so we add up all the ones that go from gray to white .PERIOD ten + ten + five + ten + zero + zero and subtract off the two that go from a white to a gray and ,COMMA still ,COMMA the net value across the flow is the same ,COMMA the value of the flow .PERIOD that's the flow value lemma that gives a particular relationship between flows and cuts .PERIOD and that's not too difficult to prove by induction on the size of one of the sets .PERIOD for example ,COMMA if we do an induction on the size of the set containing t ,COMMA it's certainly true when that set consists of just t ,COMMA because the value of the flow is exactly equal to the edges coming into t .PERIOD and then to prove by induction ,COMMA you can move any vertex from a to b in local elibriums ,COMMA local equilibrium's going to make sure that the flow value limma is true .PERIOD and so that's ,COMMA that's how it's proved .PERIOD and a corollary of that is that ,COMMA that outflow from s is equal to the inflow to t ,COMMA which is equal to the val ,COMMA all equal to the value of the flow .PERIOD and that's also easy to see in all of our examples .PERIOD so to get started let's ,COMMA let's look at what's called weak duality .PERIOD if ,COMMA f is any flow at all ,COMMA in network .PERIOD if ab is any cut .PERIOD the value of the flow is going to be less than or equal to the capacity of the cut .PERIOD so in this case value of flow is 27 and the capacity of the cut is 30 .PERIOD value of the flow is always less than or equal to the capacity of the cut .PERIOD and well the net flow across a cut has got to be less than less than or equal to it's capacity 'coz it's at least that and then if there's any edges going the other way ,COMMA they get subtracted to compute the lugnut flow .PERIOD so a weak duality ,COMMA is that ,COMMA that's an easy thing to prove .PERIOD so what we want to prove are these two theorems .PERIOD the max -DASH flow min -DASH cut theorem is really two theorems combined called the augmenting path theorem that says the flow's at max -DASH flow if and only if there's no augmenting paths ,COMMA and that the value of the max -DASH flow equals the capacity of the min -DASH cut .PERIOD in any network .PERIOD and the way we prove that is to prove that the following three conditions are equivalent .PERIOD again this is a proof that's a little intricate logically .PERIOD it's worthwhile for me to go through it ,COMMA but to really understand it you're going to need to read it carefully and convince yourself that these three conditions work .PERIOD so here's the three conditions that we're going to prove our equipment .PERIOD first one is ,COMMA there is a cut ,COMMA there's some cut whose capacity equals the value of the flow .PERIOD the second one is that f is a max flow .PERIOD so if there's a cut whose capacity equals the flow then f is a max flow .PERIOD and if f is a max flow there's such a cut .PERIOD and then the third one is that there's no augmenting path .PERIOD so we're going to prove those three conditions are equivalent .PERIOD and we'll do it with a little logic trickery .PERIOD so first we could prove that one implies two .PERIOD if there exist a cut capacities equals the value flow ,COMMA then f is the max flow .PERIOD alright ,COMMA so suppose that we have such a cut ,COMMA capacity is equal the value of the flow then any other flow by weak duality ,COMMA flow is going to be less than or equal to the capacity of that cut ,COMMA  .PERIOD in fact that cuts equal to the value of the flow ,COMMA so therefore ,COMMA that's the maximum ,COMMA max flow .PERIOD the value of any flow ,COMMA if less or equal in value of f ,COMMA so it's the max flow .PERIOD so that proves that one implies two .PERIOD okay .PERIOD now we're going to prove two implies three .PERIOD one implies two ,COMMA and also two implies three .PERIOD that also means one implies three .PERIOD so in order to prove that we're going to prove the counter -DASH positive .PERIOD so we'll prove that not three implies not two .PERIOD that is ,COMMA if there is an augmenting path then f is not a max flow .PERIOD well ,COMMA that's pretty straightforward ,COMMA then ,COMMA 'cuz that's what we do in the algorithm .PERIOD we could improve the flow by sending flow along the path .PERIOD so it can't be a max flow .PERIOD so that's ,COMMA pretty easy .PERIOD if that was a max flow ,COMMA there's no augmenting path cuz if there is an augmenting path ,COMMA that's not a max flow .PERIOD so that's the ,COMMA second ,COMMA part of the proof .PERIOD and now the third part of the proof ,COMMA will prove that three implies one .PERIOD so ,COMMA that'll give you ,COMMA the circular logic condition that proves that they're all equivalent .PERIOD so we want to prove that if there is no augmenting path ,COMMA then there is a cut in this capacity that equals the value of the flow .PERIOD so if there's no augmenting path .PERIOD then what we're going to have is a cut where a is the set of vertices .PERIOD that are ,COMMA connected to s by an undirected path with no full forward or empty backward edges .PERIOD and so there has to be such a cut if there's no odd many path .PERIOD s has got to be in a and t has got to be in b otherwise there will be a path from a to b with no four ,COMMA four front and empty backward with edges and the capacity of that cut equals the net flow across the cut but all the four edges are fallen ,COMMA all the backward edges are empty so that's exactly equal to the value of the flow .PERIOD so if there's no augmenting path then we can demonstrate a cut whose capacity equals the value of the flow and that is completes the proof of the max flow and the cut theorem .PERIOD sorry .PERIOD alright .PERIOD so the one last step is if we have computed a max -DASH flow ,COMMA then what we can do is compute the min -DASH cut by computing the set of vertices .PERIOD and we can do that just by a graph search .PERIOD we start at s and if there's a path that has no ,COMMA has a ,COMMA a forward edge that's not full then we follow that path and if we have a backward edge that's not empty ,COMMA we follow the path .PERIOD and we just do a ,COMMA a graph search to get to all the vertices that we can reach with forward edges that aren't full ,COMMA and backward edges that aren't empty .PERIOD and then we treat the full forward edges and the back empty edges as not being there .PERIOD otherwise ,COMMA we do just a regular graph search .PERIOD and that's ,COMMA going to give us ,COMMA the ,COMMA the ,COMMA then the set of edges that define by that cut are going to be the min -DASH cut .PERIOD so ,COMMA not difficult to compute a min -DASH cut from a max -DASH flow .PERIOD so that's a proof of the augmenting path there min ,COMMA max -DASH flow min -DASH cut there .PERIOD 
with mergesort is a good opportunity to take a look at the intrinsic difficulty in the sorting problem ,COMMA now that is called complexiting and we'll look at that next .PERIOD the idea of complexity is it's a frame work for studying the efficiency of all the algorithms for solving a particular problem .PERIOD that's called computational complexity .PERIOD and in order to do this sensibly ,COMMA we need what's called a model of computation .PERIOD the operations that the algorithms are allowed to perform .PERIOD for sorting that's kind of straight forward ,COMMA what we're going to do is have a cost model where we count the comparisons .PERIOD now in framing of the difficulty of problems were only two things .PERIOD one is an ,COMMA what's called an upper bound which is a cost guarantee that's provided by some algorithm for solving the problem .PERIOD that's an upper bound and how difficult it is to solve the problem .PERIOD we have an algorithm that can solve it it's the least that easy .PERIOD and then we also look for a lower bound which is a limit on the cost guarantee of all algorithms .PERIOD no algorithm can do better .PERIOD now ,COMMA what we seek ideally is what's called an optimal algorithm where we prove that the upper bound and the lower bound are the same .PERIOD that's an algorithm that's ,COMMA that we know that has the best possible cost guarantee .PERIOD that's the idea for solving any problem .PERIOD so ,COMMA for sorting ,COMMA let's look at what each of these are .PERIOD the model of computation is what's called a decision tree ,COMMA tree .PERIOD and what that mans is that all we can use is compare ,COMMA that's the only way we can access the data .PERIOD so ,COMMA our cost model is the number compares .PERIOD mergesort provides ,COMMA provides an upper bound ,COMMA that's an algorithm that's guaranteed to get the sort done in time proportional to n log n .PERIOD and what we'll look at now is the lower bound .PERIOD there's a trivial lower bound which says you have to look at all the data ,COMMA that's n and we'll look at a better lower bound and see that mergesort is optimal .PERIOD so ,COMMA here's the basic idea for proving a lower bound for sorting .PERIOD let's say ,COMMA we ha ve three different items ,COMMA a ,COMMA b and c .PERIOD whatever algorithm we have is going to ,COMMA first ,COMMA do a comparison between two of the items .PERIOD let's say ,COMMA there a and b .PERIOD and then there's two cases .PERIOD either it's yes or it's not yes ,COMMA let's ,COMMA let's say ,COMMA they're distinct .PERIOD and there will be some code between the compares but either way then there is going to be a different compare .PERIOD if it's less than b ,COMMA maybe the next compare is b against c .PERIOD and if you find that b is less than c and a is less than b ,COMMA then you know that they're in the ,COMMA any algorithm that does that knows that the items are in the order a ,COMMA b ,COMMA c .PERIOD if b less than c goes the other way ,COMMA then it takes another comparison to determine the order .PERIOD in this case ,COMMA if c is less than b and a is less than c then those three compares show that the order has to be a ,COMMA c ,COMMA b and if c is less than a ,COMMA then it's going to be c ,COMMA a ,COMMA b ,COMMA those three compares that c is less than a ,COMMA c less than b and a is less than b .PERIOD the only possibility is c ,COMMA a ,COMMA b .PERIOD in continuing on the right perhaps the next compare is a less than c and maybe if c is less than a ,COMMA then another compare ,COMMA b less than c .PERIOD so ,COMMA in this case ,COMMA if you go from top to bottom in the tree with three compares at most you can determine the ordering of the three different items .PERIOD the idea of the lower bound generalizes this argument to figure out a number of compares that you need for a minimum to determine the ordering among n items .PERIOD now ,COMMA the height of the tree ,COMMA as i just mentioned ,COMMA is the worst case number of compares .PERIOD out of all the orderings the one that's further stand in the tree that's the worst case and so the algorithm ,COMMA no matter what the input is ,COMMA the tree tells us a bound ,COMMA the number of compares taken by the algorithm .PERIOD and there's got to be at least one leaf for each possible ordering .PERIOD if there's some ordering that is not appear in a tree corresponding the particular algorithm then that algorithm hasn't can't sort ,COMMA can't ,COMMA can't tell the difference between two different orderings .PERIOD so ,COMMA the lower bound as a proposition ,COMMA that uses the decision tree like that to prove that any compare base sorting algorithm has to use at least log base two (n) factorial compares in the worst case .PERIOD and by stirling's approximation ,COMMA we know that log base two(n) factorial is proportional to n log based 2n .PERIOD and then the proof is generalizes what i talked about on the decision tree on the last side ,COMMA slide .PERIOD we assume that the array consist of n distinct values there's a position created that describes the performance of any algorithm to compare sequence done by any algorithm to determine the n factorial different orderings .PERIOD so ,COMMA this three has to have at least n factorial leaves and if the three of height h ,COMMA it has utmost two^h leaves .PERIOD the only ,COMMA the ,COMMA the tree that has the most leaves of height h is totally complete and that one has two^h leaves .PERIOD and those observations give us the lower bound .PERIOD two^h has to be greater than or equal to the number of leaves .PERIOD and the number of leaves has to be greater or equal to n factorial so that implies the height of the tree has to be greater than or equal to log base two(n) factorial which is proportional to n log n by stirling's formula .PERIOD that's a lower bound on the complexity of sorting .PERIOD so ,COMMA we knew that the upper bound was n log ,COMMA proportional to n log n and we just proved that the lower bound is proportional to n log n and that means that mergesort is an optimal algorithm .PERIOD that's the first goal of algorithm design is to try and find optimal algorithms for the problems that we need to solve .PERIOD now ,COMMA you have to take these results in context .PERIOD really what we proved is that mergesort is optimal with respect to number of compares but we already know that it's not optimal with respect to space usage .PERIOD mergesort uses twice as extra space proportional to the size of the array it has to sort .PERIOD and simple algorithms like insertions or dump ,COMMA they've they don't use any extra space at all .PERIOD so  ,COMMA what we want to take from these theoretical results is ,COMMA is a guide when we're looking at implementations and trying to solve practical problems .PERIOD in this example what it tells us ,COMMA what theory tells us is don't try to design a sorting algorithm that guarantees to use substantially for your compares than merge sort .PERIOD say ,COMMA one -DASH half n log n compares .PERIOD is there a method that use one -DASH half n log n compares ?QUESTIONMARK the lower bound says ,COMMA no .PERIOD and that's a very useful thing because otherwise ,COMMA we might try to define such an algorithm .PERIOD on the other hand ,COMMA maybe there is an algorithm that uses n log n compares and also uses optimal space .PERIOD it's optimal with respect to both space and time .PERIOD and that's what we're going to look at soon .PERIOD the other thing is that the lower bound is for the particular model of computation being studied .PERIOD in this case ,COMMA compares .PERIOD it might not hold if the algorithm has more information about the keys ,COMMA for example ,COMMA if it's known that the input is almost ordered ,COMMA we saw that insertion sort can be linear time for files that are almost ordered .PERIOD or it's something about the distribution of key values if there are a lot of equal keys we can get sorted ,COMMA get it sorted faster than ,COMMA n log n .PERIOD and maybe the way the keys are represented .PERIOD we'll look at different methods that take advantage of such properties .PERIOD so ,COMMA partially ordered arrays we may not need n log n compares .PERIOD duplicate keys ,COMMA we may not need n log n compares ,COMMA we're going to look at the method that i guess that down in linear time and a lot of situations .PERIOD and later on ,COMMA we'll look at digital properties of keys where we can use digital character compares instead of whole key compares and got a faster sort for certain practical applications .PERIOD computational complexity is very useful way to help us understand properties of algorithm and help guide our design decisions .PERIOD 
next we'll take a look at comparators which is a java mechanism that helps us sort .PERIOD the same data on different sort keys ,COMMA different orders .PERIOD and you're familiar with this .PERIOD your music library maybe i ,COMMA at one point ,COMMA you sort it by the artist's name .PERIOD in this case we're looking at the b's .PERIOD but in another situation ,COMMA you might want to sort it by song names to look through it by song names .PERIOD that's the same data using different sort keys .PERIOD how do we arrange to do something is natural as this in our java sorts ?QUESTIONMARK now ,COMMA we use the fourth in order to be able to implement sorts that can sort any type of data ,COMMA we use java's comparable interface .PERIOD and that concept is that there's some natural ordering of the data that you'll want to use most of the time ,COMMA that's what the comparable interface is all about .PERIOD but there's a different interface called the comparator interface which is a way to help a sort ,COMMA using some alternate order or many different orders on the same data .PERIOD and the comparator interface again just says that it's going to implement a method compare() that compares two different keys of the given type ,COMMA of the generic type .PERIOD again it has to be a total order and this is very familiar for example with strings .PERIOD there's many different ways that we might want to sort strings .PERIOD we might want to use the natural alphabetic order or we might want to make it case insensitive or maybe there is just different languages that have different rules of the ordering .PERIOD we're sorting strings but we're implementing a different ordering ,COMMA various different orderings on that same data .PERIOD that's what the comparator interface is for .PERIOD so the java system sort will have a different .PERIOD [cough] method to implement comparators .PERIOD the idea is that you create a comparator object and then pass that as a second argument to java's sort routine and we can do the same thing for our sorts .PERIOD the idea is when a decouple ,COMMA the definition of the data type from the definition of what it means to compare to items of that type .PERIOD with the natural order ,COMMA we had to put the definition compared to within the data type .PERIOD with comparators ,COMMA we can do that outside of the data type even at some later time .PERIOD strings were defined and as part of the java system but we can define our own ordering on strings with the comparator .PERIOD so in our sort implementations we can change them as shown in this example to support comparators .PERIOD to support comparators in our sort implementations we'll pass an array of objects and instead of an array of comparable and then ,COMMA there's a second argument passed a comparator .PERIOD then ,COMMA the less method will take that comparator as an argument and this is the one that actually invokes the method compare two different keys .PERIOD this is a straightforward modification to our sorts .PERIOD and then exchange of course rather doing comparable has to use object .PERIOD so with these straightforward changes at the comparator as argument to the sort and to less and make array to be sorted array of objects ,COMMA it's easy to convert any of our implementations to support comparators .PERIOD to implement a comparator you can use this code as a model .PERIOD i won't go through it all in detail just to point out that this implements two different comparators as nested classes .PERIOD say ,COMMA for this fictional class student ,COMMA that's got two instance variables  -DASH  name and section .PERIOD and the first one called by name implements a comparator for students and when you compare two students by name ,COMMA it's going to use the string comparative method .PERIOD if you're going to implement it compared to students by section ,COMMA then it'll return just the difference of the sections which is my minus if less zero if equal then plus if greater .PERIOD and this code is straight forward way to implement comparators that you can use as a model .PERIOD if you need to be able to sort data on two different keys .PERIOD so [cough] here is just an example of what happens if would those implemented comparators for that class student using the java system sort ,COMMA if you call array that sort with your a rray of students and you give it this by name comparator ,COMMA it will put them in order alphabetical order by the name field .PERIOD and if you give it to by section comparator ,COMMA it will them in order by the second field very convenient for all kinds of data processing applications .PERIOD and we came up with that before when we're talking about using a sort for the graham scan .PERIOD we needed to have a comparison for points that orders them by the polar angle they make ,COMMA make with the given point p .PERIOD that's what we needed for the graham scan algorithm for the convex hull .PERIOD points are defined data type for geometric objects and so what we need is code that will compute the polar angle and use that as the basis for comparison .PERIOD there's an easy way to do this based on ccw that is described here in this text .PERIOD most of the time all you need to do is do the ccw of the two points .PERIOD you either have to check whether [cough] the ,COMMA one of the points is above p and the other one is below .PERIOD but otherwise ,COMMA usually it's a ccw call in this code which again i won't go through in detail as an implementation of a comparator for two d points .PERIOD it implements the compare method that takes two points as argument and with just a little bit of calculation is able to do the compare .PERIOD so this code is the basis for applying the sort ,COMMA system sort method or any sort method for the graham scan for the convex hull that we did at the end of the last lecture .PERIOD so that's the basis for the graham scan method for the convex hull that we used at the last ,COMMA at the end of the last lecture .PERIOD 
 .PERIOD so now we've got a general scheme for computing max flow's min cuts and the proof that they are equivalent .PERIOD next what we need to do is look at an analysis of the ,COMMA cost of computing things to try to figure out ,COMMA specific ,COMMA efficient ways to compute ,COMMA augmenting paths .PERIOD so we already saw how to compute a min cuts so we'll just worry about doing the max flow .PERIOD to find an augmenting path .PERIOD well there's lots of ways to find an augmenting path .PERIOD any graph search is gonna work .PERIOD so let's just start with bfs for example .PERIOD so if word focusing terminates ,COMMA that means there's no augmenting path .PERIOD does it always compute our max slow ?QUESTIONMARK yes ,COMMA we showed that .PERIOD and well that's if it terminates .PERIOD does it always terminate ?QUESTIONMARK does it oscillate back and forth ?QUESTIONMARK well ,COMMA it's a little more work .PERIOD to show that it does always terminate .PERIOD if you have to ,COMMA a few other conditions .PERIOD so for simplicity ,COMMA we assume that each capacities are integers or there's other things that can be done with a choice of augmenting paths and maybe we'll come back to that .PERIOD but to figure out how many augmenting paths there are ,COMMA that's the key that requires some clever analysis .PERIOD and there's been a lot of different schemes studied to try to understand a way to first find the paths cheaply and then decide to try to see how ,COMMA many ,COMMA how we can limit the number of augmentations .PERIOD so ,COMMA let's look at a ,COMMA at an important special case .PERIOD and it's true in lots of applications .PERIOD where the edge capacities are integers ,COMMA between one and some ,COMMA big maximum u .PERIOD and ,COMMA a lot of the things that we talk about work when edge capacities are ,COMMA are ,COMMA are real numbers .PERIOD but let's just talk about this case .PERIOD so one thing to notice in that case ,COMMA is that our ford focus and method always keeps an integer value of flow we never take half a flow unit and put it through an edge .PERIOD so it's always integer valued ,COMMA cause the flow on each edge of the integer ,COMMA capacities are integers and so everything stays to be an integer .PERIOD every ,COMMA every augmentation either increases or decreases by the bottleneck capacity ,COMMA which is always an integer .PERIOD s o ,COMMA one thing that's definitely true is you only augment if you're gonna increase the flow .PERIOD you have to augment .PERIOD you wouldn't augment if you couldn't augment by at most one .PERIOD so it's definitely true that the number of augmentations is less than or equal to the value of the flow .PERIOD  .PERIOD so there's what's called the integrality .PERIOD integrality theorem that is important for some applications and we'll come back to it ,COMMA that says if there exists an integer valued max flow and ford focus finds so it's and waving a little bit to talk about that but we'll work with intergers and we'll be confident that we get to the answer and so the proof of the integraliy theorem is that it terminates in the max flow that it finds is integer valued and that's enough .PERIOD so ,COMMA but ,COMMA just to get an idea for what goes on ,COMMA let's look at this bad case .PERIOD even when the edge capacities are integers ,COMMA you could have a lot of augmenting paths .PERIOD and we want to avoid this case .PERIOD so look at this network here ,COMMA where we have s and t .PERIOD and we've got two big capacity edges coming out of s and two big capacity edges coming into t .PERIOD and then we have just a little edge of capacity one going between those two intermediate vertices .PERIOD here's what could happen .PERIOD so ,COMMA in the first generation we could decide that we wanna push flow along the path that goes across the middle .PERIOD now we're gonna look in a lot of different schemes for ,COMMA finding augmenting paths ,COMMA so ,COMMA maybe ,COMMA a scheme says ,COMMA if we have a choice ,COMMA let's take ,COMMA as longer path as we can find .PERIOD and that ,COMMA so ,COMMA in this case ,COMMA that's what it'd do .PERIOD there's another augmenting path that just goes from s to the left vortex down to p ,COMMA but the algorithm ,COMMA say ,COMMA chooses this one so we have an algorithm that chooses this one so that increases the flow by one but then the problem is ,COMMA maybe the next time ,COMMA we make that middle edge a backwards edge and so now we go through and increase the flow by one along that edge and now we have a total flow of two and then maybe we alternate between these two schemes .PERIOD increment by one in the left ,COMMA increment by one in the right .PERIOD and it 's gonna take 200 iterations .PERIOD to finally get to the max flow .PERIOD whereas a different algorithm might have gotten it done in two iterations and a hundred's not so bad ,COMMA but maybe these weights are a billion or something .PERIOD it would take a billion iterations .PERIOD so that's bad news .PERIOD now that's too slow in algorithm .PERIOD we want to try to avoid that .PERIOD now there's an easy way to avoid that and that's to use the shortest path or in other ways to use the farthest path ,COMMA the one you can push the most flow through .PERIOD that's just an example of the kind of pitfall that you wanna avoid and try to come up with an algorithm for choosing augmenting paths in ford fulkerson now the performance of the ford fulkerson in algorithm is gonna depend on the method used to choose the augmenting paths .PERIOD here's listed four easy ways to pick augmenting paths and they're pretty easy to implement .PERIOD they're very similar to dijkstra's algorithm or prim's algorithm and others that we've looked at .PERIOD but they lead to a different number of augmenting paths ,COMMA depending on the network .PERIOD so for example ,COMMA you could decide ,COMMA let's use the shortest path .PERIOD so that's just the augmenting path with the fewest number of edges .PERIOD and that's just ,COMMA breath for a search ,COMMA essentially in the graph that ignores the full forward and empty backward edges .PERIOD now it's been proven that ,COMMA there's no network for which the algorithm uses more than one -DASH half e times of e paths .PERIOD so at least that's an upper bound that shows that it doesn't have this bad performance involving the capacity .PERIOD i want to emphasize that this is a very conservative upper bound on the number of paths used .PERIOD in an actual network it might not use anywhere near that number of augmentations .PERIOD another example is the fattest path .PERIOD so that's the augmenting path ,COMMA with maximum bottleneck capacity .PERIOD and again ,COMMA that one is pretty easy to implement .PERIOD it's very similar to our implementations of dijkstra and prim's algorithm and we'll see in a minute .PERIOD and again ,COMMA it can serve of upper bound on the number of paths taken by that algorithm ,COMMA is the number of e dges times the log of product of edges and capacity .PERIOD but again ,COMMA that's a very conservative upper bound ,COMMA and in the real world it might only take a few ,COMMA augmentations to computing max flow ,COMMA using that method .PERIOD or you could use a random path which again is easy to implement ,COMMA and randomized graph search .PERIOD or depth -DASH first search .PERIOD now these conservative upper bounds are useful ,COMMA but in real world networks ,COMMA these algorithms are going to have running times that depend ,COMMA really a lot on properties of the network .PERIOD so people use diffent algorithms in different situations and the fact is that ,COMMA often ,COMMA we can get max flow problems solved ,COMMA even on huge networks with a relatively small number of augmenting paths .PERIOD 
next ,COMMA we're going to look at java code for solving the max flow problem .PERIOD this is the most complex .PERIOD graph processing algorithm we have seen so far but it's relatively a small amount of curve that builds upon the mechanisms that we have been studying for the last couple of lectures .PERIOD so now ,COMMA the graph that we are working with little more complicated because we have to associate with each edge not just the capacity but also a flow .PERIOD so ,COMMA we'll build a slightly more complicated data type for edges called a flow edge .PERIOD where ,COMMA for each edge ,COMMA we can keep track of that information .PERIOD so ,COMMA we not only have to keep the from vertex v and the to vertex w .PERIOD the weight or the capacity c ,COMMA associated with the edge but ,COMMA and also the flow cuz that's a flow edge .PERIOD and then the flow network .PERIOD since we're going to go through edges in the wrong direction we're going to have to put every flow edge ,COMMA kind of like an undirected graph in both adjacency lists .PERIOD and then we're going to test whether we're going ,COMMA which direction we're going through an edge .PERIOD it's kind of like using an undirected graph .PERIOD but the flow network ,COMMA anyway ,COMMA has to have edges in both places so it can do backward edges .PERIOD a simple way to arrange for this is to compute for the edges what's called the residual capacity ,COMMA and that's just what we're going to use to compute the bottleneck value ,COMMA the only max amount of flow we can pull through .PERIOD so for the backward edge ,COMMA we'll assign the residualcapacityto be the amount of flow .PERIOD and for the forward edge ,COMMA it'll be the capacity minus the flow .PERIOD so ,COMMA that's the maximum amount of stuff we can get through the edge when we're augmenting its residual capacity .PERIOD so and to actually do the augmentation ,COMMA you will have a value which is your maximum that you're going to ,COMMA that you're going to augment and so if you are on the forward edge ,COMMA you add it and if you're on a backward edge ,COMMA you subtract it .PERIOD and so ,COMMA that's the basic idea and its just quite natural from the graph representation we've been using and the way that the codes focus on how algorithm woks .PERIOD so one way to think of this is to little bit closer to the representation that we're using ,COMMA is to consider what's called a residual network that for every edge every forward edge in the network ,COMMA it has the ,COMMA the in ,COMMA forward edge going that has the amount of flow left and a backward edge with the amount of flow that's there .PERIOD and if you have a ,COMMA a full forward edge ,COMMA or a ,COMMA or an empty backward edge then you only have one such .PERIOD so this an example of the residual network for this amount of flow .PERIOD you can't put any more flow through from this vertex to this vertex ,COMMA so there's no edge going that way .PERIOD but you can remove four units of flow going that way .PERIOD so ,COMMA that's because of the backward edge .PERIOD so and in this case we have a full forward edge .PERIOD so ,COMMA there's no edge going this way ,COMMA cuz we can't put any more flow through .PERIOD but there's nine going that way ,COMMA that's another example of a full forward edge .PERIOD this empty one you can put eight units of flow that way ,COMMA so we have an edge in the residual network going that way .PERIOD but no way to go that way ,COMMA because there's no flow ,COMMA there's no backward edge .PERIOD and so this network is just a natural way to look at the network while the flow is being computed cause it's a digraph that we're going to search to find the augmenting path .PERIOD if a directed path in this network that's from s to t ,COMMA that's an augmenting path .PERIOD and that's a simple mechanism that helps us write compact and elegant code .PERIOD so that's an augmenting path in the original network and that just turns out to be a directed path in the residual network .PERIOD so then ,COMMA we can just use our algorithms that we've already studied for finding directed paths in the residual network .PERIOD alright ,COMMA so here's the api for flow edges .PERIOD and they just have the few extra methods to allow us to compute and make decisions based on the amount of flow and capacity in the edge .PERIOD these are the computations that we need to implement the forward focus in algorithm .PERIOD so every edge has a from and a to .PERIOD if you have one point ,COMMA it gives you the other one which we need just as we did in undirected graphs .PERIOD every edge has capacity and a flow and a residual capacity ,COMMA which we compute from a capacity in flow ,COMMA then we want to be an addresidualflow to any edge ,COMMA and its added and if its forward ,COMMA and it gets subtracted if it's forward .PERIOD so those are the basic methods in the api for a flow edge and ,COMMA and the implementation of all of them is straightforward .PERIOD so notice that one thing that's a little different from many othe ,COMMA you know ,COMMA classes is that actually the goal of our computation is to fill in these values flow .PERIOD so ,COMMA they're not final variables that's what we're computing .PERIOD now .PERIOD we do it through addresidualflow but still it's not a final .PERIOD so ,COMMA create an edge ,COMMA just with a v to w given capacity ,COMMA just fill in the instance variables and all these other ones are just getters .PERIOD others just like in an undirected graph .PERIOD and then ,COMMA residualcapacity and addresidualflow are also easy to implement .PERIOD so ,COMMA residualcapacity if it's on the from edge ,COMMA you return the flow ,COMMA if it's on the to edge or it's the backward edge ,COMMA you return capacity minus flow ,COMMA just as we said .PERIOD and addresidualflow makes the same test to decide whether to add or subtract the flow .PERIOD so very simple implementations of all those operations for our flow edges in a flow network .PERIOD so ,COMMA what about the floor network ,COMMA api ?QUESTIONMARK it's again going to be our standard api ,COMMA just that floor graph ,COMMA flow networks are built from flow edges .PERIOD and they're going to be built for the client which is going to be the max flow algorithm .PERIOD it's going to have a method that gives an interval for every vertex of all the forward and backward edges instant on that vertex and sh ,COMMA so that client is going to use these basic things .PERIOD and given everything we've seen this implementation is pretty straightforward .PERIOD it's pretty much just like edge -DASH weighted graph ,COMMA except we use low edges now .PERIOD and then ,COMMA when we add an edge even though it's kind of a directed network to handle flow and forward and backward edges ,COMMA we add every edge to both adjacency lists .PERIOD but simple code ,COMMA quite similar to what we've seen before .PERIOD so we'll ,COMMA again network is usually huge and sparse .PERIOD so ,COMMA we use a vertex index array and each entry associated with each vertex will contain references to all the edges that are incident on that vertex whether they're forward or backwards .PERIOD so ,COMMA just like an un -DASH directed graph ,COMMA you might have to ,COMMA you'll have two references to the same edge .PERIOD one and it's a from and the other and it's to and then rather than just to wait ,COMMA they have a flow and a capacity .PERIOD so from zero to two ,COMMA it's got capacity three and one unit of flow in it .PERIOD so ,COMMA that's an example of ,COMMA of how to represent that edge .PERIOD so ,COMMA flow network has got flows in it ,COMMA that's the grey and it's got capacities ,COMMA and that's the white .PERIOD and otherwise ,COMMA it's kind of similar to our undirected graph representation .PERIOD i've got one more processing ,COMMA the ,COMMA ,COMMA processing the graph .PERIOD we use residualcapacity to make that kind of work in the residual path in natural way .PERIOD so ,COMMA this is the implementation of the forward focus in algorithm .PERIOD and again h ,COMMA pretty straightforward to given the description that we've done ,COMMA and the graph processing code that we've written up to this time .PERIOD so it's got you have an array of vertices that we've been to .PERIOD it's got an edge two array which is the how do we get to each vertex so we can provide the client with the flow so that we can process paths in the graph you know ,COMMA it's got the value of the flow .PERIOD so ,COMMA let's look at the code ,COMMA it's kind of self -DASH documenting .PERIOD so what we'll do is we'll set the value of the flow to zero .PERIOD so we're going to find out if it has a augmenting path and we'll look at that method in a minute .PERIOD as long as it has an augmenting path then when we call ,COMMA it has augmenting path ,COMMA basically what that's going to do is that's going to do a graph search and mark the verticies that it visits and if it gets to this target ,COMMA it's going to leave that path and now the edge to array in the standard way .PERIOD the edge to of t contains the ,COMMA the edge that ,COMMA that contains the vertex that took us to t and so forth .PERIOD and so we'll use that edge to ,COMMA to go back through the path and to figure out the bottleneck capacity ,COMMA which is the minimum of the bottleneck capacity and the residual capacity in the high edge that we're processing .PERIOD so that's the ,COMMA the maximum amount of flow that we can push through the network does go through the path and find the minimum of either the unused capacity in some forward edge or the available flow in some backward edge .PERIOD so once we have the bottleneck capacity ,COMMA then we just go back through the path again and addresidualflow to every edge in that path .PERIOD so that's augment the flow .PERIOD and then ,COMMA once we've augment the flow ,COMMA then we update the value .PERIOD notice that ,COMMA when this terminates it terminated because we couldn't find an augmenting path ,COMMA and we couldn't find an augmenting path meant that ,COMMA essentially ,COMMA we did a graph search that got stuck with finding all full -DASH forward edges or empty backward edges before getting to the target and that's precisely the computation that we needed to do to compute the cut .PERIOD so to tell whether a vertex is reachable from s .PERIOD we just checkmarked v so we can tell the client which vertices are in the cut .PERIOD and then we can find the ,COMMA the edges that leave that vertex with the edges that comprise the cut .PERIOD so now ,COMMA all we have to do to finish is to look that it has augmenting path ,COMMA which is the graph search in the residual network .PERIOD and for this example we'll use breadth -DASH first search although the other search algorithms that we've studied can be adapted in the same way depth -DASH first search or using a priority queue as in prim's algorithm or dijkstra's algorithm .PERIOD so we have our standard edge to in marked arrays and so we already have a queue which is going to contain the vertices that we've encountered but not yet visited .PERIOD we'll put the source on there while the queue is not empty ,COMMA we'll take a vertex off .PERIOD and so ,COMMA we'll go through everybody associated that's connected to that vertex ,COMMA that's a flow edge .PERIOD and then ,COMMA you check the residual capacity .PERIOD and if ,COMMA if it's bigger than zero that means h ,COMMA you have a way to get to w ,COMMA and if it's not marked ,COMMA you haven't been there yet then you go ahead and go there and mark it .PERIOD it's essentially a breadth -DASH first search .PERIOD so that's the code for has augmenting path .PERIOD and that essentially completes the implementation of breadth -DASH first search .PERIOD and mark t tells the ,COMMA tells the returns true or false .PERIOD if you can get from t to s after that search is gone ,COMMA then t will be marked ,COMMA and you can return true .PERIOD this method can return true .PERIOD that's a java implementation of the max flow .PERIOD 
finally ,COMMA we talk about stability .PERIOD this is really one of the rules of the game but it's much easier to talk about in the context of the real algorithms that we've seen so far .PERIOD and really it doesn't make sense if you don't know about comparators which we just introduced .PERIOD so ,COMMA the typical application that i just used as an example is say the set of student records .PERIOD so we have them sorted by name and this is say ,COMMA something that we do just before assigning final grades .PERIOD maybe the third line there is the final grade .PERIOD so it's all fine sorted by name and but then in order to distribute it out to the people leading it to the sections ,COMMA what we want to do is sort by the second fields ,COMMA sort by section .PERIOD the problem is that when we do that ,COMMA it messes up the sort by name and that's annoying .PERIOD you might assume that once you have it sorted by name ,COMMA then when you sorted by the second field then it should maintain the sort of by name for all that have equal keys in that second field .PERIOD actually not all sorts preserve that property that is called stability .PERIOD and clearly ,COMMA it's worthwhile to think about for your application whether you want or need a stable sort .PERIOD and so ,COMMA it's an annoying surprise for many people and many applications .PERIOD so a stable sort is a sort that preserves the relative order of items with equal keys .PERIOD whichever sort are stable ?QUESTIONMARK that's an interesting question that we'll take a look at now .PERIOD the quick bottom line is that insertion sort and mergesort are stable but not selection sort or shellsort .PERIOD and even within that bottom line ,COMMA there's implementations that maybe are not stable .PERIOD you have to carefully check the code to be sure .PERIOD always ,COMMA in this class ,COMMA we have an exercise or exam question is this version of this sort stable or not ?QUESTIONMARK so ,COMMA students learn to recognize whether the code is stable .PERIOD so this is just another typical example where we've got things sorted by time ,COMMA and then what we want to do is maybe these are important events .PERIOD people buying tickets to a rock concert and i'm going to sort by location what we'd hope is that it would keep the sort by time but this is a non -DASH stable sort that doesn't do bad so then out in the location they're going to have to resort it if they use one of these .PERIOD but if they use a stable sort ,COMMA then it stay sorted by time and lots of applications you want stability .PERIOD alright ,COMMA so let's just look at each of the algorithms that we've considered so far .PERIOD insertion sort .PERIOD insertion sort is stable .PERIOD why is it stable ?QUESTIONMARK well ,COMMA we never move equal items pass one another .PERIOD in this example here ,COMMA when we get a1 ,COMMA well that's so in this case ,COMMA the index is just one that appears in the array ,COMMA it's just a's and b's .PERIOD when we get our second a ,COMMA we stop the sort as long as we're not less .PERIOD we're equal ,COMMA we're not less ,COMMA we stop it so we never move an equal item pass another one .PERIOD if this less or less than or equal ,COMMA then it wouldn't work .PERIOD or if we did the other way around and proceeded accordingly .PERIOD so ,COMMA equal items never move past each other in this code so therefore insertion sort is stable .PERIOD but selection sort is not stable .PERIOD usually way ,COMMA the way to show that a sort is not stable and it's just to see if it has a long distance exchange that might move an item pass some equal item .PERIOD so ,COMMA [cough] in this case ,COMMA for example ,COMMA for selection sort ,COMMA when we do that first exchange oops ,COMMA [cough] where we found the minimum a and b is in position zero .PERIOD we did a long distance exchange and that catapulted that first item past any item that it might be equal putting them out of order .PERIOD and that's may not get fixed so that sort is not stable .PERIOD it might move items past some equal item and leave a result where items that are equal or in different order than they were originally in the file .PERIOD selection sort is not stable .PERIOD shellsort also has long distance exchange and so it's not stable .PERIOD it moves keys past other keys that could be equal and so its easy to construct examples showing that selection sort is not stable .PERIOD and what about mergesort ?QUESTIONMARK mergesort is stable well ,COMMA it's stable as long as the merge operation is stable and that operation is going to be stable depending on how we code it .PERIOD and ,COMMA and in our code ,COMMA if the two keys are equal ,COMMA it takes from the left subarray so that means that ,COMMA it will always take the ,COMMA if there's a two sets of equal keys ,COMMA it will preserve the relative order and that's enough to show that the merge operation is stable and then therefore mergesort is stable .PERIOD stability is an important property in sorting algorithms .PERIOD mergesort is not only efficient ,COMMA it's also 
let's finish up by looking at some applications of maxflow like shortest paths maxflow is a very widely -DASH applicable problem solving model .PERIOD and it is really important to recognize at this stage ,COMMA we've looked at a lot of algorithms for solving specific problems .PERIOD and they're important problems .PERIOD and it's important to have efficient algorithms for solving them .PERIOD but when you have something like maxflow or shortest paths the ,COMMA the importance that we attach to them is really magnified by the idea that they have this property that ,COMMA that they're a very general way to state a problem and we have many ,COMMA many practical situations that we can cast in terms of these problems .PERIOD we looked at arbitrage coming or reducing down to a shortest paths problem .PERIOD and we'll look at a bunch of problems that don't seem to be related at all ,COMMA that can be modeled as maxflow problems .PERIOD so ,COMMA they're extremely important because they're problem solving models that work for a broad variety of important applications .PERIOD number one that wouldn't be any good if we didn't have efficient algorithms for solving them .PERIOD but we do have efficient algorithms for solving them .PERIOD and so ,COMMA that magnifies their importance .PERIOD and that's why people work so hard on finding efficient algorithms for solving these problems .PERIOD and we'll talk about that as well in a minute .PERIOD so ,COMMA these are ,COMMA again ,COMMA just a few of the many ,COMMA many algorithms applications of maxflow we saw an image processing algorithm called syncarving for shortest path .PERIOD there's another one called segmentation for maxflow .PERIOD again ,COMMA if you have an image and you have one vertex per pixel you have a huge ,COMMA huge graph .PERIOD and you have many explicit huge graphs and we've talked about those types of things .PERIOD but there are other things where the graph is ,COMMA is an abstraction that it gets involved in a model of the abstract graph and the maxflow problem .PERIOD its maybe a bit surprising at first ,COMMA and we'll look at a couple examples of that to illustrate the point .PERIOD over here is a medical example having to do with it .PERIOD that's the ,COMMA the image processing one on a medical example to help identify some important part of a medical image .PERIOD so ,COMMA we'll look at a ,COMMA at a couple examples to that the idea of a general problem solving model that ,COMMA once we have an efficient algorithm ,COMMA then we can think about using the problem solving model .PERIOD and later on ,COMMA we'll see that this ,COMMA this concept of a general problem solving model has really profound implications and we'll be looking at that later on .PERIOD so ,COMMA let's just look at a ,COMMA at a couple of examples .PERIOD here's one called the bipartite matching problem .PERIOD so you have this is a bit of an idealized situation .PERIOD but it works in more messy ,COMMA real life situations ,COMMA too .PERIOD so ,COMMA there's n jobs out there and n students apply for them .PERIOD and we'll use a small example where there's five students and five jobs .PERIOD but ,COMMA of course ,COMMA in the real world ,COMMA this can be huge .PERIOD now during hiring season ,COMMA the students go out and apply for the jobs and they each get a bunch of offers .PERIOD so looking at it from a student's point of view .PERIOD alice gets offers from adobe ,COMMA amazon ,COMMA and google .PERIOD adobe makes offers to alice ,COMMA bob ,COMMA and carol ,COMMA and like that .PERIOD so ,COMMA this is an association between students and jobs .PERIOD everybody gets several offers .PERIOD and in question is well ,COMMA it would be good if everybody got a job ,COMMA right ?QUESTIONMARK and the question is ,COMMA is there some way for everybody to get a job .PERIOD that's called the bipartite matching problem .PERIOD and it comes up in lots of forms directly related to graph processing .PERIOD now ,COMMA we could study and people do study algorithms for explicitly solving this particular problem .PERIOD but what i want to emphasize is that actually ,COMMA maxflow is a reasonable model for it .PERIOD so ,COMMA we can use our efficient maxflow implementation to get it solved .PERIOD we don't have to come up with a specialized algorithm for this problem .PERIOD so ,COMMA in terms of graphs ,COMMA it's called the bipartite matching problem ,COMMA given a bipartite graph ,COMMA find a perfect matching .PERIOD and a bipartite graph is one where you have two sets of vertices ,COMMA in this case ,COMMA one to corresponding to students and another corresponding to companies .PERIOD and you have every edge in the graph goes from one type of vertex to other ,COMMA the other type of vertex .PERIOD and a matching in the graph is a set of edges that are disjoint that disconnects two vertices but that's it .PERIOD and so ,COMMA in this case ,COMMA there's a perfect matching works out that if alice takes the google job and bob takes the adobe job and carol takes the facebook job and like that ,COMMA then everybody gets a job .PERIOD so ,COMMA that's a perfect matching .PERIOD but you can also have a situation where that's not possible .PERIOD so let's look at how to formulate ,COMMA how to ,COMMA well ,COMMA the one thing is ,COMMA how do we find the matching ?QUESTIONMARK and then the other thing is ,COMMA is there one ?QUESTIONMARK so this is easy to formulate as a matching network flow problem .PERIOD that's what this diagram shows .PERIOD so ,COMMA what we'll do is we'll create our source and target vertices .PERIOD we'll have one vertex for each student .PERIOD one vertex for each company in the flow network .PERIOD and we'll add a capacity one edge from s to each student .PERIOD and a capacity one edge from t to from each company to t and then it doesn't matter what the capacity .PERIOD we'll add an infinite capacity edge from each student to each job offer .PERIOD and then ,COMMA we'll ask for a maximum flow in this graph .PERIOD so ,COMMA you can see that the flow ,COMMA every augmenting path has to go from s to a student to a company to t and so ,COMMA the flow will give us the match and let's see how it works .PERIOD this is a ,COMMA a one to one correspondence between perfect matchings and bipartite graphs ,COMMA and integer value maxflows .PERIOD so ,COMMA in this case ,COMMA there's a flow of value five .PERIOD and that flow gives us the matching immediately .PERIOD so what the mean cut tells us if ,COMMA if there's a no perfect matching ,COMMA explain why .PERIOD so ,COMMA here's an example that maybe could have happened with the job offers .PERIOD and when the we're algorithm terminates it terminates with a cut we're the ,COMMA a cut of the bipartite graph ,COMMA which separates two ,COMMA four ,COMMA and five from seven and ten .PERIOD and essentially the cut tells us that students in two ,COMMA four ,COMMA or five can only be matched to companies seven and ten .PERIOD you could see all the edges from two ,COMMA four ,COMMA five go to seven and ten ,COMMA so you have two companies and three students .PERIOD so ,COMMA there's no way that everybody can be matched ,COMMA somebody's gonna be left out .PERIOD so that's a the students ,COMMA so that they'll be a mean cut ,COMMA and the s will be the students on the s side and t will be the companies on the s side and if it's bigger than ,COMMA s is bigger than t ,COMMA then i can't have a matching .PERIOD so in this case at ,COMMA there's only ,COMMA four jobs and somebody is going to be left out .PERIOD it's also interesting to trace through what happens with the maxflow algorithm on bipartite graphs like this .PERIOD essentially augmenting paths or usually forward edges makes some matching .PERIOD and then if it's possible to find a path that undoes some matching .PERIOD it ,COMMA zig zags through ,COMMA undoing matching and trying other ones to find a way through to the target .PERIOD but if there's no perfect matching ,COMMA there'll be a mean cut .PERIOD and that one will explain why .PERIOD so ,COMMA that's a problem ,COMMA the bipartite matching problem that we can model as a maxflow algorithm and just use our existing code to solve it .PERIOD here's another one that's even further away .PERIOD it doesn't seem to have a graph at all ,COMMA but it does .PERIOD it's called the baseball elimination problem .PERIOD in this is again ,COMMA just to show the breadth of applicability of the maxflow model .PERIOD it's interesting at certain times of year ,COMMA you get near the of the baseball season and often you'll hear in the news ,COMMA or see in the paper ,COMMA or see in the web ,COMMA that your team is mathematically eliminated .PERIOD actually most of the time ,COMMA they don't really get that right because they don't do the computation that we're going to talk about next .PERIOD sometimes ,COMMA it's easy this is an example where it's easy .PERIOD so we've got four teams ,COMMA they already have this win -DASH loss record and this is the number of games to play .PERIOD so in this case montreal has only three games to play .PERIOD so the best they could do is win 80 .PERIOD ag ,COMMA but atlanta has already got 83 wins so there's no way montreal is going to win .PERIOD so ,COMMA that's a mathematical elimination that anyone could figure out .PERIOD usually the newspaper will get that one right .PERIOD so but sometimes it's more complicated if you look ,COMMA say ,COMMA this case .PERIOD so philly has 80 wins ,COMMA three games to play .PERIOD so the best they can do is 83 wins .PERIOD so that's interesting .PERIOD but the thing is that atlanta has a bunch of games against ,COMMA it's got six games against the mets .PERIOD and either atlanta wins one of them ,COMMA which would give atlanta 84 wins ,COMMA or the mets win all of them ,COMMA in which case ,COMMA they get 84 wins .PERIOD either way ,COMMA philadelphia is mathematically eliminated .PERIOD that's a bit more complicated decision about which team wins .PERIOD the thing is and there's many more complicated situations that show up .PERIOD and the observation ,COMMA just from these two easy examples ,COMMA is that you can't figure out who's mathematically eliminated without knowing the full schedule of games .PERIOD it depends ,COMMA not only on how many games were already won ,COMMA how many are left to play ,COMMA but it depends on the schedule and who's playing who .PERIOD and usually ,COMMA your average sportswriter is not going to do that computation without a computer .PERIOD and i hope that one of you becomes a sportswriter and puts this in for the future for us .PERIOD so let's look at a more complicated situation .PERIOD so this is the american league east awhile ago near the end of the season .PERIOD and question is which teams are mathematically eliminated and which ones aren't .PERIOD now in this case it turn's out that the ,COMMA this is pretty far from the end of the season actually .PERIOD these 27 games to finish .PERIOD and this is a proof here that detroit is mathematically eliminated .PERIOD but it's a pretty complicated argument and well ,COMMA you can ,COMMA you can reason it out with arithmetic .PERIOD the tough part is to figure out this set of teams here are .PERIOD so what we're going to see is that you can do a maxflow computation to figure out this sets of teams .PERIOD and this ,COMMA let's just look at it for this example .PERIOD so ,COMMA at this point ,COMMA detroit is mathematically eliminated .PERIOD and so it's got 27 games to play ,COMMA so it could in theory ,COMMA win 76 of the games .PERIOD now but the logic that will convince you that they are eliminated is that if you take the four teams the other four teams and add up all their wins there's 278 of them .PERIOD and you look at the remaining games there's 27 .PERIOD so somebody's gotta win every one of those games .PERIOD the total number of games won for that set of the teams is 305 ,COMMA and if you divide by four .PERIOD it means the average is 76 .PERIOD25 .PERIOD and right there is a proof that one of them is got to win 77 games .PERIOD that takes a little thought ,COMMA but if you have the four teams ,COMMA then from the remaining games ,COMMA you can figure out that detroit is mathematically eliminated .PERIOD but the key is ,COMMA how do we find those four teams .PERIOD and the answer ,COMMA as i've already said ,COMMA is it's maxflow .PERIOD and so this is a maxflow network that can be used to solve the baseball elimination problem .PERIOD so the intuition is that ,COMMA that you have a source vertex and you have what happens in the remaining games flowing from the source to the target .PERIOD so here we're trying to prove that team four is we're trying to decide if team four is eliminated or not .PERIOD that's detroit ,COMMA in this case .PERIOD and so ,COMMA what we need is a vertex for each pair of vertices that are not the team we're interested in .PERIOD and so ,COMMA that's going to relate to all the remaining games because these are the pairs of teams .PERIOD and then you have an edge from the source to each one of those vertices .PERIOD and the capacity of the edge is the number of games left between those two .PERIOD so that's on one end .PERIOD and then ,COMMA you have a vertex for each team .PERIOD and then what we do for each one of these pair of vertices ,COMMA we put infinite capacity edges to the two teams involved .PERIOD so ,COMMA the flow is going to be an integer flow ,COMMA so some of it will go one way and some of it will go the ,COMMA the other way .PERIOD but then ,COMMA for each of the teams what we're going to do is ,COMMA make sure that they don't win more games than team four ,COMMA the team we're interested in .PERIOD so ,COMMA we'll put this upper bound on the flow here that we won't let the numbers of wins get better than what our team of interest ,COMMA team four can do .PERIOD and the fact is that if you compute a maxflow of this you can convince yourself ,COMMA that if you can fill this network up going ,COMMA going from s in ,COMMA in the maxflow then team four ,COMMA team four is not going to be eliminated .PERIOD nobody's going to get more wins than team four .PERIOD and so the way to solve the baseball elimination problem is to run maxflow on this network ,COMMA and the mean cut will give the set of keys ,COMMA it's our ,COMMA mean cut will give the set of teams that you needed in this calculation to figure out to prove to a friend that ,COMMA or to a sportswriter that the team you're interested in is ,COMMA is eliminated .PERIOD an interesting application of maxflow .PERIOD again ,COMMA we just take our problem ,COMMA use it to build a network solve the problem on the network using our existing code and translate that solution to a solution to our original problem .PERIOD that's called reduction and it's a very important technique that we're going to use we're going to talk about it in some detail later on .PERIOD so now we come to the theory of maxflow algorithms .PERIOD this is  ,COMMA ,COMMA an even hotter area than minimum spanning tree and shortest paths that we've looked at before and that it's a very frustrating situation for theoretical computer scientists .PERIOD and that we have this relatively straightforward to state algorithm and we have this all ,COMMA this design freedom ,COMMA forward focus in algorithm .PERIOD there's lots and lots of ways that we could try to find augmenting paths and there's even other methods that don't use forward focus and that are almost as simple .PERIOD and the question is ,COMMA how difficult is it to solve the maxflow problem ?QUESTIONMARK and there's literally hundreds of papers in the scientific literature that are oriented at trying to solve this problem .PERIOD now ,COMMA again the ,COMMA the theoretical computer scientists are trying to find an algorithm that's guaranteed to work well in the worst case .PERIOD so ,COMMA they're just counting the number of edges that the algorithms examine in the worst case .PERIOD but when related to practical graphs these are very ,COMMA very conservative upper bounds .PERIOD and the real performance is going to be totally different .PERIOD so ,COMMA you can't use these to compare the performance of a given algorithm .PERIOD the performance of a given algorithm really depends on the characteristic of networks .PERIOD but still ,COMMA there's a huge gap between the best algorithms that we know .PERIOD in a most recent one was discovered just this ,COMMA this year that can guarantee e squared over log e ,COMMA number of edges examined to try to find maxflow .PERIOD and so ,COMMA that's fine but there's a huge gap between ,COMMA and very small compared to say ,COMMA shortest augmenting path which is e cubed essentially .PERIOD and that's ,COMMA that's fine ,COMMA but actually in practice ,COMMA the running time of many of the algorithms seems to be relatively small factor of e ,COMMA and no one can prove that there might not exist an algorithm ,COMMA or no one has proved yet ,COMMA that there might not exist an algorithm that gets the job done in linear time .PERIOD so one of the exciting things about studying the field of algorithms is there's still room to find ,COMMA to discover interesting and innovative algorithms that could have a huge practical impact .PERIOD because we have algorithms that won't run well on practical networks .PERIOD lots and lots of important practical applications use them .PERIOD and if someone ,COMMA someone or discovered ,COMMA to discover a fast ,COMMA practical ,COMMA guaranteed linear time algorithm ,COMMA it would immediately have huge impact .PERIOD so that's the first warning was worst case order of growth .PERIOD you're not going to compare algorithms in practice .PERIOD and there's plenty of research papers out there that have done empirical studies on the maxflow algorithms for realistic networks in the so -DASH called ath ,COMMA best so far in practice is known as the push -DASH relabel method with gap relabeling ,COMMA which runs in time e square v ,COMMA where e is the number of edges .PERIOD and ,COMMA again ,COMMA even that in practical networks is going to run faster than that .PERIOD so ,COMMA there's numerous research challenges still to be addressed in studying the maxflow problem .PERIOD there's plenty of practitioners that are using the codes like the one's that we've shown and ,COMMA and variations to try to solve a huge real maxflow mincut problems and trying to get them done in linear time .PERIOD there's many theoretical computer scientist that are trying to prove that there exists or not exists ,COMMA a maxflow algorithm that is guaranteed to run in linear time ,COMMA no matter what the input .PERIOD there's many ,COMMA many people doing and there's still a great deal to be learned .PERIOD it's a fine example of why it's exciting to be working in the field of algorithms .PERIOD there's ,COMMA an opportunity for new knowledge still available and many people are still working on them .PERIOD 
welcome back .PERIOD today we're going to look at quicksort .PERIOD it was named as one of the most important algorithms of the twentieth century and it's widely used for system sorts and many other applications .PERIOD last lecture ,COMMA we looked at mergesort ,COMMA another classic sorting algorithm ,COMMA that's used in many systems ,COMMA and today we are looking at quicksort which is used in many others .PERIOD you can even get a quicksort t -DASH shirt nowadays .PERIOD so what is the quicksort method ?QUESTIONMARK it's also a recursive method ,COMMA but the basic idea behind quicksort is that it does the recursion after it does the work ,COMMA whereas mergesort did it before it did the work .PERIOD so ,COMMA the idea is first randomly shuffle the array .PERIOD that's an important step that we'll talk about later ,COMMA and then partition the array ,COMMA so that's to divide it so that for sum value j the entry a of j is in place in the array .PERIOD there's no larger entry to the left of j and no smaller entry to the right of j .PERIOD once we have the array partitioned in that way ,COMMA shown here in the middle .PERIOD right here ,COMMA we have k in its position .PERIOD and we have everybody to the left .PERIOD there's nobody greater than k .PERIOD and everybody to the right ,COMMA there's nobody less .PERIOD once we have it arranged in that way ,COMMA then we recursively sort the two parts .PERIOD sort the left part ,COMMA sort the right part .PERIOD and then after those two things are done ,COMMA the whole thing is sorted .PERIOD this method was invented in 1961 by tony hore ,COMMA who won the turing award in 1980 for this and other work .PERIOD so let's look at a demo of how quicksort partitioning works .PERIOD the idea is to arbitrarily choose the first element to be the partitioning element .PERIOD since we shuffled the array ,COMMA that's our random element from the array .PERIOD and then we're going to maintain an i pointer that moves from left to right ,COMMA and a j pointer that moves from right to left .PERIOD let's look how it works in the demo .PERIOD so we start again by picking k as the partitioning element .PERIOD and then our method is to move the i pointer from left to right .PERIOD as long as what we have is less than the partitioning element .PERIOD and move the j pointer from right to left as long as it points to an item that's greater than the partitioning element .PERIOD so ,COMMA in this example the i pointer stops right away because it's pointing to an r which is bigger than the partitioning element .PERIOD the j pointer decrements until it gets to the c which it stops there which is less than the partitioning element .PERIOD and so now what's going to happen is those two elements are out of place .PERIOD the partitioning elements in between them and they're in the wrong order .PERIOD so what we want to do is exchange those .PERIOD and then move on .PERIOD now we increment i ,COMMA as long as it's pointing to an element that's less than the partitioning element .PERIOD stop here at t cuz that's bigger .PERIOD and now we decrement j ,COMMA as long as it's pointing to something that's bigger than the partitioning element .PERIOD stop her at i because that's less .PERIOD again ,COMMA t and i are in the wrong places .PERIOD if we exchange them ,COMMA we'll maintain the invariant that everything to the left of i is less than the partitioning element ,COMMA or nothing to the left of i is greater than the partitioning element ,COMMA and nothing to the right of j is less than the partitioning element .PERIOD so exchange increment i as long as it's less .PERIOD stop at l increment j decrement j as long as it's greater .PERIOD stop at e those two elements are out of position so exchange them .PERIOD now increment i ,COMMA stop at the l which is greater than k decrement j stop at the e which is less than k and now at this point the partitioning process is complete ,COMMA coomplete cause the pointers have crossed and we have looked at everything in the array .PERIOD in fact .PERIOD j points to the ,COMMA rightmost element in the left subfiles ,COMMA everything that's not greater than k .PERIOD so we can just exchange j with our partitioning element .PERIOD and now we've achieved the goal of partitioning the array .PERIOD so that a of j is in its position .PERIOD nobody to the left is greater .PERIOD nobody to the right is less .PERIOD now ,COMMA the code for partitioning is straight forward to implement .PERIOD down below .PERIOD shows the state of the array before partitioning .PERIOD during and after partitioning .PERIOD so in the end ,COMMA the j pointer is pointing to the partitioning element v ,COMMA which was in position v in the first place .PERIOD in the ,COMMA all during the partitioning process ,COMMA the code is maintaining this invariant .PERIOD where everything to the left of i is less than or equal to v .PERIOD everything to the right of j is greater than or equal to v .PERIOD and we haven't looked at things in between .PERIOD so ,COMMA finding ,COMMA incrementing i ,COMMA as long as it's less is a simple while loop .PERIOD and then we put a test to make sure we don't run off the right end of the array .PERIOD and decrementing j .PERIOD as long as it's pointing to a bigger element that's similarly just a wide loop we put in to test to make sure we don't run off the left end of the array .PERIOD then there's a test to see if the pointers cross .PERIOD swap the elements of i and j .PERIOD when we get to the pointers cross we break out of the loop and exchange the partitioning element into position .PERIOD so that's a quick implementation of the quicksort partitioning method .PERIOD now ,COMMA quicksort itself then is going to be a recursive program that uses that partitioning method .PERIOD first thing we do is the public sort method that takes the array of comparable items as its argument .PERIOD it's gonna to do a shuffle .PERIOD and that shuffle is needed to make sure that we can guarantee that the performance is gonna be good .PERIOD and then it calls the recursive method that takes as arguments the limits of the subarray that's gonna be sorted .PERIOD so then partitioning .PERIOD simply does the partitioning .PERIOD tells us where ,COMMA which element is in position ,COMMA and then recursively sorts the last part that's loaded ,COMMA j  -DASH one .PERIOD and then the right part ,COMMA that's j + one to high .PERIOD that's a complete implementation of quicksort .PERIOD again ,COMMA as with mergesort ,COMMA studying a recursive trace is instructive .PERIOD and this one is kind of upside down as compared to mergesort .PERIOD the first line shows the partitioning where k is put into position .PERIOD then the method calls the sort for the left subfile first ,COMMA and then that's gonna be partitioned on this e ,COMMA and so forth .PERIOD and eventually we get down to small subfiles ,COMMA actually our code doesn't do anything at all for subarrays of size one ,COMMA so we just leave those in gray ,COMMA and then it does the right subfile ,COMMA and so forth .PERIOD again ,COMMA studying this ,COMMA a ,COMMA a trace like this ,COMMA gives a ,COMMA a good feeling for exactly what's going on in the recursive program .PERIOD let's look at an animation of quicksort in operation .PERIOD there's the partition .PERIOD now it's working on the left .PERIOD now it's partitioning the right .PERIOD now it's working on the left part of the right .PERIOD now it's partitioning what's left .PERIOD doing the left part of that .PERIOD and working from left to right ,COMMA by dividing each sub -DASH array in half as it goes .PERIOD so let's look .PERIOD consider some of the details in implementation of partitioning with quick sort .PERIOD so first thing is the partition is in place .PERIOD you could use an extra array and the partitioning code would be a little bit easier .PERIOD but one of the big advantages of quicksort over mergesort is that it doesn't take any extra space .PERIOD it gets the sort done in place .PERIOD now you have to be a little bit careful with terminating the loop .PERIOD when we give you working code it's not hard to see why it works .PERIOD and you might go trough the exercise of trying to implement quicksort without looking at our code ,COMMA and you'll find that testing when the pointers cross can be a little bit tricky ,COMMA particulary in the presence of duplicate keys .PERIOD also staying in bounds .PERIOD and i ,COMMA actually ,COMMA in our implementation the test of the j pointer running off the left end is redundant .PERIOD why is it redundant ?QUESTIONMARK well ,COMMA the partitioning element is sitting there and it'll stop when it hits the partitioning element .PERIOD but the other test is not in our implementation .PERIOD and the key thing ,COMMA one key thing is that the way that these implementations work .PERIOD if the in -DASH  ,COMMA the file is ,COMMA the array is randomly ordered ,COMMA then the two sub -DASH arrays after partitioning will also be randomly ordered .PERIOD actually ,COMMA some implementations of quick sort out in the wild don't have this property ,COMMA and they suffer a little bit in performance .PERIOD that random shuffle at the beginning is important and needed for guaranteeing performance .PERIOD and the other thing i have referred to but not talked about in detail is the presence of equal keys .PERIOD you might think it would be better to handle equal keys in some special way .PERIOD we'll talk about that in a second .PERIOD but this general purpose implementation stops the pointers on keys equal to the partitioning items key and we'll take a look at why that's important in a minute .PERIOD so now let's look at the running time estimates about why we care about quicksort vs mergesort .PERIOD this is extending the table we looked at last time ,COMMA and you can see over in the right column here ,COMMA quicksort is quite a bit faster than mergesort .PERIOD and again ,COMMA a good algorithm is much better than having a super computer .PERIOD even on your pc you can sort huge array of a million items in less then a second and a million items in only a few minutes .PERIOD so again this time ,COMMA sort of timing is why quicksort is so widely used .PERIOD cuz it's simply just faster than mergesort .PERIOD well in the best case quick sort will divide everything exactly in half .PERIOD and that makes it kind of like merge sort .PERIOD it's about analog in .PERIOD and in the worst case if the random shuffle winds up putting the items exactly in order ,COMMA then partitioning doesn't ,COMMA doesn't really do anything except find the smallest ,COMMA peel off the smallest item .PERIOD kind of discover that everything to the right is greater .PERIOD that's a bad case .PERIOD but if we shuffled randomly ,COMMA it's extremely unlikely to happen .PERIOD most interesting thing about the study of quicksort is the average case analysis .PERIOD this is a somewhat detailed mathematical derivation ,COMMA but it is worthwhile going through the steps ,COMMA to really get a feeling for why it is that ,COMMA quicksort is quick .PERIOD so what we do is ,COMMA as we did for merge sort ,COMMA is write down a mathematical recurrence relation that corresponds to what the program does .PERIOD in the case of quick sort ,COMMA the number of comparisons taken to sort n items is n+1 for the partitioning .PERIOD plus what happens next depends on what the partitioning element was .PERIOD if the partitioning element is k .PERIOD any particular value happens with probability one over n ,COMMA and if it's k ,COMMA then the left subfile has k  -DASH  one items in it ,COMMA and the right subfile has n  -DASH  k items in it .PERIOD so ,COMMA for every value of k ,COMMA if you add those up the probability that the partitioning element is k ,COMMA plus the cost for the two subfiles ,COMMA we get this equation .PERIOD this looks like a fairly daunting equation ,COMMA but actually it's not too difficult to solve .PERIOD first thing we do is just multiply by n and collect terms .PERIOD so ncn n times n + one .PERIOD and then these terms ,COMMA every size appears twice .PERIOD so it's twice the sum of from c0 to cn  -DASH  one .PERIOD it's a simpler equation already .PERIOD now what we can do is get rid of that sum by subtracting the same equation for n minus one .PERIOD so ncn  -DASH  n  -DASH  one ,COMMA cn  -DASH  one then the n ,COMMA n + one  -DASH  n  -DASH  one n is just 2n .PERIOD and then the sum collapses just leaving the last term .PERIOD this sum ,COMMA minus the same sum for n  -DASH  one ,COMMA just leaves the 2cn  -DASH  one .PERIOD now that's looking like a much simpler equation .PERIOD rearrange the terms ,COMMA so we get n+1 cn -DASH 1 and then divided by n ,COMMA n+1 .PERIOD that's a kind of a magic step ,COMMA but we will see that it makes possible to solve the equation easily .PERIOD because that equation ,COMMA with c over n plus one equals cn minus one over n ,COMMA is an equation that telescopes the first term at the right .PERIOD it's the same as the term on the left .PERIOD so we can apply the same equation so its two over n + one .PERIOD we apply for n  -DASH  one we get one less here and we can throw out a lot two over n .PERIOD and continue that way throwing out two over decreasing numbers all the way down until we get down to two elements ,COMMA c1 which is zero .PERIOD substitute the previous equation telescope .PERIOD and then that gives us an easy sum that we can approximate by an integral .PERIOD it's one over x from three to n+1 .PERIOD and that's a pretty close approximation ,COMMA in this case .PERIOD and that approximation gives us ,COMMA it's about two m+1 natural log n comparisons for quicksort .PERIOD about 1 .PERIOD39 n log n .PERIOD that's the average number of comparisons taken by quicksort ,COMMA and actually they for a random permutation of the elements which is what we do with the shuffle .PERIOD they the expected number of comparisons is concentrated around this value .PERIOD it's very likely to be very near this value is then as large .PERIOD so the worst case quick sort is quadratic .PERIOD so complexity's going to tell us that it's a quadratic algorithm if that's what its worst case is .PERIOD but with random ,COMMA the random shuffle it's more likely that this lecture will end ,COMMA because of a lightning strike .PERIOD or your computer will be struck by a lightning bolt .PERIOD so we can discount that .PERIOD the average case ,COMMA which is extremely likely for any practical application ,COMMA is going to be about 1 .PERIOD39 n log n .PERIOD so that's more compares than mergesort uses .PERIOD but quicksort is much faster ,COMMA because it doesn't do much corresponding to each compare .PERIOD it just does the compare and increment a pointer .PERIOD whereas ,COMMA mergesort has to move the items into and out of the auxiliary array ,COMMA which is more expensive .PERIOD so the random shuffle is a key for good performance in quicksort .PERIOD it gives us the guarantee that the worst case is not gonna happen .PERIOD and also ,COMMA it allows us to develop a math model that we can go ahead and validate with experimentation .PERIOD you run quick sort and you count compares .PERIOD if you did the random shuffle ,COMMA it'll be about 1 .PERIOD39 n log n compares .PERIOD and its running time will be proportional to n log n ,COMMA and it'll be a fast sort .PERIOD and that's what people do ,COMMA and that's why people use it .PERIOD now there are some things that you have to watch out for with quicksort because the implementation is a bit fragile and it's easy to make mistakes .PERIOD and you'll find textbook implementations or implementations out on the web that wind up running in quadratic time in certain situations .PERIOD you have to be a little bit careful of that and even if everything is randomized if there's lots of duplicates and the implementation is not done quite right the quick sort might take quadratic time .PERIOD so ,COMMA let's summarize the properties of quicksort .PERIOD it's in place .PERIOD it doesn't use any extra space .PERIOD the depth of recursion .PERIOD so tha ,COMMA that's .PERIOD again ,COMMA dependent on the random shuffling ,COMMA is going to be logarithmic .PERIOD you can ,COMMA limit the depth of recursion by always doing the smaller sub -DASH array before the larger sub -DASH array .PERIOD but that's not really necessary nowadays ,COMMA as long as you've done the ,COMMA random shuffle oh ,COMMA and by the way ,COMMA quicksort is not stable cuz partitioning does one of those long range exchanges that might put a ,COMMA a key with equal value over a key another key with the same value .PERIOD so it's a little more work to make quicksort stable ,COMMA maybe using extra space .PERIOD un ,COMMA so what about in actually in practice ?QUESTIONMARK this is our fastest sorting algorithm ,COMMA and there's a few ways to make it even faster .PERIOD and these ,COMMA we looked at some similar things with for the word ,COMMA mergesort .PERIOD and it's definitely worthwhile taking implementing for a quicksort .PERIOD first thing is small sub -DASH arrays .PERIOD even quicksort has more overhead than you want for a tiny array ,COMMA like one of size two or three or four .PERIOD so can implement it to cut off to insertion sort for small arrays .PERIOD and the exact number they use is not too ,COMMA critical .PERIOD okay .PERIOD anywhere between ten and twenty will improve the running time by maybe twenty% .PERIOD also you could just not do anything for small arrays ,COMMA and then do the insertion sorting in one pass at the end .PERIOD so ,COMMA that's a first improvement .PERIOD a second improvement is to ,COMMA try to estimate the partitioning element to be near the middle .PERIOD rather than just arbitrarily using the first element .PERIOD which on average will be at the middle .PERIOD so one thing that we can do is sample the items ,COMMA and then take a median of the sample .PERIOD and that's actually not worth the cost for enlarged samples ,COMMA not usually .PERIOD but for three it's worthwhile .PERIOD slightly reduces the number of compares .PERIOD increases the number of exchanges paradoxically ,COMMA cuz more exchanges are required when the partition is right in the middle .PERIOD so that'll also improve the running time by maybe ten% .PERIOD so this is a summary of the optimized quicksort with cut off the small subfiles in median -DASH of -DASH three partitioning .PERIOD so partition usually happens pretty close to the middle when you do that sample median -DASH of -DASH three and then small subfiles can just be left unsorted to be picked up with insertion sort right at the end .PERIOD so this gives a feeling for the .PERIOD number of items that have to be touched during quick sort .PERIOD and kind of an explanation for how it gets the sort done so quickly .PERIOD that's a summary of quicksort ,COMMA our best sorting algorithm that we've seen to date .PERIOD 
today we're gonna talk about string processing and we're gonna start by talking about string sorting .PERIOD we'll take a look at some classic methods but first we need to talk a little bit about just what strings are .PERIOD and actually ,COMMA that's really it's dependent on the programming language that you're using .PERIOD it's different programming languages nowadays really have completely different implementations of strings .PERIOD so to get started ,COMMA we need to take a look at efficient implementations of basic operations on strings .PERIOD we're going to tailor our algorithms to particular java implementation ,COMMA and that can be made to work in other situations ,COMMA but certainly ,COMMA it's starting point ,COMMA you have to be specific .PERIOD so what is a string ?QUESTIONMARK a string is just a ,COMMA sequence of characters ,COMMA and it's actually a very important fundamental attraction that's been with us from the beginning of the information processing .PERIOD so pretty much everything we communicate is a string ,COMMA email or our programs are strings .PERIOD but even ,COMMA another important area of significance that has arisen recently is in computational biology ,COMMA where our understanding of the way that life works depends on genomic sequences ,COMMA and is essentially based on string processing .PERIOD we'll see examples of that later on .PERIOD this is a quote that's talks about that issue .PERIOD the" digital information that underlies biochemistry ,COMMA cell biology and development can be represented by a simple string of g's ,COMMA a's ,COMMA t's ,COMMA and c's .PERIOD this string is the root data structure of an organisms biology .PERIOD so we're not talking just about data structures for information processing but for life models of life itself .PERIOD now back to computers .PERIOD the strings are made up of characters .PERIOD what's a character ?QUESTIONMARK well the kind of classical representation of what a character is ,COMMA is so called 7 -DASH bit ascii code .PERIOD where you have actually the underlying data type is 8 -DASH bit so you coud have up to 256 characters .PERIOD but for many ,COMMA many years programmers used only 128 of those characters that would include all the upper case and lower case letters and numbers and some punctuation .PERIOD so that's ,COMMA 7 -DASH bit ascii that's the standard for the c programming language ,COMMA that's a very widely used language .PERIOD nowadays ,COMMA people use what's called unicode .PERIOD where a character is a 16 -DASH bit integer .PERIOD and that's to allow for many ,COMMA many more characters ,COMMA two to the sixteenth ,COMMA 65 ,COMMA536 instead of only 256 .PERIOD and that allows for encoding characters from ,COMMA many different of the world's lang -DASH  ,COMMA languages ,COMMA and mathematical characters .PERIOD so it's a much more ,COMMA general and generous ,COMMA representation of what is a character .PERIOD but it's important to ,COMMA be specific .PERIOD so ,COMMA in java ,COMMA the standard is that a char is a sixteen bit unsigned integer .PERIOD now ,COMMA not all .PERIOD programming systems and applications have moved up to the unicode standard so sometimes you'll find programs looking for unicode encoding and not finding it ,COMMA and this t -DASH shirt is a joke that has something to do that to do with that .PERIOD it's supposed to be a heart which is a valid unicode character in some worlds ,COMMA but not on that t -DASH shirt .PERIOD so we'll come back to what is a character .PERIOD we're gonna use a simpler version in between those two ,COMMA or characters in the 8 -DASH bit integer .PERIOD now let's talk about what a string is in java .PERIOD there's a built -DASH in string data type .PERIOD it's not quite built -DASH in ,COMMA but many of the features for processing string are built into the java language .PERIOD so it's okay to think of it as being built -DASH in .PERIOD and so in java ,COMMA a string is a sequence of characters and it's immutable .PERIOD once you create a string ,COMMA you can't change it .PERIOD and ,COMMA the primary operations that you can perform efficiently with a string are to ,COMMA number one find it's length ,COMMA so you can get the length of the string .PERIOD and that's just the number of characters in it .PERIOD you can index into a string and get the it character ,COMMA that's the charat method .PERIOD and ,COMMA you can eps ,COMMA extract a substring of a string ,COMMA to create a new string ,COMMA that's a continuous subsequence of the characters in the string .PERIOD and .PERIOD one of the ,COMMA big ,COMMA features of java's implementation is that you can get that operation done in constant time ,COMMA and then you can also do what's called concatenation ,COMMA and that's add a character to the end of another string ,COMMA that one can't be done in constant time in the standard java string data type .PERIOD so ,COMMA this is what the implementation looks like for the string datat type in java .PERIOD the private instance variables are an array of characters ,COMMA an offset that's an index into the first character of a string in the array the length and also to make it more efficient to search using string keys java keeps a private variable which is the hashcode for that string .PERIOD so ,COMMA once the string is built and the hashcode computed ,COMMA then when it's time to use the hashcode and the hashing algorithm it's immediately available .PERIOD so ,COMMA the length method simply returns that length .PERIOD to get the it character of the string ,COMMA we add i to the offset ,COMMA and get that character .PERIOD and ,COMMA to ,COMMA create a string given an offset length and a character array ,COMMA we just reset those ,COMMA values .PERIOD and then the key thing is the substring ,COMMA method .PERIOD since all it involves is ,COMMA a pointer into the immutable string .PERIOD and ,COMMA a length ,COMMA the index of the first character we can build a string in ,COMMA constant time just by copying the reference to the character array .PERIOD so that implementation we give good feeling of why ,COMMA you know ,COMMA substring method is constant in string .PERIOD so this is the performance .PERIOD it's a sequence of characters ,COMMA is immutable .PERIOD and the underlying implementation is immutable instance variables that give the array ,COMMA offset and length .PERIOD and so it means that we can get length out of constant time ,COMMA charat in constant time just by adding in the offset indexing .PERIOD substring in constant time just by essentially cons ,COMMA copying those instance variables .PERIOD but to concatenate ,COMMA to make a new string that results from adding one character to a string ,COMMA we have to create a whole new string ;SEMICOLON and make a copy of it ,COMMA because the string itself is immutable so it takes time proportional to the number of characters in the string ,COMMA and it involves making a new string .PERIOD you can imagine string implementations ,COMMA and they exist in various programming languages ,COMMA where ,COMMA these performance guarantees are different .PERIOD and actually ,COMMA java has different implementations for applications where you might want different performance ,COMMA guarantees .PERIOD at the if you work out the memory usage for a string of length and it's 40 + 2n bytes .PERIOD you might consider using a char array ,COMMA but then you ,COMMA you lose a lot of convenience .PERIOD so ,COMMA for being able to produce substring and sublink ,COMMA and also the language features that supports strings .PERIOD so here's an implementation of a different implementation of sequence of characters in java that is mutable .PERIOD so it's ,COMMA the idea is that you can use this data type when you're building up a string a piece at a time .PERIOD like maybe reading characters off standard input or something .PERIOD the underlying implementation in this case is a resizing array of characters .PERIOD so when it fills up and doubles ,COMMA as we've done ,COMMA many times before .PERIOD and it keeps the ,COMMA the length that's an instance variable .PERIOD so with string builder ,COMMA you can get the length in constant time .PERIOD you can get characters in constant time just by doubling ,COMMA and you can concatenate ,COMMA add a new character in amortized constant time .PERIOD most of the time ,COMMA it's constant .PERIOD every once in a while ,COMMA you might have to double .PERIOD but you pay for that double by ,COMMA the number of operations ,COMMA that you did .PERIOD the thing you lose though ,COMMA is that it takes linear time to extract a sub -DASH string ,COMMA because to extract a sub -DASH string ,COMMA you have to make a new char array that can be re -DASH sizing and so forth ,COMMA and can be immutable to concat so that's two different implementations of sequence of characters in java ,COMMA where these two different ,COMMA importantly different performance characteristics ,COMMA so we have to keep in mind be mindful of that in applications ,COMMA and again in other programming languages ,COMMA something like the stringbuilder is more like the standard ,COMMA and you just have to know what the implementation is .PERIOD there's another one called stringbuffer as well in java that we will skip for now .PERIOD so here's a typical example that might have a simple computation like how do we efficiently reverse a string .PERIOD so you could use a string or you could use a stringbuilder with string you get to ,COMMA a declare it almost like a built -DASH in type and simply initialize with the null string ,COMMA and then to rev -DASH  ,COMMA rev -DASH  ,COMMA compute the reverse string ,COMMA we go backwards through the original string and concatenate the ,COMMA characters starting at the back to create our reverse string .PERIOD or with the stringbuilder ,COMMA you use ,COMMA the stringbuilder data type ,COMMA and so it create an object ,COMMA and that uses the doubling array ,COMMA and you use the append operation .PERIOD so ,COMMA what do you think ?QUESTIONMARK which one of these is ,COMMA is gonna be ,COMMA most efficient for ,COMMA a long string ?QUESTIONMARK the answer is ,COMMA that it's stringbuilder because the ,COMMA using the built -DASH in string every time you do a concatenation ,COMMA you have to make a copy of the whole string ,COMMA so if the string is of length n ,COMMA that's gonna take ,COMMA one + two + three all the way up to n ,COMMA which sums to ,COMMA n square ,COMMA about n^2/2 so it takes quadratic time to do a ,COMMA for this algorithm to run ,COMMA for a long string .PERIOD and that's gonna preclude using it for ,COMMA huge strings .PERIOD as we've seen so many times ,COMMA can't be using a quadratic time algorithm for ,COMMA lot of data .PERIOD on the other hand ,COMMA with stringbuilder it's linear time because the append operations are amortized in linear .PERIOD so that's a simple example .PERIOD here's another example .PERIOD a computation that we're gonna look at later on at the end of the lecture is how do we form an array of suffixes ?QUESTIONMARK so that is ,COMMA we have an input string in the suffixes of the string or the strings that you get by starting each position .PERIOD so the first suffix is the whole string ,COMMA the next one starts at position one ,COMMA the next one starts at position two and so forth ,COMMA each one less .PERIOD and so we have algorithms that gain efficiency by forming an array of suffixes of a given ,COMMA given string .PERIOD and so how do we create that thing in the first place ?QUESTIONMARK again ,COMMA you can do it with string or you can do it with stringbuilder .PERIOD so ,COMMA let's look at it with string .PERIOD we get the length ,COMMA that's gonna be the length of the array .PERIOD and what we do is for all values of i ,COMMA we set suffixes of i to the sub string of x .PERIOD s you get by starting at i and going all the way to n and that's our suffix array and this is the corresponding code for stringbuilder .PERIOD but ,COMMA now in this case the standard method is gonna be linear .PERIOD whereas the stringbuilder ,COMMA because there's only one string and the sub -DASH strings are a few pointers into that string .PERIOD whereas for a stringbuilder ,COMMA we have to make a new string for each suffix and there's a quadratic number of characters in the ,COMMA in all of those strings and so it takes quadratic time ,COMMA so you can't use stringbuilder to build a suffix array for a huge string .PERIOD so again ,COMMA those are typical examples of string processing where it really matters which string implementations that you're using and if you're not using ,COMMA if you're using java ,COMMA these trade -DASH offs are clear .PERIOD if you're using some other programming language ,COMMA you better make sure you know how strings are implemented before you even get started with string processing .PERIOD so here's a simple computation that we'll be using .PERIOD suppose that we have two strings and what we're interested in knowing is the length of the longest common prefix .PERIOD so here's some a static method that will implement this function .PERIOD takes two strings as argument .PERIOD we're gonna need to go as far as the length of the shortest of the two strings ,COMMA so that's n .PERIOD and then we just go ahead and start at the beginning and compare as long as the strings are equal we increment i .PERIOD and if we get to a point where they're non -DASH equal ,COMMA that's when we return i .PERIOD and that's the length of the longest common pre -DASH fixes .PERIOD in this case ,COMMA they're not equal at four ,COMMA that means they match at four characters .PERIOD and if we get to the end of one of them then that's a prefix ,COMMA so we just return n .PERIOD so that's just a little bit of warm -DASH up code ,COMMA and the amount of time that takes is proportional to the length of the longest common prefix .PERIOD although if the prefix is short ,COMMA like if the two strings have a different first character ,COMMA then it's a sublinear doesn't have to look at all the data ,COMMA just has to look at the amount that matches .PERIOD so ,COMMA the idea of a sub -DASH linear time algorithm for a string processing is a really important one that ,COMMA you know ,COMMA we're going to be taking advantage of ,COMMA as we move into more complicated algorithms .PERIOD so ,COMMA for example ,COMMA you can compare two strings without looking at them all .PERIOD it depends ,COMMA you just have to find ,COMMA the first place that they differ ,COMMA so you don't look at all the data at sub -DASH linear time .PERIOD and we're going to see sorting algorithms that take advantage of that .PERIOD now we're not gonna really do it ,COMMA in the code that we show in lecture or even in the book but it's actually fairly easy to take many of the algorithms that we're gonna look at ,COMMA and make some so that they work for general alphabets and for different applications you know ,COMMA it might be entirely appropriate to customize the code to a particular alphabet .PERIOD so ,COMMA like if the ,COMMA the thing are the things that are being processed are numbers or positive integers ,COMMA or things like account numbers ,COMMA maybe only ten decimal characters can occur .PERIOD so ,COMMA we might as well work with strings made from those well -DASH defined ten characters .PERIOD in dna ,COMMA there's only four characters ,COMMA so we might as well know that we're working with four characters .PERIOD and so it's the we'll often talk of the radix ,COMMA which is the number of possible different character values in the string .PERIOD now we're always gonna use what's called an extended ascii ,COMMA where just to fix ideas ,COMMA where the radix is 256 .PERIOD and the number of .PERIOD bits ,COMMA therefore to represent a character is the log base two of that ,COMMA so 8 -DASH bits ,COMMA 256 .PERIOD and when we talk about performance of algorithms ,COMMA we'll use r and log ,COMMA r just to make sure that it's clear that if we're working with a smaller alphabet or a larger alphabet we can still use the algorithms but the performance is going to depend on the radix .PERIOD so that's an introduction to string 
the first string sorting algorithm that we're going to look at is actually the basis for several more complicated algorithms is called key -DASH indexed counting and it's very useful on a particular special situation .PERIOD but let's take a quick review of where we left off with sorting .PERIOD so we considered a number of sorting algorithms starting with insertion sort ,COMMA and then merge sort ,COMMA quick sort and heapsort .PERIOD and we got to the point where we could find an algorithm that's heapsort that guarantees to sort nl items and time proportional to n log n without using extra space ,COMMA unfortunately not stable .PERIOD and all these algorithms were useful ,COMMA or are useful for any type of generic key as long as it implements the comparative operation .PERIOD and not only that ,COMMA we prove that ,COMMA any algorithm that just uses compares has to use number of compares proportional to n log base 2n .PERIOD so ,COMMA in a very important sense ,COMMA merge sort ,COMMA or heapsort for example ,COMMA or optimal .PERIOD you can't use syntatically fewer compares ,COMMA for ,COMMA either one and ,COMMA and ,COMMA with heapsort ,COMMA you can't use less ,COMMA extra space .PERIOD so why do we consider ,COMMA other sorting algorithms ?QUESTIONMARK there was a lower bound ,COMMA what ,COMMA what ,COMMA why are we thinking about this ?QUESTIONMARK and the question is ,COMMA can we do better and obviously we're here because ,COMMA the answer is that we can do better and if we don't depend on compares .PERIOD the lower bound ,COMMA the one assumption made by the lower bound is that we use compares ,COMMA but we don't always need to use compares .PERIOD and so let's look at an example .PERIOD key -DASH indexed counting is a fine example of that .PERIOD and it's representative of fairly common situation where ,COMMA in sorting application ,COMMA where it happens to be that the keys that we're using to sort are small integers .PERIOD so ,COMMA in this ,COMMA this case ,COMMA this is supposed to mimic an application where there's students and they're assigned to sections .PERIOD there's not too many sections and we want to get the thing sorted .PERIOD so we want to distribute the students by section and so we want to sort according to the section number and that's a small integer .PERIOD and the implication of knowing that the key is a small integer is ,COMMA that we can use the key as an array index and ,COMMA and by knowing that the key is an array index ,COMMA we can arrange for fast sort .PERIOD so lots of applications for that when we have maybe a phone numbers ,COMMA we can sort by area code or if you have a string you just want to sort by the first letter ,COMMA you can do it that way .PERIOD and actually ,COMMA that idea leads to efficient sorting algorithm actually two different ways .PERIOD now don't forget that we're sorting according to a sort key ,COMMA but usually we're sorting bigger generic items that have other information associated with if you were just sorting the small integers ,COMMA you could just count how many 1's there are ,COMMA how many 2's there are and like that ,COMMA and then in one path and if there's three 1's ,COMMA just output three 1's and so forth .PERIOD but the complication is that we have to carry the associated information along so we have to work a bit harder than that .PERIOD so ,COMMA here's the code for this method called key -DASH indexed counting ,COMMA and ,COMMA let's look at a demo .PERIOD so here's the key -DASH indexed counting demo .PERIOD now ,COMMA to make this a little less confusing in not so many numbers ,COMMA we're going to use lower case a for zero ,COMMA b for one ,COMMA c for two and like that .PERIOD so it's the a  -DASH  first letter of the alphabet ,COMMA and however you want to think of it .PERIOD so ,COMMA and we're already going to look at six .PERIOD so we're supposing that we're sorting this array that has six different small integers and we're using lower case letters to represent the integers so that we can easily distinguish between the keys and this .PERIOD so now ,COMMA let's look at ,COMMA the processing for this .PERIOD so the first thing that we do is we go through and we count the frequency of occurrence of each letter and ,COMMA so the way that we do that is we keep an array .PERIOD now their arrays actually got to be one bigger than number of different key ,COMMA keys that we have and the number of different small integers that we have .PERIOD so in this case array of size seven .PERIOD and just this ,COMMA make the code a little cleaner ,COMMA we keep the number of a's in count of one ,COMMA the number of b's in count of two and so forth .PERIOD and s o if we're ,COMMA once we've set up ,COMMA that's what we want to do ,COMMA then its trivial to go ahead and count the frequencies .PERIOD we'd simply go through ,COMMA for i from zero to n ,COMMA we'd go through our input .PERIOD and when we ,COMMA a of i ,COMMA when we access a value in our input ,COMMA it's a small integer .PERIOD so it's zero ,COMMA one ,COMMA two ,COMMA three ,COMMA four ,COMMA or five and we simply add one to that integer ,COMMA and use it to index into that array .PERIOD so when we see an a ,COMMA that's zero ,COMMA then we're ,COMMA incrementing count of one ,COMMA and we see a b ,COMMA that's one ,COMMA we're incrementing count of two and so forth .PERIOD so in this case ,COMMA we increment count corresponding to b and then a and c and like that .PERIOD and everytime we encounter a new key ,COMMA we simply increment one of these counters .PERIOD in one pass through we get an array that gives us the number of a's ,COMMA b's ,COMMA c's ,COMMA d's ,COMMA e's and f's .PERIOD that's the first path of key -DASH indexed counting ,COMMA count the frequencies of each letter ,COMMA using the key as an index .PERIOD now the next step is ,COMMA is called computing cumulus ,COMMA and that's a really easy thing as well .PERIOD all we do is we go through the count array and simply at each step we add the current one to the sum computed so far .PERIOD so if we look before ,COMMA we had two a's and three b's ,COMMA so that means there's five letters less than c .PERIOD that's the a's and the b's ,COMMA and they're six letters less than d and eight letters less than e and so forth .PERIOD and that's just obtained by ,COMMA we start with two ,COMMA add three to it ,COMMA get five ,COMMA add one to it to get five .PERIOD and with that one passed through the count array ,COMMA then we can find out for example ,COMMA there are six keys less than d and eight keys less than e .PERIOD and those cumulus tell us where the d's go in the output .PERIOD there's six keys less than d ,COMMA and eight keys less than e ,COMMA so the d's have to go in a6 and a7 .PERIOD so this is an array of indices that is going to tell us how to distribute the keys in the output .PERIOD so that's the next step ,COMMA is access the cumulus using the key as the index to move items .PERIOD so let's take a look at .PERIOD so now ,COMMA remember when we see an a ,COMMA we're just going to count that as zero ,COMMA so we're going to go to count zero and that will access this entry in the count ar ray .PERIOD so ,COMMA we go through the whole array to be sorted and we move each key exactly to where it has to go and we'll do that one at ,COMMA at time now .PERIOD so when i is zero we're looking at the d ,COMMA the count array corresponding to d has six ,COMMA so it says ,COMMA just put d in there and increment that .PERIOD it means if you get another d ,COMMA it's going to go into seven .PERIOD and these things ,COMMA the way we pre -DASH computed them ,COMMA are not going to run into one another .PERIOD so now ,COMMA a ,COMMA we go ,COMMA that goes in zero ,COMMA and we increment the count array corresponding to a .PERIOD next thing is c ,COMMA and so that's going to says to put it in five and then increment ,COMMA the count array corresponding to c ,COMMA and f ,COMMA it says put it in nine .PERIOD next is b ,COMMA we put it in two .PERIOD sorry another f ,COMMA we put in ten .PERIOD next is b that we put in wo .PERIOD so you can see the keys from the input are getting distributed in the output according to the counts and the cumulus that we've pre -DASH computed .PERIOD so now we get the other d which goes into seven ,COMMA we get the ,COMMA another b which goes into three ,COMMA and then increment the four for where the next one goes ,COMMA f goes into eleven .PERIOD the last b goes into four ,COMMA the e goes into a ,COMMA and the second a goes into one .PERIOD so that's move items again ,COMMA simply by using the key as index into the count array .PERIOD and then the last step is to just copy the sorted array back into the original input .PERIOD that's a demo of key -DASH indexed counting .PERIOD quick summary of key -DASH indexed counting ,COMMA we make one pass through the array to count frequencies of each letter using the key as an index ,COMMA then we go through that count array to ,COMMA compute cumulus just by adding each new one into the running sum .PERIOD then we use those cumulates ,COMMA and access that using key as index to actually move items over and get them in sorted order ,COMMA and then move back into the original array .PERIOD what's the running time of this algorithm ?QUESTIONMARK well ,COMMA the analysis is actually quite simple ,COMMA because it's just a couple of loops through the array that we sorted ,COMMA and through the count array .PERIOD and the key ,COMMA key fact to note ,COMMA that it takes time proportional to n plus r and space proportional to n + r .PERIOD now r ,COMMA remember is our array that excess the number of different character values .PERIOD so ,COMMA so for asking ,COMMA maybe that's the 205th .PERIOD and ,COMMA and for generic data maybe it's four .PERIOD and n ,COMMA we're assuming we're sorting huge files .PERIOD so really ,COMMA this is linear time in many ,COMMA many practical situations .PERIOD there's also the question of ,COMMA is it stable ?QUESTIONMARK yeah ,COMMA it's actually stable .PERIOD because when we do the move ,COMMA we move things with equal keys in the order that we see them ,COMMA we keep them in the order that we see them .PERIOD that's just the way the method works .PERIOD so we have for this special situation ,COMMA we have a linear time stable sorting method which beats the n log n and it's useful in many practical situations .PERIOD 
now we'll look at the problem that's related to sorting called selection that's also well solved by quicksort partitioning .PERIOD this is a simpler problem .PERIOD we're given an array of n items that are ordered and our task is to find the k -DASH th largest .PERIOD there's lots of important applications for this .PERIOD so like if we wanted to find the minimum item that's k = zero or the maximum item that's k = n  -DASH  one or the medium that's k = n/2 .PERIOD and there's many kinds of applications from people processing data .PERIOD i wanted to find the top k or the medium or other order statistics so that's what selection is all about .PERIOD now ,COMMA here's an example where we want to use theory as a guide .PERIOD what kind of efficiency might we expect in a selection algorithm .PERIOD well ,COMMA first of all ,COMMA it's easy to see that we can solve selection and in law at end time .PERIOD how would we do that ?QUESTIONMARK well ,COMMA we just sort the array and then if we want to find the smallest ,COMMA we'll look at the first position or the largest ,COMMA we'll look in the last position or the medium ,COMMA we'll look in the middle .PERIOD in fact ,COMMA if k is small ,COMMA the running time is going to be proportional to n .PERIOD because if you're looking for the smallest ,COMMA you can just go through the array and find the small or the smallest in one pass through or if you're two ,COMMA you'll find it and two passes through .PERIOD so ,COMMA you can imagine trying to look for a selection algorithm that takes time proportional to n and also the lower bound is n because you have to look at everything .PERIOD if you don't look at everything ,COMMA you might miss the one item that you're looking for .PERIOD so ,COMMA from these observations it's clear that what we ,COMMA what we'd like is a selection algorithm that takes linear time .PERIOD but at this point ,COMMA the question is ,COMMA is there a linear time algorithm that works for every k ?QUESTIONMARK or possibly selection is as hard as sorting .PERIOD this kind of question plagued a lot of people in this late 60's or early 70's as these types of problems emerge for computing applications .PERIOD so ,COMMA it's an interesting question to think about for sure .PERIOD well in his original paper in 1961 hoare gave a solution to the selection problem based on partitioning .PERIOD and the idea is just a version of quicksort in a way .PERIOD we're going to do our partitioning so that we get entry a(j) in place of the array .PERIOD nobody to the left is larger ,COMMA nobody to the right is bigger .PERIOD but then ,COMMA when we're doing selection ,COMMA what we'll do is just go in one sub array or the other depending on where j is .PERIOD if j = k ,COMMA we're done ,COMMA we've found the k is the largest .PERIOD if k is to the left of j ,COMMA then ,COMMA we just do the left sub -DASH file which is set high to j  -DASH  one .PERIOD and if k is to the right of j ,COMMA we just do the right subfiles that load the j + one and that's all this code does is that it ,COMMA we could do a recursive ,COMMA a recursive call but this just does it by resetting the values of the parameters .PERIOD do one partition then check whether you to your k -DASH th element is going to be on the left part or the right part and reset lower high accordingly .PERIOD if it's equal ,COMMA then you found it and you return it and you keep going until you get to a point where you have only one element .PERIOD that's the a quicksort like implementation solving the selection problem .PERIOD notice again that it depends on the random shuffle at the beginning that's going to be important for performance .PERIOD alright .PERIOD so there needs to be a mathematical analysis to ,COMMA to characterize the running time of this program in the fact is that quick select this method takes linear time on the average .PERIOD we won't give the full proof .PERIOD it's actually quite a bit more complicated than the one just on for quick sort .PERIOD but intuitively ,COMMA we can see kind of what happens each partitionings that maybe splits the array approximately in half .PERIOD so that ,COMMA that means you'd have ,COMMA if you did exactly and [inaudible] + n/2 + n/4 and so forth which adds up to about two n compare so linear cross .PERIOD if you do the ,COMMA actually it doesn't cut it in half at exactly each time only on average so you need a fuller analysis like the one we did for quicksort and the bottom line of that analysis gives the number of comparisons required as a function of n and of k in terms of this formula here and if you plug in k = n/2 ,COMMA you get the result that the number of compares required to fine the median that's the highest value this formula can take is two + two natural log of two .PERIOD so ,COMMA linear time to find the k -DASH th largest for any value of k .PERIOD now again it's going to use ,COMMA this is a method that's linear time on the average .PERIOD it's actually going to be quadratic in the worst case but again ,COMMA the chance of that it will happen with a random shuffle is less than the chance that we'll be struck by lightning .PERIOD its a probabilistic guaranteed fast algorithm .PERIOD now ,COMMA from a theoretical standpoint that's a little unsatisfied and in ,COMMA in 1973 ,COMMA there's a famous paper that found a compared base selection algorithm that guarantees to solve the problem in linear time .PERIOD this is areal landmark in the theory of algorithms because for a long time ,COMMA it's not known ,COMMA we knew we could have the average case ,COMMA the linear time but could we find a worst case ?QUESTIONMARK and this paper found such a construction .PERIOD now in practice ,COMMA this construction is ,COMMA is rather high .PERIOD so ,COMMA the method is not really used in practice .PERIOD and so ,COMMA there is still the goal of a ,COMMA of a fast guaranteed linear time selection algorithm maybe somebody in this class will invent someday .PERIOD this is another example where we use theory as a guide .PERIOD it's still worth while to look for a practical linear time worst case algorithm .PERIOD well then ,COMMA maybe somebody in this class will invent that but until something like that is discovered use the quick select based on quicksort partitioning you can get linear time selection when you don't need a full sort .PERIOD that selection of simple problem like sorting that is well sound with quicksort partitioning .PERIOD 
now we're going to take a look at what happens when we have significant numbers of duplicate keys which is not at all unusual in practical applications .PERIOD so ,COMMA in ,COMMA in fact ,COMMA often ,COMMA the purpose of a sort is to bring items with equal keys together for like the example that i gave where we had cities and time .PERIOD there's a lot of detailed data and the time and maybe the whole goal of the sort is to group them by cities so we can ship out the data for each city ,COMMA to each city and there's plenty of other examples like that in data processing where we find maybe remove duplicates from a mailing list or all the job applicants that we get ,COMMA we might want to sort them by the college attendant .PERIOD so the sort does huge files with huge numbers of duplicate keys .PERIOD so ,COMMA a sort ,COMMA it's worthwhile to take a careful look at what the implication of that is .PERIOD so again ,COMMA typical characteristics we have a huge file but small number of different key values .PERIOD so let's look at our algorithms in that situation .PERIOD so mergesort ,COMMA it doesn't matter that much what the key values are like and it's actually ,COMMA we can show that mergesort always uses between one -DASH half ,COMMA n log n and n log n compares .PERIOD quicksort actually ,COMMA they're up until the 1990s the most widely used implementation took quadratic time .PERIOD for files with large numbers of equal keys and that was actually found by applications user and ,COMMA and that's the standard quicksort that was in all the textbooks almost all the textbooks if you did not stop the partitioning on equal keys it would run in quadratic time .PERIOD so we want to do better than this .PERIOD so the mistake happens if we put all the items equal to the partitioning item on one side which is a natural way to implement it and the consequence is if you have all the keys equal ,COMMA then partitioning doesn't really do anything .PERIOD you just peels off one key to do file size n then you get a sub file size n  -DASH  one and then n  -DASH  two and so forth and the result is a quadratic tim e algorithm .PERIOD our implementation ,COMMA we stopped the partitioning scans on items equal to the partitioning item and then in that case ,COMMA when all the keys are equal ,COMMA it's going to divide it exactly in the middle .PERIOD and then in that case ,COMMA when all the keys are equal ,COMMA it's going to divide at exactly in the middle .PERIOD and then in that case you get an n log n compares .PERIOD but actually when you think about it ,COMMA why don't we just put all the items equal to the partitioning item in place .PERIOD that's ,COMMA that's really a desirable way to look at it and let's take a look at that option .PERIOD so the goal is so called three way partitioning .PERIOD so what we want to do is get the array into three parts so then now we have two pointers into the middle .PERIOD one that is the boundary between the keys that are less than the partitioning element and those that are equal of the partitioning element .PERIOD another one that's the boundary between the keys that are equal of partitioning elements and the one that is greater .PERIOD and then in the middle are all the equal keys and that's what we'd like to arrange .PERIOD now until the 1990s ,COMMA conventional wisdom among people implementing system was ,COMMA wasn't worth doing this .PERIOD but ,COMMA but actually it's a problem that edsger dijkstra had proposed in the 70s as an example of ,COMMA of programming problem .PERIOD he was really interested in analyzing correctness of programs and showing that this how you could convince yourself that this program was operating as expected .PERIOD but in the 1990s we figured out that really this was going to be an effective way to sort .PERIOD and this was taking a look at the qsort that a user found was broken and ,COMMA and now ,COMMA this method is incorporated into some plenty of system sorts .PERIOD so let's take a look at how it works with the demo its more complicated than standard quicksort partitioning .PERIOD a bit more complicated because there's more to do .PERIOD so now we have our i pointer which is right to the left of stuff we haven't seen ye t and then ,COMMA we have two other pointers that maintain ,COMMA maintain these boundaries everything to the right of gt is known to be greater than partitioning element .PERIOD everything to the left of lt is known to be less and between lt and i is known to be equal .PERIOD and all the method does is maintain this in variants so let's do an example or two and see how that works .PERIOD so we increment i and then figure out what to do .PERIOD so ,COMMA now it's less than the partitioning element .PERIOD so ,COMMA what we want to do is increment lt's .PERIOD so now we have one that's definitely less than the partitioning element and lt is ,COMMA is pointing at the partitioning element .PERIOD and so now in ,COMMA increment both lt and i so that's the first case there .PERIOD so now we have a second item b .PERIOD that's less than the partitioning element so exchange with lt and increment them both .PERIOD so ,COMMA we're moving the smaller ones than the partitioning element to the left of lt and keeping lt pointing on a partitioning element .PERIOD now ,COMMA what about when we get one that's greater than the partitioning elements ?QUESTIONMARK so ,COMMA in that case ,COMMA we exchange greater the one over at the right with i and decrement gt .PERIOD so now ,COMMA we have one over to the right that we know is greater than the partitioning element .PERIOD notice that we didn't increment i because that element z that is over in the right ,COMMA really hasn't been compared to the partitioning element yet .PERIOD but we did decrement gt so we made progress .PERIOD so now what happens here ,COMMA now i is pointing to a bigger one so we're going to exchange it with the one at gt and decrement gt again .PERIOD and again ,COMMA y is bigger ,COMMA so exchange it ,COMMA decrement gt .PERIOD now we have the c ,COMMA that one smaller so that's the first case .PERIOD so we'll move it to the left of lt and increment both lt and i .PERIOD w is a bigger one ,COMMA let us to go over to the right .PERIOD now we have i pointing to an element that's equal to the partitioning element .PERIOD and what are we supposed to do then ?QUESTIONMARK well ,COMMA to maintain the variant there we just need to increment i .PERIOD and again it 's pointing to one that's equal of partitioning element increment i .PERIOD and now one more time and now it's pointing to one that's greater so we exchange that with gt and decrement gt and i is pointing to the one that was there and that ones smaller .PERIOD so we exchange it will lt and increment both i and lt and now where the point ,COMMA where the pointers have crossed i and gt across there's nothing that we haven't examined yet .PERIOD so ,COMMA our partitioning is complete .PERIOD here's a trace of dijkstra 3 -DASH way partitioning for his problem which is when there's just three different values in the file .PERIOD our problem we were treating partitioning ,COMMA equal of partitioning element as one value less than as another and greater than as another .PERIOD and so this ,COMMA this trace illustrates how we always make some progress and eventually we get the file sorted .PERIOD the implementation is amazingly simple .PERIOD the whole partitioning process for three -DASH way partitioning and the modern programming language like java simply maintains the invariances described in the demo .PERIOD if we find one that's less we exchange i and lt and increment them both .PERIOD if it's greater we exchange i and gt and decrement that .PERIOD otherwise ,COMMA we increment i .PERIOD could ,COMMA could hardly be simpler .PERIOD in fact ,COMMA is simpler in many ways than these standard implementation of quicksort .PERIOD in fact ,COMMA there's an argument for just using this implementation of quicksort and forgetting about horse because it performs so well in so many practical situations .PERIOD here's a visual trace of 3 -DASH way quicksort for situation with plenty of equal keys .PERIOD and again ,COMMA when there's a lot of equal keys then there's going to be place where one of those is chosen ,COMMA it's partitioning element then a big chunk of the array gets handled just in a partitioning process .PERIOD now ,COMMA there's actually some deeper reasons why this method is important and one thing to do is to realize that the lower bound that we talked about before depended on the keys being distinct .PERIOD so ,COMMA worst case for lower bounds is when the keys are all distinct .PERIOD but if we have a situation where there are a lot of equal keys ,COMMA that model is wrong .PERIOD it's not too difficult to get a similar lower bound for the model when we know that there are some equal keys .PERIOD so ,COMMA for example this is a rather complicated formula but not too bad but in a sense that if you know that the i -DASH th key ,COMMA it occurs xi times you can write down a lower bound for the number of comparisons that are going to be required in the worst case .PERIOD and ,COMMA what's interesting about three way partitioning is that the number of compares that it uses is equal to this lower bound within a constant factor .PERIOD so that's entropy -DASH optimal and what that means is whatever the distribution of equal keys in there ,COMMA this thing is going to use a number of compares that's proportional to the best that you could possibly do .PERIOD the proof for this fact is quite beyond the scope of this course but it's still an important fact .PERIOD and the ,COMMA the bottom line is that if you randomize the order and use three -DASH way partitioning then there's lot of applications where your sort routine is going to be linear not n log n so it will be much more faster than mergesort and you know ,COMMA the methods for really a broad class of applications .PERIOD so ,COMMA taking a look at equal keys is carefully is something that can lead us to very efficient quicksort 
my key index counter is a great algorithm but that's not the end of the story .PERIOD it's also useful for creating a more general purpose algorithm for strings .PERIOD the first one we'll look at is called lsd radix sort ,COMMA least significant digit for string sorting .PERIOD and the idea is a very simple one .PERIOD we have strings so we're gonna consider now a small example where the strings are all the same length .PERIOD and again that's often true in practical applications account numbers and so forth .PERIOD string that uses ,COMMA sort these ,COMMA may all be the same length .PERIOD and what we're gonna do is consider .PERIOD the character positions in the strings ,COMMA and move from right to left .PERIOD the algorithm ,COMMA is to just stably sort using key index counting ,COMMA on ,COMMA the chara -DASH  ,COMMA deed character of the key ,COMMA where deed goes from the right end and decreases .PERIOD so ,COMMA this is ,COMMA a stable sort .PERIOD of those twelve keys ,COMMA sorting on the right -DASH most character ,COMMA the b's go before the d's go before the es .PERIOD it's crucial that the sort be stable in this application ,COMMA and that's why we checked with key index counting to make sure that it was stable .PERIOD so it's a stable sort on ,COMMA on the right most character .PERIOD and then all we do is move from right to left and do now the second character .PERIOD and this now is a stable sort of those same keys on the second character .PERIOD so now the ones with a in the second character come before the one with b and so -DASH forth .PERIOD and not only that ,COMMA it's stable ,COMMA so their relative order is maintained ,COMMA bab ,COMMA cab ,COMMA fad ,COMMA bad ,COMMA and so -DASH forth .PERIOD and then .PERIOD to finish this .PERIOD sort .PERIOD now we do it on the first key .PERIOD and the magic of lsd radix sorting is eh ,COMMA once you do it on the first key then the strings are all sorted .PERIOD so ,COMMA that's three passes ,COMMA one for each character in the string .PERIOD each taking linear time and we get a string sort .PERIOD that's lsd sort .PERIOD now we need to prove that it works .PERIOD and so this is a simple proof by induction that it worked .PERIOD after we have done i passes then we can assume by induction that the strings are sorted on the last i characters .PERIOD so we are just showing that for two ,COMMA after two passes .PERIOD it sorted on the last two characters thats we're assuming by induction .PERIOD so now what about the next character that we are sorting .PERIOD well ,COMMA there's two things that can happen .PERIOD if two strings are different on the first key ,COMMA then ,COMMA the key index sound is gonna do the job .PERIOD a string that starts with b is gonna come before one that starts with a d ,COMMA and so forth .PERIOD so if they're different on the sort key ,COMMA the key index sort puts them in order .PERIOD if they're the same on a sort key then stability does the job .PERIOD so all the ones with that stay on order because we've insisted on a stable sort .PERIOD that's a simple proof by induction that lsd string sorts fixed length strings in a descending order .PERIOD and it's really easy to implement .PERIOD this is a complete .PERIOD java implementation of lsd string sort .PERIOD so we're explicitly working with radix r256 .PERIOD = 256 and where the radix comes in ,COMMA the value of the radix comes in ,COMMA is that's the size of the array that we use for the ,COMMA counts and the accumulants .PERIOD we need one for each character .PERIOD for each possible character value ,COMMA we're gonna index into that array that has to be that big .PERIOD and all this is ,COMMA is the code for key index counting .PERIOD and then all we do is take a variable t that goes down from this is the strings of fixed width w and we start at the rightmost character and go down to the first character .PERIOD and instead of dealing with a -DASH ah ,COMMA our string a of i2 we're just look at the deed character which is a character .PERIOD otherwise just with that replacement and that replacement it's the same code as we looked at for key index counting .PERIOD so let's do key index counting on the deed character going down from the width from right to left .PERIOD that's remarkably compact code .PERIOD and that's gonna be the method of choice for lots of situations with fixed length keys as the sort key .PERIOD and ,COMMA and it gives us another look at the performance of sorting out algorithms .PERIOD that gives us another line in the table that we're requiring that ,COMMA that be ,COMMA they be fixed length keys ,COMMA there's ways to work around that .PERIOD and we'll consider another algorithm that deals with that in a minute .PERIOD but again it's often or typically the case that the .PERIOD width of the keys is not that long .PERIOD it's a small constant .PERIOD and therefore ,COMMA we have a linear time algorithm .PERIOD this even works if the keys are binary numbers represented in a binary word .PERIOD we can break them up into groups of small number of bytes say ,COMMA 64 byte number can be broken up into 88 eight bytes characters or four sixteen byte characters .PERIOD for sixteen byte characters ,COMMA w would be four and you can get a huge array of that kind of numbers sorted in just the four passes through the array .PERIOD if they don't have the same length we have to do some extra work .PERIOD it's an interesting problem to think about .PERIOD we're ,COMMA we're gonna look at a different method in a minute .PERIOD so here's the type of question that somebody might could ask for a job interview .PERIOD actually ,COMMA a web services company ,COMMA every day ,COMMA might be in the position of needing sort a million or a billion 32 bit or 64 byte integers .PERIOD and an algorithm student ,COMMA in interviewing ,COMMA might could ask what sorting method do you use ?QUESTIONMARK now ,COMMA senator .PERIOD you hear google and i like to think of the presidency as a job interview .PERIOD now it's hard to get a job .PERIOD as president .PERIOD right .PERIOD and ,COMMA and you're going through that obviously now .PERIOD it's also hard to get a job at google .PERIOD right .PERIOD [laugh] we ,COMMA we have questions .PERIOD and we ask our candidates questions .PERIOD and this one is from larry schwimmer .PERIOD okay .PERIOD [laugh] .PERIOD you guys think i am kidding ?QUESTIONMARK it's right here .PERIOD what is the most efficient way to sort a million 32 bit integers ?QUESTIONMARK well i ,COMMA no ,COMMA no ,COMMA no ,COMMA no ,COMMA no ,COMMA i ,COMMA i think the bubble sort would be the wrong way to go .PERIOD come on ,COMMA who told him this ?QUESTIONMARK okay .PERIOD i didn't see computer science in the background .PERIOD we've got our spies in there .PERIOD well .PERIOD 'kay .PERIOD let's ask ,COMMA let's ask a different interview [laugh] question .PERIOD [laugh] .PERIOD so the bottom line is if you want a good job maybe ,COMMA you wanna know about lsd string sort .PERIOD actually ,COMMA this method has been around for ,COMMA really a long time .PERIOD so we'll start with a little bit of a story .PERIOD so what did people do ,COMMA in the nineteenth century when ,COMMA they wanted to take a census ?QUESTIONMARK and actually ,COMMA the story is that ,COMMA for the 1880 census ,COMMA it was actually obsolete ,COMMA before it was completed .PERIOD it took 1 ,COMMA500 people seven years to manually process the data .PERIOD so ,COMMA during that time there was room for some invention ,COMMA and a man named herman hollerith developed an automated machine that could help do the census faster .PERIOD so what his idea was to use punch cards to record data .PERIOD the kind of data that was taken in the census .PERIOD and then the machine could tabulate the data by sorting one column at ,COMMA at time .PERIOD and we'll look a byte at how it does that in just a minute .PERIOD and the idea was that the re -DASH  ,COMMA result of that was that the next census finish really much earlier and under budget ,COMMA 'cause this machine automated much of the process .PERIOD and that had a really a profound effect on the development of computing 'cause punch cards ,COMMA it turned out were useful not just for census but for many other applications .PERIOD for accounting and for many other for business processes and for many decades ,COMMA punch cards were the primary medium that was used to store ,COMMA enter ,COMMA and process data .PERIOD and hollerith's company for building this machine later emerged with a bunch of other companies .PERIOD and in 1924 that company became known as ibm .PERIOD and actually ,COMMA punch cards were used up into the 70's' and even in the 80's' in some places .PERIOD so ,COMMA if ,COMMA it's important .PERIOD let's take a little break and talk about the role of lsd string sort .PERIOD for you know ,COMMA a couple of decades people who wrote programs were working with punched cards .PERIOD and in courses at universities ,COMMA if you want to write a program ,COMMA you wrote it by putting one line on each punched card .PERIOD in your program ,COMMA therefore ,COMMA was a deck ,COMMA a long deck of punched cards .PERIOD if you had a 1000 line program ,COMMA you had 1000 punched cards .PERIOD they came in boxes that held 2 ,COMMA000 ,COMMA and people would carry around these boxes of punch cards that ,COMMA that were their programs .PERIOD to enter the program there was a thing called a card punch which had a ,COMMA which had a keyboard kind of like a typewriter ,COMMA but all it did ,COMMA you could see the cards ,COMMA and it'd actually punche holes in the card with what you typed .PERIOD now there was a huge so then ,COMMA you ,COMMA you're program was punched cards .PERIOD and there was a machine called a card reader which would take the cards in and convert those punches back into ,COMMA into binary and characters that again ,COMMA could be processed on the computer and then you get your results printed out on paper in a line printer .PERIOD so for many ,COMMA many years people programmed by making decks of punched cards handing them to an operator who put them on a card reader and then waiting for the printed output to come out .PERIOD there were other devices ,COMMA but this was the main thing for a long time .PERIOD and lots of people learned to program this way .PERIOD now ,COMMA there was a huge flaw in the system though .PERIOD the flaw was ,COMMA if you dropped the deck ,COMMA then your program was completely scrambled and out of order .PERIOD and you had no program .PERIOD you had to go through the cards and find the first line and ,COMMA then find the second line .PERIOD well ,COMMA people figured out to work around for this really almost right from the beginning ,COMMA cause this is clearly intolerable ,COMMA situation ,COMMA and ,COMMA the ,COMMA along with the same room with the card punch ,COMMA there was a thing called a card sorter ,COMMA and the card punch did one other thing automatically .PERIOD every time you punched a card .PERIOD it would go to the last six columns of the card and it would put in ,COMMA a number .PERIOD actually they skip by ten so ,COMMA it would be .PERIOD the first card would be card ten then twenty ,COMMA 30 .PERIOD and your cards would be numbered up to six digits ,COMMA so you could have thousands of cards sequentially .PERIOD so when you typed in your program ,COMMA you get the cards numbered ,COMMA in order .PERIOD if you wanted to add a few lines to a program ,COMMA you had room to add a couple of numbers and ,COMMA re -DASH punch the numbers ,COMMA but ,COMMA nuh ,COMMA the whole point was ,COMMA that all the time when you're holding on to a card deck ,COMMA the cards are in order ,COMMA by number on the right hand column .PERIOD and if you dropped it ,COMMA all you needed to do was sort it .PERIOD or if the m -DASH  ,COMMA machine operator dropped it ,COMMA that was not viewed as a big deal for your cards to get [laugh] out of order ,COMMA because there was this machine that could sort cards .PERIOD and the way that it worked was ,COMMA lsd rate exort ,COMMA the lsd string sort on those characters that are the numbers that keep the card in order .PERIOD they would ,COMMA you'ld start on the right column .PERIOD and there was a physical thing ,COMMA you'd set to a call and ,COMMA it was gonna sort on ,COMMA you put the deck in ,COMMA and it'd distribute ,COMMA the ones with zero in the first bin ,COMMA or ones with one in the second bin ,COMMA all the way up ,COMMA it'd ,COMMA and of all the cards it start with zero would come in ,COMMA and it was stable ,COMMA whatever order the cards were in ,COMMA that's the order they'd appear in the pile ,COMMA and then you'd pick them up ,COMMA and you'd have a new deck ,COMMA and it'd be all sorted on the right -DASH most column .PERIOD then you move over for one position from right to left ,COMMA and run the cards through again .PERIOD so if running the cards through the card sorter six times ,COMMA you could get your deck sorted .PERIOD so ,COMMA every programmer knew lsd radix sort .PERIOD for decades ,COMMA it was not something that was ,COMMA difficult to teach ,COMMA 40 years ago .PERIOD and ,COMMA these ,COMMA this equipment ,COMMA is now all pretty much gone .PERIOD but lsd radix sort ,COMMA is still a good algorithm to know .PERIOD not related is something else that was going on with those initials at that time .PERIOD 
we can also get strings sorted by moving from left to right .PERIOD that's called msd string sorter .PERIOD most -DASH significant -DASH digit -DASH first string sort .PERIOD and this is going to kind of ,COMMA kind of related to what we did with quick sort ,COMMA and maybe viewed as a generalization of quick sort .PERIOD so the idea is that we start with the first character ,COMMA to use key index counting on the first character of the array and that will partition it into the strings that start with each character .PERIOD so .PERIOD if we use the first character ,COMMA the left -DASH most character in a string as ,COMMA as the first character in this case ,COMMA then we get all the strings that start with a followed by all the strings that start with b and so forth .PERIOD and then recursively use the same method for each subfile .PERIOD essentially ,COMMA we have a subarray for ,COMMA each of the characters .PERIOD and ,COMMA that cumulate that we built with key index counting gives us the subarrays and actually completely delineates the subarrays that we need to sort .PERIOD remember we had built up this array that said that there's six keys less than d and eight keys less than e and so forth .PERIOD so that tells us exactly precisely the boundaries of the subarray that contain the keys to start with d ,COMMA and then we can just use the same method recursively to sort each of the subarrays one for each character .PERIOD mm .PERIOD now ,COMMA this is a little bit complicated trace ,COMMA but if you look at it more carefully after the lecture you'll see that it's pretty simple ,COMMA setup for what we need to do .PERIOD so ,COMMA here's our input and we sort on the first character .PERIOD if we sort on the first character ,COMMA in this example ,COMMA we have lots of s's .PERIOD so the subfile for the s's ,COMMA it's already sorted on the first character .PERIOD this d is the digit that we're currently working on .PERIOD so then ,COMMA we sort that on ,COMMA it's ,COMMA the rest of it on its first character .PERIOD so it's the second character and all the words that start with s .PERIOD and then there's a lot of them that start with e ,COMMA so we move on to the third character for those ,COMMA and then there's some that start with a and so forth .PERIOD so ,COMMA recursively ,COMMA every time that we move on one character ,COMMA we have to keep going until one thing we have to do ,COMMA is if there's two keys that are equal ,COMMA we have to examine every character in the key .PERIOD we never find out that the two keys are equal until the end .PERIOD and if we reach the end of a string ,COMMA we can just assume that goes before any character value .PERIOD and with those two things ,COMMA then you ,COMMA you can trace through the recursion to see how msd string sort of works .PERIOD so and again ,COMMA in this case ,COMMA it sorts by the first character ,COMMA a and b have only size once ,COMMA so you don't have to do anything .PERIOD so then most of this slide is showing what happens in the keys that start with s ,COMMA and then at the end ,COMMA there's the two keys that start with t ,COMMA and they have both h's and both e's ,COMMA we have to go through the whole thing .PERIOD so that's an example of msd string sort .PERIOD now ,COMMA if strings are variable length like they were in that example ,COMMA we just treat them as if they had an extra character at the end that's smaller than any character .PERIOD so they'll appear before they're supposed to appear alphabetically ,COMMA before strings that have the same starting characters that are longer .PERIOD and you can do that by overloading ,COMMA you know ,COMMA implementing charat to just return minus one ,COMMA if ,COMMA if we're past the character that we're looking at .PERIOD so ,COMMA that's the easy part of the implementation .PERIOD one thing to point out ,COMMA the in the c programming language ,COMMA the representation of strings puts an extra character that's zero at the end and those string has the zero character .PERIOD so ,COMMA actually not to do anything at all .PERIOD but when that change the code for msd string sort is also really an extremely simple modification or extension to key index counting .PERIOD so we've got our sort and it takes its input array and then ,COMMA output buffer ,COMMA and then we have to take the deliminators of the subfile we're going to sort ,COMMA low and high just like we've done for other recursive sorts .PERIOD we go ahead and we do the key index counting ,COMMA again ,COMMA to take care of ,COMMA we have to take care of the fact that we have an extra character that kind of the end of string character .PERIOD and also ,COMMA pull out the d character of our string just like we did for lsd sort .PERIOD and we just go through the whole thing and sort according to the given character .PERIOD and then ,COMMA what we do next is just do a recursive call for every entry in the counter array where we ,COMMA we just sort the part of the array from count of r to lo plus count of r or lo plus count of r plus one .PERIOD really just one line of curve for each subarray .PERIOD and then we move to the right one character .PERIOD so ,COMMA again ,COMMA this is very little code to get a very useful and powerful sorting method ,COMMA that's msd string sorting .PERIOD one thing to notice is that ,COMMA with the ,COMMA extra output buffer ,COMMA we can use that even with the recursive calls ,COMMA but not the counter array ,COMMA we have to keep the counter array around .PERIOD so it's part ,COMMA it's gotta be local to the recursive procedure ,COMMA cuz when we call for the next character ,COMMA we're going to need ,COMMA a new counter array for that character but have to save the old one to do the next subarray for ,COMMA the calling ,COMMA method .PERIOD well that turns out to be important because there's a potential for big problems with msd sort when we start looking at the analysis .PERIOD and the thing to notice is that if you have a tiny array ,COMMA say an array of size two ,COMMA it doesn't matter how small your array is ,COMMA you need to have a counter array for each potential character in the alphabet .PERIOD so for ascii ,COMMA just to ,COMMA to initialize the counter and to set it to zero ,COMMA just create it ,COMMA it's going to be a hundred times slower ,COMMA then just sorting the thing or just copying it back ,COMMA even if you're using unicode ,COMMA it's 32 ,COMMA000 times slower .PERIOD and what's worse is it's a recursive program ,COMMA so there's going to be lots of small subarrays .PERIOD sorry .PERIOD this feature or characteristic of msd string sort actually [inaudible] ,COMMA we're having a lot of applications that were using it when people switched from ascii to unicode a while back .PERIOD all of a sudden programs that were really efficient sorts ,COMMA all of a sudden ,COMMA became hundreds of times slower ,COMMA with the switch to unicode ,COMMA because these big arrays in the recursive ,COMMA these big arrays in the recursive procedure .PERIOD it was a ,COMMA a serious performance problem ,COMMA so we definitely have to watch out for that ,COMMA with ,COMMA msd string sort .PERIOD now there is a good solution to avoid this danger and it's the same solution we've used before .PERIOD if you've got a small subarray and the sort is going to be slower just cut off the insertion sort .PERIOD the other thing you can do is and save some more time ,COMMA is to just have insertion sort start at the character that we're currently working on .PERIOD cuz we know things are ,COMMA equal ,COMMA to the left and we're just looking for the right .PERIOD and ,COMMA that's easy to implement just by changing the implementation of the compare function ,COMMA to take into account which character we're at .PERIOD notice it's quicker ,COMMA and ,COMMA and it happens to be quicker in java to just pull out the substrings and use compare to ,COMMA than to go in and get the charat that's just a feature of the implementation .PERIOD so switching to ,COMMA cutting off the insertion sort for small subarrays is definitely a good idea for msd string sort .PERIOD and so ,COMMA what about the performance of this method ?QUESTIONMARK well the key characteristic of ,COMMA of msd string sorting ,COMMA it examines just the characters that it needs to examine in order to get the c key sorted .PERIOD so ,COMMA that means that its performance is going to be really dependent on the data .PERIOD now ,COMMA in the ,COMMA worst case for the algorithm ,COMMA it has to examine all the data ,COMMA in this case all the characters in all the strings ,COMMA and that's ,COMMA for example ,COMMA when they're all equal ,COMMA it's going to look at all the characters .PERIOD if you have some duplicate keys ,COMMA it might have to examine all the characters in those duplicate keys ,COMMA but there's plenty of other strings that it doesn't examine all the characters .PERIOD so ,COMMA that ,COMMA depending on ,COMMA and end of the keys are random in some way ,COMMA if they ,COMMA or they're approximated by random keys .PERIOD then it's not going to examine very many characters at all ,COMMA actually and this is a typical case ,COMMA say ,COMMA for account numbers or some situation library call numbers or some situation like that ,COMMA in a case like that .PERIOD msd string sort will examine only a small fraction of the data ,COMMA a small constant fraction of the data ,COMMA and it's always going to be sublinear .PERIOD now ,COMMA it's also possible that sorts that do comparisons can be sublinear ,COMMA but msd string sort is ,COMMA you ,COMMA you know ,COMMA good and that it really only examines the characters that need to be examined in order to get the sort done .PERIOD so this gives us another line on ,COMMA on the table ,COMMA and the key here is that if the data is approximated by random log base r of n is going to be pretty well approximated by a constant in the real world .PERIOD so this is going to be a fast method .PERIOD the one danger is that ,COMMA you have to worry out [inaudible] ,COMMA worry about using too much extra space ,COMMA with those big counter arrays .PERIOD but that's a important and useful ,COMMA practical sorting method .PERIOD so now let's look at ,COMMA msd string sort versus quicksort for strings .PERIOD there ,COMMA it ,COMMA they are similar in many ways .PERIOD they're both recursive methods that ,COMMA partition a file up .PERIOD so one of the problems with msd string sort is that ,COMMA it tends to ,COMMA when it's doing the counting ,COMMA it's kind of making random accesses to memory when it ,COMMA particularly when it's distributing the keys out .PERIOD so on modern systems that have caches not everything is in the fastest memory at ,COMMA at the same time and programs that move from one piece of data to another right next are ,COMMA are going to be much more efficient .PERIOD and quicksorts like that ,COMMA an msd quicksort is not .PERIOD another disadvantage of msd string sort is that there's actually quite a few instructions in ,COMMA in our loop .PERIOD with the indexing and accounting .PERIOD and the plus and [inaudible] in the accumulating and so forth ,COMMA whereas quicksort remember is fast ,COMMA because it has only a few instructions in the inner loop .PERIOD and amnesty strings are used as extra space ,COMMA whereas quick sort ,COMMA there's two things ,COMMA one is ,COMMA it's not linear in these applications ,COMMA where msd string sort is ,COMMA and kind of the reason that it's not linear ,COMMA is that if you've got keys that have a lot of the same characters at the beginning ,COMMA when it's doing the compares ,COMMA it has to rescan or recompare ,COMMA lots of those characters .PERIOD so ,COMMA what were going to look at next ,COMMA is try to get this ,COMMA achieve this goal ,COMMA of combining the advantages of ,COMMA of these two sorting algorithms .PERIOD 
now ,COMMA we'll take a look at how the sorting algorithms that we talked about or expressed in the systems that we use everyday .PERIOD now ,COMMA the key point is that sorting algorithms rhythms are essential in a very broad variety of applications and ,COMMA and all of us use sorting algorithms pretty much every day .PERIOD many obvious out applications like or ,COMMA organizing your music library or displaying your search results or listening feeds in your in your web browsers .PERIOD there's some other applications that are not so obvious where we use sorting as a to make a problem easy once you know that they're sorted .PERIOD and so ,COMMA for example ,COMMA finding the median and if it's already sorted ,COMMA it's much easy to find the median .PERIOD and now ,COMMA the statistical problems are like that or finding duplicates .PERIOD probably finding duplicates by itself is not quite obvious what to do but the easy way to solve it is to just go ahead and sort .PERIOD and then there are plenty of applications that we'll see later in this course like data compression or computer graphics like finding the convex hull ,COMMA applications in science such as computational biology or ,COMMA or in systems development .PERIOD we're having a efficient sort as absolutely crucial .PERIOD so ,COMMA because there's all these applications most programming systems have a fast sort as an important part of their infrastructure and java is no exemption .PERIOD so ,COMMA java has a method called arrays .PERIODsort and it's intended to be a general purpose sorting method for use by java programmers .PERIOD and now ,COMMA that you have some understanding of the classic methods you can have a better idea of why arrays .PERIODsort is the way that it is .PERIOD so it has the infrastructure that allows us to be used for all types of data types and all types of ordering so it's got a method that implements comparable then its got methods easy compare order .PERIOD so that you can use the natural order or you can provide a compare order and provide your own order for any type of data .PERIOD it uses actually both quicksort and mergesort .PERIOD it uses two quick sort for primitive types of data and a two mergesort for objects .PERIOD why two different well it's just the designer's assessment of the idea that if a programmer is using object maybe spaces ,COMMA not a ,COMMA a critically important consideration .PERIOD and so ,COMMA the extra space used by merge sort maybe is not a problem .PERIOD and if the program is using primitive types ,COMMA maybe performance is the most important thing .PERIOD and so ,COMMA then we'll use the quicksort .PERIOD to invoke arrays that sort ,COMMA you have to import the name space from java .PERIODutil .PERIODarrays and then all you need to do is invoke arrays .PERIODsort .PERIOD so i just answered this question ,COMMA why do we use different algorithms for the two types ?QUESTIONMARK and this is ,COMMA is maybe arguable .PERIOD now are referred to this idea of a good system sort ,COMMA there was a good system sort that a lot of people used for many years .PERIOD and in 1991 ,COMMA there were some scientists that ,COMMA that bell labs that were using qsort for a scientific problem and they were used to taking just a few minutes and then they realized that it was taking hours of cpu time .PERIOD and the fact was that all the qsort implementations at that time in unix had this flaw well ,COMMA there are two flaws and one of them is a little complicated about the way they are raised order and the other one was for a raise that had lots of equal keys and this is wilks and becker problem and have lot of equal keys ,COMMA it was quadratic time .PERIOD so ,COMMA the system designer ,COMMA jon bentley was one of the designers to take a look at these problems and that lead ultimately to the development of the 3 -DASH way quick sort that were used today .PERIOD he worked with doug mcilroy and they wrote a ,COMMA a ,COMMA a paper that outline this problem and talk about some of these things and they had a three -DASH way partitioning method that was somewhat like the dijkstra method that we showed but a bit more complicated .PERIOD anoth er thing they did was rather than shuffling the array .PERIOD they [cough] used what's called a method for choosing partitioning element called tukey's ninther .PERIOD tukey is a statistician and he had this particular method for order statistics that has some interesting properties and use that for the partitioning element .PERIOD this paper was very influential and ,COMMA and that basic method is widely used .PERIOD and tukey's ninther is just pick nine items out of the array and take the median of the mediums and that's the ninther .PERIOD so very inexpensive and they had macros to do this so and use not too much cost to find a partitioning element that's much closer to the middle than ,COMMA and if you use a ,COMMA a random one .PERIOD so the ,COMMA the reason they used that is they thought they got them closer to the middle and they also don't like the ,COMMA some system designers don't like the idea of using random choices in a system method because of way that it changes the state of the system .PERIOD so they felt that they got better partitioning than a random shuffling and it was also less costly and then generating random numbers including this change of state problem .PERIOD but there's a problem so you would think that the system sort would be completely solid with all this resource with all these research and all of the development that's going into it .PERIOD in fact there's a file out there in your book site and get it that will actually break the java system sort .PERIOD there was a killer input that will make the thing run in quadratic time .PERIOD actually it usually crashes because it's recursive and it crashes the system stack .PERIOD and it can cause all sorts of problems .PERIOD there's a killer input for the system sort and ,COMMA and it can be disastrous in various systems and the reason is ,COMMA they didn't do the random shuffling .PERIOD mcilroy ,COMMA himself ,COMMA actually found this problem that you could while the sort is running figuring out an inp ut that would make it crash .PERIOD and so ,COMMA you can just run that program and if the sort doesn't use randomness then it's vulnerable to this attack .PERIOD so which algorithm should we use to sort that's ,COMMA that's really a key question .PERIOD we've looked at lot of sorting algorithms and actually ,COMMA there's hundreds of sorting algorithms out there and we have chosen the most important and the most interesting for you but you could literally spend a year reading all the papers on sorting and then you still continue to be invented new algorithms are developed and that are found to have good characteristics all the time .PERIOD and really ,COMMA the key idea is really important to think about cuz it applies to all sorts of algorithmic problems .PERIOD on our way ,COMMA we've been talking about rules of the game .PERIOD what is it that we care about in a sort ?QUESTIONMARK it's a little bit more complicated than just put stuff in order .PERIOD there's a lot of attributes ,COMMA the different applications have .PERIOD like stability ,COMMA that's a fairly sophisticated attribute that you really have to think about ,COMMA you maybe not be aware of .PERIOD maybe your computer is parallel and the sort has to be parallel and we found that equal keys make a huge difference .PERIOD and i didn't really think about that at the beginning but it can make a huge difference .PERIOD maybe the way your computer's memory is organized make a difference .PERIOD maybe the keys are small and the items are large or maybe the keys are really huge .PERIOD do we need guaranteed performance ?QUESTIONMARK are we happy with random performance ?QUESTIONMARK do we know ,COMMA is the array randomly ordered ?QUESTIONMARK you can think of a matrix shown in the right here where we list out all the possible attributes and then there's algorithms that worked well for different combinations of attributes .PERIOD but the thing is ,COMMA there is way more possible combinations of attributes than there are algorithms .PERIOD so there is going to be situations that are going to require an understanding of what it takes to engineer a ,COMMA a sort method that's appropriate for your application .PERIOD there can't be a system sort out there that's going to cover all possible combinations of attributes .PERIOD now ,COMMA usually it's going to be good enough but it's definitely worth while to understand what's going on with different sorting algorithms in order to even find improved performance over the system sort .PERIOD so ,COMMA here's the summary of some of the things that we've talked about .PERIOD we've talked about six different sorting algorithms .PERIOD then ,COMMA we've talked about a bunch of attributes .PERIOD for example ,COMMA the top line ,COMMA selection sort is in place it always takes about n^2 / two comparisons .PERIOD and one of the things to remark about it is that it only uses n exchanges and so forth .PERIOD insertion sort best case linear ,COMMA quadratic ,COMMA and place unstable .PERIOD and it'll work well if the file is small or partially ordered .PERIOD shellsort ,COMMA we don't know it's a running time ,COMMA it's not stable but it's a fast method for intermediate size files and not much code .PERIOD mergesort and log n guarantee unstable but not in place ,COMMA need that auxiliary array .PERIOD quicksort not stable .PERIOD quadratic time worst case but that's unlikely to occur if you do the random shuffling .PERIOD and its the fastest and most useful in practice particularly if you make improvements to deal with duplicate keys .PERIOD and it's interesting to note we've looked at important and classic algorithms that are widely deployed but we don't have a ,COMMA a useful ,COMMA practical algorithms that are widely used that's got all of these characteristics that's in place and stable worst case n log n .PERIOD there's versions of merge sort that come close but they are too complex for practitioners to have adopted them .PERIOD those are some of the situations that we encounter when developing a system sort .PERIOD and ,COMMA quicksort certainly plays a role in most system sorts .PERIOD 
next we're gonna talk about 3 -DASH way radix quicksort which is that algorithm that combines the benefits of quicksort and msd radix sort .PERIOD this algorithm actually came to me into development during the development of this course .PERIOD as it turns out ,COMMA radix sorting ,COMMA while it was really well known to everyone in the 60's and70's .PERIOD it was kind of lost sight of for a while in the'80's as people moved to a higher level of programming languages .PERIOD and it wasn't so easy or effecient to get characters out of keys .PERIOD you had to either work with numbers .PERIOD you had to use abstractions like compared to .PERIOD and radix sort got kind of lost for a while .PERIOD but then string processing became more and more important as .PERIOD computers became bigger and faster and so we needed to talk about how to sort strings and this algorithm is a really simple algorithm that comes out when you start to address that problem .PERIOD so ,COMMA the idea is that what we're gonna do is use 3 -DASH way partitioning for quicksort .PERIOD but just by character .PERIOD so since there's a ,COMMA we're gonna do one character at a time ,COMMA there's gonna be a lot of equal keys for that character .PERIOD and the idea is that when you do have equal keys ,COMMA you'll pull'em together with those leading characters ,COMMA and then you could recursively sort the subarrays ,COMMA but you can do the normal quicksort thing for those .PERIOD so for this example ,COMMA when we partition ,COMMA first partitioning item ,COMMA we're going to use it's first character ,COMMA and we're going to divide up into less than that .PERIOD equal to that and greater than that .PERIOD and then we re -DASH curse three times ,COMMA one for the greater one for the ones that start with the same character and one for the less .PERIOD that's overview of the algorithm .PERIOD so ,COMMA let's do just a ,COMMA a quick trace of the first few recursive calls .PERIOD so ,COMMA partitioning item ,COMMA again ,COMMA is s .PERIOD we divide it up that way .PERIOD and so now ,COMMA we're gonna sort the top subarray ,COMMA the ones that are less than s .PERIOD so we partition that out in b and then we get down to subarrays ,COMMA size one .PERIOD and the next thing that we need to do is the big middle sub -DASH file .PERIOD we need to sort it on its second character ,COMMA so the partition item is e this time .PERIOD so we rearrange those to have the ones that start with s ,COMMA e .PERIOD the ones that are less and there aren't any ,COMMA and the ones that are bigger .PERIOD and so next recursion is on the third letter in that middle subfile .PERIOD in this case ,COMMA it's a ,COMMA and so we have ,COMMA the ones that are equal ,COMMA so that's the ones that start with sea and the ones that are bigger of the two cells and then move on to the next character .PERIOD so it ,COMMA it's of the ones that are equal in kind of a controlled way .PERIOD that's a example of a trace for 3 -DASH way string quicksort .PERIOD now it's a program that almost writes itself .PERIOD once you've seen the idea and you've seen an implementation of quicksort ,COMMA it's a very minor modification into the 3 -DASH way quicksort that we discussed when we were talking about quicksort .PERIOD instead ,COMMA so we pick out the dth character .PERIOD we take d as an argument ,COMMA we pick out the dth character we do the regular partitioning element .PERIOD again ,COMMA picking out .PERIOD just the dth character for each key that we look at .PERIOD and this is the standard three way partitioning .PERIOD and then when we're done with the partitioning ,COMMA we do the array of ones that are less chara -DASH  ,COMMA that dth characters less than the ones that are bigger .PERIOD and then in the middle ,COMMA if we had any ,COMMA we'd sort the middle sub -DASH ray and we'd move over one character .PERIOD that's a ,COMMA a very compact string sorting algorithm that performs very well .PERIOD now ,COMMA what about the performance of that algorithm ?QUESTIONMARK well ,COMMA we talked about .PERIOD standard quicksort performance .PERIOD and ,COMMA if we randomly order the keys ahead of time .PERIOD you use 2n natural log int string compares ,COMMA on average .PERIOD and ,COMMA the thing is ,COMMA though ,COMMA if you have keys that have lots of long common prefixes .PERIOD and this happens in lots of applications .PERIOD then ,COMMA those compares are gonna go through all those keys every time .PERIOD that 3 -DASH way string quicksort uses ,COMMA although the analysis is pretty complicated ,COMMA it uses only 2n ln n character compares ,COMMA so that's an amazing ,COMMA a huge savings for typical common cases .PERIOD it doesn't have to ,COMMA go through the long common prefixes that usually cause the problem .PERIOD and what about versus msd's or ,COMMA .PERIOD well ,COMMA msd sort has this caching problem and it's got the count arrays and it's got all this overhead involved in maintaining the counts .PERIOD whereas three way string quick -DASH sort is still cash friendly ,COMMA 'cause most of the time ,COMMA it's partitioning the same way that normal quick sort is .PERIOD it's still got that short inner loop and it doesn't use any extra space .PERIOD and there's all kinds of applications that for example library call numbers or account numbers where long string keys that have non randomness in them .PERIOD this algorithm adapts really well to such situations .PERIOD the bottom line is if you've got string keys ,COMMA 3 -DASH way string quicksort is the method of choice .PERIOD it's simple to implement ,COMMA and it's gonna perform well so i'll probably leave sorting algorithms with this bottom line .PERIOD and the idea is that now we've got a quite fast algorithm that ,COMMA does a linear rhythmic number of character compares ,COMMA and that's in randomly ,COMMA random keys in some way .PERIOD but even if they're not random ,COMMA it's difficult to characterize really the worst case .PERIOD but it's more ,COMMA when data is not or this algorithm won't perform well ,COMMA and even better chance of getting sub -DASH linear performance then all the other algorithms .PERIOD that's 3 -DASH way radix quicksort .PERIOD 
 .PERIODfinally finally we're going to look at suffix arrays and string processing using this data structure that has really played a very important role in ,COMMA string processing applications that would not otherwise be possible .PERIOD to get a feeling for the idea ,COMMA we're going to look at a really old idea that you're actually familiar with called keyword in context search .PERIOD and the idea is that you're given a text ,COMMA a huge x and what you want to do is pre -DASH process it to enable fast substring search .PERIOD that is ,COMMA you want a client to be able to give a query string and then you want to give all occurrences of that query string in context .PERIOD so ,COMMA if you look for the word ,COMMA search ,COMMA it will give all the occurrences of where the word search occurs in context .PERIOD or better thing is another one .PERIOD and that's a ,COMMA a very common operation .PERIOD one ,COMMA you're certainly familiar with it from web searching ,COMMA in your browser .PERIOD and there's many other applications .PERIOD this is a pretty old idea that dates back to the late 50's ,COMMA early 60's people have always wanted to do this .PERIOD and there's an easy way to look at it called suffix sorting .PERIOD the idea is you take your input string ,COMMA and then ,COMMA form the suffixes .PERIOD remember when i talked about at the beginning with java's string data type ,COMMA you can get this done in linear time because each suffix is basically a pointer back into the input string .PERIOD so the suffix ,COMMA remember ,COMMA the i suffix just start the character i and take the rest of the string .PERIOD so ,COMMA what this does is ,COMMA it gives ,COMMA sort keys ,COMMA that ,COMMA contain ,COMMA kind of the ,COMMA the ,COMMA pieces of the string itself in context and all we do is just ,COMMA run a sort on that suffix .PERIOD and what that sort does is ,COMMA it brings if you do a search ,COMMA it brings the things that you're searching for ,COMMA close together .PERIOD and ,COMMA you can use ,COMMA once you've done that suffix sort ,COMMA you can use a binary search to find all occurrences of the string out of there .PERIOD that's the ,COMMA basic idea of a keyword and context searching .PERIOD you suffix sort the text ,COMMA then do binary search to find the query that you're looking for .PERIOD and then you can ,COMMA scan for wherever the binary search ends up .PERIOD and so ,COMMA this is all the places where ,COMMA the word search occurs ,COMMA in the text of tale of two cities ,COMMA and then ,COMMA you can use this index ,COMMA to ,COMMA print out the context of whatever's needed .PERIOD it's a fine and effective way ,COMMA for solving this important practical problem .PERIOD and that's interesting ,COMMA but i want to talk about another really important problem that ,COMMA it has ,COMMA hugely important applications .PERIOD this is the longest repeated substring problem .PERIOD so you're given a string of characters ,COMMA find the longest repeated substring .PERIOD in this case ,COMMA this is genomic data ,COMMA and ,COMMA there's the example of the longest ,COMMA repeated substring .PERIOD and now ,COMMA in scientific data ,COMMA the long repeated substring is often something that scientists are looking for .PERIOD and so ,COMMA and these strings are ,COMMA are huge .PERIOD it might be billions of these ,COMMA characters .PERIOD and so ,COMMA it's really important ,COMMA not only to know that you can find long substrings efficiently ,COMMA but also ,COMMA that you can do it for ,COMMA huge ,COMMA huge strings .PERIOD another example is ,COMMA cryptanalysis .PERIOD where ,COMMA a long repeat in a file that's supposed to be ,COMMA encrypted random file indicates that somebody did something wrong .PERIOD it might be the key to ,COMMA breaking the code .PERIOD another example is data compression .PERIOD when you've got a file that's got a lot of repeated stuff in it ,COMMA you might ,COMMA want to do this operation ,COMMA to take advantage of ,COMMA of these long repeats and not keep multiple copies of them .PERIOD here's another example ,COMMA this for ,COMMA studying or visualizing repetitions in music .PERIOD in this example ,COMMA every time there's a ,COMMA a repeat of the notes then ,COMMA there's ,COMMA a ,COMMA an arch drawn to ,COMMA visualize the repeat .PERIOD and it's ,COMMA the arch is thick if ,COMMA the number of repeats is long .PERIOD and it's high if the repeats are far away .PERIOD and this ,COMMA tells ,COMMA is an interesting way to analyze ,COMMA repetitions ,COMMA in music .PERIOD so ,COMMA how are we going to solve this problem ?QUESTIONMARK very simple to state problem .PERIOD given a sequence of n characters ,COMMA find the longest repeated substring .PERIOD as with many problems ,COMMA there's ,COMMA an easy ,COMMA brute force algorithm ,COMMA that ,COMMA at least gives us an idea of what ,COMMA what the computation is like .PERIOD but it's not going to be useful for huge strings .PERIOD and that's you try all possibilities ,COMMA all pairs of indices i and j and then just compute the longest common prefix for each pair .PERIOD the problem with that is that if n is the length of the string ,COMMA you've got ,COMMA n squared over two pairs .PERIOD and for every one of those pairs ,COMMA you might have to ,COMMA match them up to length d .PERIOD it's definitely quadratic time ,COMMA more than quadratic time in the length of the string .PERIOD and can't be using that for ,COMMA you're not going to be able to use that for strings that are billions of characters long .PERIOD another way to look at one way to solve the longest repeated substring ,COMMA is to use a suffix sort .PERIOD in fact ,COMMA just we talked about before .PERIOD so ,COMMA i would take out our input string .PERIOD reform the suffixes .PERIOD and then sort the suffixes and that brings the long repeated substrings together .PERIOD so ,COMMA that's a quite elegant and efficient solution to this problem .PERIOD just build the suffix array that's a linear time process .PERIOD do the sort .PERIOD we ,COMMA we just saw we can do that ,COMMA with n log n character ,COMMA character compares .PERIOD and then go through and find the repeated the substrings .PERIOD so ,COMMA it's just one passthrough to check for adjacent substrings to see which one's the longest .PERIOD and this is very easy to code up .PERIOD here's the java code for computing the longest repeated substring .PERIOD we get the length of our string out .PERIOD we build our suffix array .PERIOD remember that's linear time and space because of java string implementation allows us to do substring and constant time .PERIOD then we go ahead and sort the suffixes ,COMMA and then find the least common prefix between the ,COMMA adjacent suffixes in sorted order .PERIOD just keep track of the max so that's longest ,COMMA repeated substring .PERIOD and if so ,COMMA for example ,COMMA this sentence about such a funny ,COMMA sporty ,COMMA gamy ,COMMA jesty ,COMMA joky ,COMMA hoky -DASH pokie ,COMMA lad ,COMMA is the longest repeated substring in the text of melville's moby dick .PERIOD and now we run that one to ,COMMA prove that we've got a linear -DASH rhythmic algorithm because there's a lot of characters in that .PERIOD and you're not going to find this ,COMMA without a good algorithm .PERIOD and ,COMMA and this is just a humorous approach to what we've ,COMMA talked about today .PERIOD if you have ,COMMA five scientists that are looking for a long substring ,COMMA in a genome ,COMMA that ,COMMA they might encounter ,COMMA this problem ,COMMA with a billion nucleotides ,COMMA and there are plenty of scientists that are not aware of ,COMMA important algorithms are the ones ,COMMA like the ones that we are talking about .PERIOD and the one that uses the good algorithm is definitely more likely to find a cure for cancer .PERIOD but there is a flaw even in this ,COMMA that computer scientists discovered as they got into ever more complex algorithms for problems like this ,COMMA and that is if the ,COMMA the longest repeated substring is long ,COMMA there's a problem .PERIOD so this is just some ,COMMA experiments ,COMMA for ,COMMA finding the longest ,COMMA repeated substring in various files .PERIOD from just a program to ,COMMA the text of moby dick .PERIOD or a chromosome with 7 .PERIOD1 million characters .PERIOD and ,COMMA using ,COMMA the ,COMMA brute force method ,COMMA you get stuck ,COMMA and too slow ,COMMA very soon .PERIOD but using ,COMMA a suffix sort ,COMMA you can get these jobs done ,COMMA even for huge files like the first ten million digits of pi .PERIOD by the way ,COMMA if there was a really long repeated substring in the first in the digits of pi ,COMMA that would be news .PERIOD maybe it would help us ,COMMA understand more ,COMMA about this number .PERIOD so lots of people ,COMMA write programs of this sort .PERIOD but the big problem is if you have a really long repeated substring ,COMMA then suffix sort is not going to work .PERIOD our fast algorithm ,COMMA doesn't complete .PERIOD so what's going on ?QUESTIONMARK in the explanation is really simple .PERIOD if ,COMMA for example ,COMMA you have two copies of something .PERIOD when you form the suffix array ,COMMA what happens is that if you have the longest repeat ,COMMA but you also have every version of that repeat appears .PERIOD and you have to look for those when checking ,COMMA for the longest repeated substring .PERIOD so ,COMMA if d is the length longest match ,COMMA then ,COMMA just to check for the longest common prefix ,COMMA you got to do ,COMMA at least one + two + three + four up to d character compares .PERIOD which means it's going to be quadratic just for checking for the longest common prefix of adjacent ,COMMA elements in this algorithm .PERIOD it's also a problem for the sort .PERIOD so ,COMMA if you have very long repeats ,COMMA we still don't have an algorithm .PERIOD so ,COMMA the question is ,COMMA that was confronting ,COMMA computer scientists ,COMMA in the late 80's ,COMMA early 90's is how can we get this done ?QUESTIONMARK what's the best algorithm for this problem ?QUESTIONMARK and there was a great algorithm called the manber -DASH myers algorithm ,COMMA that i'll talk about in just a minute .PERIOD that got the job done in linear rhythmic time .PERIOD and actually ,COMMA there's a clever old algorithm that uses the data structure called ,COMMA suffix trees .PERIOD but it was really the manber -DASH myers algorithm that ,COMMA got people ,COMMA excited about this area .PERIOD and so ,COMMA i want to describe that ,COMMA briefly .PERIOD actually ,COMMA these two computer scientists ,COMMA one of them went on the become chief scientist of an internet company .PERIOD the other one went on to become chief scientist of a company that won the race in sequencing the genome .PERIOD in both cases ,COMMA good algorithms for processing long strings are very important .PERIOD and this is a great algorithm .PERIOD now ,COMMA it's a little too complex to give all the details in a lecture ,COMMA but i can give a pretty good idea of how it works .PERIOD so the overview is that ,COMMA it's kind of like an msd ,COMMA sort .PERIOD but ,COMMA what it manages to do is double the number of characters that it looks at in each passthrough of the array .PERIOD and ,COMMA the idea is that ,COMMA you ,COMMA since you're doubling the number of characters that you look at each time .PERIOD it ,COMMA it finishes in ,COMMA log in time that's the size of the ,COMMA suffix array .PERIOD if ,COMMA if you double until you get n ,COMMA it's log n .PERIOD and it turns out ,COMMA what's really ingenious about the algorithm is that ,COMMA you can do it ,COMMA do each phase in linear time .PERIOD so ,COMMA this is an example of how it works .PERIOD so ,COMMA it's ,COMMA we going to do a suffix sort .PERIOD and then i'll ,COMMA i'll talk about the least common prefix as well in a minute .PERIOD so ,COMMA sorting the first character ,COMMA while we just use key ,COMMA key index counting or something like that .PERIOD so we know how to do that ,COMMA in linear time .PERIOD and then the idea has given that sorted on the first character .PERIOD we can sort it ,COMMA easily sort on the first two .PERIOD well again ,COMMA we could use ,COMMA key index counting .PERIOD so now ,COMMA what we can do is ,COMMA double the number of characters that we ,COMMA involve each time .PERIOD so ,COMMA the next phase of the manber -DASH myers algorithm ,COMMA now gets it sorted on four characters .PERIOD and ,COMMA of course ,COMMA as we ,COMMA the more characters we have sorted on at the leading part ,COMMA the smaller the [inaudible] files in the trading ,COMMA in the trailing part .PERIOD so ,COMMA that's ,COMMA certainly a feature .PERIOD and then ,COMMA in this case ,COMMA after we get to ,COMMA eight characters ,COMMA and all our sub files are of size one ,COMMA and we're done with the sort .PERIOD now ,COMMA the key to the algorithm is ,COMMA the idea that ,COMMA once it's going ,COMMA it uses what's called an index sort ,COMMA which essentially means that it can do compares in constant time in the middle of the algorithm .PERIOD now ,COMMA lets just take a look at ,COMMA at ,COMMA at how that works .PERIOD so lets look at ,COMMA trying to compare string zero with string ,COMMA nine .PERIOD and we know that we've already got the thing sorted on ,COMMA four characters and we want to sort it on eight so ,COMMA zero and nine are equal on the first four characters .PERIOD they're in the same subfile .PERIOD so ,COMMA now we're going to get it sorted on the other .PERIOD but the thing is if we add four to our given indices .PERIOD so ,COMMA we're at zero ,COMMA and we add four .PERIOD that gets us to four ,COMMA and we're at nine .PERIOD we add four that gets us to thirteen .PERIOD we already know that the thing is sorted on those characters .PERIOD and ,COMMA we know that ,COMMA thirteen appears before four in this sorted list .PERIOD it's already sorted .PERIOD and we can keep track of that by ,COMMA using an inverse array which says ,COMMA for every index ,COMMA where it appears in the sorted order .PERIOD so ,COMMA this says that thirteen appears at position six ,COMMA and four appears at position seven .PERIOD that is ,COMMA thirteen appears before four .PERIOD so ,COMMA when we're trying to compare ,COMMA the ,COMMA this ,COMMA string here ,COMMA that's the zeroth suffix with the ninth suffix ,COMMA we can go in and again ,COMMA add four to get four ,COMMA add four to get thirteen go into the index array and see which one is less and the one that appears first is going to be less .PERIOD so ,COMMA that's a constant time ,COMMA comparison .PERIOD thirteen is less than or equal to four because the inverse of thirteen is less than the inverse four ,COMMA which means that suffixes of nine ,COMMA if you take eight characters out of nine and eight characters out of zero ,COMMA it's less .PERIOD it's a really ,COMMA simple and of course ,COMMA easy to implement operation .PERIOD so ,COMMA maintaining the inverse ,COMMA i can get constant time string compare .PERIOD so ,COMMA what does that imply ,COMMA for the whole suffixsort ?QUESTIONMARK ?QUESTIONMARKuh well ,COMMA with a constant time compare ,COMMA then ,COMMA i can get ,COMMA at a minimum ,COMMA i can get an ,COMMA an analog n sort ,COMMA just by using quicksort or mergesort .PERIOD and then ,COMMA i get much faster than quadratic performance no matter what the strings are .PERIOD that's a big key to the success of this algorithm .PERIOD and actually ,COMMA if ,COMMA if you use a version of three -DASH way quicksort ,COMMA it's been proven that it even gets down to linear time for the sort ,COMMA no matter what the input is .PERIOD that's one thing ,COMMA and then the other thing is when you need to do ,COMMA the longest common prefix to look for the ,COMMA longest match after the array is sorted you can also do this constant time ,COMMA string compare and get the job done .PERIOD so this is really an in -DASH  ,COMMA ingenious algorithm that ,COMMA can get ,COMMA suffix sorting done very fast .PERIOD even in the presence of ,COMMA a huge repeat .PERIOD and i think really underscores ,COMMA the importance of careful algorithmic thinking ,COMMA in addressing new computational challenges .PERIOD so ,COMMA string sorting ,COMMA just to summarize ,COMMA is a really ,COMMA interesting area of inquiry .PERIOD for one thing ,COMMA we can develop linear time sorts for many ,COMMA many applications .PERIOD we ,COMMA we thought ,COMMA we're doing well when we had ,COMMA n log n sorts ,COMMA but actually we can do much better for many applications .PERIOD and in fact ,COMMA we can even get to sublinear where we don't even have to examine all the data .PERIOD in today's world ,COMMA when we have huge amounts of data ,COMMA to be able to ,COMMA get it sorted without even looking ,COMMA at it at all is really quite a miracle .PERIOD three -DASH way string quicksort ,COMMA ,COMMAyou you can't do better than that in terms of the numbers of characters that you have to ,COMMA examine .PERIOD and it's a lot of deep mathematical analysis ,COMMA behind that result .PERIOD but i think the other lesson to learn is that algorithms like three -DASH way string quicksort and manber -DASH myers ,COMMA show that we really have a lot to learn still in string processing .PERIOD and they're not really random .PERIOD in fact ,COMMA a lot of times we're looking for non -DASH randomness and we might want to use specialized algorithms .PERIOD so ,COMMA at string processes or introduction to string processing ,COMMA we're going to look at many other string processing examples in the coming lectures .PERIOD 
welcome back .PERIOD today ,COMMA we're going to look at priority queues which is a variant of sorting that generalizes the idea to provide more flexible data structure that we can use for all sorts of applications .PERIOD to get started ,COMMA we'll look at the api and some elementary implementations .PERIOD so at a week or so ago ,COMMA we looked at collections in java and the idea of elementary data structures where we insert and delete items .PERIOD and then ,COMMA the data structures differ on the basis of which item we choose to delete .PERIOD we looked to the push down stack where we removed the item that was most recently added ,COMMA and the queue where we remove the item that was least recently added .PERIOD and then ,COMMA we talked about randomized queue or bag where we might remove a random or an arbitrary item .PERIOD today ,COMMA what we're going to talk about is called the priority queue and for that ,COMMA we insert items ,COMMA but when it's time to remove ,COMMA we consider the items to have a total order and we want to remove the largest or the smallest item .PERIOD so this little example if we insert p ,COMMA q ,COMMA and e then when we do remove max ,COMMA we want to get the q out and for later ,COMMA we insert x ,COMMA a ,COMMA and m and then we removed max .PERIOD the largest one in there is x .PERIOD we'll insert p ,COMMA l ,COMMA and e and then ,COMMA after a while ,COMMA we remove max p .PERIOD so ,COMMA that's our basic setup .PERIOD that's our definition of what a priority queue is .PERIOD so ,COMMA the api will look very similar to our stack or queue api with a difference that we want to have generic items that are comparable .PERIOD so the java language for that is in the class header .PERIOD we say that our generic type key extends comparable of key .PERIOD and that just means that our keys must be comparable and we must have a compareto() method that will compare it to another key .PERIOD otherwise we have a constructor and actually for some applications ,COMMA it's convenient to have a constructor that takes an array of keys as argument .PERIOD then ,COMMA an insert() that puts something in like push in a stack or enqueue in a queue .PERIOD then delete the maximum .PERIOD i referred to delete the minimum just to avoid confusion ,COMMA we have the implementation separate implementation usually minpq ,COMMA where we delete the minimum .PERIOD then test isempty() and we also sometimes have extra method that just gives us the value of the largest key and also size which is useful sometimes in collections .PERIOD you might also want it to be iterable but we'll skip that for now .PERIOD there are lots and lots of applications of priority queues .PERIOD even though it emerged as a data structure relatively late in the game now that we see that there are many algorithms that are much easier to implement when we think about the priority key abstraction .PERIOD we have data that we are processing we can't process it all at once .PERIOD we have to save it some of way .PERIOD and then ,COMMA what the priority queue tells us is  -DASH   let's organize it in some ways that we are always taking the best one to process next .PERIOD and it turns out to be very close to a generic algorithmic design technique that we will be looking at in many ,COMMA many different applications .PERIOD today ,COMMA we're going to talk about event -DASH driven simulation which is an interesting idea that is based on priority queues but it's also used in numerical computation and we'll see in algorithms for data compression and graph searching that it's useful .PERIOD and in many other applications in computer science and in scientific computing .PERIOD it generalizes the stack and the queue and gives us a data structure that we can use to effectively design algorithm of all sorts .PERIOD so here's just a particular client that will help explain the idea .PERIOD so our ,COMMA our challenge is let's say this is on the web we have billions of transactions ,COMMA you know ,COMMA and they are streaming through our data warehouse or processor in some way .PERIOD and just a very ,COMMA very huge number of transactions .PERIOD in fact ,COMMA we couldn't possibly hope to even store them all .PERIOD there's trillions of them there coming through as fast as possible .PERIOD but we're interested in the biggest ones and so maybe it's the biggest amount of dollars ,COMMA or the biggest cost ,COMMA or whatever it might happen to be .PERIOD and so we can pick some numbers that we can store .PERIOD i would like to ,COMMA to store the ,COMMA the thousand biggest ones .PERIOD so ,COMMA you can imagine a credit card company looking for fraud  -DASH  it's going to care about keeping track of the largest transactions .PERIOD so ,COMMA maybe we can store millions or thousands of them .PERIOD so that's our parameter m  -DASH  that's the number we can afford to store but the total number of items we couldn't possibly afford to store them .PERIOD so and this is just some test data where we've got all ,COMMA all these transactions and so we are going to be able to take in data like this and again an unbounded stream of data .PERIOD but let's say ,COMMA we want to keep track of the top five [cough] values using the third column as the value .PERIOD so we're going to look at a client program called topm that takes the command -DASH line argument ,COMMA how many and this case ,COMMA it's going to say five and then it's going to take from standard input the transactions and it will print out the top five .PERIOD so ,COMMA that's a canonical example of a ,COMMA a priority queue client that we need to design a program that can do that .PERIOD so ,COMMA with the priority queue abstraction that's not too difficult to do .PERIOD so we are going to use a min -DASH oriented priority queue so that's going to keep ,COMMA it'll [cough] it'll be one where we can delete the minimum and ,COMMA and it'll be generic so we'll have a transaction type that holds this information including natural ordering where it's ordered by dollars that last column .PERIOD so ,COMMA we'll build a new priority queue ,COMMA min priority queue or we'll have the capability to delete the minimum .PERIOD and then we read from standard input .PERIOD we read the line ,COMMA build the transaction from the information on that line .PERIOD and that will fill in the fields and then ,COMMA we put that transaction on the priority queue .PERIOD now ,COMMA if the priority queue has more than m items because we inserted that one ,COMMA then we want to delete the smallest one there and that way ,COMMA we're keeping track of the largest m .PERIOD whenever we get a new one ,COMMA then we throw away the smallest one that's there .PERIOD so ,COMMA even with this huge stream of items coming through ,COMMA we're only keeping track of the m largest items and that's a fine canonical client for priority queue .PERIOD now how we are going implement or solve this problem or you can think of lots of ways to go ahead and solve this problem of finding the largest m items in the stream of n items .PERIOD so ,COMMA for example ,COMMA you could sort them .PERIOD and then just look at the m at the end but by sending up the problem ,COMMA i already kind of ruled that one out because we don't have the space to sort them all ,COMMA to store them all .PERIOD so sorting is out of the question .PERIOD we'll look at couple of elementary priority queue implementations that are straightforward .PERIOD you know ,COMMA keep the items like we would in the stack and then when we need to find the smallest or the largest look at ,COMMA look at them all .PERIOD but that's going to be too slow .PERIOD m is large and n is huge ,COMMA and m<i>n is going to be too slow .PERIOD what would what we we'll look at is</i> very simple and practical implementation using a data structure called the binary heap that gets the job done in time proportional to n log m and only m space .PERIOD and that's pretty close to the best that we could do in theory and is very important and useful ,COMMA practical implementation and data structure .PERIOD alright .PERIOD so here's just an overview of two elementary implementations for priority queues using the example operations that i gave before .PERIOD so you can imagine keeping the item ,COMMA say ,COMMA in a linked list or in a doubling array and just keeping just an order just as we would in the ,COMMA in the stack just keeping in the way that they come in .PERIOD and we'll put a new item at the end of the array and remove it from the end of the array .PERIOD or you could do it in a linked list ,COMMA and then when it's time to find the ,COMMA remove the maximum ,COMMA you have to scan through everything to find the maximum .PERIOD so ,COMMA so ,COMMA that's a one way you could implement this with ,COMMA with a linked list or with the resizing array .PERIOD or you might to say well let's try to keep things in order .PERIOD and then that might involve some work with the ,COMMA it's like insertion sort ,COMMA you find a place to put the new item and then put it in the right place .PERIOD and again ,COMMA you could do this with a linked list or with the resizing array but then ,COMMA with array ,COMMA you'd have to move all the larger ones over one position to fit the new item in .PERIOD when we insert e and that's supposed to keep them in order ,COMMA we have to move over l ,COMMA m ,COMMA p ,COMMA and p to get the e and then so forth .PERIOD but the advantage of that might be that removing the maximum is easy .PERIOD we just take away the one at the end .PERIOD to remove the q  -DASH  we know it's at the end to remove the max .PERIOD at this point ,COMMA that's x  -DASH  it's right at the end ,COMMA and p is right at the end .PERIOD so you can imagine the implementations of priority queues using these two basic strategies .PERIOD not much code involved .PERIOD this is a an ordered array implementation of priority queues and it's quite straight forward .PERIOD we didn't put in the this is the cheat version where we require the client to provide a capacity but we could easily change this to a resizing array .PERIOD so insert() just puts it at the end ,COMMA and since its unordered delete maximum has to go through the entire array to try to find the maximum when it refines it and the changes that we're the one at the end and then removes it the same way that we do within the stack .PERIOD it'll use less and exchange just like we would in sorting methods .PERIOD so that's a fine implementation if the priority queue was going to be tiny all the time .PERIOD so if you ,COMMA without even implementing it ,COMMA you can understand this table that if we use an unordered array implementation we can get insertion done in constant time but we have to look at everything to delete the maximum or even find the maximum .PERIOD if we keep it in order ,COMMA we can find the maximum or delete it at constant time but it takes us linear time to insert .PERIOD and since as with stack and queue operations ,COMMA these insert and deletes might be intermixed in arbitrary ways and there might be huge numbers of them either one of these is very attractive because they're going to take n times the number of operations .PERIOD whereas what we can hope for and what we actually will achieve is to get log n time for all operations ,COMMA time proportion to log n for all operations .PERIOD with the clever data structure and interesting implementation we can actually achieve that goal .PERIOD that's the basic api and some elementary implementations for priority queues .PERIOD 
today we're going to talk about tries ,COMMA which is a data structure for searching with string keys that is remarkable effective in enabling us to deal with huge amounts of data that we have to process nowadays .PERIOD just as a motivation ,COMMA when we left off talking about searching algorithms ,COMMA or the symbol table implementations here's where we were .PERIOD the best algorithms that we examined were balanced red ,COMMA black ,COMMA binary search trees ,COMMA in hash tables .PERIOD and with respect to the basic search ,COMMA insert and delete operations .PERIOD red black bsts we're able to guarantee that we can get those done in logorithmic time ,COMMA actually ,COMMA pretty efficiently .PERIOD and for hashing ,COMMA we'd get'em done in constant time under certain assumptions .PERIOD that we could have a uniform ,COMMA hash function .PERIOD and also ,COMMA for hashing ,COMMA what we need to compute a hash ,COMMA code for binary search trees ,COMMA we use ,COMMA a compare to function .PERIOD and another difference is ,COMMA binary search trees ,COMMA we can support more operations .PERIOD than we can support with hashing ordered operations .PERIOD for example ,COMMA getting the rank of a key in the tree ,COMMA and other things .PERIOD and those are terrific algorithms .PERIOD and we looked at plenty of go ,COMMA good applications of those algorithms .PERIOD but still there's the question could we do better ?QUESTIONMARK and the answer is that yes ,COMMA we can do better .PERIOD as with string sorting ,COMMA we can avoid examining the entire key .PERIOD which is going to give us algorithms that can compete and even beat these classic algorithms .PERIOD so to get started we are going to articulate in api for symbol tables that specialize for the case when the keys are strings .PERIOD so simply ,COMMA we just add the modifier string to our standard symbol table epi .PERIOD and we can take a generic value just put the keys or strings .PERIOD and then we take all the methods that we articulated before .PERIOD and for key type ,COMMA instead of generic ,COMMA we use string .PERIOD and this is going to allow us to develop efficient algorithms that take advantage of properties of strings .PERIOD our goal is to get ,COMMA some algorithms that are even faster than hashing .PERIOD and maybe ,COMMA more flexible than bsts .PERIOD and we're going to be able to achieve both those goals .PERIOD so ,COMMA this again is the summary of the running times for when ,COMMA in the case that the keys are strings for red black bsts and for hashing .PERIOD and let's take a look at those so if l is the length of the string .PERIOD and n is the number of strings and then also the rate x is r is going to be a factor later on but its not going to be for these two .PERIOD then for hashing for every operation we have to compute a hash function ,COMMA which basically means looking at every character in the string .PERIOD actually in java string hash functions are cached ,COMMA so sometimes there's efficiencies cuz you only have to comp ,COMMA and they're mutable ,COMMA so you only have to compute the hash function once .PERIOD and then this is roughly the amount of space that takes into account the table and the string size for red black bsts ,COMMA the analysis is a bit more complicated .PERIOD for a search hit ,COMMA you have to look at the entire string .PERIOD given a entire key to check that every character's the same and then the comparison's depending on the nature of the keys for a typical case though its something like log squared n .PERIOD we had log n comparison's but usually you have to look at something like a log n characters in the key in order to get down the tree .PERIOD for a search miss you might be able to find out before you get to the end of the tree and sing a for an insert so the running times are something like this .PERIOD then here's some experimental evidence that ,COMMA that we ,COMMA we can use to test out these analytic hypothesis .PERIOD and we'll just look at two examples one is the entire text of melville's moby dick which we've used before and that's about a million characters .PERIOD and maybe 200 ,COMMA000 strings .PERIOD and add to this 200 ,COMMA000 strings ,COMMA about 32 ,COMMA000 are distinct .PERIOD and then this ,COMMA there's another file of actors from the internet movie database that's much bigger maybe tourism magnitude bigger .PERIOD and it's got maybe about a million different words .PERIOD so we'll want our algorithms to do better than ,COMMA or at least as well as red black bsts in hashing on these data sets .PERIOD i think ,COMMA you know ,COMMA our test is to dedupe these data sets .PERIOD so that's our challenge .PERIOD efficient performance for string keys and try to come up with algorithms that can compete with the best classic algorithms .PERIOD now in order to do that we're going to look at r way tries .PERIOD that's a particular data structure ,COMMA that was ,COMMA invented actually really quite a while ago .PERIOD this data structure ,COMMA dates back ,COMMA to the 60s .PERIOD and ,COMMA the first thing to know about it is that ,COMMA the name is based a little bit ,COMMA on a pun .PERIOD it actually is the middle letters of the word retrieval ,COMMA but we don't pronounce it tree because then we couldn't distinguish it from binary search trees ,COMMA so we pronounce it try .PERIOD and this is a confusing fact of life that we've been living with for many decades now with this data structure .PERIOD and let's look at what a try is and we'll look at some ,COMMA examples before we get to the code .PERIOD so ,COMMA for now ,COMMA we're going to think of a try as some nodes .PERIOD a tree structure with nodes where we store characters in the nodes ,COMMA not keys .PERIOD and the other thing is that each node has r children ,COMMA where r is the rate ,COMMA it's the number of possible characters .PERIOD and there's g -DASH  ,COMMA the possibility of a child for each possible character .PERIOD now in the standard implementation ,COMMA this is going to involve on all links .PERIOD we have to have a placeholder for each possible character .PERIOD so there's a lot of null links and tries .PERIOD and we'll get back to that in a minute .PERIOD but to get the concept ,COMMA we'll use this graphical representation ,COMMA where we have characters and nodes and we don't show any null length .PERIOD and the other thing is ,COMMA remember a symbol table is associating a key with a value ,COMMA so this try is built for this set of key value pairs .PERIOD and what we do is we .PERIOD store values in nodes that correspond to the last characters in keys .PERIOD and we'll look ,COMMA that's what these numbers here are .PERIOD and we'll look at a little more in detail ,COMMA on how this try is built in just a second .PERIOD so that's the basic idea .PERIOD we're going to have string keys .PERIOD we're going to associate values ,COMMA and we're going to use this tree -DASH like ,COMMA tree data structure but we're not going to draw the imply null links for now .PERIOD so ,COMMA for example ,COMMA in this trie so the root re -DASH  ,COMMA represents all strings .PERIOD and ,COMMA coming out of the root is one length for each possible letter .PERIOD in particular in this try ,COMMA the middle link is the link to the ,COMMA to a sub try that contains all the keys that start with s .PERIOD then we go further down .PERIOD each time we go by a node ,COMMA we pick off a letter so that this length ,COMMA for example ,COMMA goes to the try for all keys that start with s followed by h followed by e .PERIOD and so forth .PERIOD so now all ,COMMA out of all the keys that start with she ,COMMA actually one of them ,COMMA the one that just has the letters in then ends ,COMMA has a value associated with it .PERIOD so when the node corresponding to the last letter ,COMMA the e ,COMMA we put the value zero .PERIOD and so that's ,COMMA how the try is going to look .PERIOD so just given that definition ,COMMA then let's look at ,COMMA how to do search ,COMMA in a try .PERIOD all we do is use the characters and the key to guide our search down the data structure .PERIOD so ,COMMA let's say we're looking for the key shells .PERIOD so we start at the root ,COMMA and we go down the s link ,COMMA since we started with an s .PERIOD now our second letter is h ,COMMA so we look to see if there's a non -DASH null link that ,COMMA corresponding to h ,COMMA and in this case there is .PERIOD now our next letter is e ,COMMA so we look for an e .PERIOD now .PERIOD no need to examine the value here because well we haven't looked at all the letters in our key yet .PERIOD so now we look for l now we look for another l and then finally we find the s and when we find the s we look to see if there's a value there .PERIOD in this case there is a value and so that's what we return the value associated with the last key character .PERIOD so that's a typical search hit in a tri .PERIOD another way is .PERIOD .PERIOD .PERIOD so ,COMMA that node was down at the bottom but if you had .PERIOD we're doing a search for she ,COMMA you follow the same path .PERIOD but now when you get to the e ,COMMA that's the last character of that key and so we just know how to return that ,COMMA value associated with that node .PERIOD that is ,COMMA the search doesn't have to go all the way to the bottom .PERIOD it might terminate at an intermediate node .PERIOD and we just return the value associated with the node corresponding to the last character in the key .PERIOD what about a search miss ?QUESTIONMARK well ,COMMA there's two cases .PERIOD it's for a search miss .PERIOD so one of them is we've followed down the tree picking off the letters in the key one letter at a time as ,COMMA as before .PERIOD and then when we get to the end of the key we take a look to see if there is a value .PERIOD in this case there's no value associated with the last key character that mean there's no key in the data structure that's been associated with a value .PERIOD so we just return no .PERIOD or ,COMMA the other thing that can happen is ,COMMA we can ,COMMA reach a null link .PERIOD so ,COMMA our key now is s ,COMMA starts with s ,COMMA and then h ,COMMA and then e ,COMMA and then l ,COMMA and now our next letter is t ,COMMA so we look to see if there's a non null link coming from this node associated with t .PERIOD and in this case ,COMMA there's no such link ,COMMA so we return null .PERIOD that's evidence that ,COMMA that string ,COMMA there's no key associated with that string in our data structure .PERIOD so that's a search miss .PERIOD iii .PERIOD now ,COMMA what about insertion ?QUESTIONMARK well insertion is also pretty simple .PERIOD so we follow two ,COMMA two rules .PERIOD one is again ,COMMA we go down links corresponding each character in the key .PERIOD if we come out on a link ,COMMA we create a new node that's associated with the character that we're on .PERIOD and just keep doing that until we get to the last character of the key ,COMMA in which case ,COMMA we put the value .PERIOD so if in this try ,COMMA we're supposed to associate the value seven with [inaudible] .PERIOD we follow ,COMMA our path from the root to s ,COMMA 'cause our first letter is s ,COMMA and then h .PERIOD'cause our next letter is h .PERIOD and then a o ,COMMA we had an ,COMMA [inaudible] kinda ran into a null link .PERIOD so we have to put ,COMMA a node there ,COMMA with the character ,COMMA associated with the character o .PERIOD so in later searches for this key ,COMMA we'll be able to find it by passing through that node .PERIOD and now we move to the next letter ,COMMA and there's no node again .PERIOD in the next letter ,COMMA there's still no node .PERIOD iii .PERIOD when we get to the end ,COMMA then that's the last character in the key ,COMMA and we put our value seven .PERIOD and now we've modified the data structure ,COMMA adding the nodes that are necessary for a later search to go through ,COMMA character by character and find the value associated with that key .PERIOD so that's an insertion into a try .PERIOD just to cement all these ideas let's do a demo of how that tree was constructed from scratch .PERIOD so we have a null try .PERIOD so we're going to start by putting the ,COMMA associating the value zero with the string she .PERIOD so we start at the root node ,COMMA which ,COMMA and i'll try ,COMMA it just has that one node .PERIOD create a new node for s ,COMMA create a new node for h ,COMMA create a new node for e .PERIOD associate zero .PERIOD so the key is the sequence of characters from the root to the value ,COMMA and the value is in the node corresponding to the last character .PERIOD this try represents the symbol table that contains just on string she ,COMMA and associated with zero .PERIOD every other string ,COMMA if you search for any other string in this try you'll either end in a node that doesn't have a value or you'll end at a null link .PERIOD all right ,COMMA so now ,COMMA let's say we put in the key s ,COMMA e ,COMMA l ,COMMA l ,COMMA s and you can kinda tell where it's going ,COMMA we made room for it in the try .PERIOD so we go for s ,COMMA and now the second letter ,COMMA e ,COMMA corresponds to a null link ,COMMA so we create a new node .PERIOD and similarly we go through and create new nodes for each of the remaining characters in the key and then associate the value one at the end .PERIOD so now we have a try that has two keys in it ,COMMA she and sells .PERIOD now our next is to insert sea .PERIOD so now we have s ,COMMA we already have a node corresponding to e .PERIOD and so now we just have to create one new node ,COMMA the one corresponding to a .PERIOD and put our value two there .PERIOD and now ,COMMA we're going to put shells in .PERIOD so we already have the s ,COMMA already have the h ,COMMA already have the e ,COMMA so now we have to add nodes for the last three letters in that string .PERIOD and associate the value three with it .PERIOD now we're going to put finally a key that doesn't start with s .PERIOD so that means we create a new node corresponding to the first letter of that string ,COMMA i ,COMMA n to the other letter two .PERIOD and then associate the value four .PERIOD and here's another one that doesn't start with s .PERIOD so we create new nodes corresponding to each one of its characters ,COMMA and associate the value five with the last one .PERIOD now here's sea .PERIOD so this is ,COMMA remember ,COMMA our symbol table api is associative ,COMMA which means that if we get a new value for a key that's already in the table ,COMMA we overwrite .PERIOD the old value with the new value .PERIOD that's the way ,COMMA the convention that we've chosen for symbol tables .PERIOD so that is easily done with tries as well .PERIOD now here's one more key ,COMMA s ,COMMA h .PERIOD and now we have to add a new node because there's no node that's a child of h that corresponds letter o .PERIOD so we have to create new nodes for o ,COMMA r ,COMMA and e ,COMMA and associate the value seven with it .PERIOD so that's a tri that has precisely eight keys .PERIOD if you look for any one of those eight keys you'll get the value .PERIOD if you look for any other string you'll either come to a node that has a null value or go out on a null link and so the search would be unsuccessful .PERIOD that's is a demo of tri construction .PERIOD now that you have a basic idea of how ,COMMA what tris are and how they work ,COMMA let's take a look at what's needed to implement them in java .PERIOD the key idea in the tri representation for implementation in java or any computer language is that .PERIOD instead of representing a node as a character in the node ,COMMA what we do is represent the links as an indexed array with one entry for each possible character .PERIOD and the idea is the characters are actually .PERIOD implicitly defined by link indeces .PERIOD so just for example ,COMMA we have this small try that we built over here .PERIOD in this case ,COMMA the root has only one node below it .PERIOD that's for all the keys that start with s .PERIOD the way that's represented in real representation ,COMMA and this is for efficiency .PERIOD and it's the way that tries get their efficiency .PERIOD is we have one link corresponding to each possible letter .PERIOD and the only one that is un -DASH null is s .PERIOD so the character s is defined implicitly by the fact that ,COMMA that link that [inaudible] that ,COMMA that corresponds to s is not null .PERIOD over here there's from e to a there's two links coming out of e .PERIOD and the only way that we represent a is by having the first link be not null .PERIOD if the link corresponding to a letter is not null ,COMMA then it corresponds to having that letter in the node that it points to .PERIOD so in this case we have e connected to a and l .PERIOD so we have the entries corresponding to a and l filled with non null values .PERIOD so you can see immediately the correspondence between this tri the way we've been drawing it and the job representation of it .PERIOD where each node contains 200 ,COMMA or r links if there's r different letters .PERIOD and letters are implicitly represented by non [inaudible] links .PERIOD now ,COMMA you just go in the node .PERIOD so for example ,COMMA i ,COMMA in this try ,COMMA s ,COMMA e ,COMMA a ,COMMA but which is easy to follow down through the try .PERIOD we're looking for an s .PERIOD and s is the twentieth letter in the alphabet .PERIOD or so .PERIOD we index into the twentieth position and that takes us right to s .PERIOD and e's the fifth letter ,COMMA we take the fifth link .PERIOD then a's the first letter ,COMMA we take the first link .PERIOD so we can use the character as index into the array of links .PERIOD to quickly travel down the tree .PERIOD then when we get to the last character ,COMMA we can check the value at that node that's stored in the node .PERIOD one slight complication in the implementation that we encountered before with hashing algorithms and other things .PERIOD we're going to need arrays of nodes .PERIOD that's what our lengths are .PERIOD so we can't have any generics with nodes ,COMMA even though i would like to .PERIOD so we have to declare the value to be a type object ,COMMA and then we'll have to cast it back to whatever type it should be ,COMMA when we return it .PERIOD and we'll see that in code .PERIOD other than that little complication .PERIOD this is quite straightforward representation of tries .PERIOD and it leads to a very easy implementation .PERIOD so the keys and the characters are not explicitly stored .PERIOD they're ,COMMA they're implicitly ,COMMA because of the links .PERIOD and that's a ,COMMA a very important point to think about when it comes to ,COMMA implementing using tries .PERIOD given that representation ,COMMA this code for implementing try ,COMMA simple table in java almost writes itself .PERIOD so it's a [inaudible] implementation in this slide has the implementation of put using the same recursive scheme that was used many other times in building trees the what are the instance variables ?QUESTIONMARK well we declare artery 256 as usual in our string implementations where working with extended asking and then we have one instance variable that matters and that is the root of the [inaudible] .PERIOD so tries begin with ,COMMA start ,COMMA all tries start with a null node .PERIOD so first thing we do is create a new node and put a reference to that node in root .PERIOD so our empty trie consists of a node that's got a .PERIOD remember ,COMMA when you create a new node we build an array of r links to nodes .PERIOD and at the beginning those'll all be empty links .PERIOD or all null links .PERIOD so the root points to a node that has 256 null lengths .PERIOD now to put .PERIOD or to associate a key with the value in a trie .PERIOD we use this instance method that calls recursive method .PERIOD again ,COMMA the same way that we've done for other tree construction schemes before .PERIOD so we take the recursive method ,COMMA takes a node as argument and returns a node .PERIOD so it takes a reference to a trie and returns to ,COMMA a reference to the trie that it constructs .PERIOD after a associating the key with a value .PERIOD just to get started suppose that our first key has just one character .PERIOD so in that case ,COMMA we would call .PERIOD another recursive put for the root ,COMMA with our one character .PERIOD and so our one character key .PERIOD and call the recursive routine .PERIOD now our node is not null .PERIOD it's the root node .PERIOD so and our key is length one .PERIOD and we ,COMMA called it starting at zero .PERIOD so the first thing that we do is pick out the [inaudible] character of our ,COMMA yeah key so zero of character which is our one character and i guess its an index whatever letter might happen to b .PERIOD say its b then c would be two that's sort of thing and then all we do is recursively are follow that link in ser .PERIOD our ,COMMA associate our key value in the try pointed to by that link .PERIOD and then take the link that we get and put it back into that link out of the root node .PERIOD so the next call there's nothing in the word dot next it's a ,COMMA it's null so the next call we get null so we create a new node .PERIOD and then that new node this point we've called with d plus one moving to the next character .PERIOD so now we have d equals one which is equal to our key dot length .PERIOD so we associate the value in that node with our node and we return it .PERIOD so that return one level up will set the length of the new node in the appropriate entry corresponding to the root .PERIOD again once you've learned our normal recursive way of structuring building tree structures this code is very natural .PERIOD so for a longer key i'm again thinking recursively we find the if we're suppose to insert the key associate the key with a value ,COMMA and we're working on the [inaudible] character .PERIOD we pick out the ,COMMA the character at the deep position .PERIOD we use that to index and to be in link array of the current node and then that's the link that we set when we do a put of the new node .PERIOD so when we start with a longer string and a perfectly empty tree we create new nodes all the way down and then put their links to their parents all the way up .PERIOD in this recursive structure .PERIOD and it's a very simple and natural recursive code .PERIOD so that's the put .PERIOD now that takes a little study but not so much once you're use to our standard recursive way of producing tree structures .PERIOD and get is even simpler .PERIOD so contains and gets .PERIOD so our scenario's standard convention is to return null if we have a key that's not there or that contains and the get function is a again recursive .PERIOD procedure that will return in reference to the node ,COMMA and if that's null ,COMMA we return null .PERIOD otherwise ,COMMA we can get the value out of the node return by the recursive procedure .PERIOD and then remember we had the omega value in nodes of type objects .PERIOD so we have to cast that back to the type value .PERIOD and the recursive get is very simple .PERIOD to find the node that contains the value associated with a given key .PERIOD and we're working on the deep character .PERIOD and we're currently on ,COMMA node x .PERIOD we just ,COMMA return null .PERIOD effects happens to be null .PERIOD that means it's not there .PERIOD if we're ,COMMA at the last character in the key ,COMMA we return our current node .PERIOD otherwise ,COMMA we get that [inaudible] character .PERIOD and we use that to index into the next array of the current ,COMMA node .PERIOD and recursively called the get routine ,COMMA for ,COMMA that node moving ,COMMA one down the tree .PERIOD and incrementing our key pointer by one .PERIOD extremely simple ,COMMA recursive code to do the tri implementation .PERIOD so what about the performance ?QUESTIONMARK well in a cert chip we simply go down the tried examining all l characters just using each one to index into an x -DASH array at some note .PERIOD and then go down to the end to ,COMMA to see if there's a value there .PERIOD search miss we might have to go all the way down to the last character .PERIOD but we could also just have a miss match on the first character and find a null link right away .PERIOD and actually .PERIOD typically ,COMMA in a try .PERIOD in typical applications ,COMMA we only examine a few characters .PERIOD so right away ,COMMA you can see ,COMMA by thinking about a search miss ,COMMA that try algorithms can be sublinear .PERIOD we can find out that a key's not in the tree ,COMMA by only examining a few characters .PERIOD if we don't have any .PERIOD strings in our try that begin with the same few characters as our search key ,COMMA then ,COMMA it's not there .PERIOD that's a typical case .PERIOD now the downside of tri performance in lots of applications is the amount of space used .PERIOD there is the problem that every node's got r lengths in it .PERIOD and particularly ,COMMA down at the bottom ,COMMA the leaf nodes that correspond to the last characters and keys and ,COMMA the prefix in the key in the try that's going to be null lengths .PERIOD now it is possible in a huge try with lots of strings that are short and sharing common prefixes to actually much less space then this but be ardenal links at each leaf is a real problem in some applications so we're going to take a look on how to deal with that .PERIOD so the bottom line is for symbol tables with relatively small numbers of string keys where the amount of space used by the [unknown] is not a problem .PERIOD then we get very fast ,COMMA search hit .PERIOD and even faster search miss but we burn up some space .PERIOD that's the bottom line about try performance .PERIOD and ,COMMA just a typical application .PERIOD maybe you get a job interview question about ,COMMA what data structure you use for spell checking and then ,COMMA so ,COMMA and this is just an example ,COMMA to show ,COMMA how effective tries can be for such an application .PERIOD where all the words are three letters .PERIOD and the solution is ,COMMA build a 26 way try .PERIOD so spell checking ,COMMA usually ,COMMA there'll be pre -DASH processing to strip out everything but the lowercase letters that make up the word .PERIOD so you can build a 26 way try that ,COMMA will immediately tell you whether you have a misspelled word or not .PERIOD another interesting thing about prize is that ,COMMA deletion is ,COMMA very easy ,COMMA what do we do to delete a key value pair ,COMMA well you find ,COMMA the node corresponding to key and ,COMMA set the value there corresponding to null ,COMMA  .PERIOD so that's ,COMMA easily done ,COMMA so we want to delete shelves we cross out the ,COMMA value there ,COMMA and now ,COMMA there's two cases .PERIOD one case is this one where that node ,COMMA now we set its' value to null and its got all null links .PERIOD now there's no reason for its existence .PERIOD so it wouldn't have been created except for the fact that we inserted shells .PERIOD so if the node has got null links ,COMMA just remove it .PERIOD and then ,COMMA just delete it .PERIOD and then when you go back up the tree ,COMMA which you do because you got down there .PERIOD every node that you touch you check if it's got a no value and all no links ,COMMA just delete it .PERIOD and you keep going until you find one that has either a value or a downhill link and then that's when you can stop the leading node .PERIOD so it's pretty easy to delete a key value pair in an r -DASH way tri .PERIOD and that's unusual for other search structures that we saw in the deletion was a significant challenge to implement often .PERIOD so our challenge is to find a way to use ,COMMA less memory .PERIOD be ,COMMA particularly because ,COMMA nowadays ,COMMA many strings are built with unicode .PERIOD and the number of null links in a tri would be truly huge .PERIOD again we talked about this ,COMMA with rated sorting .PERIOD a lot a programs broke when this .PERIOD switch went from ascii to unicode .PERIOD in any program that use this reposession ,COMMA representation for tries ,COMMA certainly broke .PERIOD so that's an introduction to tries with r -DASH way tries .PERIOD 
now we're going to look at binary heaps which is an ingenious and very simple data structure that's going to help us implement all the priority queue operations quickly .PERIOD so ,COMMA the idea of a binary heap is based on the idea of a complete binary tree .PERIOD so ,COMMA a complete binary tree ,COMMA well first of all ,COMMA a binary tree is either empty or it's a node with links to left and right binary trees so that's an example of a binary tree .PERIOD a complete binary tree is one that's perfectly balanced ,COMMA except possibly for the bottom level .PERIOD so there might be a few nodes on the ,COMMA on the bottom level and one level lower than the bottom level .PERIOD but otherwise ,COMMA all the levels are full .PERIOD we'll see how that looks in just a second .PERIOD the property of complete tree is that the height of a complete tree with n nodes is the biggest integer less than log base two of n ,COMMA and that's really easy to convince yourself that that's true because the height ,COMMA if you add nodes one at a time going from left to right on the bottom level say ,COMMA the height only increases when n is a power of two .PERIOD complete binary trees actually happen in nature .PERIOD here's an example of one that goes one ,COMMA two ,COMMA three ,COMMA four levels at least ,COMMA so sixteen pushes at the end there .PERIOD alright .PERIOD now ,COMMA the way we're going to use complete binary trees to implement priority queues is to first of all ,COMMA associate information with each node .PERIOD we'll put our keys in the nodes ,COMMA and also we're going to represent it with an array .PERIOD so ,COMMA [cough] when we start putting the keys in the nodes we're going to impose one more condition that's called heap ordering .PERIOD and the idea is that the parent's key is going to be no smaller than its children's key for ,COMMA and that's true for every node in the tree .PERIOD the array representation ,COMMA all we do is ,COMMA we put we start with indices at one ,COMMA it's a little less calculation .PERIOD that way we leave a(0) empty and then we just take the nodes in level order .PERIOD so first ,COMMA we put the root .PERIOD then ,COMMA we put the two nodes on the fi rst level going left from right .PERIOD and then ,COMMA all the nodes on the third level ,COMMA going from left to right and so forth .PERIOD this is interesting because we can draw the tree to get more intuition about what's happening .PERIOD but in the actual data structure representation ,COMMA we don't need any links at all .PERIOD it's just an array .PERIOD the way that we move around the tree is by doing arithmetic on the indices .PERIOD so let's look at a few properties of binary heaps .PERIOD so that's complete binary trees represented in array with keys in the nodes satisfying the heap order property .PERIOD well ,COMMA first thing is that a(1) is the largest key .PERIOD it's larger than the keys and its two children and they're larger than theirs and so forth so it's the largest key in the data structure .PERIOD the other thing is ,COMMA as i just mentioned ,COMMA you can use the array in the seeds to move through the tree .PERIOD for example ,COMMA if the node is at position k ,COMMA index k in the array ,COMMA then it's parent is a k over two and that's integer divide .PERIOD so the parents of say h and g are both n .PERIOD h is ten ,COMMA g is at eleven ,COMMA n's at five so both of those are ten over two ,COMMA eleven over two ,COMMA integer divide is five .PERIOD and going the other way it's easy to see that the children of the node at k are 2k and 2k + one .PERIOD so we don't need explicit lengths at all to represent these data structures .PERIOD we can just use array indices .PERIOD so [cough] that's the basic setup or the invariant that we're going to maintain in this data structure .PERIOD and now ,COMMA what we're going to do is take a look at just a couple of different scenarios that where we violate that invariant temporarily and then fix it .PERIOD and that's going to give us the flexibility that we need to implement priority queue operations .PERIOD so one scenario shown here ,COMMA is if for whatever reason a child's key becomes larger than its parent's key .PERIOD so in this case ,COMMA we have an example where t ,COMMA the node t here ,COMMA its value changes and it becomes larger than its parent key p .PERIOD so ,COMMA the heap order condition is satisfied everywhere ,COMMA except at this node .PERIOD well ,COMMA it's easy to fix this one .PERIOD all we do is exchange the key in the child with the key in the parent .PERIOD after that exchange ,COMMA then ,COMMA that would have t up here and p down here then the heap order condition is satisfied at that node because the parent was smaller ,COMMA so that one's smaller .PERIOD and so that one is still smaller so t is after its exchanged up here will be bigger than both its children .PERIOD but the heap condition will be violated cuz t is still smaller than s .PERIOD so we have do it again ,COMMA exchange it with s .PERIOD so we move up the tree ,COMMA exchanging the larger key with its smaller parent ,COMMA until we get to a point where its larger than both its children .PERIOD that's restoring the heap order along the path from the place where it's violated to the root .PERIOD you can think of that as kind of like the well known peter principle where a node gets promoted to a level where it finally can't be better than ,COMMA than it's boss .PERIOD it's a level of it's maximum incompetence .PERIOD and implementing that in code is really easy .PERIOD we call that the swim operation ,COMMA it swims up to the top .PERIOD and if we have a node at index k and we know the heap condition is violated there ,COMMA as long as we're not at the root and k's parent ,COMMA k over two is less than a of k .PERIOD then ,COMMA we just exchange it with its parent ,COMMA and move up .PERIOD that's the swim operation to eliminate a violation when a key value increases .PERIOD [cough] so for example ,COMMA this gives us a way to insert a new element into a heap .PERIOD what we do is ,COMMA we add a new node at the end of the heap ,COMMA so this one position over .PERIOD the thing is ,COMMA remember represented in array ,COMMA one ,COMMA two ,COMMA three and so forth .PERIOD so the [cough] next empty position in the array there's a place to put a new node .PERIOD and then we just declare that ,COMMA that's part of the heap and that node ,COMMA well if it's less than its parent ,COMMA we're fine .PERIOD but in general ,COMMA we have to check whether the heap condition is violated and exchange it with its par ent as long as it's smaller and that's just perform the swim operation .PERIOD so if n is the number of items in the heap ,COMMA defined to be in the heap we're going to increment it ,COMMA store a new key there ,COMMA there and then perform the swim operation .PERIOD so that's a quick implementation of the insert operation .PERIOD and notice since it's just going from bottom to top in the heap it takes at most one plus log base two of n compares .PERIOD [cough] now there's another scenario where a key becomes smaller .PERIOD for whatever reason ,COMMA a parent becomes key decreases ,COMMA it might become smaller than one or both of its children .PERIOD in this case ,COMMA the value at position two has changed to h for whatever reason and that's smaller ,COMMA in this case ,COMMA than both its children .PERIOD so how do we fix that violation ?QUESTIONMARK well ,COMMA that one's also easy .PERIOD we figure out which of the children is larger .PERIOD in this case ,COMMA it's the s ,COMMA and we exchange our exchange that one with the one that's violating the condition .PERIOD so that's moving the smaller key down .PERIOD after that exchange ,COMMA then s is in position two ,COMMA and it's bigger than both p and h .PERIOD and the heap condition is only violated again where h is sitting .PERIOD and again ,COMMA we keep going until getting to the bottom ,COMMA or getting to a place where both children are smaller .PERIOD and that's maybe a little bit what happens when a ,COMMA a new boss is hired from the outside and then the two subordinates struggle to take over that position and then the bros ,COMMA boss would get demoted to it's level of competence .PERIOD and again ,COMMA that level of flexibility .PERIOD here's the implementation of it .PERIOD and again ,COMMA it's quite straightforward using the [cough] index arithmetic to move around in the heap .PERIOD if we're ,COMMA and that's called the sink operation ,COMMA cuz we're going down the heap .PERIOD if were at position k ,COMMA then what we need to worry about it is the nodes at 2k and 2k + one .PERIOD and the first thing to check is find out which one's bigger .PERIOD it's either 2k or 2k + one and so set j accordingly .PERIOD so that's j now ,COMMA is ,COMMA after this st atement is the larger of the two children .PERIOD and don't forget to check that we're going off the end of the heap .PERIOD and then if ,COMMA [cough] the k is not less than either one of those ,COMMA then we're done .PERIOD if it is ,COMMA then we exchange with the larger of the two children and move down the heap .PERIOD again ,COMMA just a few lines of code to eliminate the violation when a key value in a heap decreases .PERIOD and that one we're going to use to implement delete the maximum in a heap .PERIOD so delete the maximum ,COMMA we have to do two things ,COMMA one thing is the size of the heap has got to go down by one .PERIOD the other thing is return the maximum .PERIOD well ,COMMA we know that [cough] one that we want to return is the one at the root .PERIOD so we'll save that value away to return to the client .PERIOD and then ,COMMA since it has to go down by one the place to get the to remove the element from the heap is at the end of the array cuz it's now going to have to not occupy that position ,COMMA so we take that element and replace the root with it .PERIOD so i move the h up and actually ,COMMA put the root value there just exchange them but it's not longer in the heap .PERIOD now ,COMMA that element which went from the bottom to the top is most likely going to violate the heap order .PERIOD it's going to be smaller than one of its ,COMMA both of its children .PERIOD so ,COMMA we do a sink .PERIOD [cough] now in this case to implement the lead max we save away that value at the root in max and we eliminate loitering by nulling out that vacated position then return the max value .PERIOD so that's an implement ,COMMA implementation of the delete max operation for heap using sink where a key value that decreases ,COMMA go down ,COMMA goes down in the heap .PERIOD so let's just take a look at what happens with a ,COMMA a real heap with the demo when we do these things .PERIOD and you'll have a good feeling for how this data structure works .PERIOD so ,COMMA we're starting at some point where we have these ten keys in heap and it's heap order .PERIOD so we've drawn the data structure with the links ,COMMA so we have an intuition for what's going on .PERIOD but all the program sees is the array and grey at the bottom where t's in position one ,COMMA p and r are position two and three ,COMMA and so forth .PERIOD so now ,COMMA suppose that we're supposed to add s .PERIOD so to add it to the heap ,COMMA that's going to go in the position at the end .PERIOD then now we've added it to the heap just by incrementing n ,COMMA putting it in there but now we have to bring the heap order back into condition .PERIOD and so that's going to ,COMMA now that key is larger than its parent so we're going to swim it up exchange it with its parent as long as it's smaller than its parent .PERIOD so ,COMMA first thing it goes up exchange with the s ,COMMA it's still bigger than p .PERIOD so we exchange it with the t and now we're done because s in not bigger than t and the heap order condition is now satisfied everywhere in the heap .PERIOD so ,COMMA with just two exchanges we insert that new element in the heap in this case .PERIOD i now suppose the next operation is remove the maximum .PERIOD so ,COMMA we're going to take t and exchange it with the last element and then declare that to be no longer part of the heap .PERIOD so now [cough] we have to bring the heap order back because it might be violated at the root so now we invoke the sink where we exchange that node with the larger of its two children until we find a place where its larger than both its children .PERIOD so s is the larger of the two children r and s and now h is still smaller than both it's children so we promote the larger ,COMMA which is p .PERIOD now h has no right child ,COMMA just a left child and it's larger than that one ,COMMA so we're finished with that operation .PERIOD we've removed the maximum and we still have our data structure heap ordered and our n keys stored in first n positions in the array .PERIOD let's remove the maximum again .PERIOD again we take it out by exchanging this time g with the root and then [cough] decrease the size of the heap by one .PERIOD just take that out .PERIOD now ,COMMA t he node of the root violates the heap border so we have to exchange it with the largest of it's two children ,COMMA in this case that's r .PERIOD again ,COMMA g is not larger than it's two children so we have to exchange it with the larger of the two ,COMMA that's o and now we are done ,COMMA we've removed the largest again .PERIOD now suppose we insert s back into the heap .PERIOD so [cough] that's adding it at the end ,COMMA violates the heap order exchange it with the parent smaller and keep doing until we get to a place where it's larger than its two children .PERIOD in this case ,COMMA s goes all the way up to the root .PERIOD and it's all heap ordered again .PERIOD so that's a little survey of some operations on a heap and you can see how every operation is done with just a few exchanges along the path from the bottom to the top or the top to the bottom .PERIOD okay ,COMMA here's the complete java implementation of a priority queue using the binary heap data structure .PERIOD [cough] it's actually not so different from the elementary implementations that we looked at in the last section .PERIOD our representation is an array of keys and a size ,COMMA that's the number of items in the heap .PERIOD [cough] for simplicity ,COMMA we'll show the code where the client gives the capacity of the heap .PERIOD we can use resizing array ,COMMA in industrial strength implementation ,COMMA the same that ,COMMA we did for stacks and other data structures where we use arrays .PERIOD so we'll build a new array of keys and we have to use an ugly ,COMMA ugly cast because we can't have generic arrays in java .PERIOD and that ,COMMA so it's comparable and ,COMMA and we need one more than the capacity to handle this thing where ,COMMA we don't use position zero .PERIOD so the priority queue operations ,COMMA is the insert and del max that we showed in the previous slides ,COMMA is empty ,COMMA is just checking whether n is equal to zero .PERIOD we have the swim and sink functions that we showed earlier .PERIOD and then we have helper functions less and exchange ,COMMA that access the array directly so that the co de doesn't have to access directly .PERIOD that's a complete implementation of priority queues in java .PERIOD and this is ,COMMA this implementation by itself is extremely significant because ,COMMA it's really very simple ,COMMA optimal representation of the data .PERIOD and only a little arithmetic with array indices .PERIOD but as you can see by looking at this table ,COMMA it gives us a way to implement priority queues where ,COMMA both operations are guaranteed to happen in log n time .PERIOD now ,COMMA experts have worked to come up with improvements on this and there are slight improvements possible .PERIOD we can make the heap d way rather than just two way and depending on the frequency of execution of the uncertain del max operations that might work out better .PERIOD there's an advanced data structure called a fibonacci heap ,COMMA where inserts are done in constant time and delete max done in log n time on an average over all the operations .PERIOD that ones generally too complicated to use in practice .PERIOD but still again ,COMMA using theory as a guide maybe there's a way to ,COMMA [cough] to decrease costs a little bit from binary heaps .PERIOD and of course ,COMMA we cannot get down to having constant time for all operations .PERIOD why ?QUESTIONMARK well ,COMMA we can sort with a heap by inserting all the elements and then deleting the maximum of getting a sort done and that would be in linear time if we had this kind of variation .PERIOD if ,COMMA if we have constant time operations for both insert and del max .PERIOD but for certain applications ,COMMA we can get close to constant time for one or the other operations and that'll be useful in different implementations .PERIOD now ,COMMA there's an important consideration ,COMMA that ,COMMA in ,COMMA that we have to bring up related to the programming language and [cough] this is ,COMMA a more general consideration than usually we bring into focus in algorithms but it's worthwhile mentioning .PERIOD we're assuming that the client doesn't get to change the keys while they're on the priority queue .PERIOD and it's better not to ass ume that it's better to arrange for that in our implementations by using keys that are immutable ,COMMA who's values don't change .PERIOD there's many reasons that immu ,COMMA immutable keys are [cough] that programming languages provide the capability to build immutable keys and ,COMMA and this is a fine example of one .PERIOD so and we'll talk more about that in a minute .PERIOD the other things that ,COMMA that ,COMMA we didn't talk about in the implementation should throw in ,COMMA exception .PERIOD if the client tries to delete from an empty priority queue and we should have a no argument constructor ,COMMA and use a resizing array ,COMMA to ,COMMA account for gradual growth and shrinkage in an industrial strength implementation .PERIOD usually we provide two implementations ,COMMA one that's max oriented ,COMMA one t hat's min oriented so that nobody get's confused and they're the same except the less and greater switch .PERIOD and we'll see later on ,COMMA there's times when we want to add ,COMMA expand the api and provide other operations like removing an arbitrary item from the priority queue ,COMMA or give the client in the api the capability of changing the priority of an item .PERIOD our sink and swim methods are good for making this happen ,COMMA but we'll ,COMMA delay these implementations until we need them in a more complicated algorithm .PERIOD so what about mutability ?QUESTIONMARK so in every thing in java is implemented as a data type ,COMMA a set of values and operations on those values and the idea of immutable data type ,COMMA is you can't change the value once it's created .PERIOD so that's kind of like ,COMMA when you [cough] when you ,COMMA when you create a literal value to be assigned to an integer ,COMMA it has that value .PERIOD so here ,COMMA here's an example say using the data type for vectors might be a way to implement vectors .PERIOD so we put the word final to means that instance methods can't be overridden .PERIOD and not only that ,COMMA instance variables are private ,COMMA they can't be seen from the outside and they don't change .PERIOD and so a constructor for an immutable vector data type ,COMMA it might take an array [cough] as it's argument ,COMMA and that array has got values stored in it ,COMMA say doubles ,COMMA and those are ,COMMA those can change but what immutable implementation would do would be to copy those values into the local [cough] data array instance variable and then those values are not going to change .PERIOD and the instance methods won't change them and the client can't change them .PERIOD so that value stays the same .PERIOD lots of ,COMMA implementations ,COMMA data -DASH type implementations in java are immutable ,COMMA like string is immutable .PERIOD when you create a string that value doesn't change .PERIOD [cough] if you want a new string ,COMMA you have to create a new string ,COMMA using concatenation or some other operation .PERIOD and the same with the wrapper types ,COMMA like integer and double ,COMMA or color ,COMMA and ,COMMA what lots of things .PERIOD whereas on the other hand ,COMMA sometimes ,COMMA the whole purpose ,COMMA of a data type is to maintain a changing value like a good example is like a counter ,COMMA or a stack .PERIOD so you wouldn't put those things on a priority queue cuz the value is changing but the other ones you would .PERIOD so the advantages of immutability and again ,COMMA maybe this isn't the place to really sell those advantages more for a programming language course is that it ,COMMA it really simplifies debugging .PERIOD we can be have more confidence that our priority queue operations are going to work correctly if we know that the type of data that's on the priority queue is immutable .PERIOD if the client could change the values ,COMMA how do we know that the heap border operation is preserved ?QUESTIONMARK if we want the client to be able to change values ,COMMA we're going to provide methods for that purpose as i just mentioned .PERIOD and there's many other reasons that people use immutable data types .PERIOD there is a disadvantage that you have to create a new object for every data type value but for a lot of applications that disadvan tage is not viewed to be significant compared to the advantages .PERIOD here's a quote from a one of java's architect ,COMMA josh black .PERIOD classes should be immutable unless there's a very good reason to make them mutable .PERIOD if a class cannot be made immutable ,COMMA you should still limit its immutability as much as possible .PERIOD and many programmers live by that kind of precept .PERIOD so that's a basic implementation of priority queues using the heap data structure represented as an 
next we're going to look at ternary  search tries ,COMMA which is another data  structure that new data structure ,COMMA that  responds to the problem of too much  memory space used by our way tries .PERIOD  this is a very easy to describe and  implement data structure .PERIOD  and it came out of the same paper that  jon bentley and i wrote in the 1990s when  we developed the three way ternary  quicksort .PERIOD  the idea is now we're going to actually  store characters in nodes in values .PERIOD  but ,COMMA we're not going to store whole keys  in there ,COMMA just characters .PERIOD  but we're not going to use this idea of a  big array ,COMMA where a nominal link is an  implicit value of a character ,COMMA actually  going to store the characters .PERIOD  but what we're going to do is ,COMMA make each  node have three children not two ,COMMA like in  a binary search tree .PERIOD  and not r ,COMMA like in a nr way trie ,COMMA but  exactly three and the three children are  for the trie corresponding to smaller  keys .PERIOD  the trie corresponding to trees that  start with the same ,COMMA character in the tri  corresponding to larger trees .PERIOD  and just given this ,COMMA this des ,COMMA  description and experience with many of  the data structures that now ,COMMA we've  talked about already in this course .PERIOD  many of you could go off and implement  this data structure ,COMMA and we'll see how  simple the implementations are .PERIOD  but still let's work through precisely  what the data structure looks like .PERIOD  'cuz sometimes the recursive code looks  almost too simple and kind of mass  understanding .PERIOD  so this is the representation of trie's ,COMMA  that we started with .PERIOD  and all we do with ternary search trees  is it's ,COMMA it's almost like having a binary  search tree representation of the  non -DASH null links for every node .PERIOD  so ,COMMA in this case we're going to have an  ad ,COMMA an s at the root ,COMMA and that depends on  where your keys are inserted .PERIOD  and the key idea is ,COMMA the middle link  coming off the root node ,COMMA is a link to  the tsts that have all the keys that  start with s ,COMMA with s stripped off .PERIOD  now ,COMMA but for the left and right links  those are for keys that start with some  letter that appears before s on the left ,COMMA  and after s on the right .PERIOD  and then say ,COMMA on the left ,COMMA the node for b  is ,COMMA if you go down this link ,COMMA it's all  the keys that start with b .PERIOD  otherwise the b is just to divide the  ones that are less ,COMMA from the ones that  are bigger ,COMMA and so forth .PERIOD  and again ,COMMA if you [cough] search for a  key by say ,COMMA look search for she ,COMMA so  that's going down middle links and  matching keys .PERIOD  then some nodes will have values  associated with them ,COMMA that's the value  associated with the last letter ,COMMA last  character in the search key .PERIOD  so ,COMMA that's what the data structure looks  like .PERIOD  and i'd begin to describe the search  algorithm ,COMMA it's quite simple given the  definition of the data structure .PERIOD  again ,COMMA we follow links corresponding to  each character of a key .PERIOD  if we have a character that's less than  the character in the node ,COMMA we go left ,COMMA if  we have one that's greater ,COMMA we can go  right .PERIOD  and if it's equal we move to the next  character ,COMMA and take the middle link .PERIOD  so this is an example of a search for a  sea .PERIOD  start with s ,COMMA that's a match ,COMMA we take the  middle link .PERIOD  now the next character is e that's a  mismatch and e is less than 8 ,COMMA so we go  to the left .PERIOD  now we find a note that has e ,COMMA and we  didn't update our pointer into the key  character ,COMMA because we didn't find a  match .PERIOD  so ,COMMA we're still looking at the e ,COMMA and  now ,COMMA now we can match that e ,COMMA so we go  down the middle link .PERIOD  now we're looking at the a in the search  key ,COMMA and that's less than l ,COMMA so we go to  the left .PERIOD  now we're still looking at the a in the  search key ,COMMA and that's a match and it's  the last character in key ,COMMA so ,COMMA we return ,COMMA  the value associated with the last  character in the key .PERIOD  so ,COMMA it's the same basic algorithm ,COMMA that  we used for trie's except ,COMMA we just have a  different way to decide whether we match  the character .PERIOD  we explicitly store characters in nodes .PERIOD  we follow middle link on a match ,COMMA and  update the pointer in our key character .PERIOD  otherwise ,COMMA we ,COMMA we follow the left or  right link ,COMMA because we know that the key  is going to be found in the left or right  sub -DASH tree .PERIOD  and each node has exactly three links .PERIOD  so here's a example of search in a tst ,COMMA  again this is the example i just talked  about in a dynamic form ,COMMA form .PERIOD  so ,COMMA if s is the first character in the  key ,COMMA matches the s in the first node of  tree ,COMMA so we take the middle link ,COMMA and  move on to the second character in the  key which is e .PERIOD  compare that against h ,COMMA it's not a match  in fact it's less ,COMMA so we go left .PERIOD  so ,COMMA now we're still looking at e and c ,COMMA  and it's a match with the character in  the node that we're currently processing .PERIOD  so ,COMMA we take the middle ,COMMA and now we move  to the next character in the key which is  a .PERIOD  and now we take a compared to l ,COMMA and a is  less ,COMMA so we go left ,COMMA we're still looking  at the a ,COMMA didn't updated it ,COMMA 'cuz it's  not a match ,COMMA and now it is a match .PERIOD  and it's the last character in the key ,COMMA  so we look at the value ,COMMA and that's the  value we return .PERIOD  what about unsuccessful search ?QUESTIONMARK  well ,COMMA let's see how that works .PERIOD  so ,COMMA for shelter ,COMMA it starts with an s ,COMMA so  we take the middle link ,COMMA second ,COMMA and move  to the second character .PERIOD  second character's an h ,COMMA and that's a  match .PERIOD  so ,COMMA we take the middle link ,COMMA and move to  the next character .PERIOD  third character's an e and third  character ,COMMA and that ,COMMA that's also a match .PERIOD  so again ,COMMA we take the middle link ,COMMA and  move to the next character .PERIOD  the fourth character's an l ,COMMA that's also  a match .PERIOD  so ,COMMA again ,COMMA we take the middle link ,COMMA and  move to the next character .PERIOD  now the next character is a t ,COMMA which is  not a match ,COMMA so we want to move to the  right but moving to the right takes us to  a null link .PERIOD  so that means that shelter is not in the  tst and ,COMMA and so we return null .PERIOD  again ,COMMA in every ,COMMA in every step what we do  is completely well -DASH defined .PERIOD  and any search for a key that in the tst ,COMMA  it's going to return it's associated  value .PERIOD  any search for any other key ,COMMA is either  going to ,COMMA go out on a null link ,COMMA or end  on a node that involves a mismatch .PERIOD  so ,COMMA with that basic idea ,COMMA let's take a  more detailed look in the demo ,COMMA of how  the tree gets constructed .PERIOD  and following through this demo ,COMMA will  give you a pretty good feeling for how  these trees are constructed .PERIOD  so ,COMMA we're going to associate the value 0  with a string ,COMMA she .PERIOD  so ,COMMA again every time we move to a new  letter ,COMMA we have to create a new node ,COMMA  until we get to the end of the key .PERIOD  and at which case ,COMMA we put the ,COMMA associated  the value with the node that contains the  last character in the key .PERIOD  so ,COMMA that's the starting point .PERIOD  key is a sequence of characters down the  middle links that [cough] goes to from  the root to some node .PERIOD  and the value is in the node that  corresponds to the last character .PERIOD  so ,COMMA how do we put a new one in this tree  so the in this ternary search trie .PERIOD  our first character is s ,COMMA so we go down  the middle .PERIOD  our next character is not a match so  [cough] we go to the left ,COMMA and it's a  null link but we have a node that we want  to put there .PERIOD  that's the one corresponding to the  second letter ,COMMA in sell's so we do that ,COMMA  and then we make nodes with middle links ,COMMA  going until we get to the last character  in sell's ,COMMA and we associate that with the  value 1 .PERIOD  so ,COMMA what about sea ,COMMA let's see how that  one works .PERIOD  so ,COMMA first character is s ,COMMA so i take the  middle link ,COMMA second character is e which  is less than h and not a match so we move  to the left and continue looking for the  e .PERIOD  now this node we find the e ,COMMA so we take a  middle link ,COMMA and move to the next node  [cough] next character which is a ,COMMA a is  less than l .PERIOD  it's not a match so we go to the left ,COMMA  that's a null linl ,COMMA and that's where we  put our a ,COMMA and we associate it with the  value 2 .PERIOD  ok ,COMMA here's sh ,COMMA shells so we have a match  at s ,COMMA go to the middle link ,COMMA and go to  the next letter ,COMMA match h middle link next  letter .PERIOD  and then we go down and add the three  nodes corresponding to the last three  letters and put a three at the node  corresponding to the last letter .PERIOD  ok ?QUESTIONMARK  now b y we look at s not a match it's  less ,COMMA so we're going to go to the left ,COMMA  that's a null link .PERIOD  that's where we put our first character ,COMMA  and then we go down the middle link to  add the node for the last character ,COMMAand  then ah ,COMMAassociate the value for there .PERIOD  and then b is a similar thing on the  right .PERIOD  and then go for the t and h and e ,COMMA and  that gets our share with the value 5 .PERIOD  sea again ,COMMA it's associative ,COMMA so we do the  search ,COMMA so s is a match .PERIOD  so we go down the middle link ,COMMA and move  to the next letter .PERIOD  e is less than h so we go to left ,COMMA and  keep looking for e .PERIOD  now we find e is a match ,COMMA so we go down  the middle link ,COMMA and move to the next  letter .PERIOD  that's a ,COMMA which is less than l ,COMMA so we go  to the left to look for the a ,COMMA and there  we find it .PERIOD  and we're [cough] building an associate  symbol table ,COMMA so we update and overwrite  the old value with the new value ,COMMA 6 .PERIOD  s ,COMMA h ,COMMA o ,COMMA r ,COMMA e .PERIOD  we match the s ,COMMA match the h ,COMMA now we're on  o ,COMMA that does not match e ,COMMA so we go to the  right ,COMMA and keep looking for o .PERIOD  now ,COMMA we don't find it ,COMMA so we create a new  node for o ,COMMA r ,COMMA e ,COMMA and then put the value  7 in the values associated with the last  character in that key .PERIOD  so ,COMMA that's the construction of a ternary  search tree containing eight keys .PERIOD  let's take a look at a slightly bigger  ternary search trie .PERIOD  so here's our example with three letter  words .PERIOD  now for that example ,COMMA we didn't show all  the null links ,COMMA but there's lots of null  links ,COMMA 26 null links in each leaf for  this 26 way trie .PERIOD  and there's other null links higher in  the tree ,COMMA and actually counting up  there's over a thousand null links in  this tiny 26 way trie .PERIOD  but in a tst ,COMMA it's got about the same  number of nodes it's actually got more  nodes ,COMMA because it's got one for each  character .PERIOD  and the other ones correspond to links ,COMMA  but not that many more nodes .PERIOD  but the key thing is ,COMMA it has many fewer  null links ,COMMA because there's only three  links per node .PERIOD  and this effect is obviously going to be  much more dramatic when r is much bigger .PERIOD  like a 256 way trie or even a unicode  65 ,COMMA000 way trie .PERIOD  that's the key benefit of tsts ,COMMA that and  they're much more space -DASH efficient ,COMMA then  our way trie's for large r .PERIOD  so ,COMMA let's take a look at the  implementation in java ,COMMA and then we'll  look at the code ,COMMA and then we'll talk  some more about performance .PERIOD  oh ,COMMA the representation in java is very  straightforward ,COMMA as i said many of you  could code this up ,COMMA just from the  description .PERIOD  what does a node have to have ?QUESTIONMARK  it's going to have a value ,COMMA it's going to  have a character .PERIOD  it's going to have references to left ,COMMA  middle ,COMMA and right tsts .PERIOD  and that's what it's built from .PERIOD  so whereas the standard trie  representation has a ray of links with  characters implicit .PERIOD  tst has explicit characters with only  three links per node .PERIOD  so that's tst representation and then  given the representation the code is  follows almost immediately .PERIOD  with our standard setup if we're supposed  to ,COMMA now we use ,COMMA we call a recursive  routine ,COMMA giving the root as first  argument .PERIOD  and give the tree returned going to give  a reference that back to the root .PERIOD  so our recursive routine takes a node and  returns a node and for most of the time ,COMMA  it ,COMMA it doesn't do much .PERIOD  but when it can do node ,COMMA is created this  this code is effective ,COMMA because any link  we go down ,COMMA we replace with a link that  we got back ,COMMA our standard setup .PERIOD  so ,COMMA the recursive port routine if we're  that character d ,COMMA we pull out the d  character .PERIOD  if once we've done that ,COMMA if our node is  null ,COMMA we create a new node and give it  that character .PERIOD  and now we test our character in our  search key ,COMMA against the character in the  given node .PERIOD  either the one we just created ,COMMA or the  one we happen to be on .PERIOD  if if it's equal ,COMMA it will fall through to  test if we are on the last key .PERIOD  if we're not ,COMMA if ,COMMA if we're on the last  character in the key we just reset the  value .PERIOD  if its equal and we're not on the last  character in the key ,COMMA we go down the  middle link .PERIOD  and we replace that link with what we get  by going down the middle link by moving  to the next character in the key .PERIOD  otherwise ,COMMA we go either down the left or  right link under the same circumstances ,COMMA  without moving to the next character in  the key .PERIOD  so that's extremely straightforward code  for put in ternary search trie's .PERIOD  and again ,COMMA get is even simpler .PERIOD  it's a similar set up that we've used  several times before .PERIOD  use a recursive routine that returns a  node ,COMMA and we pull our value out of that  node .PERIOD  we don't have to cast in this case ,COMMA cause  we're not running arrays ,COMMA and our nodes  just has the value type in it .PERIOD  and if we get a null node back ,COMMA yea ,COMMA we  return null that its not there ,COMMA the  recursive routine will pull out the  character if its less than our if our  search character is less we go to the  left .PERIOD  and if its greater we go to the right ,COMMA  and if its equal we and we're not at the  end of the key ,COMMA we go down to the middle  and we move to the end of the key .PERIOD  if its equal and we are at the end of the  key ,COMMA we return the node .PERIOD  and even that node ,COMMA is going to contain a  value or it's not ,COMMA but that's what we'e  return .PERIOD  so ,COMMA extremely straightforward  implementation of both get and put for  ternary search drives .PERIOD  so this ,COMMA adds this line to our table ,COMMA  where ,COMMA the amount of space taken for  ternary search trie's is just three  lengths you know ,COMMA plus the value  character in each node .PERIOD  so similar to what red -DASH black bst and  hashes would use ,COMMA so no space  disadvantage .PERIOD  the determining the cost of search hits  and search miss ,COMMA these values are given  for random keys ,COMMA and they're the subject  of deep analysis .PERIOD  but it's not too many .PERIOD  le ,COMMA let's ,COMMA let's put it that way .PERIOD  and our experimental results bear that  out .PERIOD  so ,COMMA for ,COMMA for a search miss in a ternary  search trie ,COMMA you don't have to look at  the whole key .PERIOD  usually ,COMMA you look at maybe fewer  characters than than the whole key ,COMMA and  actually these results are ,COMMA are for  typical ,COMMA or random .PERIOD  but actually tsd's really shine ,COMMA in the  case where data is not random .PERIOD  they very well adapt to the data .PERIOD  like text written in english language ,COMMA is  not really language really random .PERIOD  and you can see that ternary search trees  actually out perform both hashing and red  black bsts for our benchmark ,COMMA which is  deduping these big text files .PERIOD  [cough] now you ,COMMA you can go ahead and try  to get worst case guarantees .PERIOD  by using rotations to balance the the the  internal binary search tree's  corresponding to each character in ,COMMA in  tsts .PERIOD  although that's probably normally not  worth the trouble .PERIOD  but the bottom line is that tst is at  least it's as fast as hashing for string  keys and it's it's space efficient for  sure .PERIOD  and it's pretty easy to speed it up .PERIOD  the idea is to speed it up ,COMMA that works  extremely well in practice is to ,COMMA use our  way of branching ,COMMA at the be ,COMMA at the top  of the tst .PERIOD  so rather than fool around with the  first ,COMMA couple of characters ,COMMA simply do a  big branching at the root .PERIOD  you can do r way branching at the root of  26 ,COMMA but in practice ,COMMA it's pr ,COMMA proven it  works fine to do ,COMMA let's say ,COMMA r squared  way branching at the root .PERIOD  and immediately take care of the first  two characters ,COMMA which is the common case ,COMMA  and then get down to small tsts .PERIOD  and there's variations of this ,COMMA that you  might imagine ,COMMA but this is a really  simple one that almost always works .PERIOD  you have to deal especially with one and  two letter words .PERIOD  and we'll leave that for exercise .PERIOD  but with that change now we get a ,COMMA an  algorithm that's is definitely faster  than hashing in red -DASH black bsts for our  benchmarks .PERIOD  and that'll turn out to be the case ,COMMA for  many applications .PERIOD  so ,COMMA just to summarize what are the trade  offs between tsts and hashing ?QUESTIONMARK  for hashing you have to examine the  entire key ,COMMA in order to compute the hash  function .PERIOD  we talked about examples ,COMMA where people  try to skip doing that ,COMMA and wind up with  performance problems .PERIOD  not much difference between a hit and a  miss in a hashing ,COMMA and there's a lot of ,COMMA  of reliance and maybe difficulty of  implementation ah ,COMMAdepending on the hash  function .PERIOD  and also ,COMMA hashing is really only good for  search and insert .PERIOD  the other kinds of operations that we'd  like to perform in symbol table when  there's order in the keys is not  supported by hashing .PERIOD  with tsts ,COMMA it only works for strings or  if you have keys that are numbers ,COMMA then  you can rework them into strings ,COMMA or  string like things .PERIOD  and that's that's a restriction but does  cover a huge number of applications .PERIOD  it ,COMMA it only examines the key characters  that it needs to ,COMMA and in particular ,COMMA a  search miss might involve only a few  characters .PERIOD  so ,COMMA in typical applications you'll get  sub -DASH linear performance in tsts .PERIOD  you can get searches done without looking  at the whole key .PERIOD  the other thing is there's other ,COMMA the  ordered symbol table operations you can ,COMMA  you know easily support with tsts .PERIOD  just by extending ,COMMA what we did for binary  search tree .PERIOD  and even more important there's other  interesting operations that we can add  for string keys .PERIOD  that are very useful ,COMMA and we'll see  applications ,COMMA and implementations of  these ,COMMA in just a minute .PERIOD  so the bottom line is that this data ,COMMA is  a relatively new data structure .PERIOD  but ,COMMA its better than the classic ones for  important applications .PERIOD  its faster than hashing particular for  search misses .PERIOD  and its got more flexibility even than  red black bsts ,COMMA and that's what we will  talk about soon ,COMMA but that's an  introduction to tsts .PERIOD  
now ,COMMA we're going to finish up by looking at some extra operations that are supported for string keys when we use tries .PERIOD so ,COMMA we're going to look at a couple of character based operations that can ,COMMA that are quite useful and ,COMMA and can be supported by the string symbol table api with tries .PERIOD one important one is a prefix match .PERIOD so that's given a prefix ,COMMA like say sh ,COMMA what we want is the method to return all the keys .PERIOD let's start with that prefix .PERIOD in this case ,COMMA it'll be shells ,COMMA shore and she .PERIOD another one is so -DASH called wild card match .PERIOD so that's when we don't specify one of the characters ,COMMA or multiple characters .PERIOD so we put a dot to say we'll take any key that matches the other characters and we don't care what that one is .PERIOD so he .PERIOD would match she and the .PERIOD and another one is so -DASH called longest prefix .PERIOD so now we've got a long key and we want to find the best match that's in our symbol table that matches that key .PERIOD the key in the symbol table that has the longest match with our key .PERIOD so going ,COMMA in this case ,COMMA the ones that's the longest prefix of shells sort is shells .PERIOD later on we're going to see applications of some of these and the important idea for now is that these are easy to articulate .PERIOD and not only that ,COMMA they're easy to implement with tries .PERIOD nts tr ,COMMA and turner research tree .PERIOD so ,COMMA we're going to take our standard api and add these four methods .PERIOD so ,COMMA while there's keys that returns all keys .PERIOD and ,COMMA and ,COMMA as is our usual practice .PERIOD when we have a lot of things to return ,COMMA we're going to return'em as a ,COMMA as an iterable .PERIOD so the clients can just ,COMMA iterate through the what's returned .PERIOD and that's usually what clients want to do .PERIOD and then we have keys with prefix .PERIOD give a string s ,COMMA and the iterable will return all the keys in the symbol table that have s as a prefix .PERIOD if the client wants to find the associated values ,COMMA they can do gets to get the values .PERIOD and then we have keys that match so that's where we allowed dot to be a wild card ,COMMA in s ,COMMA and we want to return all the keys that ,COMMA match ,COMMA s ,COMMA taking dot to be a wild card .PERIOD and then longest prefix of s is the key in there that's the longest prefix of s .PERIOD we're gonna see later on .PERIOD this particular one plays ,COMMA an important ,COMMA role in a ,COMMA in a more complicated algorithm .PERIOD we could also go ahead and add all the ordered symbol table methods that we considered when we looked at binary search trees like floor ,COMMA and ,COMMA and rank .PERIOD and ,COMMA we're not going to take time to do that right now .PERIOD it's very straightforward .PERIOD so one thing that we haven't really talked about but it's a good warm up for the kinds of methods that we're going to look up .PERIOD look at for these implementations is ordered iteration .PERIOD and this is trie -DASH traversal ,COMMA so we are going to do an in -DASH order traversal of the trie ,COMMA that is ,COMMA visit the left ,COMMA now visit the middle ,COMMA visit the right .PERIOD in that traversal ,COMMA we can maintain the sequence of characters on the path from the root to the current node just by adding an ,COMMA adding a character when we go down and removing a character when we go up .PERIOD and when we encounter values ,COMMA then we can put out this ,COMMA the characters that we have ,COMMA and that's the way to pull out all the keys in the trie .PERIOD so ,COMMA for example ,COMMA in this case we go down and we have b ,COMMA and then we hit the y's .PERIOD so we can output ,COMMA .PERIOD say onto a queue we can output by .PERIOD and then we go back ,COMMA we have s ,COMMA e and a .PERIOD and ,COMMA we find a value ,COMMA so we go ahead and put out the a .PERIOD now we drop the a and do the l ,COMMA and that's the l ,COMMA l ,COMMA l ,COMMA l ,COMMA .PERIOD and then we get to that s ,COMMA we have a value we can put ourselves .PERIOD and then we can drop these ,COMMA get back to the s ,COMMA and get the sh .PERIOD she ,COMMA finite value ,COMMA and put ,COMMA put the she in the queue .PERIOD lls and put shells on the queue .PERIOD drop all those values down to the h ,COMMA and get us sho ,COMMA shor ,COMMA shore ,COMMA find the value and drop shore onto the queue .PERIOD and then finally ,COMMA t ,COMMA th ,COMMA the and ,COMMA find a value and put the ,COMMA down the queue .PERIOD so it's easy to ,COMMA very easy to keep track of the sequence of characters on the path from the rout to every node and every node check for value and programmer key .PERIOD that's a ordered iteration and implementations of these extra operations are just based on multiplying ordered iteration .PERIOD so this is a implementation of keys with ,COMMA which is essentially of the operation that i was tracing on the last slide .PERIOD so if client wants keys ,COMMA we make a queue .PERIOD then we call a recursive routine that collects all the keys in the try ,COMMA starting at that node .PERIOD and ,COMMA given a null string ,COMMA which is ,COMMA the ,COMMA sequence of characters on the path to the given node .PERIOD when that recursive routine ,COMMA returns ,COMMA then we just return the queue .PERIOD and the recursive routine does encode what i said in words ,COMMA most of the time .PERIOD this is for a try .PERIOD you can do the same thing for a turner research tree with just a little more code .PERIOD so for every character we just move down the trie for that character add the character to the prefix and also pass the queue along .PERIOD if we get a null value ,COMMA we put what we have on the queue when we get null when we return .PERIOD so a very simple implementation of ordered iteration of the recursive .PERIOD so that's the implementation of the keys method .PERIOD so prefix matches an other things like that going to work .PERIOD are going to work ,COMMA just by modifying that ,COMMA and you're familiar with ,COMMA prefix matches ,COMMA when you type ,COMMA nowadays ,COMMA in your browser ,COMMA a search ,COMMA function ,COMMA you're getting ,COMMA a prefix match of all the things that you typed or other people have typed ,COMMA that ,COMMA matches those strings .PERIOD and you find that also nowadays when searching in your address books .PERIOD it's a quite ,COMMA common function nowadays .PERIOD so let's look at how that looks ,COMMA in an r -DASH way trie .PERIOD so what about finding all the keys in a symbol table that start with a given ,COMMA prefix .PERIOD well ,COMMA we just search for that prefix .PERIOD and then ,COMMA then just do a collect at the keys in that sub tri .PERIOD so that's ,COMMA very straightforward .PERIOD so you get the node .PERIOD that is the one you get to by starting with that prefix and then you just call the recursive collect and boom you're done .PERIOD extremely simple ,COMMA implementation of keys with a prefix in an r -DASH way trie .PERIOD .PERIOD what about longest prefix ?QUESTIONMARK and here's one that ,COMMA is ,COMMA is ,COMMA very ,COMMA actually very heavily used ,COMMA in the internet .PERIOD if your query strings are ip addresses on the internet and you have some given destination ip address ,COMMA the router has a lot of ip addresses in a routing table .PERIOD an it wants to choose the one that will get you as far as close to the destination as you can .PERIOD so it's going to choose the longest prefix .PERIOD so if you want to get to 128 by 112 ,COMMA you can think of these as hops on the way to where you want to get ,COMMA where eleven is the final destination .PERIOD and essentially this table says ,COMMA it knows how to get this far and so that's what it wants is the longest prefix .PERIOD the longest prefix matches this one .PERIOD well ,COMMA it doesn't know how to get any further than 112 and this other one only to 128 .PERIOD i ,COMMA and this operation gets performed extremely often on the internet nowadays .PERIOD just a quick note ,COMMA it's not the same as the floor function and it actually is a kind of a string operation .PERIOD these things actually ,COMMA usually on the internet ,COMMA they're not represented as strings .PERIOD they're represented as binary numbers .PERIOD but in machine or assembly language implementation tries are even easier .PERIOD you can just take a bunch of bits and use them as index into a table to move down the try .PERIOD and actually tries are pretty old because so easy to implement data structures in that way in the past .PERIOD you'd be surprised at how much of our computational infrastructure is built by program or consists of programs that are written in machine or assembly language that can make use ,COMMA efficient ,COMMA really efficient use of low level representations like this .PERIOD but it's also useful in higher -DASH level languages .PERIOD so what does it look like in an r -DASH way trie .PERIOD .PERIOD well ,COMMA all we're going to do is just do a search and then we're going to keep track of the longest key that we encountered .PERIOD so ,COMMA we have a path .PERIOD and on that path there is the most recently seen value that's the longest key that we found if we end that at no link that's fine .PERIOD it's the ,COMMA if there is a value on that node that's kind of a no link that's the value we're going to return .PERIOD so that's a very straightforward implementation .PERIOD just keeping track of the longest key encountered on the search for our key .PERIOD that's implementation of longest prefix of and the usual set up of ,COMMA of making recursive calls .PERIOD and this code is quite straightforward .PERIOD and application of this one and so -DASH called t9 texting .PERIOD and now you know ,COMMA when we do a course like this ,COMMA we try to keep up with modern technology .PERIOD and modern technology is moving almost as fast as we can .PERIOD there are lots of young people who really don't know about texting with keypads anymore .PERIOD but there's a certain range of ,COMMA you know ,COMMA five or ten years where people got extremely adept at doing so called multi -DASH tap input ,COMMA where the only keys on the phone were the nine keys to dial numbers .PERIOD and then you had three letters associated with each number ,COMMA like on old dial telephones .PERIOD and to enter a letter you had to like to enter an h you had to tap twice ,COMMA cuz that's the second letter on the four key you had to tap four twice or something like that .PERIOD so ,COMMA the so -DASH called t9 text input would use the kinds of algorithms that we're talking about to make it so that maybe you didn't have to do multi -DASH tap .PERIOD so rather than type two 4's ,COMMA you would do a tries type search to figure out which word that you typed .PERIOD and that now looked ,COMMA it'll look good to us as a potential application for a while .PERIOD glad we didn't spend too much time on it .PERIOD if you study this keyboard ,COMMA maybe you'll see ,COMMA see why .PERIOD well you think about how to implement it .PERIOD but once we get into it ,COMMA we realize ,COMMA kevin realized there's no s in this sample keypad ,COMMA what happened to the s ?QUESTIONMARK so what are we going to implement because even if there's no s there ,COMMA so what exactly are they doing and well maybe this is a bit of a fantasy that this is the response that ,COMMA maybe these people lived in a world with no s's .PERIOD mmm .PERIOD well anyway ,COMMA we've moved on from tries from ,COMMA from that type of ,COMMA way of entering text .PERIOD but i still want to mention a few more ideas because the basis behind tries and turner research trees is still out there and is still really an important part of our infrastructure .PERIOD and there's some really great algorithms that we just don't have time to cover .PERIOD now one of them's an old algorithm called patricia .PERIOD and ,COMMA this one ,COMMA is a really interesting and intricate algorithm .PERIOD particularly when implemented for binary tries ,COMMA where you just do a bit at a time .PERIOD and people ,COMMA again ,COMMA implemented this kind of algorithm in machine language .PERIOD and got extremely efficient performance .PERIOD if we cast it in ,COMMA in ,COMMA our way tries that we've talked about it's really the best way to think about it is ,COMMA a way to remove one way branching .PERIOD it seems wasteful ,COMMA to have ,COMMA all these nodes that just have one branch .PERIOD and so one of the main ideas behind patricia there's others that ,COMMA don't really ,COMMA show up ,COMMA in the level ,COMMA high level representation we're using .PERIOD but one of the main ideas behind patricia was rather than associate a character with each node ,COMMA associated sequence of characters with each node ,COMMA so you just don't have any one way branching .PERIOD implementing this is maybe one step beyond this course but maybe it's within what we could do in this course .PERIOD where just not going to take the time to do so .PERIOD and you'll find implementations that in practice avoid the one -DASH way branching that are used in many ,COMMA many applications ,COMMA performance critical applications for searching nowadays ,COMMA i already mentioned ip routing tables .PERIOD there's probably ,COMMA you know ,COMMA no piece of code that's executed more often than that one .PERIOD that's based on a trie type algorithm .PERIOD and we have these other applications listed as well .PERIOD it's got some other names too .PERIOD another thing ,COMMA is ,COMMA so called ,COMMA suffix tree .PERIOD so ,COMMA that's ,COMMA building a tree from a suffix table .PERIOD so ,COMMA we talked about having ,COMMA for suffix sorting ,COMMA we talk about applications .PERIOD you can also build a search structure from suffixes of a string .PERIOD that admits ,COMMA all kinds of ,COMMA fast string processing application .PERIOD and again ,COMMA usually ,COMMA eliminate on way branching in suffix trees ,COMMA and also amazing ,COMMA amazingly you can get'em constructed in linear time .PERIOD and there's all kinds of interesting applications of suffix trees probably the most important now a days are in computation biology databases .PERIOD again extensions of the kinds of algorithms that we've talked about today .PERIOD so i think the bottom line for considering string search trees is that it's a real success story in algorithm design and analysis .PERIOD it's a number of clever algorithms that really have made a difference in the kinds of operations that we can perform in the amount of data that we can handle in modern applications .PERIOD we ,COMMA we started with red -DASH black bst's which is a pretty good solution for a general symbol table .PERIOD and also hash tables ,COMMA which are also widely used .PERIOD but with tries ,COMMA and turner research tries we have a performance guarantee where we'll only have to really access log -DASH in characters .PERIOD and when you think about that ,COMMA that's ,COMMA even when n is huge ,COMMA that's going to be a pretty small number .PERIOD say we're looking among billions ,COMMA billions of things log in ,COMMA even in you only have two wave branching would be 30 .PERIOD and when we have 256 way branching ,COMMA it's way ,COMMA way smaller .PERIOD and that's just the number of ,COMMA so it's the number of characters accessed .PERIOD and the ,COMMA really the bottom line is ,COMMA if you ,COMMA you can set things up nowadays even on the internet when there's huge ,COMMA huge amounts of data out there you can set things up so that you can only need to look at maybe 100 bits to get at anything .PERIOD we think about 100 bits ,COMMA that's specifies two to the 100th of possibilities .PERIOD and two to the 100th is a huge number .PERIOD there are not two to the 100th pieces of information ,COMMA even on the internet ,COMMA even will ever exist on the internet in the .PERIOD into this galaxy .PERIOD but with just 100 bits ,COMMA which really isn't too much ,COMMA we can search for anything efficiently .PERIOD and that's an amazing success story for algorithm design and analysis .PERIOD so that completes our look at tries and turner research tries .PERIOD 
next we're going to look at the use of the binary heap data structure to implement a clever sorting algorithm known as heapsort .PERIOD so here's the basic plan .PERIOD what we're going to do is we have our end keys and we'll have them in an array .PERIOD we'll view that array as eventually being a max heap .PERIOD so what we have to do first is to rearrange the keys in the array to heap order it .PERIOD so just make it so that every key is larger than it's two children .PERIOD and for example ,COMMA the largest of all the keys is at the root .PERIOD and then ,COMMA the next phase would be to take that heap ordered array and get ,COMMA get it to be a sorted result in ,COMMA in place .PERIOD and again ,COMMA the ,COMMA heap is stored in the array ,COMMA with the first key position one ,COMMA next to position two and three and like that .PERIOD so the end result would be like that ,COMMA with ,COMMA no keys in the heap ,COMMA but all the keys in the array in sorted order .PERIOD so it's a little exercise in abstraction .PERIOD part of the array is the heap .PERIOD part of the array is the sorted sub array .PERIOD and eventually we bring it down to the whole thing being sorted .PERIOD it's very little code beyond the basic heap code that we've looked at can get this implemented .PERIOD and that's called heapsort .PERIOD let's take a demo of how heapsort works in our example .PERIOD so the idea is we're going to use a bottom up method .PERIOD so all that means is we start with an array in arbitrary order and then we're going to work from the bottom up to make sure that it's heap order .PERIOD well all the nodes with no children are heap order ,COMMA they are only a size one ,COMMA the first one we have to worry about is this one here the root ,COMMA the root .PERIOD we haven't examined yet ,COMMA it's children are heap ordered so it's a small heap of size three that may not be heap ordered .PERIOD in this case it's not because one of the children is larger ,COMMA so that's where things are going to start .PERIOD we have a lot of one node heaps and then we're going to have to perform the sync operation on this one ,COMMA that node five ,COMMA that's ,COMMA in this case just to change it with it's parent .PERIOD and then proceeding in that way ,COMMA moving bottom up or moving from right to left ,COMMA the next thing we do is but then worry about a three node heap that's heap ordered and we're fine .PERIOD now we'll move over to the t and again ,COMMA that's the root of a three node heap that's heap ordered except at the root .PERIOD we may need to fix it with the sync operation .PERIOD in this case nothing is required because it's larger than its children ,COMMA so we have a three node heap .PERIOD and then we move one more to the left ,COMMA now we're looking at the r .PERIOD again root of a three node heap may or may not be heap ordered ,COMMA we do have to do the sync operation .PERIOD in this case that brings the x up .PERIOD a three node heap .PERIOD now we go to two .PERIOD now that's the root of a seven node heap .PERIOD we know the two three node heaps that are the children are heap ordered but we may have to correct the heap ordering at the root so we do a sync on two .PERIOD and that's going to involve ,COMMA exchanging with the t ,COMMA because t is larger than o .PERIOD and exchanging with the p because p is larger than o .PERIOD now that heap is a seven node heap that's all heap ordered ,COMMA and then the last thing is to do the root of the whole thing and again ,COMMA now the two sub trees are heap ordered ,COMMA that's what we mean by bottom up ,COMMA we took care of the heep ordering from the bottom up .PERIOD and so we'll do a sync on the s and bring it into a heap ordering ,COMMA so that's with just a few exchanges we got that whole array heap order ,COMMA and now what we want to do is take advantage of the heap ordering in the array to do a sort .PERIOD and the concept is very simple .PERIOD right away we have the maximum element in the array right at the root ,COMMA we want that to be at the end so that's what we're going to do and that's what we're going to do is just put it at the end .PERIOD we exchange the element at the root with the last element .PERIOD pull it off the heap and then that's our example .PERIOD we might have violated the heap order condtion at the heap right now .PERIOD so now we have to do a sync operation on ,COMMA on the e .PERIOD and so ,COMMA it's larger than ,COMMA it's both children ,COMMA and the larger of the two children is t ,COMMA so we promote the t .PERIOD and the p is larger ,COMMA the two children promote that and then finally ,COMMA the e comes down to the bottom .PERIOD so now that's one step in the sort ,COMMA we got the largest element off .PERIOD now the next largest element in the array is now at the root of the heap .PERIOD we're going to do the same thing ,COMMA exchange it with the last element in the heap .PERIOD then now that t is in its final position in the sorted array ,COMMA we take it off the heap .PERIOD so now ,COMMA we've got a heap with nine elements and two of the elements in the array are already in their final position .PERIOD and now this one's not heap ordered ,COMMA so we have to exchange over the largest of its two children .PERIOD in this case that involves regarding the s and the r .PERIOD now it's heap ordered .PERIOD so that's the end of the two steps in heapsort .PERIOD and then we just keep going .PERIOD pulling off the largest element from the heap .PERIOD exchanging it with the .PERIOD element in the heap in the largest position in the array which brings that element into its final position in the sorted array .PERIOD and then adjusting the heap ordering with the sync operation .PERIOD so that e again is going to come down and now it only goes down one step in this case .PERIOD so now r exchanges with m .PERIOD it's in it's final position and you can see down at the bottom ,COMMA the large elements in the array filling in ,COMMA in their final position ,COMMA in the ,COMMA the left part of the array is representing the heap .PERIOD the r goes off the heap ,COMMA do the sync operation on the m ,COMMA and now we have a heap ordered array .PERIOD so now do the p ,COMMA exchange that with the a .PERIOD take it off the heap .PERIOD do the sync operation on the a .PERIOD now we're going to do the o .PERIOD exchange that with the e .PERIOD take it off the heap .PERIOD do the sync operation on e which involves promoting the larger of its two children ,COMMA until it gets to the bottom ,COMMA or a place where it's larger than both its children .PERIOD so now we have ,COMMA just five elements left .PERIOD we'll ,COMMA get the m .PERIOD do heap ordering on the ,COMMA heap of four and that only involves one exchange .PERIOD now we get the l .PERIOD a exchange for the larger of its two children .PERIOD while ,COMMA they're both the same ,COMMA so i t goes with the left one .PERIOD that's the heap of size three .PERIOD pull off the first e ,COMMA it's already heap ordered .PERIOD pull off that e .PERIOD and ,COMMA now we are left with only one element in the heap in this in the first position ,COMMA so there is nothing to do .PERIOD so with a series of in exchange and then sync operations ,COMMA we pull the sorted array out of the heap .PERIOD okay .PERIOD this ,COMMA slide summarizes the code for ,COMMA heap construction .PERIOD and as you can see ,COMMA it's a one liner .PERIOD we go backwards through the heap .PERIOD starting at n over two because the ,COMMA n over ,COMMA half of the ,COMMA right most half of the array is just little heaps of size one .PERIOD we just go backwards doing a sync starting at k .PERIOD so that's the first piece of code for heap ordering an array with arbitrary values and then these diagrams summarize the sync calls that ,COMMA that we just went through in the demo starting at five ,COMMA four ,COMMA three ,COMMA two ,COMMA one .PERIOD as you can see ,COMMA only one ,COMMA two ,COMMA three ,COMMA four ,COMMA five exchanges are needed to bring this into heap order .PERIOD then the second pass again that's only a two liner ,COMMA we exchange the first element with the one at the end and then decrement the size of the heap and then do a sync operations .PERIOD and these diagrams summarize the sync operations that we showed in the demo .PERIOD on every smaller heap ,COMMA now we continue just performing sync operations at the root until we get a completely sorted array .PERIOD so given the sink implementation ,COMMA we had done a one liner for the first pass and a three liner for the second pass so that gives a complete implementation of heap sort with the code that we have given so for ,COMMA so far .PERIOD there's is one little detail when you are sorting an array of course position zero comes into account and we've been building our heaps from position one .PERIOD so ,COMMA but we can take care of that in the less and exchange methods by just decrementing the indices in those methods to have it work as if the array were zero through n .PERIOD that's a little implementation detail ,COMMA but otherwise this is a fine sword implementation ,COMMA that actually is very little code ,COMMA and its got a place in ,COMMA in the theory of algorithm ,COMMA that i will talk about in a second .PERIOD this is just another trace without the data -DASH structure shown ,COMMA to just show in our standard way ,COMMA the elements in black and red are the ones that are touched and the elements in grey are the ones that are not touched at all .PERIOD and to just show that this thing gets the sort done with touching relatively few elements .PERIOD that's a trace .PERIOD let's look at an animation ,COMMA an animation with heapsort is interesting to watch so the construction of the heap happens in a blink and now it's pulling off the largest elements ,COMMA moving from right to left .PERIOD so again ,COMMA a very efficient way to get a sorting job done .PERIOD so what about the mathematical analysis ?QUESTIONMARK well the mathematical analysis ,COMMA for the heapsort part is pretty easy .PERIOD n times ,COMMA we're doing a sink operation ,COMMA and the size of the heap is at most lg n so it's n lg n .PERIOD the construction ,COMMA actually ,COMMA it turns out although it's a little more complicated to prove ,COMMA that it always uses just a linear number of comparison exchanges .PERIOD and that's an interesting result in itself .PERIOD you can build a heap from n values in linear time .PERIOD and then ,COMMA and then lg n more time .PERIOD you can sort from that heap and that's significance be ,COMMA significant because it's the first sorting algorithm that we've seen that is both in place .PERIOD and manages to get the sorting job done with guaranteed analogs and compares .PERIOD mergesort doesn't do that .PERIOD it takes linear extra space .PERIOD quicksort doesn't do that .PERIOD it takes quadratic time in a worse case even though we make that unlikely by random shuffling .PERIOD it still takes quadratic time in the worse case but heapsort does both .PERIOD now there is more complicated versions of mergesort and quicksort that can do this in theory but heapsort is pretty simple algorithm that gets both done ,COMMA so in a job interview somebody asks you what's an in -DASH place sorting algorithm that's guaranteed n lg n ?QUESTIONMARK your answer's going to be heapsort .PERIOD now in practice heapsort is actually not used that much for a couple of reasons .PERIOD and they might ask you these on your job interview too .PERIOD first thing is the inner loop is longer than quicksorts .PERIOD like mergesort there is more things to do in the inner loop .PERIOD there is that compare are the two children bigger ,COMMA then compare .PERIOD so there are two compares that get done at n lg n times .PERIOD and then there is some that array index arithmetic .PERIOD the other thing that is probably more significant on modern machines is .PERIOD that the references to memory are all over the place when it's a huge array ,COMMA so it's not a good algorithm for a situation where there's caching which is almost everywhere nowadays .PERIOD it doesn't have a local reference ,COMMA like quicksort does .PERIOD it's always refers to something that's nearby something else that i just referred to .PERIOD so if a big block of things comes into memory ,COMMA there's no more extra costs ,COMMA whereas heapsort is going to look far away from the current place as it goes down the tree and that makes it slower in a lot of situations .PERIOD and on the other thing is it's not stable ,COMMA sometimes people choose to use mergesort in practice because of the stability but heapsort isnot stable for the usual reason that it does long distance exchanges that might bring items that have equal keys back out of order .PERIOD so that ,COMMA that ,COMMA that's our full summary of sorting algorithms to and completes our treatment of sorting algorithms with heapsort .PERIOD and this is just adding the heapsort line to the table .PERIOD it's in place we don't use any auxiliary array it's not stable ,COMMA but its worst -DASH case guaranteed time is proportional to n lg n as well as the average and ,COMMA and the best this is not a result but that's also the case so it's n lg n guarantee n place ,COMMA but it's not stable ,COMMA and we still have the hope that someday somebody will develop a simple in -DASH place stable worst case n lg n algorithm but we're not quite there yet .PERIOD and that completes our treatment of sorting algorithms with the heapsort algorithm .PERIOD 
now ,COMMA look at an interesting application of priority queues that is actually representative of whole family of a critically important applications in applications of computing .PERIOD it's called event driven simulation .PERIOD and the idea is we want to study some property of the natural world by simulating it .PERIOD and that's something that's very ,COMMA very common in ,COMMA in scientific inquiry nowadays .PERIOD and this is a very natural idea .PERIOD and actually ,COMMA the idea goes back to einstein .PERIOD so ,COMMA we want to simulate the motion of n moving particles that might collide with the priority .PERIOD this ,COMMA this kind of stimulation is enabled by priority queues .PERIOD and without something like priority queues ,COMMA you couldn't do this for a large number of particles because it would require quadratic time and simply can't be afforded for a huge number of particles .PERIOD so ,COMMA and let's take a look at how we can possibly make this happen .PERIOD so we use a simple scientific model called the hard disc model .PERIOD and then ,COMMA this is just for simplicity to get this done and just part of a lecture .PERIOD clearly ,COMMA these things can be extended in many ways .PERIOD so ,COMMA we're going to have moving particles that either collide with each other and with the walls .PERIOD and each particle is a disc that's got known position ,COMMA velocity ,COMMA mass ,COMMA and radius .PERIOD and there's no other forces involved .PERIOD it gets more complicated if there's more forces ,COMMA like gravity involved .PERIOD and this point by itself is very significant .PERIOD as i mentioned ,COMMA it goes back to the study of physics with [cough] the trying to understand the pressure and temperature in einstein's famous experiment on a pollen grain showing that their motion was brownian and random .PERIOD so whether it's individual atoms and molecules or some bigger kinds of particles .PERIOD it's a complex dynamic situation that is better understood through computer simulation .PERIOD and nowadays that means priority queues .PERIOD [cough] so ,COMMA as a wa rm -DASH up ,COMMA here's code to implement bouncing balls without the collisions .PERIOD and this is an elementary programing exercise that is the ,COMMA the code at the left has the effects shown at the right .PERIOD so ,COMMA we have a data type called ball that represents just one of the particles and has instance variables that has the position and the velocity .PERIOD so ,COMMA that's why we make a bunch of them and then we have a ,COMMA a while loop which is just every 50 milliseconds clear the ,COMMA the whole drawing and then move the balls a little bit and then draw them in their current position .PERIOD and then the only to move [cough] operation does is to update the position of the ball by the velocity ,COMMA which is just another number and then it does the bouncing off the walls .PERIOD if it happens to hit the left of the wall then you reflect the x -DASH coordinate in the right wall ,COMMA you reflect the x -DASH coordinate bottom to top ,COMMA you do the same for the y -DASH coordinate .PERIOD so ,COMMA this the is an easy programming exercise given the right display primitives .PERIOD and it's a good exercise in object -DASH oriented programming showing how just one implementation then we can use that same implementation to simulate a number of instances .PERIOD so ,COMMA that's our starting point in terms of the code .PERIOD so this is the implementation of the ball class .PERIOD so ,COMMA it's got position and velocity as i mentioned ,COMMA and every ball has a ,COMMA a radius .PERIOD and then there is a constructor and maybe we have a constructor that takes arguments that would initialize the position and the velocity or maybe initialize them to a random position if there's no arguments .PERIOD and then ,COMMA here's the move method .PERIOD and the move method again ,COMMA most of the times ,COMMA just takes the x and y coordinates and adds the current velocity times the speed constant .PERIOD the dt speed ,COMMA speed variable that's given as argument dt .PERIOD and then these tests are for whether it hits the walls in which case ,COMMA you have to flip the x or y velocity .PERIOD and then draw ,COMMA it's just using standard draw .PERIOD just draw the ball .PERIOD so ,COMMA that's all the code for doing the bouncing ball simulation .PERIOD now ,COMMA what's missing in this is what happens when the balls collide with each other .PERIOD and to cope with that we need to do both .PERIOD a little bit of high school physics and a little bit of basic computer science .PERIOD the physics problem is exactly what happens when two balls hit and they bounce off each other according to some well -DASH understood physical process ,COMMA and that's the high school physics .PERIOD and the cs problem is how and when to we exactly do these computations for each of the balls .PERIOD and how can we do it efficiently that is in ,COMMA in log n time versus quadratic time .PERIOD because if we have a computational process that takes quadratic time ,COMMA then it's not going to scale ,COMMA we're not going to be able to do large number of particles .PERIOD simulations in the real world ,COMMA usually ,COMMA we wind up doing huge amounts of data and we cannot have a quadratic algorithm .PERIOD this is just first indication of that of why if you want to do this simulation ,COMMA you better know about some data structure like priority queues .PERIOD if you try to do it without it ,COMMA you're not going to be successful .PERIOD alright ,COMMA so ,COMMA let's take a look at what happens .PERIOD so there's a number of things that you might consider trying .PERIOD so ,COMMA one idea is the so -DASH called time driven simulation .PERIOD and we just say ,COMMA we're going to update everything every dt seconds .PERIOD then we go ahead and then we could check if there's a collision ,COMMA if the two balls ,COMMA pieces of the two balls are occupying the same space .PERIOD and if there is ,COMMA then we could roll back time just a little bit and i'll try to figure out exactly ,COMMA the moment of which they collided and then figure out how the position and velocity should change accordingly and then continue the simulation .PERIOD but this has a huge problem .PERIOD the first one is that you have t o check all pairs of balls for overlap so that's quadratic ,COMMA so it's going to be really ,COMMA really lot of overall texture you're not going to be able to do it for a huge ,COMMA huge value of n .PERIOD but the other thing is even if n is small if you do a very small dt ,COMMA then you're just doing this calculation over and over again and there's just too much computation moving the balls little bit at a time .PERIOD on the other hand ,COMMA if you try to improve things by making dt too large you might completely miss a collision as shown in the example at right .PERIOD so figuring out the value of dt that would really work is a huge problem for the time driven simulation .PERIOD instead ,COMMA what we want to do is called an event driven simulation .PERIOD and this is a very general concept that's useful in all kinds of context .PERIOD and we are going to change things when something happens .PERIOD so ,COMMA since the only thing that matters is collisions ,COMMA we are going to figure the particles move in a straight line ,COMMA between collisions .PERIOD and what we are going to do is focus only on the times when the collisions are going to occur .PERIOD and the way we are going to that ,COMMA is to maintain a priority queue and that priority queue is going to have all the possible collisions that could happen in the future and they're going to be prioritized by time .PERIOD and when we remove the minimum element from the priority queue ,COMMA that's the next collision that we have to deal with .PERIOD and so we have two phases ,COMMA we have prediction and resolution .PERIOD so ,COMMA that's sometime t ,COMMA we can take two particles .PERIOD we know their position and velocities shown at the bottom here and we can predict exactly the moment ,COMMA which they'll collide assuming that something else doesn't happen to them in between and then so they will put that predicted collision time on the priority queue and later on ,COMMA when that time comes to pass we will be right at moment when they collide and we can figure out what to do .PERIOD now ,COMMA there is a possibly that something else happened to t hem in between and we'll talk about that change ,COMMA too .PERIOD so ,COMMA we have to do collision prediction ,COMMA which is given position ,COMMA velocity ,COMMA and radius when's it going to hit with another particle or ,COMMA or the wall .PERIOD and then there's resolution which is to figure out how to change the velocities of the particles according to physical laws .PERIOD now this part i'm not going to talk about in that much detail right now because it's high school physics .PERIOD and so ,COMMA i think most students have had high school physics and will be able to do ,COMMA do this math or at least be convinced that the code that does this math is correct .PERIOD so ,COMMA if you know that you have a particle that's at a certain position or x or y and has got a certain velocity ,COMMA the x in the x -DASH direction and y in the y -DASH direction ,COMMA then you can from the distance to the pro ,COMMA vertical wall you can figure out how many seconds this is going to take until it hits it .PERIOD it's basically that distance divided by the by the velocity .PERIOD and so that's the prediction .PERIOD and then ,COMMA the resolution .PERIOD when it hits the wall is ,COMMA is just going to change the velocity .PERIOD so that's in ,COMMA you know what the position is .PERIOD so that's just an example of collision ,COMMA of collision prediction ,COMMA when's it going to hit the wall and resolution what do you do when it gets to the wall .PERIOD when you have two particles there's definitely more math .PERIOD and again ,COMMA this is high school physics .PERIOD and we're not going to test on it or even go through the details .PERIOD but it's just a little bit of arithmetic with the velocities and positions to deal with what happens when ,COMMA when how to predict when a given particle is going to collide with another given particle knowing their velocity and position .PERIOD so ,COMMA you have to take both velocities and divide their distance by those and ,COMMA and so forth .PERIOD so there's simple formulas to tell us what to do and we can also figure out the formulas for what we do o nce they do collide .PERIOD and again nobody's claiming that this is easy but this is the physics part and it's worked out and it comes from newton's second law .PERIOD and ,COMMA and ,COMMA anybody taking high school physics will ,COMMA be able to deal with these formulas and the rest of this may have to go to a reference book to get up to speed on them .PERIOD [cough] but once it's reduced to code we can be ,COMMA it might have some trouble debugging at first but at least we can be convinced that it works .PERIOD but now ,COMMA let's look at the computer science code .PERIOD so ,COMMA this is just extending our ball data type that we use for the bouncing balls that didn't collide to take in ,COMMA into account these extra things .PERIOD so ,COMMA ours will have mass ,COMMA so there will be some big heavy ones that make things more interesting .PERIOD and there's also a variable called count ,COMMA which is the number of collisions of particles have been involved in .PERIOD and that's useful for a couple of purposes .PERIOD so ,COMMA we're going to need a bunch of procedures which do the prediction and the collision resolution .PERIOD i want ,COMMA what's the ,COMMA given a particle what's the time till we hit that particle ?QUESTIONMARK what's the time till we hit vertical horizontal wall ?QUESTIONMARK and the same thing is if we're at the point where we're hitting a particle ,COMMA what would we do ,COMMA the ,COMMA the same way with the vertical and horizontal wall .PERIOD so ,COMMA that's the skeleton .PERIOD we need those procedures that implement those physics rules for every particle .PERIOD and ,COMMA and this is what they look like and again this is high school physics so we're not going to do it in detail other than to point out it's really not a huge amount of code .PERIOD lots of the xs and the ys and the vs but really not a huge amount of code .PERIOD and the other point is we're going to return infinity if there's no collision at all so that it's going to keep ,COMMA keep that on the priority queue ,COMMA that ran on the priority queue forever .PERIOD okay ,COMMA so that's the procedures that we need and then they're similar ones for the horizontal and vertical walls .PERIOD so now ,COMMA let's look at the main loop for the event driven simulation .PERIOD so ,COMMA the first thing is we're going to for every particle we're going to compute the next time that it might hit every horizontal and vertical wall .PERIOD well ,COMMA actually if it's going away from a wall ,COMMA it's not going to hit it so that would be infinity .PERIOD but if it's going towards a wall ,COMMA then we'll compute the time .PERIOD and then that's a time in the future and we'll put that event on the priority queue with that time as the key .PERIOD and then ,COMMA we'll do the same thing for all pairs of particles .PERIOD so ,COMMA we do have a quadratic initialization phase that we perform just once to get the priority queue filled up .PERIOD now ,COMMA all collisions are ,COMMA might not happen so we might have two particles that are on a collision course that and we're going to predict that point for both of those particles ,COMMA you know ,COMMA even right at the beginning .PERIOD but it might be the case that there's a third particle that knocks one of those out before that thing happens and that event would be invalidated .PERIOD so ,COMMA the simulation has to be careful to take that into account .PERIOD but that's not difficult to do .PERIOD so ,COMMA here's what the main loop is .PERIOD so ,COMMA we're going to take the next event from the priority queue .PERIOD that's the next collision that's going to happen from all our calculations .PERIOD there's one collision that's going to happen next .PERIOD then ,COMMA we test whether that event has been invalidated .PERIOD and we do that by using that count field in the particle .PERIOD so ,COMMA then that tells us what time it's going to be next .PERIOD so ,COMMA then we have to go through all the particles and change their positions on a straight line trajectory ,COMMA where would they'll be after that much time ?QUESTIONMARK then we have to take the two particles that collide and change their velocity .PERIOD they bounce off one another .PERIOD now those two particles' velocities have changed  ,COMMA essentially that invalidates the future collisions involving those .PERIOD and then we ,COMMA what we have to do is for those two particles is go through and predict the future collisions with any walls and collisions with any other particles .PERIOD and put all those new events on to the priority queue .PERIOD but that's it .PERIOD you got two particles ,COMMA change your velocities figure out the future collision of those particles with the wall and update the priority queue and then the main loop is take the next thing off the priority queue and keep going .PERIOD that's the code that we'll look at next .PERIOD so we have a ,COMMA a ,COMMA a bunch of conventions just to reduce the code .PERIOD and if we this the ,COMMA the thing called event which involves it says between two particles ,COMMA something is going to happen at a certain time and we're going to adopt the conventions that ,COMMA if ,COMMA neither particle is null then we're talking about two particles .PERIOD if one of the particles is null then we're talking about a wall ,COMMA a vertical or horizontal wall .PERIOD and if both particles are null we're saying we just want to redraw things .PERIOD that's a bit of a hack ,COMMA but it cuts down on a lot of code .PERIOD our compared to is by time .PERIOD and then again ,COMMA we need an ,COMMA is valid to check about intervening collision .PERIOD and then here's the skeleton of what's going to happen with the collision system which is the key thing is this prediction method that takes a particle as argument ,COMMA and adds to the priority queue ,COMMA all the possible collisions involving this particle .PERIOD so ,COMMA it's going to go through every particle and call the time to hit method for that particle .PERIOD and then ,COMMA it'll put an event on the priority queue for that time ,COMMA this particle with that particle .PERIOD and then ,COMMA it'll also put an event for the vertical wall and the horizontal wall ,COMMA again ,COMMA using this null convention to say that the event second argument null is vertical .PERIOD first argument null is horizontal .PERIOD so that's a key method t hat gets used in the simulation for each of the two particles that are going to collide .PERIOD so ,COMMA now we can look finally at the main event driven simulation loop .PERIOD so there's build a priority queue .PERIOD there's do this prediction for every one of the particles .PERIOD and then ,COMMA also we're going to put as the first thing that happened always a ,COMMA an event that says redraw everything .PERIOD so that's just a ,COMMA a way of make suring that the simulation keeps proceeding .PERIOD it's an easy way to get things drawn .PERIOD okay .PERIOD so ,COMMA now the main loop is while the priority queue is not empty we're going to pull off an event .PERIOD we're going to test whether it's valid .PERIOD and that's just checker if anything happened with those two particles .PERIOD we're going to pull off the two particles and then we're going to all ,COMMA we're going to move all particles by the amount of time that has elapsed since the last event .PERIOD and then ,COMMA we're going to test which of the four types of events that it is .PERIOD it's either redraw ,COMMA bounce ,COMMA b of a or ,COMMA or bounce off a vertical wall or ,COMMA or a horizontal wall .PERIOD and then we'll go ahead and do the predictions of each of those particles ,COMMA a and b ,COMMA against all other particles .PERIOD that's the pretty much all the code for the simulation .PERIOD so this is data driven code .PERIOD so ,COMMA one thing we can do is just run it for a 100 balls in random position at random velocity .PERIOD but what's nice about data driven code is now that the code's working and again we ,COMMA we're not saying that this is a trivial code to write but it's definitely manageable .PERIOD and it's enabled by priority queues .PERIOD without priority queues ,COMMA it would be quite a bit more complicated to figure out how to do this .PERIOD and also ,COMMA it wouldn't be reasonably efficient at all for large data sets .PERIOD so ,COMMA that's a ,COMMA a simple simulation to just generate random positions .PERIOD people might be interested in this one .PERIOD now this isn't exactly precisely wh at would happen in the real world mainly because we didn't put in the simulation what happens when three particles are touching or there's two touching in another one hits them .PERIOD and also nobody racks up a ,COMMA a set of billiard balls such that all fifteen are touching in all places .PERIOD so life can be complicating when you try to simulate the natural world .PERIOD this is a little bit about einstein's experiment .PERIOD if you got one big particle like a pollen grain and lots of little particles like atoms molecules and bouncing against it the big one is going to move about randomly .PERIOD and then this is another famous physics experiment showing diffusion .PERIOD and there's many other things that you can do with this basic collision system .PERIOD if you have huge numbers of particles and you measure the number that hit the size and the frequency with which they hit they sides you can do experiments relating temperature and pressure and many other things or do three -DASH dimensional versions .PERIOD again simulation of the natural world is an increasingly important application of computing and need efficient data structures like priority queues to get it done .PERIOD 
today we're going to look at substring search algorithms .PERIOD this is a really fascinating family of algorithms .PERIOD the problem is very simple to state .PERIOD and the algorithms we're going to look at are among the most ingenious that we've seen ,COMMA so far .PERIOD so it's useful to introduce the problem ,COMMA very simple to state the problem .PERIOD we have two strings ,COMMA one we call the pattern and the other we call the text .PERIOD and usually ,COMMA it's good to think of the pattern as relatively small ,COMMA and the text as relatively long .PERIOD in fact ,COMMA usually we want to think of text as unlimited length ,COMMA coming in on an input stream .PERIOD and we have a small pattern ,COMMA we want to find out if the pattern occurs in the text .PERIOD so you're doing this .PERIOD all the time .PERIOD when you do a ,COMMA a simple search .PERIOD on your computer or on the web .PERIOD and there's practical applications where ,COMMA for various reasons ,COMMA people want to search the entire contents of memory or disc for a particular pattern ,COMMA to make sure to check for whether there's something in the computer that's of interest .PERIOD and again ,COMMA you've got to ,COMMA such an application you've got a small pattern and maybe a huge text .PERIOD or maybe you're looking for your e -DASH mail which you can think of as a continuous stream of stuff coming in nowadays ,COMMA and you want to look for patterns that might indicate that there's spam and certainly you're all familiar with these types of patterns .PERIOD and so what we want is to be able to identify the pattern quickly and efficiently in a huge text file .PERIOD that's the ,COMMA one of the most important indicators of skipped spam ,COMMA i guess .PERIOD  .PERIOD okay .PERIOD so we'll try to set this up .PERIOD this isn't really a real situation but it's not too far actually .PERIOD and so we're going to have these few characters to try to point out the kinds of issues that might be involved .PERIOD so imagine an internet surveillance situation .PERIOD where there's a need to monitor what's on the internet for needs of security .PERIOD but there might be a ,COMMA a judge saying ,COMMA wait a minute ,COMMA you can't be looking at all internet traffic .PERIOD that's private information particularly among private individuals in ,COMMA in the u s for example .PERIOD well ,COMMA so what about if we just look for this one pattern ,COMMA that ,COMMA we really need to know about and that ,COMMA that ,COMMA really shouldn't violate anybody's privacy ,COMMA like tank or dorm .PERIOD and the judge can say ,COMMA okay ,COMMA how about if you build a machine that just looks for that ?QUESTIONMARK and that's what we're going to talk about today ,COMMA actually .PERIOD one of the techniques that we look at is perfect for ,COMMA actually building hardware ,COMMA that can ,COMMA be ,COMMA put on ,COMMA a stream of data passing by ,COMMA and just light the light if ,COMMA that ,COMMA particular pattern is seen .PERIOD so you attach one of those machines ,COMMA all over the web ,COMMA and ,COMMA if attack at dawn happens ,COMMA then you find it .PERIOD that's the i would say a simplified explanation of what it is that we're going to try to do .PERIOD here's another kind of application .PERIOD this is called ,COMMA screen scraping .PERIOD so ,COMMA we might want to and ,COMMA and you can do this ,COMMA write programs to do this for ,COMMA extracting relevant data from a webpage .PERIOD and the idea is that there's different institutions out there that are committed to providing information on the web .PERIOD and they'll promise to ,COMMA for example this is yahoo's page that gives the stock price of google .PERIOD when you look at the page ,COMMA it says last trade but if you write a program to look at the code that produces the page it also says last trade .PERIOD and since this html code is produced by a program .PERIOD it's always going to have the same structure .PERIOD so if we want to find ,COMMA write a program to find google's stock price at any time what we can do is take this page put it on an input stream ,COMMA and search for the pattern ,COMMA last trade .PERIOD and then just after last pray ,COMMA trade ,COMMA there's the price ,COMMA in bold .PERIOD so what we really want is the string between ,COMMA b and backslash b ,COMMA which delimits bold ,COMMA after the first occurrence of the pattern last trade .PERIOD and it's simple to write a java program that ,COMMA implements this .PERIOD this is the program ,COMMA and ,COMMA the key is ,COMMA well ,COMMA number one ,COMMA our input .PERIOD standard n ,COMMA input stream methods .PERIOD allow a webpage ,COMMA as argument .PERIOD so in this case ,COMMA we provide a command line argument ,COMMA which is whatever company you want the quote for .PERIOD and we simple read in the whole webpage .PERIOD so now you have the webpage in a long string .PERIOD and then java .PERIOD has a ,COMMA what's ,COMMA index of method for every string .PERIOD and it tells you ,COMMA where that particular string occurs .PERIOD and so ,COMMA we'll start at index of last ,COMMA last trade .PERIOD and then ,COMMA what we wanna do is find the first b .PERIOD in brackets after that position .PERIOD and the first being closed with backslash being brackets ,COMMA starting from that position .PERIOD and skipping over the ,COMMA angle bracket b closed bracket .PERIOD you get the price ,COMMA and you can print it out .PERIOD now this is a little utility that screen scraps from yahoo's website .PERIOD so sub string searching is quite in quite useful in it's built in as a method in java's string data type .PERIOD so it's practically useful that's an introduction .PERIOD so now let's look at algorithms for implementing .PERIOD string searching .PERIOD 
welcome back .PERIOD in this and the next few lectures ,COMMA we're going to look at symbol tables .PERIOD a fundamental and extremely important data type that have led to all kinds of fascinating implementations and we're going to see at several of them in this course .PERIOD to begin ,COMMA we'll take a look at the api and some elementary implementations and various operations that people want to perform on symbol tables .PERIOD start with the api .PERIOD the idea behind symbol tables is to implement the following abstraction .PERIOD we are going to have keys ,COMMA like our keys in priority queues but ,COMMA the whole ideas that we are going want to associate ,COMMA values with each key .PERIOD so two operations that we're going to perform in symbol tables is the insert operation where we're really putting a value ,COMMA a key value pair into the symbol table ,COMMA a value with a specified key ,COMMA and then given a key we want to search for a corresponding value .PERIOD those are the two basic operations .PERIOD now the keys and the values can interchange roles .PERIOD and that's ,COMMA that's why we ,COMMA have the abstraction to separate them .PERIOD so for example ,COMMA a domain name server might have a look up where you've got a table that's got an ip address ,COMMA and a url associated with that ip address .PERIOD and different clients might want to use this data in different ways .PERIOD one might want to use the url as key .PERIOD given the url ,COMMA give us the corresponding ip .PERIOD the address .PERIOD another client ,COMMA might want to use the ip address as key ,COMMA have an ip address ,COMMA give me the corresponding client .PERIOD so those are just a couple of examples .PERIOD this is a very fundamental and basic abstraction .PERIOD in the list of applications is huge ,COMMA in fact almost any computer application system is going to have symbol table or multiple symbol tables at its core ,COMMA all the way down to the basic memory system of the computer or the networking system that your computer accessed information depends on .PERIOD you can think of it intuitively ,COMMA as ,COMMA like a dictionary .PERIOD well ,COMMA there used to be books ,COMMA and people would open up those books to look for a word ,COMMA to find the definition .PERIOD nowadays ,COMMA you're more likely ,COMMA to do that online .PERIOD or ,COMMA when you're trying to find a song to download ,COMMA you provide the name of the song .PERIOD and then a value will tell you what computer to go to ,COMMA to get that or in commercial computing ,COMMA the key might be an account number ,COMMA and the value might be the transaction details ,COMMA for that account .PERIOD web search is something ,COMMA we all do multiple times every day .PERIOD and the key is a keyword ,COMMA or a list of keywords .PERIOD and the value is a list of places where that keyword is found .PERIOD and there's many ,COMMA many other applications ,COMMA including scientific applications where say in genomics people use simple tables to keep track of finding markers in the genome and again many other applications .PERIOD so ,COMMA its a very fundamental concept and we will look at plenty of applications .PERIOD but first we want to look at some algorithms so the way that it's convenient to set up a symbol table is to implement the so -DASH called associative array abstraction .PERIOD and the idea behind that is to think about just associating one value with each key .PERIOD and well it's like in java array of integers say .PERIOD we're only ,COMMA our keys in that case are indices that are restricted between ,COMMA to be between zero and the array size .PERIOD but we're only associating one value with each index .PERIOD we think of storing the value in the array position given by that index .PERIOD and a good way to think of a symbol table is as shown in the right here .PERIOD when we put a key value pair onto the symbol table .PERIOD think of that as using the key to index an array ,COMMA and storing the value there .PERIOD now this ,COMMA isn't legal in java if key is not an int .PERIOD and ,COMMA and we're going to do this generic .PERIOD it can be any type of data .PERIOD but ,COMMA it's a good way to think about it .PERIOD and then ,COMMA to retrieve it ,COMMA you just give that same key ,COMMA and it'll return the value .PERIOD so that's our ,COMMA two primary operations .PERIOD put a key value pair into the table .PERIOD so that is associate the value with key ,COMMA and then get the value paired with the key .PERIOD now th ere's particular rules for null that i'll talk about in a second .PERIOD and then to properly maintain the symbol table in a dynamic situation in many clients you want to support and delete operation and contains is ,COMMA is simpler operation than depth .PERIOD it's convenient for many clients where it just tells us whether there's some value paired with that key in the table isn't in size .PERIOD and then another thing that you might want to do is iterate through all the keys in ,COMMA in the table .PERIOD so those are the basic operations that we're going to want to implement to get the associative array abstraction .PERIOD and then there's many ,COMMA many possibilities for clients and we'll look at some later on .PERIOD now there is a couple of conventions around null .PERIOD and these are not critical ,COMMA but they make it bit more convenient for several implementations .PERIOD so we are not going to allow null values ,COMMA we cannot associate null with any key .PERIOD and then we are going to adopt the convention that the get method returns null ,COMMA if the key is not present in the table .PERIOD and also the associative array abstraction is the put method ,COMMA well ,COMMA overwrite an old value with a new value .PERIOD so these are our consequences .PERIOD so ,COMMA it's ,COMMA the contains implementation is the same for all our ,COMMA symbol typal implementations .PERIOD if get returns ,COMMA a non null value ,COMMA then there's a value corresponding to that key in the table if it returns null .PERIOD it's not get returns null keys not present .PERIOD and the other thing that we could do is we can use null in some situations or temporary situations to implement a lazy version of the delete operation .PERIOD we can associate the key with null internally and then a client won't know the difference whether that's in there or not .PERIOD and some algorithms take advantage of the ability to use null in this way .PERIOD these are just conventions and somewhat details but it's important to point them out at front .PERIOD so now ,COMMA we're going to want the value to be any generic type at all ,COMMA but the key type we have to make some natural assumptions about them .PERIOD and actually there's different assumptions that we make in our implementations depending on the application .PERIOD though one of the most useful ones is to have comparable keys .PERIOD just as in sorting algorithms we'll assume that the keys have values that have come from a total order .PERIOD and we can use compare to ,COMMA to compare whether one key is less than ,COMMA than other or not .PERIOD this is for two reasons .PERIOD one is we can get more efficient app implementations if we can use the ordering of the keys to help us find our way around the data structure .PERIOD and the other reason is that we can support a broader set of simple table operations that are very convenient for many clients .PERIOD and it's very typical for keys to come from an ordered set .PERIOD now ,COMMA for example in the dictionary application or if keys are stings or numbers .PERIOD or account numbers or many other situations .PERIOD so if they're going to be comparable we might as well take advantage of it .PERIOD both to get more efficient algorithms and to be able to take advantage of a broader set of operations .PERIOD now in other situations ,COMMA maybe they're not comparable .PERIOD and all we're allowed to use is to ,COMMA use the equals operation .PERIOD that is everything every type of data in java has to support and equals operation that reads out to test whether they're equal .PERIOD and there's another family of methods where there's no ordering .PERIOD then there is a special method called hash code that helps us [cough] inject randomness into the process and that's built into java and also some classic algorithms depend on that .PERIOD we're going to start out with the comparable mostly .PERIOD and again ,COMMA as with priority queues ,COMMA the best practice is to use immutable types ,COMMA and experienced programmers know this and it's not difficult to arrange for the natural types of data that people are going to use for simple table keys .PERIOD unreasonable to expect the implementation to work well if the client can change the values of keys that are in the table .PERIOD if you want that ,COMMA you have to provide that as a specific operation .PERIOD in the case of symbol tables  ,COMMA we are not going to do that .PERIOD you have to remove it and put it back in .PERIOD alright ,COMMA so there's equalities .PERIOD now ,COMMA equality again we're getting into programming language issue but it's still it's important to be explicit about what's going on with ,COMMA equality .PERIOD how do we test if two objects are equal ?QUESTIONMARK so ,COMMA the job has got requirements as for compared to in ,COMMA here's the basic requirements about equals .PERIOD there is a method that all java for equals ,COMMA but the default implementation is simply to test whether the references are equal .PERIOD are those precisely the same objects or not .PERIOD usually in applications when we want to have something more general than that and have a concept of a value or like a key in our case .PERIOD and then we want to know if two references refer to objects that have the same value and we want to call that equal ,COMMA that's what equals is about .PERIOD so anyway we're required to make sure that x is always equal to x and that ,COMMA x = y is the same y = x ,COMMA and if x = y ,COMMA y = z ,COMMA then x = z .PERIOD so that means that mathematical terms equals is called an equivalence relation .PERIOD and also no ,COMMA no object is equal to null .PERIOD so those are absolute requirements for java .PERIOD and again ,COMMA the default implementation is to check whether they refer to the same object .PERIOD and that's rarely what we want .PERIOD java systems programs maybe want that .PERIOD but client programs usually have customized implementations that are based on comparing some sort of value and the standard built -DASH in types of the java language are going to have those customized implementations and we can rely on them doing what we expect .PERIOD if we're going to implement our own types and then use those types as keys and symbol tables you have to exercise a little bit of care and we'll talk about that briefly .PERIOD say we have this simplified date implementation we talked about before it's a mutable type and every day it's got a month a day in a year .PERIOD it seems like it should be easy to implement equals basically ,COMMA we're just going to check that all the significant fields are the same .PERIOD two dates should be equal if they have the same day ,COMMA month ,COMMA and year .PERIOD and if any one of those are not the same value ,COMMA then just return false .PERIOD so that seems as if it should work .PERIOD but that doesn't have all the characteristics that we need in a job implementation .PERIOD and so all of this code in red shows a model for what you might do if you're going to implement your own type of data equals for your own type of data .PERIOD so we shouldn't use it in connection with inheritance so we don't use inheritance that much so i won't talk about that the type of the argument in the equals must be object ,COMMA do you think it should be date ?QUESTIONMARK and experts debate about that ,COMMA and people who are interested can look on the web for that kind of date .PERIOD if it is the case that you happen to be testing two objects that are the same object for equality ,COMMA you might as well ,COMMA optimize everything and just test that .PERIOD if y is a reference that's pointing to the same object as this object just returned true because ,COMMA if you're going to test the values they're going to have the same values anyway .PERIOD and that's a good optimization for lots of ,COMMA situations .PERIOD why go through all that risk to that code if you know right away they're ,COMMA equal .PERIOD there's this test for null ,COMMA that has to be there .PERIOD and if not there can lead to nefarious plugs and ,COMMA and ,COMMA unusual problems .PERIOD so on your equals test you'd better ,COMMA test that ,COMMA the client didn't give you null .PERIOD they have to be in the same class .PERIOD and while there's a couple of different ways to check about the same class ,COMMA and that's another religious debate .PERIOD that we'll ignore .PERIOD we'll use ,COMMA get class and that's something that's got to work or they'll get ,COMMA they'll get an exception in this later code .PERIOD because since y had to be an object ,COMMA now we have to ,COMMA cast it to a date .PERIOD and then it better be the right class ,COMMA or else it's not going to have these fields ,COMMA that ,COMMA we can test for .PERIOD so ,COMMA details but anyway ,COMMA you can use this code as a model to implement equals for any data type that you might wind up using as a simple table key .PERIOD okay so that's a standard this is just in words the standard recipe for user find ,COMMA type optimize for reference equality ,COMMA check against null .PERIOD make sure they're the same type and do the casting ,COMMA and then compare all the similar ,COMMA significant fields .PERIOD it could be that if one of the fields is an object ,COMMA then you use that object's equals ,COMMA which reapplies the world the rule recursively .PERIOD and then if you ever feel that it's an array you can go ahead and try applying it to each entry .PERIOD and there's implementations in java .PERIOD you don't want to use a ,COMMA a .PERIOD = b .PERIOD that checks if those arrays are the same objects .PERIOD and that's not what you want you want to check that all the values are the same .PERIOD and if it's array of objects you can see that testing for equals can actually involve a lot a code and a lot a cost .PERIOD alright so and certainly you want to follow some of these best practices .PERIOD so fields that are most likely to differ .PERIOD those are the ones you might want to compare first .PERIOD and your also going to want to make compare to consistent with equals .PERIOD the rule generally if we're have a comparable types we'll use to compare to .PERIOD if we don't have a comparable types then we'll use equals .PERIOD okay ,COMMA so now let's look at a couple of test clients before we look at any particular implementation .PERIOD so this is a test client so symbol tables are st is the type ,COMMA symbol table ,COMMA they're generic on key and value .PERIOD and so this ,COMMA this statement builds a new symbol table with string keys and integer values that's going to associate integers with strings .PERIOD and so what the test client is going do is going to a just go in a loop as long as standard n is not empty ,COMMA and it's going to read strings ,COMMA read a string off standard input ,COMMA and then put it in the symbol table associated with the value i where did it appear in the value input .PERIOD so this is an index same client where we associate each string with its position most recent position in the input .PERIOD and ,COMMA notice it's an associative array implementation so for example ,COMMA we have two es and at the end e is a associated value twelve .PERIOD the place where it most recently appeared .PERIOD we could also keep these things in a bag and do a client that does all the positions that appeared .PERIOD this is a simple indexing client that we use for our traces .PERIOD [cough] for analysis for bigger problems we'll use a client called the frequency counter client .PERIOD and so that one is going to read a sequence of strings from standard input and print out the one that occurs with highest frequency .PERIOD so ,COMMA so for this small data from the beginning of dickens' tale of two cities if we run a frequency count -DASH  ,COMMA or the frequency counter client .PERIOD and this first argument is just ignore words of fewer than this many letters .PERIOD it'll say that the most frequent word where there's no word that appears more frequently than it which appears ten times .PERIOD and we'll want this client to work well for huge data sets so liepzeig is a ,COMMA a data set from the web of about twenty million words .PERIOD about half a million distinct ones and in that corpus ,COMMA the word government appears about 25 ,COMMA000 times .PERIOD so ,COMMA if you have a quadratic time algorithm for implementing simple tables or linear time for each operation .PERIOD you're not going to be able to run this client in a reasonable amount of time for a big amount of data .PERIOD so that's the client that we're going to use for analysis .PERIOD here's the code for that frequency counter client .PERIOD again ,COMMA it's similar to the other one ,COMMA we're creating a simple table that associates strings with integers .PERIOD we take that command line argument which is the minimum length that we care about .PERIOD we will read a new word .PERIOD we'll ignore the short strings .PERIOD just trap out if the word length is too small .PERIOD and now the integer we are going to associate with each word is the frequency of occurrence of that word in a symbol table .PERIOD so if word is not in the symbol table ,COMMA we'll put it there with a frequency of occurrence of one .PERIOD that's the first time we saw the word .PERIOD if it is in the symbol table ,COMMA we will just over write .PERIOD the old value ,COMMA which is st get word ,COMMA with the new value ,COMMA st ge t word plus one .PERIOD so increment the frequency in the symbol table .PERIOD so that's ,COMMA read ,COMMA this loop reads in all the data and associates each word with its frequency of occurrence .PERIOD and then we'll have a client that uses the iterator ,COMMA going through all the keys in the symbol table .PERIOD it'll get the value associated with each key .PERIOD and if that's bigger than the maximum found so far ,COMMA we'll save that away .PERIOD and then print out the ,COMMA the word that occurs the ,COMMA the most often along with its frequency .PERIOD so this is a useful and non trivial client that's enable by symbol table .PERIOD and ,COMMA but it won't work well unless we have an efficient symbol table operation .PERIOD and we'll use this client to compare different symbol table implementations .PERIOD so that's the symbol table api .PERIOD and next ,COMMA we'll take a look at implementations .PERIOD 
as usual ,COMMA it's very instructive to take a look at the simplest brute force algorithm for the problem .PERIOD we'll look at that in a little detail ,COMMA because it illustrates ,COMMA really what ,COMMA fundamental issues involved with getting efficient algorithms for this .PERIOD and it's also the basis for more efficient algorithms .PERIOD so the brute force method ,COMMA we could give in a beginning programming class .PERIOD you have your text ,COMMA you have an index i that index as in to text ,COMMA and you have an index j that indexes into the pattern .PERIOD and ,COMMA start out with both i and j at zero ,COMMA and you compare text to pattern ,COMMA and you keep going until you find a mismatch .PERIOD if you find a mismatch before the end of the pattern ,COMMA then what you do is move the pattern over one position ,COMMA that corresponds to simply incremental the text pointer .PERIOD and then ,COMMA here we have a mismatch right away ,COMMA so we move the pattern over one position ,COMMA increment the text pointer .PERIOD and then starting with i at two ,COMMA we compare the second text character with j of zero ,COMMA the first pattern character .PERIOD increment j to one ,COMMA increment i to three ,COMMA we have a mismatch .PERIOD mismatch happens at j and +j ,COMMA j .PERIOD the jth character the pattern versus the ij + character of the text .PERIOD now we have a mismatch ,COMMA move over .PERIOD that's increment i to three ,COMMA compare the first character of the pattern ,COMMA j = zero would be the i plus j pattern of the text .PERIOD that's a mismatch .PERIOD move over one .PERIOD so we go first one is a match .PERIOD the second one j of i is four compare against five ,COMMA that's a mismatch .PERIOD move the pattern over one ,COMMA that's a mismatch .PERIOD finally get to i = position six ,COMMA and we go for j equals zero ,COMMA one ,COMMA two ,COMMA three ,COMMA all matches .PERIOD when j gets to four ,COMMA which is the number of characters in the pattern that's when we know we've found a match .PERIOD so ,COMMA in this table ,COMMA the entry's engraved ,COMMA just there for a reference .PERIOD the black ones are where when we found matches ,COMMA and the red ones are where we found mismatches .PERIOD so ,COMMA that's ,COMMA we do the trace before the code ,COMMA because the code is extremely simple .PERIOD so this is ,COMMA to implement brute force substring search ,COMMA to look for a pattern ,COMMA a given pattern ,COMMA in a given text ,COMMA or for job as index of ,COMMA this woud be ,COMMA on the index of method in ,COMMA string ,COMMA takes the argument pattern .PERIOD so we get the pattern length ,COMMA and we get the text length .PERIOD and we're going to potentially look at every ,COMMA straight ,COMMA the pattern could start at any position in the text from zero to n  -DASH  m .PERIOD and for every value of i ,COMMA we've create a new j and we look for the match between the pattern in position j and the text character of position + j .PERIOD if we get all ,COMMA all the way to j = m ,COMMA then we found a match in i .PERIOD if we get a mismatch ,COMMA then we get a break before j = m ,COMMA and we go and try the next value of i .PERIOD and if we get all the way through there without returning ,COMMA then we just return n ,COMMA which is one past the index of the last text character ,COMMA the length of the text .PERIOD and that's an indication that the pattern was not found in the text .PERIOD very straightforward implementation of the pattern match algorithm .PERIOD now ,COMMA the key point is that ,COMMA this algorithm is fine in ,COMMA in many contexts ,COMMA and actually it's the one that java's index of uses .PERIOD but the real problem is that it can be slow .PERIOD number one ,COMMA just the algorithmic problem ,COMMA it can be slow if there's a lot of ,COMMA repeat ,COMMA repetitive characters in the text and the pattern .PERIOD for example ,COMMA suppose ,COMMA that the ,COMMA text is ,COMMA all a's and a b ,COMMA and imagine that there is a million a's and a b or whatever .PERIOD and then the pattern also was a smaller copy of the same thing ,COMMA all a's and a b .PERIOD then what happens in this case is that for every possible position matching the pattern against the text ,COMMA we go through all the pattern characters and only find the mismatch on the last one .PERIOD so ,COMMA and then we find a mismatch ,COMMA we have to go over one and try them all and find the mismatch in the last one .PERIOD and we eventually do find a match ,COMMA but for every text character we've looked at almost m  -DASH  one pattern characters .PERIOD so ,COMMA this is a worst case that shows that the running time of the brute force algorithm can be proportional to m  n ,COMMA where m is the pattern length .PERIOD and the pattern could be long ,COMMA say that the pattern could be hundred characters and n can be huge ,COMMA like a billion and that's going to be slow ,COMMA particularly by comparison to the alternatives that we're going to look at .PERIOD now a more important issue than just the worst case performance is the idea of backup .PERIOD as i mentioned ,COMMA for lots of applications ,COMMA if we're going to put our machine in ,COMMA on one of the wires of the internet and watch the input go by or if we just take the abstract standard input model ,COMMA you don't get to go ,COMMA you don't get to back up when you find a mismatch but the brute force algorithm is always backing up .PERIOD if we go through ,COMMA matching our pattern against our text ,COMMA when we find a mismatch ,COMMA we say we want to move the potential pattern over one position ,COMMA but that means backing up in the text .PERIOD so ,COMMA we would that's ,COMMA ways to deal with that by ,COMMA saving the most recent m text characters that we've seen .PERIOD but it's definitely problematic for larger patterns and certainly inconvenient .PERIOD so the brute force algorithm uses backup .PERIOD and so you could maintain a buffer as i mentioned ,COMMA but what we're going to look at is an ingenious way couple of ingenious ways to avoid having to do backup .PERIOD to setup for that ,COMMA we're going to look at ,COMMA a slightly different implementation or alternate implementation of brute force .PERIOD it ,COMMA it ,COMMA compares the same characters as the previous ,COMMA implementation .PERIOD but ,COMMA it ,COMMA does things in a slightly different order ,COMMA without ,COMMA without a second for loop .PERIOD and it does the explicit backup ,COMMA so let's look at that .PERIOD so ,COMMA we have our i and j pointers ,COMMA and ,COMMA and we initialize them both at zero .PERIOD and so it's a for loop where ,COMMA i gets incremented on every iteration through the loop .PERIOD and so what we do is ,COMMA as long as we see a match we also increment j ,COMMA so that while the pattern is matching we're implementing both i and j .PERIOD when we see a mismatch what we do is just subtract .PERIOD the current value of j from i the pointer .PERIOD that's the next ,COMMA character that we have to look at .PERIOD so ,COMMA when we find this mismatch ,COMMA we wanna ,COMMA subtract the current value of j .PERIOD then increment i at the end of the four loop .PERIOD and that puts us right on the ,COMMA next ,COMMA text character that we wanna look at and then we reset j to zero .PERIOD so this ,COMMA does the same ,COMMA character comparisons .PERIOD but it explicitly shows that we're backing up in the text .PERIOD and then ,COMMA if we ever get to the end of the pattern then we return i minus m .PERIOD which is the position of the first character in the text that matches the pattern which we found there was m matches .PERIOD so it's an alternate implem ,COMMA implementation that will come back to .PERIOD so ,COMMA the ideas that there are a couple of out rhythm challenges even though this brute force method ,COMMA is simple it is not always good enough .PERIOD and so the first one is just ,COMMA from a purely algorthmic stand point .PERIOD this is a challenge .PERIOD do we need n  m ?QUESTIONMARK or m is the length of the pattern ?QUESTIONMARK or can we do it in time independent of the length of the pattern ?QUESTIONMARK what we want is a linear time guarantee .PERIOD and that was a fundamental problem algorithmic problem that people worried about .PERIOD and for a ,COMMA for a ,COMMA for a bit and we're going to look at the ,COMMA how people approach this fundamental algorithmic problem .PERIOD and then there's the practical challenge of we don't ,COMMA we might not have the room or the time to save the text and actually the judge might not be happy about us saving text away in some computer .PERIOD so we want to avoid backup in the text stream .PERIOD all we're supposed to know about is our pattern .PERIOD and we're supposed to light the light if we find our pattern and that's it .PERIOD so what we're gonna see next is a way to deal with both of those challenges at the same time .PERIOD 
next ,COMMA we'll look at some elementary symbol table implementations .PERIOD these are so simple that we won't go into much detail .PERIOD but still ,COMMA it's worthwhile to take a look at them to set the stage for the more advanced implementations we'll consider next .PERIOD well ,COMMA one thing we could do is maintain a link list .PERIOD we could keep it in order or keep it unordered ,COMMA this version keeps it unordered .PERIOD so ,COMMA we are going to have nodes in the link list ,COMMA that have key value pairs ,COMMA they have every key in the symbol table and a value associated to that key .PERIOD for search ,COMMA we have to ,COMMA since it's unordered ,COMMA scan through the whole list to find a match ,COMMA a key that's there .PERIOD for insert ,COMMA i would also have to scan through all keys to find the place to update a value ,COMMA if it's a value that's already there .PERIOD and if there's no match ,COMMA then we could add it to the front .PERIOD so here's our simple client for traces .PERIOD so if we associate s with zero ,COMMA we just had it that's our one node link ,COMMA link list that's got that information .PERIOD associate e with one that's not there ,COMMA so we just add it to the beginning of the list .PERIOD a with two ,COMMA r with three ,COMMA c with four ,COMMA h with five ,COMMA and so forth .PERIOD so now ,COMMA when we associate e with six ,COMMA we have to search through the list to see if there's an e .PERIOD in this case there is ,COMMA and then we update ,COMMA just update that value .PERIOD that's the associative array abstraction .PERIOD it's possible to implement symbol tables that allow multiple values with the same key and so forth .PERIOD and that leads to different types of clients ,COMMA different types of implementations .PERIOD we're going to stick to this associative array abstraction and no duplicate keys in the symbol table because it both simplifies implementations and leads to simpler client code .PERIOD okay ,COMMA x7 is a new value a8 we found a in there and update the value eight and then m9 ,COMMA p10 ,COMMA l11 are all out there ,COMMA and they go at the beginning ,COMMA and then the last one changes the value at e again ,COMMA twelve .PERIOD so ,COMMA this is a ,COMMA a simple implementing this as a example of link list processing .PERIOD slight modification of our stack and queue code .PERIOD and we will skip the details and just a note that what's the cost of implementing this .PERIOD well if there's been if there are n things on the symbol table ,COMMA you have to ,COMMA for both search and insert look all the way through .PERIOD and if everything's random then on average ,COMMA you only have to look halfway through for a successful search .PERIOD and well ,COMMA you still have to insert another issue is for many clients if the keys are ordered it's nice to be able to iterate through the symbol table in order and this one by definition doesn't provide that .PERIOD and this one just uses equals .PERIOD so ,COMMA the keys don't have to be comparable for this it just uses equals .PERIOD so our challenge is to look for methods that give us more efficient implementations than search and insert searching operations .PERIOD and we've already looked at an algorithm that can do this and that's binary search .PERIOD so for binary search the now ,COMMA what we're going to do is use an ordered array .PERIOD and actually use parallel arrays ,COMMA one for the keys and one for the values .PERIOD and the idea is to keep the array of keys in sorted order .PERIOD and then find the index associated with the key that we're searching for using binary search and then use that index to get the value that's associated with that key that's stored in the parallel array .PERIOD and we looked at the binary search algorithm earlier in the course .PERIOD and so ,COMMA for example ,COMMA if we're doing a ,COMMA if these are the keys in our symbol table .PERIOD and we're doing a search for the index where p is stored .PERIOD we look at the middle .PERIOD p is bigger than l ,COMMA so we look to the right .PERIOD look in the middle of the right half .PERIOD p is less than r so we look to the left .PERIOD continue until we find p .PERIOD when we find p ,COMMA we return its index ,COMMA and we use that index to get us the value that we need or another way to look at this is that implements the function ,COMMA how many keys are there that are less than k .PERIOD so ,COMMA for example ,COMMA for queue that's unsuccessful search and you can figure out from the last index when you don't find your the element that you're seeking you can figure out the return value ,COMMA which is the number of keys that are less than it .PERIOD so ,COMMA that's a trace of implementing binary search to find the rank of a key in an ordered array ,COMMA and again ,COMMA for successful ,COMMA you can use that rank to return the value and for if it is unsuccessful ,COMMA you can use that rank to figure out where to insert the new key .PERIOD alright .PERIOD so ,COMMA this is the code for the get operation in this rank ,COMMA which is binary search .PERIOD so this is precisely the binary search curve that we looked at before .PERIOD so ,COMMA let's look at again .PERIOD so if the whole table is empty ,COMMA return null .PERIOD otherwise ,COMMA we call rank and that could gives us the number of keys less than the current key .PERIOD and so ,COMMA that is where we look to check to see if that key is there .PERIOD if it's there ,COMMA then we return the value with the same index in the parallel array .PERIOD if it's not there ,COMMA then we return null ,COMMA saying the key's not there .PERIOD now ,COMMA the problem with minor searches well ,COMMA not necessarily a problem but the situation is that if when it's time to insert a new element ,COMMA we have to move everything larger over one position just like an insertion sort .PERIOD so ,COMMA if the table has a ,COMMA e ,COMMA r ,COMMA and s and we have to insert the value c ,COMMA then we have to move the e ,COMMA r ,COMMA and s over one position to put the c and then put the value associated with c if they're the same thing in the values array .PERIOD move all the values associated with those keys over one position and put the associated value in .PERIOD so ,COMMA this is a trace of what would happen for our trace .PERIOD and ,COMMA and again ,COMMA every insertion involves ,COMMA involves making a new position by moving all the larger keys over one position do the same thing in the values array .PERIOD and if it's changing the value associated with a key that's already there ,COMMA then it's just a matter of finding where the key is and changing the value at that index .PERIOD so ,COMMA those from that trace is pretty easy to see what's involve ,COMMA what's involved for the code and we'll skip that code .PERIOD and just take a look at the comparison between this elementary implementation for symbol tables with the sequential search in an unordered list .PERIOD so ,COMMA one thing is we're using a different key interface .PERIOD we're taking advantage of the fact that the keys are comparable to give us an efficient search .PERIOD ah .PERIOD ,COMMA we can do search in worst case in average case ,COMMA in time proportional to log n .PERIOD that's what binary search provides for us .PERIOD and this is a fine data structure for symbol tables where there's where ,COMMA that are relatively static ,COMMA where the values don't change much ,COMMA and most of the operations are search .PERIOD it's hard to beat binary search .PERIOD on the other hand ,COMMA in a dynamic situation where there are a lot of inserts .PERIOD this method is going to be problematic because the cost of its insert is linear and proportional to n/2 .PERIOD if you have a huge number of operations and everyone who is proportional to the symbol table size ,COMMA then you're just not going to be able to support huge numbers of keys .PERIOD what we want is efficient implementations of both search and insert .PERIOD those are elementary implementations .PERIOD next we'll look at more advanced ones .PERIOD 
so ,COMMA the algorithm that we're going to look at for solving the substring search problem is called the knuth -DASH morris -DASH pratt algorithm .PERIOD it's got an interesting history that we'll get to at the end .PERIOD but i just want to start by saying that .PERIOD this is one of the coolest algorithms that we'll cover in this course .PERIOD and it's not an algorithm that anyone would come up with without a lot of lotta hard work .PERIOD but understanding this algorithm really gives somebody an appreciation for what's possible with careful algorithmic thinking even for such a simple problem as this .PERIOD it's a quite ingenious method .PERIOD so ,COMMA here's the intuition behind the algorithm .PERIOD so ,COMMA say ,COMMA we're looking for the pattern .PERIOD b followed by a bunch of a's in the text .PERIOD so we're going along and so ahm well ,COMMA we're trying to mismatch right away so we'll move over to first position .PERIOD and we'll go baaaa ,COMMA and then we find a mismatch at the end in this case .PERIOD so now ,COMMA what the ,COMMA brute force method is going to do is back up to move over one position if b doesn't match the a ,COMMA back up again if b doesn't match the a ,COMMA and keep going matching the first b against all these a's before getting to the next character in the text .PERIOD so ,COMMA we've matched five characters and we mismatched on the sixth .PERIOD but the key point is that when we got that mismatch all we have is a's and b's .PERIOD we already matched baaaa ,COMMA four a's and we got a mismatch so it's ab .PERIOD .PERIOD so ,COMMA at that point we know what the previous characters in the text are ,COMMA and we know that if we move over one position ,COMMA we're going to be trying to match b against a .PERIOD so we should be able to take advantage of that knowledge ,COMMA that's the intuition on the method of the knuth -DASH morris -DASH pratt .PERIOD we don't need to back up the text pointer in this case .PERIOD when we get the mismatch ,COMMA we can just keep going .PERIOD we don't even have to match the first b we know it's there so ,COMMA we can just keep going in the text pointer and start in the second pattern pointer .PERIOD the knuth -DASH morris -DASH pratt algorithm is a very clever method that manages to always avoid backup no matter what the pattern is .PERIOD so ,COMMA let's take a look at what's involved .PERIOD it's based on the idea of building a deterministic finite state machine for string searching .PERIOD now ,COMMA the deterministic finite state machine ,COMMA if you're not familiar or don't remember ,COMMA it's a very simple thing .PERIOD you've got a finite number of states .PERIOD it's always in one of the states .PERIOD there's a start state and a ,COMMA and a halt state .PERIOD and from every state ,COMMA there's exactly one transition for each possible character in the alphabet .PERIOD so we're ,COMMA if we're in a state and we're reading a particular character we move to the state that is indicated by that character .PERIOD so ,COMMA if we're in state two and we're reading an a ,COMMA we move to state three ,COMMA that's what this line in the table says .PERIOD if we're in state two and we read a ,COMMA that happens to be the pattern character is a ,COMMA and if we see and a ,COMMA we move to state three .PERIOD if we see ab or ac ,COMMAc we go back to state zero .PERIOD that's what this machine says .PERIOD it says ,COMMA the tabular representation and the graphical representation .PERIOD if we get to stage six then we just say ,COMMA except we found the pattern and you could see how that is ,COMMA the pattern and then if we match the pattern character ,COMMA we move right through this machine till we get to the halt state .PERIOD so ,COMMA let's first take a look at exactly how the machine works to make sure that everybody follows that .PERIOD and then we'll look at how to rebuild this machine .PERIOD so that's our machine and that's our text up at the top .PERIOD so ,COMMA we start at state zero we're reading in a .PERIOD what are we supposed to do if we're in state zero and we're reading an a ?QUESTIONMARK this enter the table and says ,COMMA we're supposed to go to state one .PERIOD so ,COMMA we go to state one .PERIOD every ,COMMA at every step ,COMMA we consume a text character .PERIOD a .PERIOD and in the graphical representation ,COMMA it says ,COMMA stay in state one .PERIOD or in this representation ,COMMA it says ,COMMA if you're in state one and you see an a ,COMMA stay in state one .PERIOD so that's what we'll do .PERIOD we'll read the a and stay in state one .PERIOD now ,COMMA we're in state one and so you can say that in ,COMMA in state one is reading a's and in a way ,COMMA looking for something that's not a ,COMMA no matter how many a's you have ,COMMA you'll read them right here in state one .PERIOD so now ,COMMA we're in state one and we're reading a b and it says ,COMMA go to state two in that case .PERIOD so ,COMMA that's where we'll go ,COMMA read the b .PERIOD now ,COMMA we're in state two and reading an a ,COMMA so we go to state three and read the a .PERIOD now ,COMMA we're in state three and see a c .PERIOD in state three ,COMMA when we see a c we're supposed to go back to state zero .PERIOD that's a mismatch our pattern sees not until the end .PERIOD so now ,COMMA we have to start the search all over again .PERIOD although in the final state machine does not know that ,COMMA it's just plotting along according to the state transitions they're supposed to do .PERIOD so ,COMMA we read the c ,COMMA c ,COMMA now we're back in state zero .PERIOD so now ,COMMA we're in state zero looking at an a .PERIOD and we move to one ,COMMA and read the a .PERIOD and then we see another a so we stay in one and read the a .PERIOD and now we see a b ,COMMA and we go to state two ,COMMA and read the b .PERIOD and then we go to state three and read the a ,COMMA state three and read the a .PERIOD state four and read the a .PERIOD state five and read the c .PERIOD and now ,COMMA we're in state six .PERIOD and that means we found the pattern .PERIOD so ,COMMA that's the simulation of what the deterministic finite state be .PERIOD that is corresponding to this pattern would do .PERIOD and as we'll see the code for implementing this simulation is quite simple .PERIOD that's a demo of dfa simulation .PERIOD so let's just take a quick look at what the interpretation of what this dfa is .PERIOD so ,COMMA what is it ,COMMA what does it mean after we just read the ith character of the text ?QUESTIONMARK well the number of the state is the number of characters in the pattern that we've matched up to the current point .PERIOD so ,COMMA that is it .PERIOD at state three ,COMMA we've matched three characters in the pattern .PERIOD and what's happened is ,COMMA that we've matched a prefix of a pattern ,COMMA the first three characters of the pattern .PERIOD it's ,COMMA and actually ,COMMA it's the longest prefix of the pattern that's also a suffix of the i ,COMMA first i plus one characters from the text ,COMMA text from zero to i .PERIOD that's the interpretation of what it is .PERIOD so and if the dfa is in state three after the first six characters of the text it's got aba is the longest prefix of a pattern .PERIOD that's also a suffix of first six characters of the text .PERIOD so ,COMMA another prefix of the pattern that looks like it might work is ababa but that's not a suffix of the text string ending at character six .PERIOD and third ,COMMA interpretation is useful to understanding what's going on .PERIOD so given that we've constructed this dfa .PERIOD it's just the state transition table for the dfa is simply a two -DASH dimensional array .PERIOD that's indexed by the pattern character .PERIOD so ,COMMA if ,COMMA if you in a ,COMMA a certain ,COMMA if you're reading a certain pattern character sorry ,COMMA if you're reading a certain text character then for each we reset the pattern pointer to be the entry given in the table that corresponds to the current one .PERIOD so let's go back to the table to be sure about that .PERIOD so when we're in a particular state like two and we see an a we read ,COMMA so this would be j we refer to that column .PERIOD and whatever text character we happen to see ,COMMA that's how we update j .PERIOD so that's what this code does .PERIOD and then ,COMMA if we ever to get to the transition state ,COMMA the final state ,COMMA we just return i minus m .PERIOD now ,COMMA this is just like that alternate implementation of the brute force method that we gave .PERIOD but the key idea is that ,COMMA notice that i never gets decremented .PERIOD all we're doing is incrementing i and changing j .PERIOD either always just referring to the table .PERIOD when we have a match ,COMMA the table automatically increments j .PERIOD we have a mismatch ,COMMA it figures out the right state to go to .PERIOD so ,COMMA that's a very simple and economical and fast implementation of substring search .PERIOD so the running time is clearly ,COMMA all it does it look up an entry in the table for every text character .PERIOD so ,COMMA that's linear time .PERIOD the key is ,COMMA is .PERIOD how do we build that table that drives the algorithm ?QUESTIONMARK and that's the tricky algorithm .PERIOD so a warning .PERIOD this is definitely the trickiest algorithm we've looked at so far .PERIOD and the idea ,COMMA the importance ,COMMA again ,COMMA of no backup is that since the text pointer never decrements ,COMMA you could use the input stream and just replace text [unknown] just read the next character in the next input stream .PERIOD and this algorithm is going to work fine ,COMMA no matter how big the input stream is .PERIOD it will just go right ,COMMA right through .PERIOD its not no memory of what the text is .PERIOD but its got some memory of what the pattern is that's built into the dfa .PERIOD so ,COMMA this is the key that ,COMMA you have a pattern ,COMMA you can spend some time building this dfa table and doing pre -DASH processing .PERIOD but then ,COMMA when you get the text ,COMMA just ,COMMA just index into this table for every text character and you're doing this substring search .PERIOD so ,COMMA you can build a machine that does this .PERIOD no backup .PERIOD okay .PERIOD so let's take a look at what it means to construct this dfa .PERIOD so it depends on the pattern instead of with one character one state for each character in the pattern plus an extra at substate .PERIOD and let's look at what it means to build the same .PERIOD so first thing now we do to one character one stage for each character in the pattern .PERIOD so the first thing we do is deal with the match transitions .PERIOD so ,COMMA that's when the you've ,COMMA you're in state j ,COMMA that means you've already matched j characters in a pattern .PERIOD then if ,COMMA if the next character matches .PERIOD so that the character that you have is the ,COMMA the character that's supposed to match .PERIOD you're going to so it's ,COMMA add that character j ,COMMA that's just a j plus first character ,COMMA then you know that you've matched j plus one characters .PERIOD so ,COMMA all that means is we can put in the match transitions .PERIOD so ,COMMA we have ababac ,COMMA and these guys go ababac if you're in state zero and you see an a you go to state one ,COMMA if you're state one and you see a b ,COMMA you go to state two and so forth .PERIOD that's how we get the match transitions to get us all the way through the pattern to the accept state .PERIOD so that's the ,COMMA the easy part .PERIOD and then the hard part is the mismatch transitions .PERIOD what are you supposed to do if you come against a text character that does not match the current text character ?QUESTIONMARK so ,COMMA for example ,COMMA if you're in state zero ,COMMA the pattern starts with an a .PERIOD if you didn't see if you don't see an a as the first character in the text ,COMMA if you see a b or a c ,COMMA then obviously you want to stay in state zero .PERIOD so ,COMMA you can think of state zero as ,COMMA scanning through the text looking for an a .PERIOD it's going to stay in ,COMMA in state zero as long as it sees a b or c as soon as it sees an a ,COMMA it'll go to state one .PERIOD that completes state zero ,COMMA you know what to do if you have a ,COMMA an a ,COMMA you know what to do if you have a b or a c .PERIOD what about state one ?QUESTIONMARK so ,COMMA we know that if you're in state one ,COMMA you saw an a in the text ,COMMA and you see a b in the text ,COMMA what are you supposed to do ?QUESTIONMARK well there's two different cases .PERIOD if you ,COMMA if you see a b going to state two if you see a c and that's not going to match the first character a in the pattern .PERIOD so ,COMMA you go back to state zero .PERIOD but if you see an a ,COMMA it's just as if you saw an a ,COMMA a in state zero ,COMMA so ,COMMA you might as well stay in state one .PERIOD so ,COMMA that's how we fill in the dfa for state one ,COMMA if you see a b going state two ,COMMA you matched .PERIOD if you see an a ,COMMA well that matches the first character .PERIOD so ,COMMA stay in state one .PERIOD if you see a c ,COMMA clearly you have to go back to state zero .PERIOD okay ,COMMA what about the next one ?QUESTIONMARK so if we're in state two and we see an a we know that we go on to state three .PERIOD and what about the mismatch pages ?QUESTIONMARK well ,COMMA in that case ,COMMA it's a b or c and again if you're sitting out a b or a c ,COMMA c you'd better go back to state zero to keep looking for an a .PERIOD this is state three ,COMMA and well ,COMMA now it gets to be a little more complicated .PERIOD c ,COMMA you state three ,COMMA see a b ,COMMA you succeeded ,COMMA if you see a c ,COMMA you go back to state zero .PERIOD it's not so bad if you see an a ,COMMA it's just like before .PERIOD that's going to be like the first one .PERIOD so seems like we're going along pretty fine .PERIOD and again if we're in state four ,COMMA we seen a ,COMMA you go to five .PERIOD if you see a b or a c ,COMMA then you better go back and look for an a again .PERIOD this one ,COMMA is the one that's a little more complicated .PERIOD if you're in state five and you see a b you ,COMMA you go back to state four .PERIOD and that's it's a little more work to figure out why that's the case .PERIOD and then that last case is kind of the essence of the algorithm .PERIOD so we'll look at a systematic way to be able to figure out what you do on a mismatch in each case .PERIOD in this case ,COMMA you only needed that ,COMMA that for that one state .PERIOD otherwise ,COMMA it was elementary reasoning .PERIOD so that's a full dfa for knuthmorrispratt .PERIOD a demo of at least thinking about how it's going to be constructed .PERIOD okay ,COMMA let's look a little more carefully and systematically at the construction process for the knuthmorrispratt dfa .PERIOD so the ,COMMA the start is clear .PERIOD we're going to go through the pattern .PERIOD and for systematically fill in the match transitions .PERIOD if we're in state zero and we see an a ,COMMA we want to go state one .PERIOD if we're in state one and we see a b ,COMMA we're going to ,COMMA we want to go to state two .PERIOD state two ,COMMA so we look up the pattern character and then ,COMMA whatever that one is ,COMMA we want to go to the next state .PERIOD so ,COMMA we can fill in at least that much automatically .PERIOD now the real key is the mismatch transition .PERIOD so ,COMMA here is the idea of the mismatched transition .PERIOD so if you're in stage j and you get a mismatch ,COMMA the next character in the text does not match the jth character in the pattern .PERIOD so as pointed out at the beginning as motivation for knuthmorrispratt ,COMMA you know a lot about the text at that point .PERIOD and you know that the last j ,COMMA j minus one characters of the text are if you lop off the first character of the pattern ,COMMA it's from one to j minus one .PERIOD so ,COMMA in this case and then ,COMMA it's followed by the text character that ,COMMA that you're looking at .PERIOD so one thing that you could do ,COMMA so what you want to do ,COMMA so you know that .PERIOD and what you could do is simulate the dfa that you have built on that part of the pattern and then take the transition for the character that you just find .PERIOD so ,COMMA let's ,COMMA let's look at this .PERIOD so let's run this machine ,COMMA if we'd seen it on the text of ,COMMA of baba ,COMMA .PERIOD what we want to do ,COMMA we want to put the machine in the state as if we have backed up ,COMMA but we don't want to backup .PERIOD so ,COMMA if we see a b ,COMMA we stay in zero ,COMMA if we see an we ,COMMA we go to one .PERIOD then we see a b we go two .PERIOD and if we see an a ,COMMA we go to three .PERIOD so now we're in state three in if we had a mismatch then the ,COMMA for the fifth character ,COMMA what we do on a ,COMMA on a mismatch here we have to look what happens if we get an a or we get a b .PERIOD if we'd run it on baba and we get an a ,COMMA then we should go back to one .PERIOD so ,COMMA what that says is ,COMMA if we had a mismatch and we saw an a in five we would need to be in state one .PERIOD because if we had ,COMMA had run the thing on the characters that we know ,COMMA babaa ,COMMA we would wind up in state one .PERIOD and similarly if we were if we got the mismatch on a b ,COMMA a if we did baba ,COMMA ,COMMA we would be in state three .PERIOD and ,COMMA we're in state three and we saw b we'd go to four .PERIOD so again to summarize ,COMMA if four instate five and we see a c ,COMMA we know that's a match ,COMMA we go to six .PERIOD if we see an a ,COMMA we know that the previous five characters in the text were babaa .PERIOD so ,COMMA we can just simulate the machine .PERIOD babaa ,COMMA we're in state one .PERIOD and ifwe get a mismatch that's a b ,COMMA then that's dfab five ,COMMA then we know that the previous five characters in the text were babab .PERIOD and that would put us in state four .PERIOD so that's the simulation of baba puts us in state three .PERIOD if we get an a ,COMMA we go to one .PERIOD so that means that from five ,COMMA we go back to one .PERIOD and if we get a b ,COMMA we go to four .PERIOD so ,COMMA that's how ,COMMA one way to calculate the mismatched transitions .PERIOD and as we've noted in the simulation ,COMMA this is the only non -DASH trivial one for this example .PERIOD now ,COMMA there's a little problem with that ,COMMA is that it seems to require j steps to do the simulation .PERIOD in order to figure out these mismatched transitions ,COMMA i had to all the way through the pattern shifted over one to figure out this state three .PERIOD so that seems to be a bit of a problem ,COMMA but actually it's no problem at all ,COMMA because we can run this simulation one character at a time as we're building the machine .PERIOD all we need to do is keep track of the that we would be at if we had run the dfa on the pattern starting at position one .PERIOD once ,COMMA once we get going it's pretty easy but just let's start well ,COMMA let's just illustrate it by saying ,COMMA okay ,COMMA we maintain this state x ,COMMA which is where we would be if we if we had run the machine and the pattern had shifted over one .PERIOD now when we come to do our mismatches to figure out where the mismatch transitions from five are all we do is look at if we get ,COMMA if we were to get an a ,COMMA would be as if we were to state x and got an a .PERIOD so that's one and if we were to get a b it's as if we were at state x and got a b .PERIOD and that's state four .PERIOD so ,COMMA what we need to do is to compute the mismatch transitions is keep track of state x .PERIOD and that is where would the thing be if we had run it starting with the ,COMMA at the pattern one position shifted over .PERIOD and we want to update that .PERIOD so ,COMMA when we're moving to the next state ,COMMA if we had a match on c ,COMMA state x gets updated to where it would have gone if it got a c .PERIOD because for the next character ,COMMA when we move j over for the match on c we'll want to have x updated .PERIOD so ,COMMA that's the key is keeping track of the state where the machine would be if we had backed up or if we had run it on the pattern shifted over one .PERIOD so let's take a look at a demo that does the full construction for the kmp dfa .PERIOD so here ,COMMA here goes .PERIOD again ,COMMA one state for every character plus an accept .PERIOD match transitions are easy .PERIOD we build those .PERIOD and we're going to start at position zero .PERIOD and the mismatched transitions are easy .PERIOD so now ,COMMA when we move over x is when we're in position one of the pattern ,COMMA x is where we would be if we started out without that ,COMMA that character ,COMMA which would be the empty string .PERIOD so we start out with just filling in zeros .PERIOD for state zero and we can do that without any further every reason and now we've got x initialized .PERIOD so now ,COMMA what we need to do is fill in the mismatch transitions for state one .PERIOD so ,COMMA what are they ?QUESTIONMARK they're what would happen if we found those characters ?QUESTIONMARK and ,COMMA and we're in state x ,COMMA if we found an a ,COMMA we would go to state one .PERIOD if we found a c ,COMMA we'd go to state zero .PERIOD and maybe you noticed ,COMMA that's just taking the entries corresponding to the entries we need from x's column and putting them in j's column .PERIOD that's all it is .PERIOD and then ,COMMA we need to update x ,COMMA which is where it would be if we matched a b .PERIOD so ,COMMA well stay and x will stay in state zero .PERIOD so now let's look at state two .PERIOD so we need to fill in what would happen if we got a b and what would happen if got a c .PERIOD well ,COMMA it's what would happen if we were in state x and we got a b or a c ,COMMA so what we'll do is move those two zeroes over to column two .PERIOD and then don't forget we have to update x and x goes where the machine goes if we saw an a ,COMMA that transitions from two to the three .PERIOD so ,COMMA we just move x to state one .PERIOD so now ,COMMA we have x in state one ,COMMA and we're doing position three and now you can see how really simple the algorithm is once it gets going .PERIOD so now the mismatched transitions are a and c ,COMMA and that's what we have to fill for column but those mismatched transitions were already computed that's where x would go if we ,COMMA that's where it would go if we happen to be in state one .PERIOD so ,COMMA we move the one and zero from column one over to column three .PERIOD and again ,COMMA we update x and when we see a b x goes to state two .PERIOD and ,COMMA and again ,COMMA you can check what ,COMMA what is x suppose to be .PERIOD it's ,COMMA it's suppose to be where you would be if you started the machine on the pattern with the first letter cut off .PERIOD so ,COMMA it's ,COMMA it's suppose to be where would you wind up if you got bab ,COMMA bab and that's a check .PERIOD alright ,COMMA so now it's straightforward ,COMMA straightforward we have to fill in b and c .PERIOD we go to x's column and copy over b and c from x's column .PERIOD then we update x .PERIOD that's if you see an a ,COMMA you go to state three .PERIOD now we're ready for state five .PERIOD we've got x all computed and we need to do a and b .PERIOD and we get those from x .PERIOD if it's an a it's a one .PERIOD and if it's a b it's a four .PERIOD it's just moved them over .PERIOD and then when we do the c and get the accept there's no mismatch .PERIOD that's the we do update x to get ready .PERIOD but when we get to state six we're done .PERIOD and again ,COMMA it's just as a doublecheck ,COMMA x is where you'd be if you saw babac .PERIODbac that's the construction of the knuth -DASH morris -DASH pratt dfa efficient algorithm .PERIOD really ingenious and as it turns out ,COMMA simple to implement .PERIOD implementation for the dfa construction for knuth -DASH morris -DASH pratt requires remarkably little code so it just goes through with what we did in the demo .PERIOD so we've got x and for every entry of the dfa and x's column that corresponds to everyone except for the match we just copy x's column to j's column .PERIOD in fact ,COMMA we just copy'em all ,COMMA and then overwrite one corresponding to the match case ,COMMA to j plus one .PERIOD so there .PERIOD and the entry in the column that corresponds to the pattern character ,COMMA that's where do we go if we match ,COMMA that's j plus one ,COMMA all the rest of them are copied from x .PERIOD so ,COMMA one forwarded the copy from x then set the match case and the only other thing to do is update x .PERIOD and how do you update x ?QUESTIONMARK you take the [unknown] machine to where it would go if it were at state x and i got the current x pattern ,COMMA pattern character .PERIOD so that's the ,COMMA dfa construction amazingly a line of code .PERIOD so the only ,COMMA so flaw in this codec ,COMMA is that it does take time proportional to r times m where are r is the radix and ,COMMA and m is the length of the pattern and ,COMMA and as we'll see this ,COMMA ways to ,COMMA get around this .PERIOD but for relatively small alphabets this is no problem because the search is so efficient this way and the construction as well .PERIOD but if you're doing this for unicode for a long pattern maybe that's too much memory to devote to the dfa representation .PERIOD so the bottom line is and this follows immediately from examining the code is that the substrings can be substring search as linear time .PERIOD your only access at most ,COMMA each character in the pattern ,COMMA each character in the texts wants quite remarkable .PERIOD each pattern character you have accessed once when your making the dn ,COMMA dfa .PERIOD and each text character is accessed once when you're simulating the dfa ,COMMA and that's in the worst case .PERIOD now the space again ,COMMA is proportional to rm because we have all those mismatches .PERIOD it is possible to develop a version of knuth -DASH morris -DASH pratt that constructs the automaton in time and space proportional to m .PERIOD it's actually a non -DASH deterministic automaton cuz it's either a match or all mismatches and mismatch might involve multiple hops .PERIOD so if you are interested you can read about that version of kmp .PERIOD but it's sufficiently more complicated that you should be ,COMMA be prepared to study it carefully to really understand it .PERIOD this algorithm is really interesting because of its history .PERIOD it was actually independently discovered by two theoreticians and a hacker .PERIOD so there's knuth who was one of the fathers of computer science .PERIOD who read a paper that was a very esot by steve cook ,COMMA a very esoteric theoretical result that he realized implied that it should be possible to solve the substring search problem in linear time .PERIOD the theorem really didn't give any way to solve it but it indicated that it should be possible to solve it in linear time .PERIOD so ,COMMA knuth worked on it and figured out a way .PERIOD and then pratt who was a student of knuth's at stanford at the time figured out a way to take care of this mismatch ,COMMA independent of the alphabet side .PERIOD and in the meantime ,COMMA across the bay at berkeley jim morris was busy writing a text editor .PERIOD in those days people were using typewriters .PERIOD and other people were realizing that computers would be really good at editing text .PERIOD and so you know ,COMMA many people would work on text editing and formatting systems .PERIOD ahm it was kind of a badge of honor in those times .PERIOD morris actually worked for the computer center at berkeley .PERIOD and wanted to have a really bolt -DASH proof text editor that everyone could use .PERIOD and one of the things he wanted to do was avoid backup .PERIOD cuz backup was just really inconvenient ,COMMA involved a lot of code .PERIOD and just something that he didn't want to have .PERIOD and he basically came up with the same algorithm and the community was kind of small at that time .PERIOD and theory meets practice .PERIOD and that's where this paper came from 1977 .PERIOD morris ,COMMA then went on to get his phd ,COMMA and to work at xerox parc .PERIOD and unfortunately later on another systems programmer came and took a look at morris's code and couldn't understand it ,COMMA and put the brute force algorithm back in .PERIOD but that part of the story is maybe a less successful example of theory meeting practice .PERIOD that's knuth -DASH morris -DASH pratt algorithm ,COMMA one of the most ingenious algorithms that we'll see .PERIOD 
when keys are comparable and we can put them in order .PERIOD we saw that we can use binary search to get an efficient symbol table implementation .PERIOD but we can also provide a lot of convenient functionality for the client that's what we are going to look at next .PERIOD so this is just an example of an application that might try to associate keys with values .PERIOD an illustration of all the different operations that a client might want .PERIOD so we already looked at the get operation so we might want to know what city is associated with the event that happened at time nine o'clock ,COMMA thirteenth and so that should return that value .PERIOD but there's plenty of other things that we might want .PERIOD like ,COMMA for example ,COMMA what's the earliest time ?QUESTIONMARK that's the min or what's the latest time ?QUESTIONMARK that's the max .PERIOD what about ,COMMA being able to iterate between ,COMMA among all the keys between two given times ?QUESTIONMARK that ,COMMA certainly is convenient .PERIOD then there's ,COMMA what's the seventh largest times ,COMMA that's select that like a median ,COMMA it generalizes min or max ?QUESTIONMARK which key is that ,COMMA happens second or seventh ?QUESTIONMARK so that's ,COMMA order statistics ,COMMA a dynamic thing what happened ,COMMA whats the closest time ,COMMA thing that happened just before ,COMMA five past nine .PERIOD certainly ,COMMA plenty of clients might want ,COMMA want that .PERIOD so this one is ,COMMA i've only got ten tickets to sell .PERIOD so that's the cut off point for ,COMMA selling ,COMMA seven tickets that's the cut off point .PERIOD for ,COMMA anybody after that time doesn't get a ticket .PERIOD and ,COMMA and this one might be ,COMMA if there's a time cut off .PERIOD i'm not going to sell tickets to anyone that came after that time .PERIOD and then the corresponding one is ,COMMA what's the first thing that happened after that time ?QUESTIONMARK that's call in to the radio show ,COMMA i'm going to take that caller ,COMMA the first call that comes at nine :COLON30 .PERIOD and so forth .PERIOD so then see how many things happen between nine :COLON15 and nine :COLON25 .PERIOD and how many calls were there before nine :COLON10 :COLON25 ?QUESTIONMARK so you can see that there's ,COMMA all of these operations are quite natural when we have the ,COMMA table in sorted order .PERIOD and that's what we have for our binary search implementation .PERIOD so we can ,COMMA implement these ,COMMA efficiently and they are ,COMMA convenient and useful for the clients .PERIOD so typically for ordered simple tables ,COMMA when keys are comparable will provide a much wider interface it's very useful for many clients .PERIOD so we say that we're dealing with keys that are comparable by simply adding this extents comparable key to our declaration .PERIOD same way we did for sorting methods .PERIOD so all that means is that our implementations can use compared to but for the client it means that all these operations have meaning .PERIOD give me the minimum key ,COMMA give me the largest key ,COMMA and then i can get the value associated with that using that .PERIOD give me the largest key less than or equal to this key value or the smallest key greater than that key value ,COMMA give me the number of keys less than that key .PERIOD you can actually implement priority queues this way .PERIOD delete the minimum key ,COMMA delete the largest key .PERIOD now usually we argue against why the interface is just adding operations to an interface ,COMMA usually our reason for doing so is that we can't guarantee that all the operations can be performing efficiently .PERIOD in this case ,COMMA as we'll see ,COMMA ultimately we have ways to guarantee that all the operations can be formed efficiently .PERIOD and they're so convenient for clients .PERIOD it's certainly worth adding them .PERIOD so we have iterate through all the keys ,COMMA and iterate through all the keys in a given range ,COMMA and count the number of keys in a given range .PERIOD all of these operations are very useful for clients and we'll see plenty of examples later on .PERIOD so we have to greatly expand our ,COMMA our table .PERIOD what ,COMMA what are going to be the cost of all of these things .PERIOD and this is a big difference between the binary search implementation where the keys are kept in order in an array ,COMMA in the sequential search implementation ,COMMA when they're all in a link list .PERIOD so ,COMMA for example ,COMMA to provide order and iteration ,COMMA you have to get them sorted .PERIOD and that's ,COMMA going to be a lot of work ,COMMA and take n lg n time .PERIOD whereas binary search ,COMMA you just iterate through ,COMMA the things in order .PERIOD the give me the seventh key we just go and look there ,COMMA they are in order .PERIOD rank operation ,COMMA that is essentially what binary search provides .PERIOD that's the ,COMMA our basic implementation is providing rank .PERIOD floor and ceiling that's again is an outgrowth of the rank operation .PERIOD minimum and maximum well again those are like select .PERIOD their just right there ,COMMA you look at the first or the last .PERIOD to insert or delete however takes linear time .PERIOD to maintain the sorted array in dynamic fashion is going to take linear time you have to go through the whole thing .PERIOD and so that's really are the key to thinking about what are symbol table and symbol tables in general .PERIOD how could we guarantee that all operations are fast ?QUESTIONMARK binary research is pretty good but that's a major flaw .PERIOD it can't maintain a dynamic table efficiently with binary search and that's going to be your focus in the next lecture 
welcome back .PERIOD next we're going to talk about binary search trees ,COMMA a classic data structures that'll enables us to provide efficient implementation of symbol table and out rhythms .PERIOD [cough] let's look at the basic binary search tree data structure with heaps we talk about implicit representation of trees with an array .PERIOD for binary search trees we're going to talk about actually explicit tree data structures .PERIOD a binary search tree is a binary tree in symmetric order .PERIOD let's look at the meaning of those words .PERIOD so ,COMMA a binary tree is an explicit data structure .PERIOD it's got what we call nodes which contain information and every node's got two links to binary trees that are disjoint from one another ,COMMA a left tree and right tree associated with each node .PERIOD each node has a left tree and a right tree .PERIOD links can be null .PERIOD left tree can be null and right tree can be null or both .PERIOD we refer to every node in the tree as the root of a sub -DASH tree and [cough] referred to ,COMMA the nodes below .PERIOD each node is its children so this is the right child of the root .PERIOD and that's a left link ,COMMA and so forth .PERIOD so that's the definition of a binary tree .PERIOD a binary search tree ,COMMA each node has a key and every nodes key is larger than all the keys in its left subtree and smaller than all the keys in its right subtree .PERIOD this is a different ordering than we have to heap if we have a node larger than both its children ,COMMA this one ,COMMA every node is between the values ,COMMA the value of every node is between the values of the nodes in its two subtrees .PERIOD so the nodes to the left of e are smaller and nodes to the right of e are larger .PERIOD [cough] now we're going to use these to implement symbol tables and there's values associated with each key when appropriate ,COMMA we'll write the values in smaller numbers next to the keys .PERIOD but usually ,COMMA we're just going to worry about the keys and we'll keep the values ,COMMA in the nodes along with them [cough] so that's binary search trees .PERIOD a binary tree in symmetric order that's the data structur e that we're going to use to implement symbol table operations .PERIOD so how are we're going to represent binary search trees in java ?QUESTIONMARK well ,COMMA we're going to extend our implementations of linked list structures to have two references instead of just one .PERIOD so first of all ,COMMA is the ,COMMA there's a node at the root .PERIOD so ,COMMA a binary search tree in java is just going to be referenced to a root node .PERIOD and every node's got four fields ,COMMA a key and a value ,COMMA and references to the left subtree ,COMMA that contains the smaller keys ,COMMA and the right subtree that contains the larger keys .PERIOD so ,COMMA here's what the ,COMMA [cough] code is based on .PERIOD the ,COMMA inner class that we used to implement nodes has ,COMMA one ,COMMA two ,COMMA three ,COMMA four instance variables .PERIOD all of which are private as usual .PERIOD a key of type key ,COMMA a value of type value and then references to a left and a right node .PERIOD for convenience ,COMMA we'll provide a constructor that takes the key and value as argument and fills in the key and value instance variables then the left and right links are initialized to null .PERIOD and our data structure then will be a root that points to a node in the tree and then that node will point to subtrees and that will be the data structure that we use for symbol tables .PERIOD so here's the skeleton of our symbol table implementation .PERIOD it's for comparable keys associated with values and those are both generic types .PERIOD the only instance variable is a link to the root node called root .PERIOD the inner class node is the code that was given on the previous slide ,COMMA and then we'll need implementations of put and get ,COMMA and we'll also look at an implementation of delete ,COMMA and an iterator as well .PERIOD so that's our skeleton implementation ,COMMA let's look at the keys .PERIOD so let's look at search first .PERIOD so here's a binary search tree let's do a demo of what different searches will look like in this tree .PERIOD so there's a tree so s is at the root everybody to the left of is less than s over to the right is bigger .PERIOD so this is a dynamic data structure that kind of follows the same rule as binary search .PERIOD so to look for a ,COMMA to do a search for the key h in this tree ,COMMA we start at the root and we compare our key against the key at the root .PERIOD and in this case ,COMMA h is less so all that says to us is that if h is in the tree ,COMMA it has to be to the left cuz everybody to the right is greater than s .PERIOD so we move to the left and compare h against the root of the left subtree .PERIOD in this case that's e .PERIOD now h is greater so that says we should go right .PERIOD now we can pair h against the root of the right subtree of e ,COMMA and that's r and it's less so we have to go left cuz everybody to the right of r is bigger and h is smaller .PERIOD and eventually if the key is in the tree ,COMMA we're going to hit it .PERIOD in this case we ,COMMA we find h as the left sub tree of r in [cough] that's a search hit and then for the get operation ,COMMA we can return the value that's stored in that node along with the key h .PERIOD what about an unsuccessful search ?QUESTIONMARK well the same rules follow .PERIOD if it's in the tree ,COMMA it's gotta be according to the left or right ,COMMA according to whether it's smaller or larger than the key at the route .PERIOD in this case ,COMMA if we're searching for g ,COMMA it's gotta go left ,COMMA because it's less than s .PERIOD when we come against the e ,COMMA we gotta go right because it's bigger than e against the r ,COMMA we have to go left ,COMMA because it's less than r .PERIOD we come against the h ,COMMA we have to go left .PERIOD and then we come off a null link ,COMMA and all that says is that there's no place in this tree where g could be so g is not there .PERIOD so that's a search miss .PERIOD and the get operation would return null in that case .PERIOD what about insertion ?QUESTIONMARK well ,COMMA to insert a new key ,COMMA all we do is follow the same steps as we did for search .PERIOD that following off that null link and again ,COMMA we'll just ,COMMA for g ,COMMA travel down the tree until we come to the ,COMMA null link .PERIOD really ,COMMA what we're saying is when we go to the left link of h ,COMMA it says ,COMMA if g is in the tree ,COMMA it has to be down this link .PERIOD since it's not there to in sert g ,COMMA all we need to do is just put it there and that's how we insert a new node into a binary search tree .PERIOD alright ,COMMA here's the code corresponding to the process that we just demo .PERIOD and it's quite straight forward simple code as simple as binary search really .PERIOD we start at the root then we set variable x to be the root and that's going to be the pointer to the current node as we move down the tree .PERIOD as long as our ,COMMA our current node x is not null what we'll want to do is a comparison between the key at node x and our search key .PERIOD if our search key is less ,COMMA we go to the left .PERIOD if it's greater we go to the right .PERIOD and if it's equal we don't even have to test that ,COMMA that's why it's in grey .PERIOD if it's not greater or lesser it has to be equal ,COMMA than we return the value right at that node .PERIOD if we get to the bottom and our current node is null and that's falling off the bottom of the tree we return null and that's equivalent to saying our buyer convention that ,COMMA that key is not in our data structure ,COMMA or not in our symbol table .PERIOD so that's very straightforward implementation of the get operation for symbol tables with a binary search tree representation .PERIOD now ,COMMA what's the cost ?QUESTIONMARK well ,COMMA we went down a path in the tree so it's one plus the depth of the node in the tree .PERIOD [cough] so what about search well search for put there's two cases .PERIOD if the if we're supposed to associate a value with a key .PERIOD if the key's already in the tree then we're just going to reset the value .PERIOD if they key's not in the tree then we add a new node at the bottom .PERIOD so now it's a little bit tricky the way that we implement it since we're using we use a recursive implementation .PERIOD and the reason we do this is that it generalizes to give us more efficient data structures later on .PERIOD so ,COMMA what we'll do is use a recursive implementation that as it moves down the tree it'll return a link up higher in the tree .PERIOD and so when we insert a new node l say in this tree we go down that path ,COMMA we create a new node and then return the link to that node higher up .PERIOD there's ways to implement that don't involve this ,COMMA but its ,COMMA the code is so simple and it extends to more powerful data structures later on that we'll introduce this right now and ,COMMA and you'll see how it works .PERIOD so here's the ,COMMA this is very concise recursive code but its tricky because of that last point so its worth reading carefully .PERIOD so ,COMMA we're going to use a recursive method put .PERIOD that put a associate a value with a key in the tree .PERIOD and that recursive [cough] method is going to return a node .PERIOD so the client method put of course ,COMMA just is supposed to do the association so it has a void return .PERIOD but what we'll do is invoke a recursive method starting at the root and whatever link gets returned ,COMMA we'll set that to root .PERIOD so right away ,COMMA we can see ,COMMA let's suppose that we have an empty tree where root is null .PERIOD so then if we put with null as the first argument ,COMMA then null is the first argument .PERIOD what we do is we say if ,COMMA if the argument is null ,COMMA return a reference to a new node that associates key with value and then that one has null links .PERIOD so in this case ,COMMA that first call will return a link and whatever link gets returned ,COMMA that will be set to root .PERIOD so ,COMMA without any extra special code we insert a node into an empty tree .PERIOD and that works ,COMMA again ,COMMA recursively say we have one node in the tree ,COMMA and we have a new key to associate .PERIOD and let's say that key is less than the key at the root .PERIOD so ,COMMA so now we do put in it's actually a link to that one node that's got two null links .PERIOD so it's not null so we'll compare our key against the key in that node .PERIOD if that comparison comes out left ,COMMA here's how we do the insert .PERIOD we change our left link which is right now it's null to whatever put returns .PERIOD so what's put going to return ?QUESTIONMARK well ,COMMA that left link is null ,COMMA so what's going to happen is ,COMMA in that call x is null .PERIOD it's going to be cre ated a new node and the link to that node will be returned and that's the link that we'll put in the left .PERIOD this is a very concise code that otherwise we'd have various cases about saving which link we went down in order to reset that later on .PERIOD so now the best way having looked at those small examples ,COMMA the best way to understand this code is recursively .PERIOD let's believe that it works for small cases which we have just done .PERIOD so ,COMMA lets see what the code does .PERIOD so if x is null ,COMMA we want to create a new node and return the link to that node .PERIOD so ,COMMA even if it's a huge tree down at the bottom ,COMMA we just came of a null link .PERIOD we just want to create a new node with our new key and return a link to that node ,COMMA that's all we want to do .PERIOD now ,COMMA we can assume that put is going to return a link to a sub -DASH tree that contains our new key and if our new key is smaller than the key at the node that ,COMMA that we're processing now ,COMMA then [cough] we want to insert the new key value there and the new node on the left otherwise ,COMMA we want to insert on the right .PERIOD most of the time ,COMMA the link that we get back will be same as the link that we put in but for the bottom node it will be different .PERIOD so ,COMMA if put works properly inserting a new node on the left ,COMMA then that's what we want our left link to be .PERIOD if it works properly ,COMMA putting in the subtree on the right ,COMMA that's what we want our right link to be .PERIOD and by the way ,COMMA if we find a key that's in the tree already ,COMMA then we just want to reset the value .PERIOD and in all of these cases where we're on a node that already existed ,COMMA we just want to return the link to that node .PERIOD again ,COMMA when we look at more sophisticated values we'll be returning something else .PERIOD so it's worthwhile you know ,COMMA checking that you believe that this code implements the simple binary search tree algorithm that we demoed where when we fall off a null link we created a new node and replaced that null link with the new node  .PERIOD so that's insert for a binary search tree in a symbol table .PERIOD and again ,COMMA the cost of this is the number of compares is equal to one plus the depth of the node .PERIOD we just go down a path in the tree .PERIOD now ,COMMA what's interesting about binary search trees is that there are many different binary search trees that correspond to the same set of keys .PERIOD so the number it compares is going to depend on the order in which the keys come in .PERIOD and that's a key feature of binary search trees that we'll come back to again when we look at more sophisticated data structures .PERIOD so it depends on how the keys come in .PERIOD the shape of the ,COMMA of the tree could be well in the best case so it would be perfectly balanced .PERIOD and one of the things we'll look at is algorithms that come very ,COMMA very close to achieving that goal .PERIOD the typical ,COMMA typical case it'll be sort of balanced .PERIOD now but one problem is if the keys come in and ,COMMA and really unfortunately ,COMMA if they come in ,COMMA in a natural order .PERIOD like if they come in ,COMMA in order ,COMMA that's the worst case .PERIOD we don't get any benefit from having it in a tree shape .PERIOD it's no different than a link list .PERIOD so we'll ,COMMA we'll come back to dealing with that worse case in the next lecture .PERIOD but the point is ,COMMA the tree shape depends on the order of insertion .PERIOD now ,COMMA but let's look at what's happened or visualize what happens when keys come in ,COMMA in random order .PERIOD so the tree grows from the bottom in the little side to side motion it's just accommodating room for each new key as it's added .PERIOD but you could see that even for this case which is hundreds of keys ,COMMA the length of the path from top to bottom is not so much .PERIOD in this case ,COMMA the maximum distance from the top to the bottom is sixteen the average is only nine and the best you could in a perfectly balanced tree it would be seven .PERIOD so it's pretty well balanced which means that our search and insert cost in this case for 255 keys is only going to be sixteen quite a bit less .PERIOD so one remark before we do the analysis is that actually binary search trees correspond exactly to quicksort partitioning .PERIOD in the binary search tree ,COMMA we have a node at the root and we have everybody smaller to the left ,COMMA and everybody larger to the right .PERIOD in quicksort partitioning ,COMMA after the random shuffling we have the partitioning element and then we process everybody to the left independently of everybody to the right .PERIOD so it's a [cough] there's a direct correspondence .PERIOD if there is no duplicate keys quicksort processes them and referred them out in bsts and if there's no duplicate keys there's a one -DASH to -DASH one correspondence between what happens with quicksort and what happens with binary search trees .PERIOD and we point that out because that helps with the mathematical analysis .PERIOD in fact ,COMMA this correspondence with quicksort partitioning tells us we can take that proof and prove that if you insert in distinct keys into a bst ,COMMA in random order ,COMMA then the expected number of compares for a search and an insert is two natural log n .PERIOD so again about 1 .PERIOD38 log base two of n almost the best that you could do .PERIOD it also has been shown actually not that long ago ,COMMA that the expected height of the tree if they're inserted in random order ,COMMA the height that's the worst case length of a path in the tree .PERIOD this is the average path in a tree ,COMMA this is the ,COMMA the worst of all the keys .PERIOD this is about four natural log n .PERIOD so ,COMMA if you have the keys in random order the binary search tree gives efficient search and insert .PERIOD now but there is this problem that the actual worst case height if the keys come in ,COMMA in order and reverse order and other natural orders that the time could be proportional to n .PERIOD so ,COMMA we have this summary which is looking pretty good ,COMMA because we have the average case for both operations ,COMMA the search and insert ,COMMA to be 1 .PERIOD39 log n and that's probabilistic if they are in random order ,COMMA its extremely likely to be there .PERIOD but the problem by comparison with sorting is ,COMMA we don't get to randomize the order the client is providing the keys .PERIOD so we're going to need something better to provide the guarantee than just randomly ordering the keys .PERIOD that's what we're going to be looking at next when we look at more efficient algorithms .PERIOD but first we're going to look at the implementation of order and operations with the binary search tree structure .PERIOD it expands like binary search to handle all these convenient client operations in a very natural manner .PERIOD that's the implementation of binary search trees for symbol tables .PERIOD they give sufficient implementation of both search and insert .PERIOD 
 .PERIOD so knuth -DASH morris -DASH pratt is a linear time algorithm ,COMMA we can't ,COMMA surely we can't do better than that ,COMMA can we ?QUESTIONMARK well ,COMMA it's not the end of the story .PERIOD now we're going look at the boyer -DASH moore algorithm .PERIOD and it's also a very simple idea that's extremely effective in practice .PERIOD so here's the idea .PERIOD instead of matching the pattern against the text moving from left to right in both pattern and text .PERIOD boyer -DASH moore said ,COMMA what ,COMMA what if we try to scan the characters in the pattern from right to left ?QUESTIONMARK" so ,COMMA then ,COMMA when we find a mismatch we can skip ,COMMA we know all the characters in the pattern .PERIOD so ,COMMA for example ,COMMA if we're looking for a needle in the ,COMMA in a haystack ,COMMA if we first look at the last character in the pattern ,COMMA which is an e ,COMMA and we find that n in the text .PERIOD now then ,COMMA it's clear that the next possible match is when the ns lined up ,COMMA cuz if it was any other lineup ,COMMA it'd be all these characters that we know are not n ,COMMA compared against n ,COMMA so we might as well just move it so the ns are lined up .PERIOD and that's good but that's not as good as the next case .PERIOD if we happen to run into a character that's not in the pattern ,COMMA then we can just skip all the way over .PERIOD we don't have to compare any of our pattern character against that one .PERIOD so we can just add m if we have m -DASH pattern characters .PERIOD and so then in this case we have a more complicated situation .PERIOD we match the e ,COMMA and we have a bunch of es ,COMMA and so ,COMMA part of the algorithm is to figure out ,COMMA when you do match a character that's in the pattern and that what do you do .PERIOD but the intuition is ,COMMA it's fast ,COMMA because you're often going to have this kind of case where you find a mismath .PERIOD and since you're going from right to left ,COMMA that's you know ,COMMA that ,COMMA there's character in the text that's not in the pattern at all ,COMMA you can shift over n characters at a time .PERIOD and that's a huge win in a lot of practical situation .PERIOD so ,COMMA so how much do we skip ?QUESTIONMARK so the ,COMMA the first case is clear .PERIOD if there's ,COMMA if you run into a text character that's not in the pattern ,COMMA then you just move i from wherever it was to one character beyond the current one that you're looking at .PERIOD so ,COMMA and that's an easy ,COMMA easy calculation ,COMMA it's just increment it by the number of pattern characters that you've not looked at .PERIOD now ,COMMA but if you have a character in a pattern then ,COMMA you want to align the text and in this case ,COMMA with the rightmost pattern ,COMMA and ,COMMA and that's pretty good .PERIOD but you don't always want to do that .PERIOD if you for example ,COMMA we have a mismatch on e .PERIOD if you were to say ,COMMA oh ,COMMA let's line up on the rightmost most e on the pattern ,COMMA that would involve backup .PERIOD so you don't want to do backup .PERIOD in that case ,COMMA you just move on by one .PERIOD so there are times when the heuristic is no help .PERIOD so what you really want to do is just increment by one in that case .PERIOD so just given ,COMMA those basic preliminaries ,COMMA it's ,COMMA clear that it's ,COMMA actually easy to go ahead and precompute ,COMMA how much ,COMMA you might want to skip .PERIOD so ,COMMA you start out with ,COMMA with  -DASH one .PERIOD so this is the ,COMMA amount ,COMMA that ,COMMA you're going to increment the ,COMMA the text pointer .PERIOD n  -DASH  one means you just it's not in the pattern ,COMMA so you're just going to move on one .PERIOD and so all you do is go through the pattern ,COMMA and so let's start with n .PERIOD so we want too fill in this table for n .PERIOD and it says ,COMMA so if we ,COMMA if we are going to find an n in the text ,COMMA what do we want to do .PERIOD well we want to move to the next text character sorry ,COMMA we want to co ,COMMA compare the next text character against this one ,COMMA which is zero .PERIOD and so right of path .PERIODcharat j = j .PERIOD it's going to ,COMMA just going to fill in that zero .PERIOD then we go to j = one for the e ,COMMA e ,COMMA d ,COMMA l .PERIOD it's same ,COMMA so for what happens is for if you do that for every letter in the pattern ,COMMA if you have a letter that appears more often it gets overwritten until the right most occurrence is the one that's there .PERIOD so ,COMMA that precomputation is just one path through the pattern .PERIOD and then giving that precomputation and ,COMMA again we're going to implement ,COMMA this is an implementation of boyer -DASH moore ,COMMA for using for loop incrementing in the text characte .PERIOD and so we ,COMMA are going to have the text pointer i .PERIOD i in the course of the algorithm ,COMMA we're going to compute a value skip which is the amount that we're going to move the text character .PERIOD so we go all the way through the pattern from right to left .PERIOD if we get all the way through the pattern and we find a match ,COMMA and we don't change the value of skip ,COMMA then we've found a match .PERIOD if we don't ,COMMA sorry ,COMMA if we get all the way through the pattern and don't find a mismatch .PERIOD it's all matches we don't change the value of skip and we found a match .PERIOD if we do find a mismatch than we're going to compute the value that we skip ,COMMA which is where we are minus that table that thing that we computed .PERIOD and that's the amount that now that we're going to add to the text character to take care of the mismatch for the right to left mismatch .PERIOD and if it's ,COMMA it's ,COMMA always going to be at least one ,COMMA but if this thing is negative ,COMMA we're not going to back up .PERIOD that's ,COMMA that's it .PERIOD so it's a very simple implementation based on this idea of moving from right to left and skipping over the whole thing if we find a mismatch .PERIOD and the key thing about boyer -DASH moore you can study that implementation and figure it out easily ,COMMA but the key thing is that this mismatched character here is ,COMMA takes time proportional to n over m .PERIOD that's kind of amazing .PERIOD we had started out with a brute force which was n  n ,COMMA and then we got linear time ,COMMA we were happy with n ,COMMA but actually there's a lot of practical situations where you can do the search in n over m .PERIOD the longer the pattern gets ,COMMA the faster the search gets .PERIOD it's not only sublinear ,COMMA it gets better .PERIOD that's kind of amazing .PERIOD now there's a caveat there because there is a worse case that could be as bad as the brute force .PERIOD so this is just a example of the worst case where you go from right to left ,COMMA let's say ,COMMA and always get to the first character before finding the mismatch ,COMMA and you can't do anything better than move over one .PERIOD but actually ,COMMA what you can do is build something kind of like knuth -DASH morris -DASH pratt to make sure that you don't do something like this with a ,COMMA repetitive pattern .PERIOD and you ,COMMA you can get the worst case to the linear ,COMMA but it's really of importance for ,COMMA for intermediate length patterns with ,COMMA because you so often are going to be able to get this n over m performance .PERIOD and that's a widely used algorithm .PERIOD the boyer -DASH moore algorithm .PERIOD 
now ,COMMA we're going to take a look at ordered symbol table operations using the binary search tree data structure as the underlying implementation .PERIOD well ,COMMA each one of these operations are fairly straight forward but just to check our ability to manipulate this data structure ,COMMA we'll take a look at each .PERIOD suppose ,COMMA we wanted to find the minimum key in a binary search tree ,COMMA or the maximum key .PERIOD well ,COMMA just looking at one example you can see almost immediately what to do to find the minimum ,COMMA we move left from the root until we find a null key ,COMMA that's where the smallest key in the data structure is .PERIOD to find the maximum ,COMMA we move right from the root ,COMMA until we find a null key .PERIOD what about floor and ceiling ?QUESTIONMARK well ,COMMA those are a little bit more complicated and we'll have to ,COMMA not quite the same as in the ordered array for the binary search so we have to do a little bit more work for that .PERIOD so just for example ,COMMA let's take a look at the problem of computing the floor .PERIOD so ,COMMA what we want to find is so say ,COMMA we're seeking the floor of g .PERIOD so ,COMMA that's the largest key in the data structure that is less than g .PERIOD in this case ,COMMA the answer is e .PERIOD so let's just take a look at what we have to do in the tree ,COMMA the path we have to take in the tree to figure that out .PERIOD well so ,COMMA we are looking for the largest key that's less than g .PERIOD and have s well ,COMMA that key is definitely going to be in the left subtree .PERIOD its not going to be bigger than s because s is bigger than g so we go to the left .PERIOD so now ,COMMA we are sitting at e .PERIOD and so what's the largest key that's less than g in this ,COMMA in this tree here .PERIOD well ,COMMA it might be e but there's no way it's to the left of e because those keys are all smaller than e and therefore smaller than g .PERIOD so ,COMMA e is a key candidate .PERIOD but it might also be in the right so we move to the right in this case .PERIOD alright [cough] .PERIOD so that's [cough] if k is equal to the key at the root ,COMMA the floor of k is k .PERIOD if k is less than the key ,COMMA it roots i n the left subtree .PERIOD that's the one we just did .PERIOD if it's greater than the key at the root .PERIOD the floor of k is in the right subtree ,COMMA if there is any key smaller than k in the right subtree .PERIOD so ,COMMA in this case ,COMMA there's no key smaller than g in the right subtree .PERIOD so therefore ,COMMA the answer is e .PERIOD so ,COMMA our code has to check for these three cases .PERIOD and here's the code that does it .PERIOD it's not that much code .PERIOD it's just complicated code to understand .PERIOD so if we find our key ,COMMA that's the floor .PERIOD if we're going to the left we find the floor ,COMMA the one on the left .PERIOD and in on the right we have to do a ,COMMA a little bit of tricky code to make sure that we return the floor on the right subtree ,COMMA if there's some tree there .PERIOD if there's ,COMMA if there's no node there then ,COMMA then ,COMMA then we ,COMMA we return the root itself .PERIOD so ,COMMA that's a ,COMMA a implementation that ,COMMA that code is definitely tricky and a similar code for ceiling .PERIOD so now ,COMMA what about operations like rank and select ?QUESTIONMARK how many keys are there less than a given key ?QUESTIONMARK and ,COMMA give us the seventh largest key to facilitate implementing those operations and also size all we do is keep an extra field in each node ,COMMA which is the number of the nodes in the subtree rooted at that node .PERIOD so ,COMMA this tree has got eight nodes in it .PERIOD this subtree has six nodes in it and so forth .PERIOD and those counts are going to not only enable us to immediately implement the size function ,COMMA just return the count at the root but also ,COMMA they'll give us good implementations of rank and select .PERIOD so ,COMMA let's look at those now .PERIOD so ,COMMA we add account field to every node and then to implement the size function well ,COMMA if it's null ,COMMA we return zero .PERIOD so a client might call us for a null tree or [cough] or an empty tree .PERIOD otherwise we return ,COMMA x .PERIODcount ,COMMA which is the number of nodes in that ,COMMA in that subtree by definition .PERIOD the way we maintain ,COMMA there's a number of ways we can maintain the thing but the one that we'll adopt un iformly because it adapts to more complicated situations is just before we're done with the put operation we'll say ,COMMA okay we've done all our work and before we return the pointer to the given subtree we're going to take the size of what's on the left and the size of what's on the right and add one for us and that's going to be our count .PERIOD so ,COMMA whether or not there was a new node added we don't have to test for that this recursively takes care of the problem of maintaining the size in every node when there's a new node inserted .PERIOD and ,COMMA it also handles more general situations ,COMMA as we'll see later on .PERIOD so ,COMMA that's how to maintain size .PERIOD so now ,COMMA how do we implement rank ?QUESTIONMARK well ,COMMA it's a little like floor .PERIOD it's an easy recursive algorithm ,COMMA but there are three cases .PERIOD so let's look at the ,COMMA at the three cases .PERIOD so ,COMMA we want to know the number of keys less than k .PERIOD so [cough] we're going to have a recursive algorithm for our given key .PERIOD so ,COMMA let's ,COMMA one of the easy ones is ,COMMA if our key is equal to the ,COMMA if were [cough] to the ,COMMA the key at the current node then the number of keys less than our key is the size of the left subtree of that node .PERIOD so ,COMMA if we're looking for the rank of e say ,COMMA how many keys are there less than e there's exactly two ,COMMA that's by definition in the data structure that's the number of keys that are less than e .PERIOD so ,COMMA that's that one for rank .PERIOD what about the [cough] starting at the root if we have the case where e is less than s .PERIOD so ,COMMA the rank of e in this whole tree is the same as the rank of e in the left subtree .PERIOD so ,COMMA there's that case and then if we're going to the right ,COMMA then we have to add one for the root and one for the left subtree of the root and then find the rank of us on the right .PERIOD so ,COMMA that's an easy recursive algorithm for finding out the rank .PERIOD and it's definitely an instructive exercise to check that you believe that ,COMMA that method works .PERIOD the other thing we h ave to do is iteration .PERIOD and iteration is a fundamental operation on tree structure .PERIOD and it's based on so called in -DASH order traversal .PERIOD and that's also a simple recursive algorithm .PERIOD traverse the left subtree enqueue the key ,COMMA traverse the right subtree .PERIOD so ,COMMA to iterate we're going to maintain a queue of keys .PERIOD and then ,COMMA we're going to call this recursive in -DASH order [cough] method .PERIOD and that method is going to add all the keys in the tree to the queue .PERIOD and then we'll just return that queue .PERIOD and that's ,COMMA a queue is an iterable data structure ,COMMA and the client can iterate that .PERIOD and ,COMMA in order ,COMMA it's just a simple recursive method .PERIOD put everybody to the left on the queue then put the root on the queue ,COMMA then put everybody to the right on the queue .PERIOD and to believe this method ,COMMA you just have to think recursively and prove by induction that this in order method puts all the keys in the data structure on the queue in their natural order .PERIOD first ,COMMA it puts all the ones to the left on the queue .PERIOD if that ,COMMA that happens in their natural order ,COMMA then the next thing that has to appear is the key at the root .PERIOD and then if the ones on the right go in their natural order ,COMMA and then ,COMMA by induction ,COMMA they're all in their natural order .PERIOD that's a very simple implementation of an iterator for these symbol table with comparable keys .PERIOD so we have to again prove that property by induction .PERIOD and that's easy to do .PERIOD the diagram at the right gives another simple way to look at it pictorially .PERIOD all the keys that are smaller on the left we are going to put them out ,COMMA and then we put the key at the root and then we put all the keys on the right out in order .PERIOD and then that key is going to have all those keys in order by induction .PERIOD so ,COMMA here's the operation summary for ordered symbol table .PERIOD and the quick summary is that every one of those operations ,COMMA while ordered iteration is optimal ,COMMA it just gets them in linear time .PERIOD and all the res t of'em take time proportional to the height of the tree .PERIOD now ,COMMA if the ,COMMA the keys are inserted in random order ,COMMA we know that height by analysis ,COMMA is going to be proportional to log n .PERIOD or if it's some application where the order of insertion of the keys is well modeled by random order and that's not unusual at all .PERIOD a binary search tree is a simple and extremely effective data structure that can support all of these operations in a quickly ,COMMA much better than binary search in an ordered array which is not dynamic and slow for insertion .PERIOD so ,COMMA that's a look at binary search tree implementations of ordered operations when keys are comparable .PERIOD 
 .PERIOD and that's still not the end of the story .PERIOD we're gonna look at one more really interesting al -DASH  ,COMMA algorithm that has ,COMMA lots of important applications ,COMMA called a rabin karp algorithm .PERIOD invented by two turing award winners .PERIOD michael rabin and dick karp .PERIOD i can remember hearing about this algorithm ,COMMA from my friend ,COMMA dick lipton ,COMMA who explained it to me over the phone ,COMMA and ,COMMA i ,COMMA he explained it to me in about ,COMMA fifteen seconds ,COMMA and i realized i had to have this ,COMMA in the book .PERIOD and ,COMMA so now ,COMMA here we are ,COMMA presenting it .PERIOD th ,COMMA that was ,COMMA in the 70's .PERIOD so the basic idea for the rabin -DASH karp algorithm is ,COMMA has to do with hashing .PERIOD in it's a particular kind of hashing ,COMMA called modular hashing .PERIOD it's just a particular way of computing a hash function .PERIOD it's easiest to think about in terms of numbers ,COMMA although it ,COMMA it works in all kinds of situations .PERIOD because remember everything in a computer is encoded as a byte ,COMMA which can be treated as bytes which could be treated as binary numbers .PERIOD and so what we are going to do is in this case we saw a pattern characters are decimal digits .PERIOD and so ,COMMA we'll treat a sequence of pattern characters as the decimal number .PERIOD and modular hashing is ,COMMA just take a big prime .PERIOD and compute the remainder when you divide your number by that prime .PERIOD so in this case ,COMMA 613 is the remainder that you get when you divide 26 ,COMMA535 by 997 .PERIOD so you can check that .PERIOD so that's what we're going to use as the hash function .PERIOD and that .PERIOD this type of hashing is widely used .PERIOD you have a prime number ,COMMA we talked about it when we talked about hashing .PERIOD it satisfies ,COMMA it seems to satisfy something like the uniform hash assumption under various circumstances .PERIOD so that's our pattern ,COMMA a five character pattern ,COMMA and we're going to keep the small hash values 613 and this is going to generalize to longer patterns ,COMMA and we'll talk about that in a minute .PERIOD so now ,COMMA suppose we have this text .PERIOD and our pattern happens to occur here in the text .PERIOD and what the method is built on is the idea of you take the first five characters in the text and compute its hash value .PERIOD in this case ,COMMA 31 ,COMMA415 ,COMMA mod down 97 ,COMMA is 508 .PERIOD so that's different so that's not the pattern .PERIOD maybe take the next five characters ,COMMA that's 201 .PERIOD that's diffent it's not the pattern .PERIOD take the next one .PERIOD that's 715 ,COMMA different it's not the pattern 15 ,COMMA926 by 97 is 971 ,COMMA it's not the pattern .PERIOD eventually ,COMMA when you have the text characters that are the same as the pattern characters you're gonna get the same result ,COMMA it's a match .PERIOD if the pattern hat ,COMMA hash equals the text sub -DASH string hash you ,COMMA you have the potential for a match .PERIOD and that's what the algorithm is based on .PERIOD now it seems like ,COMMA we're doing a lot of calculation ,COMMA with ,COMMA making numbers out of these things .PERIOD and ,COMMA and keep doing modular arithmetic on it .PERIOD but actually there's ,COMMA a really ,COMMA simple way to ,COMMA severely limit the amount of calculation .PERIOD and give a quick linear algorithm for ,COMMA search .PERIOD sub -DASH string search .PERIOD so first thing is how to compute the hash function .PERIOD so we take the ,COMMA just convert the math .PERIOD so r's our radix .PERIOD so in this example ,COMMA we're using ten so we have decimal numbers .PERIOD and then the digits ,COMMA say t's of i that's the text characters .PERIOD so we have a number x of i ,COMMA which is the ,COMMA m characters starting at position i .PERIOD and that's just in math ,COMMA ti<i>r to the m -DASH 1</i> so you know ,COMMA in this case that's two<i>10000+6<i>1000+5<i>100+3<i>10+5 that's just</i></i></i></i> math for that .PERIOD and our goal is so it's an n digit base based our integer modular q and our and our goal is to do the math .PERIOD that gives us the remainder that we would get when dividing that by q well there's really easy method called horner's method that we can use to evaluate a degree in polynomials just with a multiplied m multiply and add .PERIOD and we can do the modular computation all the way through at each step ,COMMA to keep the numbers less than q and we still get the same result .PERIOD and so the idea is ,COMMA you multiply by r .PERIOD you go from left to right through the digits and you just multiply by r and add the digit ,COMMA and then do mod q at every time .PERIOD so we start with two mod 97 is two .PERIOD to six mod 987 is two<i>10+6 mod 987 and</i> that's 26 .PERIOD and then i take that value .PERIOD multiply by ten and add five that's 265 mod 997 .PERIOD in that case it's ,COMMA it's 265 .PERIOD so 265<i>10+3 is 2653 .PERIOD</i> our remainder is divided by 997 ,COMMA it's 659 ,COMMA so even though our number gets bigger than 997 ,COMMA might take them out every time ,COMMA we keep our running total less than 997 .PERIOD and then the last step is to take the 659 .PERIOD basically we've thrown out a bunch of multiples of 997 that we don't care about .PERIOD and 659<i>10+5 mod 997 is exactly equal to</i> 26535 mod 997 and that's 613 .PERIOD that's our value .PERIOD so that's a using horner's method we got a ,COMMA well known linear time method to do compute or hash function with this simple code .PERIOD and this notice will work even for a huge key that we wouldn't compute a hundred dig ,COMMA convert a hundred digit key in to some number to do the calculation .PERIOD we do one digit at a time using horner's method and then we have no limit because we're always keeping our numbers less than our prime queue .PERIOD so that's a first step ,COMMA so no matter how big the pattern is ,COMMA we can efficiently compute a hash or ,COMMA since that is the first step .PERIOD so now the second step for the rabin karp algorithm is to realize that if we know xi mod q we can efficiently compute xi+1 mod q cause they have a lot of digits in common .PERIOD and you can just do a little math to get to xi+1 you take .PERIOD xi ,COMMA we don't care about the first digit anymore ,COMMA so you subtract it off .PERIOD multiply by r and then add the new digit .PERIOD that's like one step of horner's method .PERIOD now ,COMMA then you have to take that computation and you can do mod q all the way through .PERIOD all you have to do is pre -DASH compute r to the n+1 mod q and so here's the computation for one example .PERIOD if we're at this position 41592 and we know 41592 mod q we can compute 15926 mod q by subtracting off 40 ,COMMA000 .PERIOD the tir -DASH 1 and that gives us just the four digits ,COMMA multiply by the radix add the new trailing digit and that's the new value .PERIOD and if we just keep that all mod q then we can with just a multiply and an add at each step we can keep a running total of the modular hash value of the five digit thing .PERIOD so ,COMMA for example ,COMMA this is the case that ,COMMA that we just did 4152 on 997 is ,COMMA is done by ex ,COMMA exactly as we said we subtract and then add and then multiply by the radix mod 997 .PERIOD so ,COMMA doing those calculations all the way through the search ,COMMA we eventually get to a match .PERIOD that's again remarkably small amount of code .PERIOD we're going to keep a long random prime .PERIOD just keep it a little smaller than the biggest long value to avoid overflow .PERIOD so we pre -DASH compute r to the m  -DASH  one mod q 'cause that's the little calculation that we have to do .PERIOD we compute the hash function .PERIOD and for the pattern .PERIOD and then ,COMMA with those pre -DASH computations ,COMMA the search is extremely straight forward .PERIOD so we take our current hash value .PERIOD and this is just ,COMMA add a q make sure it's positive .PERIOD and subtract off rm times the first character in then add in the next character mod q .PERIOD and that gives us the text hash for the current position .PERIOD and then we compare to see if that's equal to the pattern hash .PERIOD now there's this is an introduction to the idea of randomized algorithms .PERIOD there's two ways to proceed from here .PERIOD one way called monte carlo version .PERIOD where we guaratee that the algorithm is gonna be quick but with low probability ,COMMA it might get the answer wrong .PERIOD in that version we don't ever bother to check whether the go through and check all digits to see if there's actually a match .PERIOD we take queue large enough so that we're confident the probability of the ,COMMA to ,COMMA two digit numbers or two m digit numbers having the same hash value .PERIOD and so low that we're not gonna worry about it ,COMMA that's called the monte carlo version .PERIOD the las vegas version is guarateed to get the right answer .PERIOD in that one we would go and check to make sure that the m characters match if we have a hash match .PERIOD and then if it could be that with such at a low probability could be that there's a hash match but not a substring match .PERIOD then we're just .PERIOD move on .PERIOD and from a theoretical point of view there's some very extremely low possibility that one could be slow .PERIOD but lets look over at what the analysis says .PERIOD so the theory says that if you take a sufficiently large random prime say mn^ three so a long value maybe you can get that and remember n is huge .PERIOD then the probability of a false collision is about 1/n .PERIOD so you know in a billion things you might get ,COMMA you might get 1/n ,COMMA you might get a false collision .PERIOD so in practice we choose actually q just to be ,COMMA there's no reason not to choose as large as we possibly can ,COMMA not related to m and n .PERIODm and then the probably collision is going to be about 1/q .PERIOD so we're going to take it to be like the biggest law ,COMMA and that means that probably collision is extremely small .PERIOD and then you can take your chances .PERIOD you can do a monte carlo version where you just say i got a match because i got a hash match .PERIOD and be confident in the laws of probability .PERIOD and not worry about the client getting the wrong answer .PERIOD or you can have the las vegas version where you go ,COMMA go ahead and return the correct answer .PERIOD and .PERIOD and be confident that your client's not gonna run into a slow case cuz the probability is so ,COMMA so tiny ,COMMA 1/q ,COMMA that you don't have to worry about it .PERIOD that's the rabin -DASH karp algorithm .PERIOD now ,COMMA why look at this algorithm ?QUESTIONMARK it's linear time .PERIOD we have other algorithms that are linear time .PERIOD one of the key reasons to ,COMMA be interested in rabin -DASH karp is that it's easy to extend it to more complicated situations .PERIOD so ,COMMA say you wanna look for one of ,COMMA several different patterns .PERIOD well ,COMMA you just compute the hatches for those patterns ,COMMA and then look for any one them use ,COMMA a symbol table ,COMMA to look for'em .PERIOD so ,COMMA that's a much more ,COMMA general capability than ,COMMA we can provide with the other methods .PERIOD it also can be extended to do 2 -DASH dimensional search and other things like that .PERIOD for straight suffering search ,COMMA it's gonna be a little slower because ,COMMA there's ,COMMA interloop it's kind of long ,COMMA the arithmatic operation ,COMMA are gonna be a little slow ,COMMA if you wanna do the las vegas version you have to back up the text and you have this ,COMMA monte carlo las ,COMMA las vegas thing ,COMMA and you should think about ,COMMA writing code to extend it to look for any one of p possible patterns ,COMMA thats ,COMMA an interesting ,COMMA algorithmic puzzle as i mentioned is not so difficult to solve .PERIOD so here's our summary .PERIOD we started with a brute force algorithm ,COMMA and although typically you don't have this worst case thing .PERIOD it works fairly well for typical cases .PERIOD and then we've got the knuth -DASH morris -DASH prath method that can guarantee linear time and has no backup .PERIOD and maybe uses extra space unless you use pratt's version .PERIOD the aboriamor who can get the running time down to n/m which is quite an amazing jump and quite useful and in a rabin karp that's very flexible and extends through all these other situations .PERIOD this is a nice mac ,COMMA microcosm of algorithmic technology where ,COMMA really interesting ,COMMA and unique and path breaking algorithmic ideas give us .PERIOD a good algorithm ,COMMA for even such a simple problem .PERIOD that's an introduction to pattern 
if our symbols table's really going to be dynamic ,COMMA we need to be able to delete key valued pairs from the table .PERIOD as we'll see ,COMMA all symbol table implementations have ,COMMA lead to complications when we try to do this operation .PERIOD binary search trace is our first example .PERIOD so we need to fill in this one table .PERIOD what's ,COMMA what's the cost of deletion in a binary search tree ?QUESTIONMARK how are we going to really do that ?QUESTIONMARK well let's take a look at a very lazy approach which we set up for in our basic conventions for simple tables .PERIOD what we can do to remove a node with a give key is just mark it with a tombstone .PERIOD say ,COMMA well ,COMMA we'll leave the key in the tree to guide searches ,COMMA but we won't ,COMMA count it as being in the symbol table .PERIOD and actually you can ,COMMA make some progress with this kind of method .PERIOD leaving tombstone throughout the tree .PERIOD and ,COMMA make sure that you keep ,COMMA as long as there aren't too many deletions ,COMMA you can keep the search costs ,COMMA and deletion and insert costs to be logarithmic .PERIOD but it definitely becomes ,COMMA inconvenient to manage large numbers of tombstones in highly dynamic situations with large numbers of keys and values .PERIOD eventually you're going to get an overload of memory and you're going to have to rebuild the thing or clean out the tombstones in some way so we need to look for a better way .PERIOD this is a general method that people often use on all different types of implementations ,COMMA but in modern systems it's rather unsatisfactory .PERIOD also got a simpler problem .PERIOD what about deleting the minimum ?QUESTIONMARK well actually ,COMMA that's maybe not too difficult to delete the minimum in a binary search tree .PERIOD again ,COMMA we just go to the left until we get a null left link .PERIOD and then ,COMMA what we can do is just return that node's right link then that old node ,COMMA nobody's pointing to it ,COMMA so it's available for garbage collection .PERIOD and then we use our usual trick of returning the link that we went down to update the other links after the recursive calls .PERIOD and also we have to update the counts ,COMMA something happened down below and we used that code to update the counts ,COMMA in a co nsistent way ,COMMA so this code implements deleting ,COMMA not too bad at all .PERIOD if x .PERIOD left null ,COMMA return x right .PERIOD otherwise x left = delete min x left .PERIOD and then when you're done with that ,COMMA it fix the count so maybe a node got deleted down there ,COMMA but always ,COMMA the invariant is that the count of the node is one + size of the left and right .PERIOD and then return x and fix the links and the counts on the way up .PERIOD that's a fine implementation for delete min ,COMMA and it also works for delete max .PERIOD and that's the basis for a general method for deleting nodes from bsts known as hibberd deletion .PERIOD so ,COMMA that's the second case ,COMMA the first case for hibberd deletion is what we want to do to delete a ,COMMA a node with key k ,COMMA is we search for the node that contains the key ,COMMA and the easiest case is that node has no children .PERIOD so to ,COMMA to delete a node that has no children just return null .PERIOD and then go back up to update the counts as usual ,COMMA that's the easy case .PERIOD the next most difficult case is like the delete min case we find a node t that contains our key ,COMMA so like deleting r in this tree ,COMMA it only has one child .PERIOD just go ahead and return the link to that child and that updates the link and everything works fine and then the node that the leads that available for garbage collection that nobody's pointing to it .PERIOD and then again update all the accounts after the recursive calls .PERIOD zero children no problem one child no problem .PERIOD the problem is what happens when there is two children .PERIOD so say we want to delete node e in this tree .PERIOD we have only one link ,COMMA and we can get rid of the node but we have only one link pointing to it .PERIOD but we have two links pointing down from it .PERIOD so what are we going to do with those two links ?QUESTIONMARK well the hibbard deletion mechanism which is pretty old .PERIOD 50 years ago ,COMMA it was proposed .PERIOD says ,COMMA go ahead and find the next smallest node in the right subtree of that tree .PERIOD so in the case that's h and what's that node ?QUESTIONMARK well it's the minimum in t's right sub tree .PERIOD and we know how to delete the minimum .PERIOD so we just find that minimum node and ,COMMA in this case it's h ,COMMA and we put that node in t spot and then delete the minimum .PERIOD so ,COMMA find the h that's the minimum ,COMMA hang on to it ,COMMA and then delete the minimum nt sub tree and then ,COMMA so we take the e ,COMMA replace it with the h ,COMMA delete the h ,COMMA and then everything is fine .PERIOD it is still a bst .PERIOD so we ,COMMA essentially we are finding a node that has only one link ,COMMA deleting that node ,COMMA and then replacing the node that we need to delete with that one .PERIOD that's hibbard deletion .PERIOD it's a little bit asymmetric .PERIOD why are we using the successor and not the predecessor ?QUESTIONMARK no real reason .PERIOD and it's not really satisfactory because of that ,COMMA and we'll come back to this but it works .PERIOD so this is the code for hibbard deletion .PERIOD so we search for the key .PERIOD if it's got no right child ,COMMA we're fine .PERIOD we just return ,COMMA x out left ,COMMA and that handles both cases zero and one .PERIOD if it does have a right child ,COMMA then we do this ,COMMA find the minimum ,COMMA on the right .PERIOD delete min on the right and then fix the links and then update our count that covers all cases .PERIOD so actually not that much code ,COMMA it's complicated but not particularly more complicated than other code we have seen like rank and floor and ceiling and that implements hibbard deletion .PERIOD so now we have a fully dynamic symbol table where we can insert and delete .PERIOD the number of nodes that we have in the tree as always proportion to the number of key value pairs in the symbol table .PERIOD and the problem is ,COMMA and this was quite a surprise when it was first discovered actually many years after hibbard proposed the algorithm is this lack of symmetry that tends to lead to difficulties .PERIOD and here we are just inserting the leading alternating insert and delete a random key .PERIOD so that maybe well models a situation ,COMMA practical situation .PERIOD and as you watch it go for awhile .PERIOD you can see that this thing about going to the right and taking the successor all the time .PERIOD the tree's becoming much less balanced than it was .PERIOD and ,COMMA this seems to be a ,COMMA a problem .PERIOD we can't be having ,COMMA supposedly having a dynamic situation ,COMMA that is going to ,COMMA allow support of lots of different inserts and de letes .PERIOD and in the end ,COMMA win up with a less balanced tree .PERIOD what's worse ,COMMA if you ,COMMA so how you are going to fix it ?QUESTIONMARK at the end researches show that after ,COMMA sufficiently long sequence of random inserts and deletes ,COMMA the height of the tree becomes square root of n not lg n .PERIOD square root of n is usually bigger than lg n .PERIOD it might make difference between acceptable and unacceptable performance in real applications .PERIOD then what's worse is you try to fix it by say randomly choosing between the left and the right ,COMMA that doesn't work ,COMMA it still becomes square root of n .PERIOD and that's a very long standing open problem to find a natural ,COMMA simple ,COMMA efficient delete for binary search trees .PERIOD that's another one like merging in place ,COMMA that you think there ought to be another easy way to do it ,COMMA but in 50 years no one's really discovered one .PERIOD now we're going to look at something pretty close in the next lecture ,COMMA but here's the situation that we're left with .PERIOD we have a binary search tree algorithm ,COMMA which is fine in that gives us lg n performance for search and insert ,COMMA in a situation where we can think that these things are happening randomly .PERIOD but we're kind of stuck if we allowed delete .PERIOD in fact everything regenerates to square root of n ,COMMA and we also have a problem with ,COMMA with the worst case if the keys happen to have some order in them our trees are not going to be balanced at all .PERIOD and that's going to make the difference between acceptable and not acceptable performance .PERIOD what we're going to look at next time ,COMMA called a red black minor search tree ,COMMA will guarantee logarithmic performance for all operations .PERIOD so that's extremely significant and much better then binary search trees but the delete operation for binary search trees shows us the kind of complexity that we can encounter with working with these kinds of data structures .PERIOD 

